- en: Chapter 3\. The Dark Side of Distributed Systems
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第三章。分布式系统的黑暗面
- en: Now that you have a better understanding of Reactive and had a brief overview
    of Quarkus, let’s focus on why you would want to use them and, more specifically,
    build reactive systems. The reason emanates from the cloud and, more generally,
    the need to build *better* distributed systems. The cloud has been a game changer.
    It’s making the construction of distributed systems easier. You can create virtual
    resources on the fly and use off-the-shelf services. However, *easier* does not
    mean *straightforward*. Building such systems is a considerable challenge. Why?
    Because the cloud is a distributed system, and distributed systems are complicated.
    We need to understand the kind of animal we are trying to tame.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 现在您对反应式有了更好的理解，并简要了解了 Quarkus，让我们专注于为什么您想要使用它们，更具体地构建反应式系统。理由源于云，更一般地说，需要构建*更好的*分布式系统。云已经改变了游戏规则。它使得构建分布式系统变得更容易。您可以动态创建虚拟资源并使用现成的服务。然而，“更容易”并不意味着“直截了当”。构建这样的系统是一个巨大的挑战。为什么？因为云是一个分布式系统，而分布式系统是复杂的。我们需要了解我们试图驯服的动物的种类。
- en: What’s a Distributed System?
  id: totrans-2
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 什么是分布式系统？
- en: 'There are many definitions of distributed systems. But let’s start with a loose
    one, written by professor emeritus Andrew Tanenbaum, and see what we can learn:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 有许多关于分布式系统的定义。但让我们从一位名誉教授安德鲁·塔能鲍姆的宽泛定义开始，看看我们能学到什么：
- en: A distributed system is a collection of independent computers that appears to
    its users as a single coherent system.
  id: totrans-4
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 分布式系统是一组独立的计算机，对其用户呈现为一个单一的一致系统。
- en: 'This definition highlights two important aspects of distributed systems:'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 此定义突出了分布式系统的两个重要方面：
- en: A distributed system is composed of *independent* machines that are autonomous.
    They can be started and stopped at any time. These machines operate concurrently
    and can fail independently without affecting the whole system’s uptime (in theory,
    at least).
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 分布式系统由*独立*的机器组成，这些机器是自主的。它们可以随时启动和停止。这些机器并行操作，并且可以独立失败而不影响整个系统的正常运行时间（至少在理论上是这样）。
- en: 'Consumers (users) should not be aware of the system’s structure. It should
    provide a consistent experience. Typically, you may use an HTTP service, which
    is served by an API gateway ([Figure 3-1](#figure:machine)), delegating requests
    to various *machines*. For you, the caller, a distributed system behaves as a
    single coherent system: you have a single entry point and ignore the underlying
    structure of the system.'
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 消费者（用户）不应该意识到系统的结构。它应提供一致的体验。通常情况下，您可以使用由 API 网关提供的 HTTP 服务（[Figure 3-1](#figure:machine)），将请求委托给各种*机器*。对于您作为调用者而言，分布式系统表现为一个单一的一致系统：您只有一个入口点，忽略系统的底层结构。
- en: '![Example of an HTTP service delegating calls to other machines/services](assets/rsij_0301.png)'
  id: totrans-8
  prefs: []
  type: TYPE_IMG
  zh: '![一个 HTTP 服务将调用委托给其他机器/服务的示例](assets/rsij_0301.png)'
- en: Figure 3-1\. Example of an HTTP service delegating calls to other machines/services
  id: totrans-9
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 3-1\. 一个 HTTP 服务将调用委托给其他机器/服务的示例
- en: To achieve this level of coherence, the autonomous machines must collaborate
    one way or another. This collaboration and the need for good communications that
    arise from it are the heart of distributed systems but also their primary challenge.
    But that definition does not explain why we are building distributed systems.
    Initially, distributed systems were workarounds. The resources of each machine
    were too limited. Connecting multiple machines was a smart way to extend the whole
    system’s capacity, making resources available to the other members of the network.
    Today, the motivations are slightly different. Using a set of distributed machines
    gives us more business *agility*, eases evolution, reduces the time to market,
    and from an operational standpoint, allows us to scale more quickly, improves
    resilience via replication, and so on.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 要实现这种一致性水平，这些自主机器必须以某种方式进行协作。这种协作以及由此产生的良好通信需求是分布式系统的核心，但也是它们的主要挑战。但是这个定义并没有解释为什么我们要构建分布式系统。最初，分布式系统是一种变通方法。每台机器的资源太有限了。连接多台机器是扩展整个系统容量的一种聪明方式，使资源对网络中的其他成员可用。如今，动机略有不同。使用一组分布式机器使我们在业务*灵活性*上更有优势，促进了演进，缩短了上市时间，并且从运营角度来看，允许我们更快速地扩展，通过复制提高了弹性，等等。
- en: Distributed systems morphed from being a workaround to being the norm. Why?
    We can’t build a single machine powerful enough to handle all the needs of a major
    corporation, while *also* being affordable. If we could, we’d all use the giant
    machine and deploy independent applications on it. But this necessity for distribution
    draws new operational and business boundaries based on physical system boundaries.
    Microservices, serverless architecture, service-oriented architecture (SOA), REST
    endpoints, mobile applications—all are distributed systems.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 分布式系统已经从一种权宜之计演变为常态。为什么？我们无法构建一个足够强大且 *同时* 又负担得起的单一机器来处理一个大型公司的所有需求。如果可以的话，我们都会使用这个巨型机器并在其上部署独立的应用程序。但这种分布的必要性根据物理系统边界绘制了新的操作和业务边界。微服务、无服务器架构、面向服务的架构（SOA）、REST
    端点、移动应用程序，所有这些都是分布式系统。
- en: This distribution is stressing, even more, the need for collaboration among
    all the components forming the system. When an application (for instance, implemented
    in Java), needs to interact locally, it just uses a method call. For example,
    to collaborate with a `service` exposing a `hello` method, you use `service.hello`.
    We stay inside the same process. Calls can be synchronous; no network I/O is involved.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 这种分布更加强调了系统中所有组件之间合作的需求。当一个应用程序（例如，用 Java 实现）需要本地交互时，它只需使用方法调用。例如，要与暴露 `hello`
    方法的 `service` 合作，你使用 `service.hello`。我们保持在同一进程中。调用可以是同步的；不涉及网络 I/O。
- en: However, the dispersed nature of distributed systems implies interprocess communication,
    and most of the time, crossing the network ([Figure 3-2](#figure:network)). Dealing
    with I/O and traversing the network makes these interactions considerably different.
    A lot of middleware tried to make the distribution transparent, but, don’t be
    mistaken, complete transparency is a lie, as explained in [“A Note on Distributed
    Computing”](https://oreil.ly/iCz3c) by Jim Waldo et al. It always backfires one
    way or another. You need to understand the unique nature of remote communications
    and realize how distinctive they are in order to build robust distributed systems.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，分布式系统分散的特性意味着进程间通信，大部分时间都是通过网络进行跨越（[图 3-2](#figure:network)）。处理 I/O 并穿越网络使得这些交互显著不同。许多中间件试图使分布透明化，但不要误解，完全透明是一个谎言，正如
    Jim Waldo 等人在 [“关于分布式计算的一则说明”](https://oreil.ly/iCz3c) 中所解释的那样，它总会以某种方式失败。你需要理解远程通信的独特性质，并认识到它们在构建健壮分布式系统中有多么独特。
- en: '![Remote interactions are leaving one process space and crossing into another
    process space via a network connection.](assets/rsij_0302.png)'
  id: totrans-14
  prefs: []
  type: TYPE_IMG
  zh: '![远程交互通过网络连接离开一个进程空间，进入另一个进程空间。](assets/rsij_0302.png)'
- en: Figure 3-2\. Remote interactions leave one process space and cross into another
    process space via a network connection
  id: totrans-15
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 3-2\. 远程交互通过网络连接离开一个进程空间，进入另一个进程空间
- en: The first difference is the duration. A remote call is going to take much more
    time than a local call. That time is several degrees of magnitude higher. When
    everything is fine, sending a request from New York City to Los Angeles takes
    around 72 ms.^([1](ch03.html#idm45358832499760)) Calling a local method takes
    less than a nanosecond.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 第一个区别在于持续时间。远程调用比本地调用需要花费更多的时间。这段时间高出几个数量级。当一切正常时，从纽约市到洛杉矶的请求发送大约需要 72 毫秒。^([1](ch03.html#idm45358832499760))
    而调用本地方法则少于一纳秒。
- en: A remote call also leaves the process space, so we need an exchange protocol.
    This protocol defines all the aspects of the exchange, such as who is initiating
    the communication, how the information is written to the wire (serialization and
    deserialization), how the messages are routed to the destination, and so on.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 远程调用同样会离开进程空间，因此我们需要一个交换协议。该协议定义了交换的所有方面，例如谁发起通信，信息如何写入到网络中（序列化和反序列化），消息如何路由到目标等等。
- en: When you develop your application, most of these choices are hidden from you
    but present under the hood. Let’s take a REST endpoint you want to call. You will
    use HTTP and most probably some JSON representation to send data and interpret
    the response. Your code is relatively simple, as you can see in [Example 3-1](#distributed-system::http-example).
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 在开发应用程序时，大多数这些选择对你是隐藏的，但在幕后是存在的。我们来看一个你想调用的 REST 端点。你将使用 HTTP 并且很可能使用 JSON 表示来发送数据和解释响应。你的代码相对简单，就像在
    [示例 3-1](#distributed-system::http-example) 中所看到的。
- en: Example 3-1\. Invoke an HTTP service using a Java built-in client (*chapter-3/http-client-example/src/main/java/http/Main.java*)
  id: totrans-19
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 3-1\. 使用 Java 内置客户端调用 HTTP 服务（*chapter-3/http-client-example/src/main/java/http/Main.java*）
- en: '[PRE0]'
  id: totrans-20
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Let’s describe what’s happening when you execute it:'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们描述一下您执行它时发生的情况：
- en: Your application creates an HTTP request (`request`).
  id: totrans-22
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 您的应用程序创建 HTTP 请求（`request`）。
- en: It establishes an HTTP connection with the remote server.
  id: totrans-23
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 它与远程服务器建立 HTTP 连接。
- en: It writes the HTTP request following the protocol.
  id: totrans-24
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 它按照协议编写 HTTP 请求。
- en: The request travels to the server.
  id: totrans-25
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 请求发送到服务器。
- en: The server interprets the request and looks for the resource.
  id: totrans-26
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 服务器解释请求并查找资源。
- en: The server creates an HTTP response with the representation of the resource
    state in JSON.
  id: totrans-27
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 服务器使用 JSON 表示创建 HTTP 响应资源状态。
- en: It writes the response following the protocol.
  id: totrans-28
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 它按照协议编写响应。
- en: The application receives the response and extracts the body (as `String` in
    this example).
  id: totrans-29
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 应用程序接收响应并提取正文（在本例中为`String`）。
- en: It’s the role of middleware (HTTP server and client, JSON mappers…) to make
    these interactions easy for us developers. In our previous example, steps 2 to
    8 are all hidden in the `send` method. But we need to be aware of them. Especially
    today, with the cloud, distributed systems and distributed communications are
    everywhere. It becomes rare to build an application that is not a distributed
    system. As soon as you call a remote web service, print a document, or use an
    online collaboration tool, you are creating a distributed system.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 中间件（HTTP 服务器和客户端，JSON 映射器等）的角色是使我们开发者可以轻松进行这些交互。在我们之前的例子中，步骤 2 到 8 都隐藏在`send`方法中。但我们需要意识到这些。特别是在今天，随着云计算、分布式系统和分布式通信无处不在，构建非分布式系统的应用程序变得越来越少。一旦您调用远程
    Web 服务、打印文档或使用在线协作工具，您就在创建分布式系统。
- en: 'The New Kids on the Block: Cloud Native and Kubernetes Native Applications'
  id: totrans-31
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 云原生和 Kubernetes 原生应用的新秀
- en: The role of the cloud can’t be overstated, and it’s a significant factor in
    the popularization of distributed systems. If you need a new machine, database,
    API gateway, or persistent storage, the cloud can enable the delivery of these
    on-demand computing services. As a reminder, though, for as much as the cloud
    improves efficiencies, you must never forget that running your application on
    the cloud is equivalent to running on someone else’s machine. Somewhere there
    are CPUs, disks, and memory used to execute your application, and while cloud
    providers are responsible for maintaining these systems and have built a reputation
    around reliability, the hardware is outside your control.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 云的作用不可言喻，它是推广分布式系统的一个重要因素。如果您需要新的机器、数据库、API 网关或持久存储，云服务可以实现这些按需计算服务的交付。但请记住，尽管云服务提高了效率，您绝不能忘记在云上运行您的应用程序等同于在别人的机器上运行。无论何处都有用于执行您的应用程序的
    CPU、磁盘和内存，尽管云服务提供商负责维护这些系统并以可靠性著称，但硬件设备不在您的控制之下。
- en: Cloud providers provide fantastic infrastructure facilities, making running
    applications much more straightforward. Thanks to dynamic resources, you can create
    many instances of your application and even autotune this number based on the
    current load. It also offers failover mechanisms such as routing requests to a
    healthy instance if another instance crashed. The cloud helps to reach high availability
    by making your service always available, restarting unhealthy parts of your systems,
    and so on. This is a first step toward elastic and resilient systems.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 云服务提供商提供了出色的基础设施设施，使得运行应用程序变得更加简单。由于动态资源，您可以创建许多应用程序实例，甚至根据当前负载自动调整这个数量。它还提供了故障转移机制，例如在另一个实例崩溃时将请求路由到健康实例。云服务有助于通过使您的服务始终可用、重新启动系统中不健康的部分等方式达到高可用性。这是通向弹性和具有韧性系统的第一步。
- en: 'That being said, it’s not because your application can run in the cloud that
    it will benefit from it. You need to tailor your application to use the cloud
    efficiently, and the distributed nature of the cloud is a big part of it. *Cloud
    native* is an approach to building and running applications that exploit the cloud
    computing delivery model. Cloud native applications should be easy to deploy on
    virtual resources, support elasticity through application instances, rely on location
    transparency, enforce fault-tolerance, and so on. The [Twelve-Factor App](https://12factor.net)
    lists some characteristics to become a *good cloud citizen*:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 话虽如此，你的应用程序能在云中运行并不意味着它会从中受益。你需要定制你的应用程序以高效利用云，并且云的分布式特性是其中很大的一部分。*云原生*是一种构建和运行利用云计算交付模型的应用程序的方法。云原生应用程序应该易于部署在虚拟资源上，通过应用程序实例支持弹性，依赖位置透明性，强制执行容错性等。[十二因素应用程序](https://12factor.net)列出了一些成为*良好的云公民*的特征：
- en: Codebase
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 代码库
- en: One codebase tracked in version control, many deploys.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 一个代码库在版本控制中跟踪，多个部署。
- en: Dependencies
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 依赖关系
- en: Explicitly declare and isolate dependencies.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 明确声明和隔离依赖关系。
- en: Config
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 配置
- en: store config in the environment.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 将配置存储在环境中。
- en: Backing services
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 支持服务
- en: Treat backing services as attached resources.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 将支持服务视为附加资源。
- en: Build, release, run
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 构建、发布、运行
- en: Strictly separate build and run stages.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 严格区分构建和运行阶段。
- en: Processes
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 进程
- en: Execute the app as one or more stateless processes.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 将应用程序作为一个或多个无状态进程执行。
- en: Port binding
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 端口绑定
- en: Export services via port binding.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 通过端口绑定导出服务。
- en: Concurrency
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 并发性
- en: Scale out via the process model.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 通过进程模型扩展。
- en: Disposability
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 可处置性
- en: Maximize the robustness with fast startup and graceful shutdown.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 通过快速启动和优雅关闭来最大化鲁棒性。
- en: Dev/prod parity
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 开发/生产对等性
- en: Keep development, staging, and production as similar as possible.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 使开发、分级和生产尽可能相似。
- en: Logs
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 日志
- en: Treat your logs as event streams.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 将您的日志视为事件流。
- en: Admin processes
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 管理进程
- en: Run admin/management tasks as one-off processes.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 将管理/管理任务作为一次性进程运行。
- en: Implementing these factors helps to embrace the cloud native ideology. But achieving
    cloud native is not an easy task. Each factor comes with technical challenges
    and architectural constraints.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 实现这些因素有助于拥抱云原生理念。但实现云原生并不是一件容易的事情。每个因素都伴随着技术挑战和架构约束。
- en: In addition, each cloud provider provides its own set of facilities and APIs.
    This heterogeneity makes cloud native applications nonportable from one cloud
    provider to another. Very quickly, you end up in some kind of vendor lock-in,
    because of a specific API or services, or tooling, or even description format.
    It may not be an issue for you right now, but having the possibility to move and
    combine multiple clouds improves your agility, availability, and user experience.
    Hybrid cloud applications, for example, run on multiple clouds, mixing private
    and public clouds, to reduce response time and prevent global unavailability.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，每个云提供商都提供其自己的一套设施和 API。这种异构性使得云原生应用程序无法从一个云提供商迁移到另一个云提供商。很快，由于特定的 API、服务、工具或甚至描述格式，您最终会陷入某种供应商锁定，这可能不是您目前面临的问题，但是拥有移动和结合多个云的可能性可以提高您的敏捷性、可用性和用户体验。混合云应用程序，例如，在多个云上运行，混合私有云和公共云，以减少响应时间并防止全球不可用。
- en: Fortunately, both public and private clouds tend to converge around Kubernetes,
    a container orchestration platform. Kubernetes abstracts the differences between
    providers using *standard* deployment and runtime facilities.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 幸运的是，公共云和私有云都倾向于围绕 Kubernetes 收敛，这是一个容器编排平台。Kubernetes 使用*标准*部署和运行时设施来抽象提供商之间的差异。
- en: To use Kubernetes, you package and run your application inside a container.
    A *container* is a box in which your application is going to run. So, your application
    is somewhat isolated from the other applications running in their own box.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 要使用 Kubernetes，您需要将应用程序打包并在容器中运行。*容器*是一个盒子，您的应用程序将在其中运行。因此，您的应用程序在某种程度上与在其自己的盒子中运行的其他应用程序隔离开来。
- en: To create containers, you need an image. A *container image* is a lightweight,
    executable software package. When you deploy a container, you actually deploy
    an image, and this image is instantiated to create the container.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 要创建容器，您需要一个镜像。*容器镜像*是一个轻量级的、可执行的软件包。当您部署一个容器时，您实际上部署了一个镜像，并且此镜像被实例化以创建容器。
- en: 'The image includes everything needed to run an application: code, runtime,
    system libraries, and configuration. You can create container images by using
    various tools and descriptors such as *Dockerfile*. As you have seen in [Chapter 2](ch02.html#quarkus),
    Quarkus offers image creation facilities without having to write a single line
    of code.'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 图像包含运行应用所需的一切：代码、运行时、系统库和配置。您可以使用诸如*Dockerfile*之类的工具和描述符来创建容器镜像。正如您在[第2章](ch02.html#quarkus)中看到的，Quarkus提供了无需编写一行代码即可创建镜像的功能。
- en: To distribute your image, you push it to an image registry such as [Docker Hub](https://hub.docker.com).
    Then you can pull it and finally instantiate it to start your application ([Figure 3-3](#figure:containers)).
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 要分发您的镜像，您将其推送到像[Docker Hub](https://hub.docker.com)这样的镜像注册表。然后，您可以拉取它并最终实例化它以启动您的应用程序（[图3-3](#figure:containers)）。
- en: '![Creation, Distribution and Execution of Containers](assets/rsij_0303.png)'
  id: totrans-66
  prefs: []
  type: TYPE_IMG
  zh: '![容器的创建、分发和执行](assets/rsij_0303.png)'
- en: Figure 3-3\. Creation, distribution, and execution of containers
  id: totrans-67
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图3-3\. 容器的创建、分发和执行
- en: While containerization is a well-known technique, when you start having dozens
    of containers, their management becomes complicated. Kubernetes provides facilities
    to reduce this burden. It instantiates containers and monitors them, making sure
    your application is still running.^([2](ch03.html#idm45358832353200)) As you can
    imagine, this can be useful for implementing the responsiveness and resilience
    characteristics from reactive systems.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然容器化是一种众所周知的技术，但当您开始拥有数十个容器时，它们的管理变得复杂。Kubernetes提供了设施来减少这种负担。它实例化容器并监控它们，确保您的应用仍在运行。^([2](ch03.html#idm45358832353200))
    可以想象，这对于实现反应式系统的响应性和弹性特征是非常有用的。
- en: Note
  id: totrans-69
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注
- en: Though Kubernetes facilitates reactive systems through responsiveness and resilience,
    that does not mean you cannot implement a reactive system outside of Kubernetes.
    It’s definitely possible. In this book, we use Kubernetes to avoid having to implement
    the underlying infrastructure features such as deployment, replication, and fault
    detection.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管Kubernetes通过响应性和弹性促进了反应式系统，这并不意味着您不能在Kubernetes之外实现反应式系统。这是完全可能的。在本书中，我们使用Kubernetes来避免实现部署、复制和故障检测等基础设施特性。
- en: Under the hood, Kubernetes pulls container images, instantiates containers,
    and monitors them. To achieve this, Kubernetes needs to have access to *nodes*
    to run the containers. This set of nodes forms a *cluster*. Thinking of a machine
    as a node allows us to insert a layer of abstraction. Whether these machines are
    Amazon Elastic Compute Cloud (EC2) instances, physical hardware from a data center,
    or virtualized is irrelevant. Kubernetes controls these nodes and decides which
    part of the system will run where.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes在底层拉取容器镜像、实例化容器并监控它们。为了实现这一点，Kubernetes需要访问*节点*以运行这些容器。这些节点的集合形成一个*集群*。将机器视为节点允许我们插入一层抽象。这些机器可以是亚马逊弹性计算云（EC2）实例、数据中心的物理硬件或虚拟化都不重要。Kubernetes控制这些节点，并决定系统的哪个部分在哪里运行。
- en: Once Kubernetes has access to your container image, you can instruct Kubernetes
    to instantiate the image so that it becomes a running container. Kubernetes decides
    on which node the container is executed. It may even move it later to optimize
    resource utilization, another characteristic that fits with reactive architectures.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦Kubernetes可以访问您的容器镜像，您可以指示Kubernetes实例化镜像，使其成为一个运行中的容器。Kubernetes决定在哪个节点上执行容器。它甚至可能稍后将其移动以优化资源利用率，这与反应式架构的特性相契合。
- en: Just as applications need to be cloud native to benefit from the cloud, they
    need to be Kubernetes native to benefit from Kubernetes. That includes supporting
    Kubernetes service discovery, exposing health checks used for monitoring, and,
    more importantly, running efficiently in a container. You will see in the next
    chapter how these three characteristics are essential from a Reactive point of
    view. You can wrap almost any application in a container. But it may not be a
    good idea.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 就像应用程序需要云原生才能从云中受益一样，它们需要成为Kubernetes原生才能从Kubernetes中受益。这包括支持Kubernetes服务发现、暴露用于监控的健康检查，更重要的是，在容器中高效运行。您将在下一章中看到，这三个特征对于反应式视角来说是至关重要的。几乎可以将任何应用程序封装在容器中。但这可能不是一个好主意。
- en: When running in a container, your application lives in a shared environment.
    Multiple containers share the resources from the *host*, the machine executing
    them. They share the CPU, the memory, and so on. If one container is too greedy,
    it penalizes the other containers, which may starve. Of course, you can use quotas,
    but how would the greedy container behave under resource restrictions? So, yes,
    containers provide isolation, *and* enable resource sharing.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 在容器中运行时，你的应用程序存在于一个共享环境中。多个容器共享来自执行它们的 *主机* 的资源。它们共享 CPU、内存等。如果一个容器过于贪婪，会惩罚其他容器，可能会饿死。当然，你可以使用配额，但在资源限制下贪婪的容器会如何行事？因此，是的，容器提供隔离，并且
    *允许* 资源共享。
- en: 'One role of containers and Kubernetes is to increase the deployment density:
    running more using the finite set of available resources. Deployment density is
    becoming essential to many organizations because of the economic benefits. It
    allows reducing costs, either by reducing the monthly cloud bill or by running
    more applications on the current in-house infrastructure.'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 容器和 Kubernetes 的一个作用是增加部署密度：利用有限的可用资源运行更多应用程序。由于经济效益，部署密度对许多组织变得至关重要。它可以通过减少每月的云账单或在当前内部基础设施上运行更多应用程序来降低成本。
- en: '[Table 3-1](#table::kube) summarizes concepts presented so far around containers
    and Kubernetes.'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: '[表 3-1](#table::kube) 总结了迄今为止关于容器和 Kubernetes 的概念。'
- en: Table 3-1\. Important concepts around containers and Kubernetes
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 表 3-1\. 关于容器和 Kubernetes 的重要概念
- en: '| Name | Description | Associated command |'
  id: totrans-78
  prefs: []
  type: TYPE_TB
  zh: '| 名称 | 描述 | 关联命令 |'
- en: '| --- | --- | --- |'
  id: totrans-79
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| Container image | Lightweight, executable software package | `docker build
    -f my-docker-file -t my-image:version` |'
  id: totrans-80
  prefs: []
  type: TYPE_TB
  zh: '| 容器镜像 | 轻量级、可执行的软件包 | `docker build -f my-docker-file -t my-image:version`
    |'
- en: '| Container | A box in which your application is going to run | `docker run
    my-image:version` |'
  id: totrans-81
  prefs: []
  type: TYPE_TB
  zh: '| 容器 | 在其中运行你的应用程序的盒子 | `docker run my-image:version` |'
- en: '| Pod | The unit of replication in Kubernetes, composed of one or more containers
    | `kubectl get pods` |'
  id: totrans-82
  prefs: []
  type: TYPE_TB
  zh: '| Pod | Kubernetes 中复制的单位，由一个或多个容器组成 | `kubectl get pods` |'
- en: '| Deployment | Describes the content of a pod and number of pod instances we
    need | `kubectl get deployments` |'
  id: totrans-83
  prefs: []
  type: TYPE_TB
  zh: '| 部署 | 描述 pod 内容及我们需要的 pod 实例数 | `kubectl get deployments` |'
- en: '| Service | A channel of communication delegating to a set of pods, selected
    by labels | `kubectl get services` |'
  id: totrans-84
  prefs: []
  type: TYPE_TB
  zh: '| 服务 | 一个通信通道，委托给一组通过标签选择的 pod | `kubectl get services` |'
- en: If you missed it, check out [“Kubernetes with Quarkus in 10 Minutes”](ch02.html#quarkus::kube-ten),
    where we deployed a Quarkus service to Kubernetes!
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你错过了它，请查看[“在10分钟内使用 Quarkus 部署 Kubernetes”](ch02.html#quarkus::kube-ten)，我们在其中将一个
    Quarkus 服务部署到 Kubernetes！
- en: The Dark Side of Distributed Systems
  id: totrans-86
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 分布式系统的暗面
- en: Our system is simple, but even such a basic system can illustrate the hard reality
    of distributed systems. Cloud providers and Kubernetes provide excellent infrastructure
    facilities, but the laws of distributed systems still rule the system you are
    building. The technical complexity around provisioning and delivery has been replaced
    with fundamental issues from the nature of distributed systems. The size and complexity
    of modern applications make them undeniable.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的系统很简单，但即使是这样一个基本系统也能说明分布式系统的艰辛现实。云提供商和 Kubernetes 提供了优秀的基础设施设施，但分布式系统的法则仍然统治着你正在构建的系统。围绕配置和交付的技术复杂性已被分布式系统的本质问题所取代。现代应用程序的规模和复杂性使它们不可否认。
- en: 'At the beginning of this chapter, you saw a first definition of distributed
    systems. It was capturing the need for collaboration and communication to provide
    a consistent experience. [Leslie Lamport](http://www.lamport.org), a computer
    scientist and Turing Award winner, gives a different definition that describes
    the dark nature of distributed systems: “A distributed system is one in which
    the failure of a computer you didn’t even know existed can render your own computer
    unusable.”'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章的开头，你看到了对分布式系统的第一个定义。它捕捉到了提供一致体验的协作和通信的需求。计算机科学家和图灵奖获得者[莱斯利·兰波特](http://www.lamport.org)给出了另一个定义，描述了分布式系统的黑暗本质：“分布式系统是一种其中你甚至不知道存在的计算机的故障可以使你自己的计算机无法使用。”
- en: In other words, failures are inevitable. They are an inherent component of distributed
    systems. No matter how your system is built, it is going to fail. As a corollary,
    the bigger the distributed system, the higher the level of *dynamism* (the fluctuating
    availability of the surrounding services) and the greater the chance of failure.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 换句话说，故障是不可避免的。它们是分布式系统的固有组成部分。无论你的系统如何构建，它都会失败。作为推论，分布式系统越大，*动态性*（周围服务的波动可用性）越高，失败的机会就越大。
- en: 'What kind of failures can we encounter? There are three types:'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可能会遇到哪些故障？有三种类型：
- en: Transient failure
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 临时故障
- en: Occurs once and then disappears, like a temporary network disruption
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 发生一次，然后消失，就像临时网络中断
- en: Intermittent failure
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 间歇性故障
- en: Occurs, then vanishes and then reappears, like a failure happening once in a
    while for no apparent reason
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 发生后消失，然后重新出现，就像偶尔会出现的故障，原因不明
- en: Permanent failure
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 永久故障
- en: Continues to exist until the faulty component (either software or hardware)
    is fixed
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 直到故障组件（无论是软件还是硬件）被修复之前一直存在。
- en: Each type of failure can have two kinds of consequences. First, it can crash
    the application. We call these *fail-stop* failures. There are *bad*, of course,
    but we can easily detect them and repair the system. Second, a failure may introduce
    unpredictable responses at random times. We call them *Byzantine failures*. They
    are much harder to detect and to circumvent.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 每种故障类型都可能有两种后果。首先，它可能会使应用程序崩溃。我们称这些为*停止故障*。当然，它们是不好的，但我们可以轻松检测并修复系统。其次，故障可能会在随机时间引入不可预测的响应。我们称之为*拜占庭故障*。检测和规避它们要困难得多。
- en: Fallacies of Distributed Computing in a Kubernetes World
  id: totrans-98
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Kubernetes世界中的分布式计算谬论
- en: 'As developers, imagining and planning for all the types of failure and consequences
    can be challenging. How would you detect them? How would you handle them gracefully?
    How can you continue to provide a consistent experience and service if anything
    can fall apart? Building and maintaining distributed systems is a complex topic
    full of pitfalls and landmines. The [“Eight Fallacies of Distributed Computing”](https://oreil.ly/0g3lL)
    list, created by L. Peter Deutsch along with others at Sun Microsystems, walks
    us through many false assumptions around distributed systems:'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 作为开发者，想象和规划所有类型的故障及其后果可能是一项挑战。你如何检测它们？你如何优雅地处理它们？如果任何东西都可能出问题，你如何继续提供一致的体验和服务？构建和维护分布式系统是一个充满陷阱和雷区的复杂主题。由L.
    Peter Deutsch与Sun Microsystems的其他人员共同创作的["分布式计算的八大谬论"](https://oreil.ly/0g3lL)列出了分布式系统中的许多错误假设：
- en: The network is reliable.
  id: totrans-100
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 网络是可靠的。
- en: Latency is zero.
  id: totrans-101
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 延迟为零。
- en: Bandwidth is infinite.
  id: totrans-102
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 带宽是无限的。
- en: The network is secure.
  id: totrans-103
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 网络是安全的。
- en: Topology doesn’t change.
  id: totrans-104
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 拓扑结构不会改变。
- en: There is one administrator.
  id: totrans-105
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 只有一个管理员。
- en: Transport cost is zero.
  id: totrans-106
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 传输成本为零。
- en: The network is homogeneous.
  id: totrans-107
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 网络是同质的。
- en: 'These fallacies were published in 1997, long before the era of the cloud and
    Kubernetes. But these fallacies are still relevant today—even more relevant. We
    won’t discuss all of them but focus on the ones related to the cloud and Kubernetes:'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 这些谬误是1997年发表的，早于云和Kubernetes时代。但这些谬误今天仍然相关——甚至更加相关。我们不会讨论所有谬误，而是专注于与云和Kubernetes相关的内容：
- en: The network is reliable
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 网络是可靠的
- en: The developer often assumes that the network is reliable on the cloud or Kubernetes.
    Indeed, it’s the role of the infrastructure to handle the network and make sure
    things work. Health checks, heartbeats, replications, automatic restart—a lot
    of mechanisms are built in at the infrastructure layer. The network will do its
    best, but sometimes, bad things happen, and you need to be prepared for that.
    Data centers can fall apart; parts of the system can become unreachable, and so
    on.^([3](ch03.html#idm45358832286384))
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 开发者通常假设云或Kubernetes上的网络是可靠的。确实，基础设施的角色是处理网络并确保事物正常运行。健康检查、心跳、复制、自动重启——基础设施层面有很多机制。网络会尽力而为，但有时候，坏事情发生了，你需要为此做好准备。数据中心可能会崩溃；系统的部分可能会变得无法访问，等等。^([3](ch03.html#idm45358832286384))
- en: Latency is zero
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 延迟为零
- en: 'The second fallacy seems obvious: a network call is slower than a local call,
    and the latency of any given call can vary significantly, even from one invocation
    to the next. We already discussed this. The latency is not limited to that aspect;
    it can change over time for various reasons.'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 第二个谬误似乎很明显：网络调用比本地调用慢，并且每次调用的延迟可能会显著变化，我们已经讨论过了。延迟不仅仅限于这个方面；它会因多种原因随时间而变化。
- en: Bandwidth is infinite *and* the network is homogeneous
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 带宽是无限的*并且*网络是同质化的
- en: You may reach the bandwidth limit, or parts of the system may use a faster network
    than some other parts because they are running on the same *node*. Estimating
    latency is not trivial. Many capacity-planning techniques and time-out computation
    are based on network latency.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能会达到带宽限制，或者系统的某些部分可能使用比其他部分更快的网络，因为它们运行在同一个*节点*上。估算延迟并不是一件简单的事情。许多容量规划技术和超时计算都基于网络延迟。
- en: Topology doesn’t change
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 拓扑结构不会改变
- en: On the cloud or on Kubernetes, services, applications, and containers move.
    Kubernetes can move containers from one node to another anytime. Containers are
    frequently moving because of the deployment of new applications, updates, rescheduling,
    optimization, and so on. Mobility is a great benefit as it allows optimizing the
    whole system, but interacting with services always on the move can be challenging.
    You may interact with multiple instances of your service, while, for you, it acts
    as one. Some instances can be close to you (and provide a better response time),
    while some may be farther or just slower because of limited resources.^([4](ch03.html#idm45358832279664))
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 在云上或 Kubernetes 上，服务、应用程序和容器可以移动。Kubernetes 可以随时将容器从一个节点移动到另一个节点。由于部署新应用程序、更新、重新调度、优化等原因，容器经常移动。移动性是一个巨大的好处，因为它允许优化整个系统，但是与总是移动的服务进行交互可能是具有挑战性的。你可能会与多个实例的服务进行交互，对你来说，它们就像一个服务。某些实例可能离你更近（响应时间更好），而另一些可能因为资源有限而较慢。
- en: There is one administrator
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 有一个管理员
- en: Managing systems has drastically changed over the past few years. The old-school
    system administration processes and maintenance downtimes are becoming less common.
    DevOps philosophies and techniques such as continuous delivery and continuous
    deployment are reshaping the way we manage applications in production. Developers
    can easily deploy small incremental changes throughout the day. DevOps tools and
    site reliability engineers (SREs) work hard to provide an almost constant availability,
    while a continuous stream of updates provides new features and bug fixes. The
    administration role is shared among SREs, software engineers, and software. For
    example, [Kubernetes operators](https://oreil.ly/cX8nN) are programs deployed
    on Kubernetes and responsible for installing, updating, monitoring, and repairing
    parts of the system automatically.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 过去几年中，管理系统发生了巨大变化。老派的系统管理流程和维护停机时间变得不那么常见。DevOps 的理念和技术，比如持续交付和持续部署，正在重新定义我们在生产中管理应用程序的方式。开发人员可以在一天中轻松部署小的增量变更。DevOps
    工具和站点可靠性工程师（SRE）努力提供几乎恒定的可用性，而持续的更新提供新功能和错误修复。管理角色由SRE、软件工程师和软件共享。例如，[Kubernetes
    operators](https://oreil.ly/cX8nN) 是部署在 Kubernetes 上的程序，负责自动安装、更新、监控和修复系统的各个部分。
- en: Transport cost is zero
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 运输成本为零
- en: Considering the network to be free is not only a fallacy, but also an economic
    mistake. You must pay attention to the cost of network calls and look for optimization.
    For example, crossing cloud regions, transferring large amounts of data, or (especially)
    communicating to separate cloud providers can be expensive.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 认为网络是免费的不仅是错误的，而且是一种经济错误。你必须注意网络调用的成本并寻找优化方法。例如，跨越云区域、传输大量数据或（特别是）与不同的云提供商通信可能很昂贵。
- en: So, not that simple, right? When you build a distributed system, consider all
    these issues and take them into account in your architecture and application code.
    Those are just some of the issues. Another one is the inability to reach a consensus.^([5](ch03.html#idm45358832272336))
    In addition, the CAP theorem prevents a distributed data store from simultaneously
    providing more than two out of the following three guarantees:^([6](ch03.html#idm45358832270720))
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，不是那么简单，对吧？当你构建分布式系统时，要考虑所有这些问题，并在你的架构和应用代码中加以考虑。这些只是其中的一些问题。另一个问题是无法达成共识。
- en: Consistency
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 一致性
- en: Every read receives the most recent write.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 每次读操作都会收到最近的写操作。
- en: Availability
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 可用性
- en: Every request receives a response.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 每个请求都会收到响应。
- en: Partition tolerance
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 分区容忍性
- en: The system continues to operate despite an arbitrary number of messages being
    dropped (or delayed) by the network.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 系统可以继续运行，即使网络丢失（或延迟）了任意数量的消息。
- en: Can things get even darker? Oh yes, distributed systems can be wonderfully imaginative
    to drive us crazy.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 事情会变得更糟吗？哦是的，分布式系统可以非常有创造力地让我们发狂。
- en: 'A Question of Timing: The Synchronous Communication Drawback'
  id: totrans-129
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 时间问题：同步通信的缺点
- en: Time is an often misunderstood issue. When two computers communicate and exchange
    messages, we make the natural assumption that the two machines are both available
    and reachable. We often trust the network between them. Why wouldn’t it be entirely
    operational? Why can’t we invoke remote services as we would for a local service?
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 时间经常是一个被误解的问题。当两台计算机进行通信并交换消息时，我们自然会假设这两台机器都是可用和可访问的。我们经常信任它们之间的网络。为什么它不能完全正常运行呢？为什么我们不能像调用本地服务一样调用远程服务呢？
- en: But that may not be the case, and not considering this possibility leads to
    fragility. What happens if the machine you want to interact with is not reachable?
    Are you prepared for such a failure? Should you propagate the failure? Retry?
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 但情况可能并非如此，不考虑这种可能性会导致脆弱性。如果你要交互的机器无法访问会发生什么？你准备好处理这种故障了吗？是否应该传播这个失败？重试吗？
- en: In a hypothetical microservices-based example, it’s common to use synchronous
    HTTP as the main communication protocol between services. You send a request and
    expect a response from the service you invoked. Your code is synchronous, waiting
    for the response before continuing its execution. Synchronous calls are simpler
    to reason about. You structure your code sequentially, you do one thing, then
    the next one, and so on. This leads to *time-coupling*, one of the less considered
    and often-misunderstood forms of coupling. Let’s illustrate this coupling and
    the uncertainty that derives from it.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 在一个假设的基于微服务的示例中，通常使用同步HTTP作为服务之间的主要通信协议。你发送一个请求，并期望从调用的服务获取响应。你的代码是同步的，等待响应后再继续执行。同步调用更容易理解。你按顺序结构化你的代码，一件事做完再做下一件事，依此类推。这导致了*时间耦合*，这是一种较少考虑和常被误解的耦合形式。让我们来说明一下这种耦合及由此引发的不确定性。
- en: In the *chapter-3/quarkus-simple-service* [directory of the GitHub repository](https://oreil.ly/vZR3j),
    you will find a simple Hello World Quarkus application. This application is similar
    to the one built in [Chapter 2](ch02.html#quarkus). It contains a single HTTP
    endpoint, as shown in [Example 3-2](#Jax-rs-simple-service).
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 在GitHub仓库的*chapter-3/quarkus-simple-service* [目录](https://oreil.ly/vZR3j)中，你会找到一个简单的Hello
    World Quarkus应用程序。这个应用程序类似于[第2章](ch02.html#quarkus)中构建的应用程序。它包含一个单一的HTTP端点，如示例 3-2所示。
- en: Example 3-2\. JAX-RS simple service (*chapter-3/quarkus-simple-service/src/main/java/org/acme/reactive/SimpleService.java*)
  id: totrans-134
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 3-2\. JAX-RS简单服务（*chapter-3/quarkus-simple-service/src/main/java/org/acme/reactive/SimpleService.java*）
- en: '[PRE1]'
  id: totrans-135
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Hard to have code simpler than this, right? Let’s deploy this application to
    Kubernetes. Make sure minikube is started. If it’s not, start it as shown in [Example 3-3](#start-minikube-3-3).
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 没有比这更简单的代码了吧？让我们将这个应用程序部署到Kubernetes上。确保minikube已启动。如果没有，请按照示例 3-3中的步骤启动它。
- en: Example 3-3\. Start minikube
  id: totrans-137
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 3-3\. 启动minikube
- en: '[PRE2]'
  id: totrans-138
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: '[![1](assets/1.png)](#co_the_dark_side_of_distributed_systems_CO1-1)'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: '[![1](assets/1.png)](#co_the_dark_side_of_distributed_systems_CO1-1)'
- en: Don’t forget to connect the Docker socket to minikube.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 别忘了将Docker套接字连接到minikube。
- en: Verify that everything is fine by running the `kubectl get nodes` command ([Example 3-4](#get-node-names)).
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 通过运行`kubectl get nodes`命令（见示例 3-4）来验证一切是否正常。
- en: Example 3-4\. Get the node names and roles
  id: totrans-142
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 3-4\. 获取节点名称和角色
- en: '[PRE3]'
  id: totrans-143
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Now, navigate in the *chapter-3/simple-service* directory and run [Example 3-5](#deploy-quarkus-app-to-kubs).
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，在*chapter-3/simple-service*目录中导航并运行[示例 3-5](#deploy-quarkus-app-to-kubs)。
- en: Example 3-5\. Deploy a Quarkus application to Kubernetes
  id: totrans-145
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 3-5\. 将一个Quarkus应用部署到Kubernetes上
- en: '[PRE4]'
  id: totrans-146
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Wait for the pod to be *ready*, as shown in [Example 3-6](#get-list-of-running-pods).
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 等待pod处于*就绪*状态，如示例 3-6中所示。
- en: Example 3-6\. Get the list of running pods
  id: totrans-148
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 3-6\. 获取运行中的pod列表
- en: '[PRE5]'
  id: totrans-149
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Then expose the service by using [Example 3-7](#retrieving-url-of-service).
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 然后使用示例 3-7来暴露服务，获取服务的URL。
- en: Example 3-7\. Retrieve the URL of the service
  id: totrans-151
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 3-7\. 检索服务的URL
- en: '[PRE6]'
  id: totrans-152
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Don’t forget that the port is assigned randomly, so you will need to replace
    the port in the following commands.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 别忘了端口是随机分配的，所以你需要用以下命令替换端口。
- en: Finally, let’s invoke our service by running [Example 3-8](#invoking-service)
    in another terminal.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，让我们在另一个终端上运行[示例 3-8](#invoking-service)来调用我们的服务。
- en: Example 3-8\. Invoke the service
  id: totrans-155
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 3-8\. 调用服务
- en: '[PRE7]'
  id: totrans-156
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: So far, so good. But this application contains a *mechanism* to simulate distributed
    system failures to illustrate the problem of synchronous communication. You can
    look at the implementation in *chapter-3/quarkus-simple-service/src/main/java/org/acme/reactive/fault/FaultInjector.java*.
    It’s basically a *Quarkus route* (a kind of interceptor) that monitors the HTTP
    traffic and allows simulating various failures. It intercepts the incoming HTTP
    request and outgoing HTTP response and introduces delays, losses, or application
    failures.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，一切顺利。但是，这个应用程序包含一个 *机制*，用于模拟分布式系统的失败，以说明同步通信的问题。你可以在 *chapter-3/quarkus-simple-service/src/main/java/org/acme/reactive/fault/FaultInjector.java*
    中查看其实现。它基本上是一个 *Quarkus 路由*（一种拦截器），用于监视 HTTP 流量并允许模拟各种故障。它拦截传入的 HTTP 请求和传出的 HTTP
    响应，并引入延迟、丢失或应用程序故障。
- en: 'When we call our service in a synchronous way (expecting a response, such as
    with `curl` or a browser), three types of failure can happen:'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们以同步方式调用我们的服务（期望得到响应，比如使用 `curl` 或浏览器）时，会出现三种类型的失败：
- en: The request between the caller and the service can be lost. This results in
    the service not being invoked. The caller waits until a time-out is reached. This
    simulates a transient network partition. This type of failure can be enabled by
    using the `INBOUND_REQUEST_LOSS` mode.
  id: totrans-159
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 调用者与服务之间的请求可能会丢失。这导致服务未被调用。调用者会等待直到超时。这模拟了短暂的网络分区。这种类型的失败可以通过使用 `INBOUND_REQUEST_LOSS`
    模式来启用。
- en: The service receives the request but fails to handle it correctly. It may return
    an incorrect response or maybe no response at all. In the best case, the caller
    would receive the failure or wait until a time-out is reached. This simulates
    an intermittent bug in the called service. This type of failure can be enabled
    by using the `SERVICE_FAILURE` mode.
  id: totrans-160
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 服务接收到请求但未能正确处理它。它可能返回一个错误的响应，或者根本没有响应。在最好的情况下，调用者会收到失败信息或等待超时。这模拟了被调用服务中断性错误。这种类型的失败可以通过使用
    `SERVICE_FAILURE` 模式来启用。
- en: The service receives the request, processes it, and writes the response, but
    the response is lost on its way back, or the connection is closed before the response
    reaches the caller. The service got the request, handled it, and produced the
    response. The caller just doesn’t get it. As in the first type of failure noted
    previously, the response is in a transient network partition but happening after
    the service invocation. This type of failure can be enabled using the `OUTBOUND_RESPONSE_LOSS`
    mode.
  id: totrans-161
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 服务接收到请求，处理它，并写入响应，但响应在返回途中丢失，或者在响应到达调用者之前连接关闭。服务收到了请求，处理了它，并生成了响应。调用者只是没有收到。正如之前提到的第一种失败类型一样，响应在一个短暂的网络分区中，但发生在服务调用之后。这种类型的失败可以使用
    `OUTBOUND_RESPONSE_LOSS` 模式启用。
- en: Tip
  id: totrans-162
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 提示
- en: Don’t forget to update the port in the previous and following commands, as minikube
    randomly picks a port.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 别忘了更新上一个和下一个命令中的端口，因为 minikube 会随机选择一个端口。
- en: To illustrate how the system behaves when facing failures, let’s inject some
    request losses ([Example 3-9](#configure-system-lose-50)).
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 为了说明系统在面对失败时的行为，让我们注入一些请求丢失（[示例 3-9](#configure-system-lose-50)）。
- en: Example 3-9\. Configure the system to lose 50% of the incoming requests
  id: totrans-165
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 3-9\. 配置系统使其丢失 50% 的传入请求
- en: '[PRE8]'
  id: totrans-166
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: This command configures `FaultInjector` to randomly lose 50% of the incoming
    requests. The caller waits for a response that will never arrive half of the time,
    and will eventually time out. Try the command in [Example 3-10](#invoke-service-timeout)
    until you experience a time-out.
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 此命令配置 `FaultInjector` 以随机丢失 50% 的传入请求。调用者等待一个永远不会到达的响应，并最终超时。尝试在 [示例 3-10](#invoke-service-timeout)
    中执行该命令，直到遇到超时。
- en: Example 3-10\. Invoke the service with a configured time-out
  id: totrans-168
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 3-10\. 使用配置的超时调用服务
- en: '[PRE9]'
  id: totrans-169
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: '[![1](assets/1.png)](#co_the_dark_side_of_distributed_systems_CO2-1)'
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: '[![1](assets/1.png)](#co_the_dark_side_of_distributed_systems_CO2-1)'
- en: '`--max-time 5` configures a time-out of 5 seconds. Again, do not forget to
    update the port.'
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: '`--max-time 5` 配置了 5 秒的超时时间。同样，别忘了更新端口。'
- en: To simulate the second type of failure, execute the command in [Example 3-11](#configure-system-inject).
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 要模拟第二种失败类型，请执行 [示例 3-11](#configure-system-inject) 中的命令。
- en: Example 3-11\. Configure the system to inject faulty responses
  id: totrans-173
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 3-11\. 配置系统以注入错误响应
- en: '[PRE10]'
  id: totrans-174
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: You have now a 50% chance of receiving a faulty response; see [Example 3-12](#invoke-faulty).
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 现在你有 50% 的机会收到错误响应；参见 [示例 3-12](#invoke-faulty)。
- en: Example 3-12\. Invoke the faulty application
  id: totrans-176
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 3-12\. 调用有故障的应用程序
- en: '[PRE11]'
  id: totrans-177
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: Finally, let’s simulate the last type of failure. Execute the commands in [Example 3-13](#configure-system-to-lose).
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，让我们模拟最后一种类型的故障。执行[示例 3-13](#configure-system-to-lose)中的命令。
- en: Example 3-13\. Configure the system to lose responses
  id: totrans-179
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 3-13\. 配置系统以丢失响应
- en: '[PRE12]'
  id: totrans-180
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: Now, the caller has a 50% chance of getting no response. The connection is closed
    abruptly before the response reaches the caller. You don’t get a valid HTTP response.
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，调用方有50%的概率得不到响应。在响应到达调用方之前连接突然关闭。你得不到有效的HTTP响应。
- en: The purpose of these examples is to illustrate the strong coupling and uncertainty
    arising from synchronous communication. This type of communication, often used
    because of simplicity, hides the distributed nature of the interaction. However,
    it makes the assumption that everything (including the services and the network)
    is operational. But that’s not always the case. As a caller using synchronous
    communication, you must gracefully handle faulty responses and the absence of
    response.
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 这些示例的目的是说明由同步通信引起的强耦合和不确定性。这种通信类型通常因为简单性而被使用，但它隐藏了交互的分布式特性。然而，它假设一切都正常运行（包括服务和网络）。但事实并非总是如此。作为使用同步通信的调用方，你必须优雅地处理错误响应和无响应。
- en: So, what can we do? We immediately think about a time-out and retries. With
    `curl`, you can specify a time-out (`-max-time`) and retries (`--retry`), as shown
    in [Example 3-14](#invoke-app-3-14).
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 所以，我们能做什么？我们立即考虑超时和重试。使用`curl`，你可以指定超时（`-max-time`）和重试（`--retry`），如示例 3-14](#invoke-app-3-14)所示。
- en: Example 3-14\. Invoke the application by using a time-out and `retry`
  id: totrans-184
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 3-14\. 使用超时和`retry`调用应用
- en: '[PRE13]'
  id: totrans-185
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: There is a good chance that we can reach our service with 100 tries. However,
    bad luck and random numbers may decide otherwise, and even 100 may not be enough.
    Note that during the time that the caller (you) is waiting, that’s a rather bad
    user experience.
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 我们有很大的机会在100次尝试内到达我们的服务。然而，倒霉和随机数可能会决定另一种方式，甚至100次也不足够。请注意，在调用方（你）等待的时间内，这是一个相当糟糕的用户体验。
- en: 'Yet, do we know for sure that if we get a time-out, the service was not invoked?
    Maybe the service or the network was just slow. What would be the ideal duration
    of the time-out? It depends on many factors: where the service is located, the
    latency of the network, and the load of the service. Maybe there isn’t a single
    instance of this service but several, all with different characteristics.'
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，我们是否确定如果我们遇到超时，服务就没有被调用？也许服务或网络只是慢了。超时的理想持续时间是多少？这取决于许多因素：服务的位置、网络的延迟和服务的负载。也许这个服务不是单个实例，而是有几个，每个都具有不同的特性。
- en: Retries are even more sneaky. As you can’t know for sure whether the service
    was invoked, you can’t assume it was not. Retrying may reprocess the same request
    multiple times. But you can retry safely only if the service you are calling is
    idempotent.
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 重试甚至更加狡猾。因为你无法确定服务是否已被调用，所以也无法假设它没有。重试可能会多次重新处理相同的请求。但是，只有调用的服务是幂等的情况下，你才能安全地重试。
- en: 'So, what can we do? It’s essential to understand the impact of the time and
    decouple our communication. Complex exchanges involving multiple services cannot
    expect all the participants and the network to be operational for the complete
    duration of that exchange. The dynamic nature of the cloud and Kubernetes stresses
    the limit of synchronous communications. Bad things happen: partitions, data loss,
    crashes…'
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 所以，我们能做什么？理解时间的影响并解耦我们的通信是至关重要的。涉及多个服务的复杂交换不能指望所有参与者和网络在整个交换期间都处于可操作状态。云和Kubernetes的动态特性对同步通信的限制产生了压力。糟糕的事情会发生：分区、数据丢失、崩溃⋯⋯
- en: In [Chapter 4](ch04.html#reactive-systems), you will see how Reactive addresses
    this issue. By using message passing, and spatial and time decoupling, a reactive
    system not only is more elastic and resilient, but also improves the overall responsiveness.
    In other words, reactive systems are distributed systems done right. Also, in
    [Chapter 5](ch05.html#reactive-programming), you will see the approaches Reactive
    is proposing to embrace the asynchronous nature of distributed systems and how
    we can elegantly develop event-driven and asynchronous code. The result not only
    is concurrent and efficient applications, but also paves the road to new classes
    of applications such as data streaming, API gateways, and so on.
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 在[第四章](ch04.html#reactive-systems)中，您将看到响应式是如何解决这个问题的。通过使用消息传递、空间和时间解耦，响应式系统不仅更具弹性和韧性，而且提高了整体响应能力。换句话说，响应式系统是正确构建的分布式系统。此外，在[第五章](ch05.html#reactive-programming)中，您将看到响应式提出了哪些方法来拥抱分布式系统的异步特性以及我们如何优雅地开发事件驱动和异步代码。结果不仅是并发和高效的应用程序，还铺平了通往新类别应用程序的道路，如数据流处理、API
    网关等等。
- en: Summary
  id: totrans-191
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: Distributed systems are challenging. To build distributed systems, you need
    to understand their nature and always plan for the worst-case scenario. Hiding
    the nature of distributed systems to seek simplicity does not work. It results
    in fragile systems.
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 分布式系统具有挑战性。要构建分布式系统，您需要了解它们的本质，并始终为最坏情况做计划。隐藏分布式系统的本质以追求简单并不起作用。它会导致脆弱的系统。
- en: 'This chapter covered the following:'
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 本章涵盖了以下内容：
- en: The erratic nature of distributed systems
  id: totrans-194
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 分布式系统的不稳定性质
- en: The evolution of distributed systems from a workaround to the norm
  id: totrans-195
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从权宜之计到常态的分布式系统演变
- en: Use of the cloud and Kubernetes to simplify the construction of distributed
    systems
  id: totrans-196
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用云和 Kubernetes 简化分布式系统的构建
- en: Potential failures of distributed communications caused by network disruptions,
    or slowness
  id: totrans-197
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 由网络中断或缓慢引起的分布式通信潜在故障
- en: But we won’t stop on a failure! Time to rebound! Let’s look a bit more into
    Reactive and see how it proposes to address these issues.
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 但我们不会因为失败而止步！是时候反弹了！让我们更深入地了解一下响应式，并看看它是如何解决这些问题的。
- en: ^([1](ch03.html#idm45358832499760-marker)) You can check the latency between
    the main American cities at [the Current Network Latency site](https://oreil.ly/ws4Xd).
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: ^([1](ch03.html#idm45358832499760-marker)) 你可以在[当前网络延迟网站](https://oreil.ly/ws4Xd)查看美国主要城市之间的延迟。
- en: ^([2](ch03.html#idm45358832353200-marker)) Kubernetes provides health checks
    that constantly verify the state of the application. In addition, [Prometheus](https://prometheus.io)
    is becoming the standard framework for metric collection.
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: ^([2](ch03.html#idm45358832353200-marker)) Kubernetes 提供健康检查，不断验证应用程序的状态。此外，[Prometheus](https://prometheus.io)
    正成为度量收集的标准框架。
- en: ^([3](ch03.html#idm45358832286384-marker)) In 2018, a power loss incident in
    AWS US-East-1 caused many Amazon service disruptions.
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: ^([3](ch03.html#idm45358832286384-marker)) 2018年，AWS US-East-1发生电力故障事件，导致许多Amazon服务中断。
- en: ^([4](ch03.html#idm45358832279664-marker)) Kubernetes may move containers to
    achieve a higher deployment density, but also be instructed to move interacting
    applications on the same node to reduce the response time.
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: ^([4](ch03.html#idm45358832279664-marker)) Kubernetes 可以移动容器以实现更高的部署密度，但也可以被指示将相互作用的应用程序移动到同一节点上以减少响应时间。
- en: ^([5](ch03.html#idm45358832272336-marker)) See [“Distributed Consensus Revised”](https://oreil.ly/qRVeD)
    by Heidi Howard for a discussion on the problem of consensus in modern distributed
    system.
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: ^([5](ch03.html#idm45358832272336-marker)) 参见[《重新审视分布式一致性》](https://oreil.ly/qRVeD)，由
    Heidi Howard 讨论现代分布式系统中的一致性问题。
- en: ^([6](ch03.html#idm45358832270720-marker)) [“Perspectives on the CAP Theorem”](https://oreil.ly/p33qM)
    by Seth Gilbert and Nancy A. Lynch explains the technical implications of the
    CAP theorem in *future* distributed systems.
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: ^([6](ch03.html#idm45358832270720-marker)) [《对 CAP 定理的观点》](https://oreil.ly/p33qM)，由
    Seth Gilbert 和 Nancy A. Lynch 解释了 *未来* 分布式系统中 CAP 定理的技术含义。
