- en: 'Chapter 7\. Tomorrow’s Solutions: Serverless'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The second industrial revolution, unlike the first, does not present us with
    such crushing images as rolling mills and molten steel, but with “bits” in a flow
    of information traveling along with circuits in the form of electronic impulses.
    The iron machines still exist, but they obey the orders of weightless bits.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Italo Calvino
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: The serverless computing model has great momentum with public cloud offerings,
    and recently also within the open source community thanks to many projects that
    enable it for any platform. But, what is serverless, exactly? What are some use
    cases for serverless? And, how can it be used for modern Java applications?
  prefs: []
  type: TYPE_NORMAL
- en: What Is Serverless?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The best definition of serverless comes from the [CNCF Serverless Whitepaper](https://oreil.ly/yYbmP):'
  prefs: []
  type: TYPE_NORMAL
- en: Serverless computing refers to the concept of building and running applications
    that do not require server management. It describes a finer-grained deployment
    model where applications, bundled as one or more functions, are uploaded to a
    platform and then executed, scaled, and billed in response to the exact demand
    needed at the moment.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Running an application that “does not require server management” is the most
    relevant part of that definition. In the previous chapters, we explored how Kubernetes
    helps with functional requirements for modern architectures, and how container
    images represent a convenient way to package and ship applications to any cloud
    platform. There are still servers in serverless, however, they are abstracted
    away from app development. While a third party handles the complexity of maintaining
    and managing such servers, developers can simply package their code in containers
    for deployment.
  prefs: []
  type: TYPE_NORMAL
- en: The main differentiator between the deployment model that we discussed in Kubernetes
    and the serverless model is the so-called *scale-to-zero* approach. With this
    approach, an application is automatically launched on demand when called, and
    idle when not used. This execution model is also called event-driven, and it is
    the core foundation of serverless. We discuss event-driven serverless architectures
    later in this chapter.
  prefs: []
  type: TYPE_NORMAL
- en: Typically, a series of events can trigger the launch of the application, which
    will produce an outcome, as you can see in [Figure 7-1](#fig7-1). This can be
    a single action or a chain of actions where the output of one app is the input
    of the subsequent app. The event can be anything, such as an HTTP request, a Kafka
    message, or a database transaction. The application can be autoscaled to multiple
    replicas proportional to the needed amount to handle the traffic load, and then
    scaled down when there isn’t any activity.
  prefs: []
  type: TYPE_NORMAL
- en: '![Serverless execution model](Images/moej_0701.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 7-1\. Serverless execution model
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Architectural Evolution
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The serverless model is not good for all use cases. In general, any asynchronous,
    concurrent, easy-to-parallelize-into-independent-units-of-work application is
    a good fit for this model. If you look at the diagram in [Figure 7-2](#fig7-2),
    you can see how the microservices-based architectures evolution started from a
    monolithic applications approach using the service-oriented architectures (SOA)
    model, and it is now evolving again into a new model of *functions*.
  prefs: []
  type: TYPE_NORMAL
- en: '![Architectural evolution](Images/moej_0702.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 7-2\. Architectural evolution
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'These functions represent a minimal computing unit that accomplishes a specific
    scope or task. Examples are:'
  prefs: []
  type: TYPE_NORMAL
- en: Processing web hooks
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Data transformation (image, video)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: PDF generation
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Single-page apps for mobile devices
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Chatbots
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: With this approach, you can focus on convenience, as it is generally offered
    as *best-effort*. Failures are tolerated, and short actions are preferred. That’s
    why the serverless model is not good for use cases such as real-time applications,
    long-running tasks, or contexts where reliability and/or atomicity are key. It’s
    up to the developer to take care of verifying that inputs and outputs have been
    successfully processed by any serverless function involved. This gives great flexibility
    and high scalability to at least some part of the overall architecture.
  prefs: []
  type: TYPE_NORMAL
- en: 'Use Cases: Data, AI, and Machine Learning'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The serverless model helps avoid common headaches for capacity planning for
    projects, as it mitigates overprovisioning and underprovisioning, thereby reducing
    the IT cost of idle resources. With serverless, all of the resources consumed
    are tailored to the actual usage as the applications start only when invoked,
    and there’s no need to preallocate or measure-and-update hardware resources.
  prefs: []
  type: TYPE_NORMAL
- en: This is very important when you have to analyze in real time a large amount
    of data, and that’s why serverless is gaining lots of attention from data scientists
    and ML experts, as the functions that can process data for analysis are flexible
    and leave a minimal footprint. On the other hand, serverless doesn’t pair well
    with all of the design principles of existing ML frameworks. A certain amount
    of tolerance is also required, in particular for processes that may take longer
    such as model training.
  prefs: []
  type: TYPE_NORMAL
- en: If you look at [Figure 7-3](#fig7-3), you will see an example of a serverless-driven
    architecture for machine learning for classification and prediction. The process
    starts with a trigger to get an inference of a group of objects from a trained
    model. This starts a sequence of asynchronous functions that run in parallel,
    used to predict the class of the object based on its characteristics and return
    the classification as output. The tolerance we expect is that one of these functions
    may fail or not complete the task in time. However, those are all independent
    workloads. It’s important to have workloads that can run in parallel without a
    specific order so any failure to a single function is not affecting the whole
    system. In addition, the autoscaling component of the serverless architecture
    will make sure that any high data load will be processed faster on demand than
    with traditional approaches.
  prefs: []
  type: TYPE_NORMAL
- en: '![Machine learning with serverless](Images/moej_0703.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 7-3\. Machine Learning with serverless
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'Use Cases: Edge Computing and IoT'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Edge and IoT devices are everywhere. From vocal assistants to home automation,
    nowadays nearly every item in our house can be connected to the internet, talking
    to some controller application. As a developer, you may be responsible for either
    the backend logic or the device application logic.
  prefs: []
  type: TYPE_NORMAL
- en: An example of this scenario for Java developers comes from the [Quarkus for
    IoT](https://oreil.ly/0Lmiu) project, which aims to collect pollution data from
    sensors with [Raspberry Pi devices](https://raspberrypi.org) using Quarkus and
    containers both on the device and the server-side backend. The latter is running
    a serverless application to provide on-demand high scalability of the huge amount
    of sensor data that may come in some bursty way.
  prefs: []
  type: TYPE_NORMAL
- en: The project also offers a very good reference on how IoT architectures should
    be implemented on top of Red Hat OpenShift, as shown in [Figure 7-4](#fig7-4).
  prefs: []
  type: TYPE_NORMAL
- en: '![Quarkus for IoT project architecture](Images/moej_0704.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 7-4\. Quarkus for IoT project architecture
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Serverless is used to scale up Quarkus microservices from device messages using
    the MQTT protocol for data ingestion, with Kafka streams used in the architecture
    as well as for data collectors. This makes the architecture complete and reliable,
    but also cost-efficient as there’s no allocation of resources until they are needed.
  prefs: []
  type: TYPE_NORMAL
- en: 'Knative: Serverless for Kubernetes'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Serverless can be considered the engine of functions as a service (FaaS), which
    is a more convenient way for developers to package and deploy apps. Often, particularly
    with public clouds, serverless and FaaS fit together, since packaging apps in
    containers is also automated. However, a scale-to-zero app is not necessarily
    a function. As we discussed, serverless is not just a prerogative of public clouds.
    For instance, anyone can also adopt this model on any Kubernetes cluster thanks
    to an open source project called [Knative](https://knative.dev).
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: We will discuss FaaS in more detail later in this chapter.
  prefs: []
  type: TYPE_NORMAL
- en: Knative enables serverless on Kubernetes, supporting event-driven scale-to-zero
    applications. It provides a higher level of abstraction for common app use cases.
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Knative can easily be installed on Kubernetes through an Operator from [OperatorHub.io](https://oreil.ly/ni1wkr).
  prefs: []
  type: TYPE_NORMAL
- en: 'There are two main components in Knative:'
  prefs: []
  type: TYPE_NORMAL
- en: Knative Serving
  prefs: []
  type: TYPE_NORMAL
- en: Takes care of scale-to-zero, creating all Kubernetes resources needed (e.g.,
    Pod, Deployment, Service, Ingress)
  prefs: []
  type: TYPE_NORMAL
- en: Knative Eventing
  prefs: []
  type: TYPE_NORMAL
- en: A subscription, delivery, and management component for handling events on-cluster
    and off-cluster (e.g., Kafka messages, external services)
  prefs: []
  type: TYPE_NORMAL
- en: It’s easy to make an app serverless in Kubernetes with Knative. An example of
    a Knative Service for the Inventory Quarkus microservice that you created in [Chapter 2](ch02.xhtml#changing_technologies)
    follows.
  prefs: []
  type: TYPE_NORMAL
- en: 'You can also find the example in this [book’s GitHub repository](https://oreil.ly/kyQfu):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: '[![1](Images/1.png)](#co_tomorrow_s_solutions__serverless_CO1-1)'
  prefs: []
  type: TYPE_NORMAL
- en: This is the definition of Knative Service, a Custom Resource representing a
    serverless workload on Kubernetes.
  prefs: []
  type: TYPE_NORMAL
- en: '[![2](Images/2.png)](#co_tomorrow_s_solutions__serverless_CO1-2)'
  prefs: []
  type: TYPE_NORMAL
- en: It is using the same container image we used for the Deployment object. With
    Knative Service, a Deployment and a Service are automatically created for you.
  prefs: []
  type: TYPE_NORMAL
- en: 'To create a serverless version for the Inventory microservice, you can create
    a Knative Service object with the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: Tip
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Knative also provides a convenient CLI called `kn` to create Knative Services
    and manage all Knative serverless components. You can find more info about it
    in the [official documentation](https://oreil.ly/vDtU2).
  prefs: []
  type: TYPE_NORMAL
- en: 'Immediately, you can verify that a new Knative Service has been created with
    this command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'You should get output similar to the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'As you can see, all of the Kubernetes manifests, such as Pod, Deployment, and
    Service, have been created automatically from the Knative Service. There’s no
    need to maintain them in this case, since you can rely on a single object that
    controls deployment and networking:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'Under the hood, the traffic to a Knative Service is routed into the cluster
    through the Knative networking. Invoking the Inventory microservice will also
    trigger the Pod creation if the application is idling:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'You should get output similar to the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'After a certain amount of time with no new requests, the scale-to-zero model
    applies and the Pod number is scaled down to zero:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: Event-Driven Serverless Architectures
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Events are everywhere. As we discussed in the previous section, an HTTP request
    can trigger the start of an application that can be idling when not used, which
    is consistent with the serverless execution model represented in [Figure 7-1](#fig7-1).
    But there are plenty of events out there, such as a Kafka message, a database
    stream, or any event from Kubernetes, that an application may want to subscribe
    to.
  prefs: []
  type: TYPE_NORMAL
- en: A popular pattern in this scenario is the [publish-subscribe messaging pattern](https://oreil.ly/ThcHL)
    where many senders can send messages to an entity on the server, often called
    a topic, and receivers can subscribe to said topic to get messages. According
    to the serverless model, your application can be registered and connected to process
    incoming events. One example for Kubernetes is the [Knative Eventing](https://oreil.ly/NF2gB)
    component, which implements [CloudEvents](https://cloudevents.io), a specification
    for describing event data from multiple protocols and formats (such as Kafka,
    AMQP, and MQTT) [in a common way](https://oreil.ly/oGI1q).
  prefs: []
  type: TYPE_NORMAL
- en: With Knative Eventing, event producers and event consumers are independent.
    A Knative Service is triggered by a source of events through a broker, as you
    can see in [Figure 7-5](#fig7-5). The goal of the eventing framework is to decouple
    everything. The sender doesn’t directly call the subscriber or even know how many
    subscribers there are. Instead, brokers and triggers handle the communication.
  prefs: []
  type: TYPE_NORMAL
- en: '![Knative eventing architecture](Images/moej_0705.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 7-5\. Knative Eventing architecture
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Rather than relying on the inbound request cascading through all the microservices,
    you could use an arbitrary HTTP event as an example of an event to wake up the
    Inventory service.
  prefs: []
  type: TYPE_NORMAL
- en: 'First, we need to create a Knative Broker. An example of a Knative Broker for
    the Inventory Quarkus microservice that we created in [Chapter 2](ch02.xhtml#changing_technologies)
    is listed below, which you can also find in this [book’s GitHub repository](https://oreil.ly/8Gwys):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'Create the Broker:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'You should get output similar to the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: Note
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: We are using the internal Kubernetes networking for this part, so any endpoint
    we are using is a Kubernetes Service in the fully qualified domain name (FQDN)
    format accessible only within the cluster.
  prefs: []
  type: TYPE_NORMAL
- en: Now let’s create a Trigger to wake up the Inventory microservice. It can be
    any event compliant with the CloudEvents specification. In this case, you can
    use an HTTP request from another Pod.
  prefs: []
  type: TYPE_NORMAL
- en: 'An example of a Knative Trigger for the Inventory Quarkus microservice that
    you created in [Chapter 2](ch02.xhtml#changing_technologies) follows; you can
    find it in this [book’s GitHub repository](https://oreil.ly/GmG6r):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: '[![1](Images/1.png)](#co_tomorrow_s_solutions__serverless_CO2-1)'
  prefs: []
  type: TYPE_NORMAL
- en: Name of the Broker.
  prefs: []
  type: TYPE_NORMAL
- en: '[![2](Images/2.png)](#co_tomorrow_s_solutions__serverless_CO2-2)'
  prefs: []
  type: TYPE_NORMAL
- en: Attribute type. This can be used to filter which event to wake up.
  prefs: []
  type: TYPE_NORMAL
- en: '[![3](Images/3.png)](#co_tomorrow_s_solutions__serverless_CO2-3)'
  prefs: []
  type: TYPE_NORMAL
- en: Name of the Knative Service to connect to and wake up to field the event.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s create the Knative Trigger as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'You should get output similar to the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: Now you can simulate an external event that can wake up your microservice. In
    this case, it’s a simple HTTP call, but it can also be something like a database
    stream with Debezium or a Kafka message.
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: '[Debezium.io](https://debezium.io) is an open source data capture platform
    that enables streaming from popular databases such as PostgreSQL, MySQL, etc.
    Check out the [online documentation](https://oreil.ly/bFEJi) to learn more.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Run this command to download a minimal container image containing the `curl`
    command to run directly on Kubernetes as a Pod, sending an HTTP `POST` to the
    Knative Broker to trigger the microservice start:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: '[![1](Images/1.png)](#co_tomorrow_s_solutions__serverless_CO3-1)'
  prefs: []
  type: TYPE_NORMAL
- en: The attribute we defined in the Knative Broker before.
  prefs: []
  type: TYPE_NORMAL
- en: '[![2](Images/2.png)](#co_tomorrow_s_solutions__serverless_CO3-2)'
  prefs: []
  type: TYPE_NORMAL
- en: A name for the event.
  prefs: []
  type: TYPE_NORMAL
- en: 'You should get output similar to the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 'You should now see the Inventory Pod has been started:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: Function as a Service for Java Applications
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'We previously discussed how Knative Serving helps to reduce the complexity
    of maintaining multiple Kubernetes objects, and how scale-to-zero helps optimize
    resource usage by scaling down and scaling up applications on demand when needed.
    But there is another layer of abstraction that helps with automatically building
    and deploying the application following the serverless model: the FaaS model,
    which we introduced earlier.'
  prefs: []
  type: TYPE_NORMAL
- en: FaaS is an event-driven computing execution model where developers write apps
    that are automatically deployed in containers fully managed by a platform, then
    executed on demand following the scale-to-zero model. As a developer, you don’t
    have to write anything like a Kubernetes manifest with this model. You can simply
    write the application logic and let the platform package the application as a
    container and deploy it on the cluster as a scale-to-zero serverless app.
  prefs: []
  type: TYPE_NORMAL
- en: Popular public cloud serverless solutions such as AWS Lambda, Azure Functions,
    or Google Cloud Run provide a convenient SDK to start developing functions written
    in the most popular programming languages, to be packaged and deployed in the
    FaaS model. There are also open source solutions available, such as [Apache OpenWhisk](https://openwhisk.apache.org)
    or [Fn project](https://fnproject.io), that implement FaaS with Docker. In the
    following sections, we will focus on Knative and Kubernetes, as we have discussed
    throughout the book how Kubernetes provides a complete ecosystem for easing the
    migration of Java enterprise applications to the cloud native paradigm.
  prefs: []
  type: TYPE_NORMAL
- en: Functions Deployment for Java Applications
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Functions are a piece of code delivered according to the serverless model and
    are portable between different infrastructure configurations. The life cycle of
    a function is described in [Figure 7-6](#fig7-6) starting with code writing, as
    well as specification and metadata. The building phase automatically happens afterward,
    and the deployment publishes the function in the platform. This enables a mechanism
    of updates that will trigger a new build and a new publish when a new change is
    needed.
  prefs: []
  type: TYPE_NORMAL
- en: '![Functions deployment model](Images/moej_0706.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 7-6\. Functions deployment model
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Boson Function CLI (func)
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[Boson Function CLI](https://oreil.ly/lKYKc) is an open source CLI and framework
    that connects to Knative to provide FaaS capabilities to Kubernetes. With this
    tool, you can avoid writing Kubernetes manifests and building the container image
    yourself, as it will be done automatically:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: Tip
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: You can download the latest `func` CLI from the [official website](https://oreil.ly/d6oXo)
    and configure it to your system.
  prefs: []
  type: TYPE_NORMAL
- en: Functions can be deployed to any Kubernetes cluster that has been configured
    to support serverless workloads, such as with Knative.
  prefs: []
  type: TYPE_NORMAL
- en: 'Currently, `func` CLI supports these programming languages and frameworks:'
  prefs: []
  type: TYPE_NORMAL
- en: Golang
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Node.js
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Python
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Quarkus
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Rust
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Let’s create a Quarkus function inside the `coolstore` namespace that you created
    in the previous sections. You can also find this function in this [book’s GitHub
    repository](https://oreil.ly/M3yPE).
  prefs: []
  type: TYPE_NORMAL
- en: 'To create a new Quarkus function, run this command specifying the `-l` option
    to select the language as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: 'You should get a similar output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: 'This created a skeleton of a Maven project for Quarkus, with a POM file containing
    all dependencies needed:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: '[![1](Images/1.png)](#co_tomorrow_s_solutions__serverless_CO4-1)'
  prefs: []
  type: TYPE_NORMAL
- en: This is the file containing configuration information for your function project.
  prefs: []
  type: TYPE_NORMAL
- en: '[![2](Images/2.png)](#co_tomorrow_s_solutions__serverless_CO4-2)'
  prefs: []
  type: TYPE_NORMAL
- en: The POM file for this Quarkus project.
  prefs: []
  type: TYPE_NORMAL
- en: '[![3](Images/3.png)](#co_tomorrow_s_solutions__serverless_CO4-3)'
  prefs: []
  type: TYPE_NORMAL
- en: The Java class containing annotations and code to run the function.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s add some content for the `func.yaml` function’s configuration file to
    transform your function into a runnable container image on Kubernetes:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: '[![1](Images/1.png)](#co_tomorrow_s_solutions__serverless_CO5-1)'
  prefs: []
  type: TYPE_NORMAL
- en: Name of the function.
  prefs: []
  type: TYPE_NORMAL
- en: '[![2](Images/2.png)](#co_tomorrow_s_solutions__serverless_CO5-2)'
  prefs: []
  type: TYPE_NORMAL
- en: The Kubernetes namespace where your function will be deployed.
  prefs: []
  type: TYPE_NORMAL
- en: '[![3](Images/3.png)](#co_tomorrow_s_solutions__serverless_CO5-3)'
  prefs: []
  type: TYPE_NORMAL
- en: The language runtime for your function declared at creation time.
  prefs: []
  type: TYPE_NORMAL
- en: '[![4](Images/4.png)](#co_tomorrow_s_solutions__serverless_CO5-4)'
  prefs: []
  type: TYPE_NORMAL
- en: This is the image name for your function after it has been built.
  prefs: []
  type: TYPE_NORMAL
- en: '[![5](Images/5.png)](#co_tomorrow_s_solutions__serverless_CO5-5)'
  prefs: []
  type: TYPE_NORMAL
- en: The invocation event that triggers your function. For example, `http` for plain
    HTTP requests such as in this case, or `event` for CloudEvent-triggered functions.
  prefs: []
  type: TYPE_NORMAL
- en: '[![6](Images/6.png)](#co_tomorrow_s_solutions__serverless_CO5-6)'
  prefs: []
  type: TYPE_NORMAL
- en: Specifies the buildpack builder image to use when building the function.
  prefs: []
  type: TYPE_NORMAL
- en: '[![7](Images/7.png)](#co_tomorrow_s_solutions__serverless_CO5-7)'
  prefs: []
  type: TYPE_NORMAL
- en: Reference to any environment variables that will be available to your function
    at runtime.
  prefs: []
  type: TYPE_NORMAL
- en: '[![8](Images/8.png)](#co_tomorrow_s_solutions__serverless_CO5-8)'
  prefs: []
  type: TYPE_NORMAL
- en: Annotations for the function to be used to tag items.
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: '`func` builds functions and transforms them in container images with [Buildpack](https://buildpacks.io),
    a popular open source project used to build source code into a runnable application
    container image.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s review the POM file:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: '[![1](Images/1.png)](#co_tomorrow_s_solutions__serverless_CO6-1)'
  prefs: []
  type: TYPE_NORMAL
- en: Version of Quarkus
  prefs: []
  type: TYPE_NORMAL
- en: '[![2](Images/2.png)](#co_tomorrow_s_solutions__serverless_CO6-2)'
  prefs: []
  type: TYPE_NORMAL
- en: Quarkus Funqy dependency, a Java API for FaaS environments
  prefs: []
  type: TYPE_NORMAL
- en: '[![3](Images/3.png)](#co_tomorrow_s_solutions__serverless_CO6-3)'
  prefs: []
  type: TYPE_NORMAL
- en: Native profile for building Quarkus native applications
  prefs: []
  type: TYPE_NORMAL
- en: '[Quarkus Funqy](https://oreil.ly/1CNPK) is part of Quarkus’s support for serverless
    workloads and aims to provide a portable Java API to write functions deployable
    to various FaaS environments, such as AWS Lambda, Azure Functions, Knative, and
    Knative Events (Cloud Events). Funqy is an abstraction that spans multiple different
    FaaS providers and protocols. It is optimized for small workloads and faster execution
    while providing a simple framework with no overhead.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s look at the source code of the Java function generated in the `src/main/java/functions/Function.java`
    path:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: '[![1](Images/1.png)](#co_tomorrow_s_solutions__serverless_CO7-1)'
  prefs: []
  type: TYPE_NORMAL
- en: To enable a function, you simply need to annotate your method with the `@Funq`
    annotation that comes from Quarkus Funqy API.
  prefs: []
  type: TYPE_NORMAL
- en: '[![2](Images/2.png)](#co_tomorrow_s_solutions__serverless_CO7-2)'
  prefs: []
  type: TYPE_NORMAL
- en: Java classes can also be used as input and output. They must follow the JavaBean
    convention and have a default constructor. Here we are using `Input` and `Output`
    Beans.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s look at the source code of the `Input` JavaBean generated in the `src/main/java/functions/Input.java`
    path that will be used to represent input messages to the function:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: 'And let’s have a look at the source code of the `Output` JavaBean generated
    in the `src/main/java/functions/Ouput.java` path:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: 'We are now ready to build the function. By default, the Boson CLI will connect
    to the local Docker instance locally to create the container with buildpacks and
    then push to the container registry you declared in the `func.yaml` configuration
    file:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: Tip
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: In future versions, Boson CLI will also delegate the building phase to Kubernetes
    via Tekton.
  prefs: []
  type: TYPE_NORMAL
- en: 'After a few minutes, you should get a similar output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: 'After the function has been built, you can test it locally as a running container
    image before deploying it to Kubernetes:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: 'You should get an output similar to this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: 'In another terminal, verify the process is running:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: 'Try to access it:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: 'You should get an output similar to this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: 'Now let’s deploy it to Kubernetes and let Knative use it as a scale-to-zero
    application. When we invoke the function via HTTP, Knative will start it automatically,
    and it will scale down to zero when not used:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: 'After a few seconds, you should see an output similar to this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: Finally, start your Quarkus function on Kubernetes!
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs: []
  type: TYPE_PRE
- en: 'You should get an output similar to this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs: []
  type: TYPE_PRE
- en: 'You can verify that a new pod has started in your Kubernetes cluster inside
    the `coolstore` namespace:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs: []
  type: TYPE_PRE
- en: 'And, you should see that a new Knative Service has been created:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs: []
  type: TYPE_PRE
- en: 'You can now see all the details of your newly deployed function with the following
    command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE41]'
  prefs: []
  type: TYPE_PRE
- en: 'You should get an output similar to this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE42]'
  prefs: []
  type: TYPE_PRE
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we analyzed how Java developers can create modern applications
    following the serverless execution model. We outlined some of the most common
    use cases and architectures that Java developers are likely to work with today,
    and tomorrow. Edge computing, Internet of Things, data ingestion, and machine
    learning are all contexts where event-driven architectures are a natural choice,
    and where serverless and Java can play a strategic and supporting role. We discussed
    FaaS, which represents the latest evolution in software development, and how Kubernetes
    can automate the whole life cycle of applications deployed as decoupled, asynchronous,
    easy-to-parallelize processes called functions.
  prefs: []
  type: TYPE_NORMAL
- en: With this chapter, we complete this “Concise Cloud Native Guide for Developers.”
    From microservices to functions, Java developers today have a complete set of
    frameworks, tools, and platforms such as Kubernetes that can help them modernize
    their architectures, innovate their solutions, and look ahead to solve the next
    challenges in today’s IT context. This context is one that is ever more heterogeneous,
    ubiquitous, large scale, and cloud native.
  prefs: []
  type: TYPE_NORMAL
- en: To you I have given wings, on which you may fly aloft
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Above the boundless sea and all the earth […]
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: To all who care for them, even to those who are not yet born, you will be
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Alike a theme of song, so long as Earth and Sun exist.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Theognis of Megara
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
