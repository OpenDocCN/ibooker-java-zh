- en: Chapter 7\. Securing Your Binaries
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Sven Ruppert
  prefs: []
  type: TYPE_NORMAL
- en: Stephen Chin
  prefs: []
  type: TYPE_NORMAL
- en: Data is the pollution problem of the information age, and protecting privacy
    is the environmental challenge.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Bruce Schneier, *Data and Goliath*
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Software security is a critical part of any comprehensive DevOps rollout. New
    breaches uncovered in the past year have called attention to the consequences
    of weak software security, and have prompted the creation of new government security
    regulations. The impact of meeting these new regulations spans across the entire
    software lifecycle, from development through production. As a result, DevSecOps
    is something that every software developer and DevOps professional needs to understand.
  prefs: []
  type: TYPE_NORMAL
- en: In this chapter, you will learn how to evaluate your product and organizational
    risk for security vulnerabilities. We will also cover static and dynamic techniques
    for security testing, and scoring techniques for risk assessment.
  prefs: []
  type: TYPE_NORMAL
- en: Regardless of your role, you will be better prepared to help secure your organization’s
    software delivery lifecycle. But first let’s look deeper into what happens if
    you don’t have a focus on security and take steps to secure your software supply
    chain.
  prefs: []
  type: TYPE_NORMAL
- en: Supply Chain Security Compromised
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: It started in early December 2020, when FireEye noticed that it had become a
    victim of a cyberattack, which is remarkable because the company itself specializes
    in detecting and fending off cyberattacks. Internal analysis showed that the attackers
    managed to steal FireEye internal tools, which FireEye used to examine its customers’
    IT infrastructure for weak points. This highly specialized toolbox is optimized
    for breaking into networks and IT systems, which in the hands of hackers is a
    tremendous risk. It wasn’t until later that this breach and a massive cyberattack
    known as the *SolarWinds hack* were discovered to be connected. (FireEye has since
    become Trellix, through a merger.)
  prefs: []
  type: TYPE_NORMAL
- en: SolarWinds, a company based in the United States, specializes in the management
    of complex IT network structures. For this, the company developed the Orion Platform.
    The company itself has over 300,000 active customers who use this software internally.
    The software for managing network components has to be equipped with generous
    administrative rights within the IT systems in order to be able to carry out its
    tasks, which is one of the critical points the hackers used in their strategy.
    It took some time to recognize the connection between the FireEye hack and the
    later, massive cyberattacks, because the chain of effects was not as direct as
    previous vulnerability breaches.
  prefs: []
  type: TYPE_NORMAL
- en: Because of the long gap between exploitation of the SolarWinds vulnerability
    and discovery of the breach, many companies and government organizations ended
    up being affected by this attack. Over a period of a few weeks 20,000 successful
    attacks were launched. Because the pattern of the attacks was similar, security
    researchers were able to identify that these attacks were related. One of the
    common characteristics was that all of the organizations that suffered an attack
    used SolarWinds software to manage their network infrastructure.
  prefs: []
  type: TYPE_NORMAL
- en: The attackers used FireEye tools to break into SolarWinds networks. They attacked
    the CI pipeline, which is responsible for creating the binaries for the Orion
    software platform. The software delivery production line was modified so that
    each time a new version was run through, the resulting binary was compromised
    and included a backdoor prepared by the hackers. The Orion Platform was used here
    as a Trojan horse to deliver the compromised binaries to thousands of networks.
    Any recipient who checked the fingerprint would see a valid binary because it
    was signed by SolarWinds, which is a vendor they trust. And this trust relationship
    is the flaw that this cyberattack takes advantage of to attack downstream networks.
  prefs: []
  type: TYPE_NORMAL
- en: The precise account of the way this attack was executed is as follows. The company,
    SolarWinds, created an update of its software and made these binaries available
    to all 300,000 customers via an automatic update process. Almost 20,000 customers
    then installed this update in a short period of time. The compromised software
    waited about two weeks after activation and then began to spread in the infected
    systems. As if that wasn’t bad enough, over time, further malware was then dynamically
    loaded, making it impossible to repair the compromised system without a full rebuild.
  prefs: []
  type: TYPE_NORMAL
- en: Stepping back a bit, let’s differentiate between the perspective of the SolarWinds
    company and the perspective of the affected customers. Whose responsibility is
    it to mitigate this attack, and what does the procedure look like if you are affected
    yourself? Which tools can you use to identify and address the vulnerability? Who
    can take action against such attacks, and at what point in the vulnerability timeline?
  prefs: []
  type: TYPE_NORMAL
- en: Security from the Vendor Perspective
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: First, let’s start with the perspective of a software manufacturer (in this
    example, SolarWinds) that distributes software to its customers. When a supply-chain
    attack is carried out, you have to prepare yourself because you will be only the
    carrier of the viral software. Compared to a conventional attack, the damage is
    amplified because you are enabling hackers to open a security hole in thousands
    of your customers. Preventing this requires a stringent approach in your software
    development and distribution process.
  prefs: []
  type: TYPE_NORMAL
- en: Securing the tools used in your software delivery pipeline is one of the most
    important aspects, because they have access to your internal systems and can maliciously
    modify binaries in your software pipeline. However, this is challenging because
    the number of direct and indirect tools used in software delivery lifecycles is
    constantly increasing and expanding the attack surface.
  prefs: []
  type: TYPE_NORMAL
- en: Security from the Customer Perspective
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: As a customer of a vendor like SolarWinds, it is essential to consider all elements
    in the value chain, including all of the tools that a software developer uses
    daily. You also have to check the binaries generated from your CI/CD system for
    the possibility of modification or vulnerability injection. It is essential to
    keep an overview of all components used with a secure and traceable bill of materials.
    Ultimately, it helps only if you break your own products into their constituent
    parts and subject each element to a security review.
  prefs: []
  type: TYPE_NORMAL
- en: How can you protect yourself as a consumer? The approach that all elements in
    the value chain must be subjected to a critical review also applies here. As shown
    in the SolarWinds case, individual fingerprints and the exclusive use of confidential
    sources do not provide the best possible protection. The components used must
    be subjected to a deeper security inspection.
  prefs: []
  type: TYPE_NORMAL
- en: The Full Impact Graph
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: A *full impact graph* represents all areas of an application that are affected
    by the known vulnerability. Analyzing a full impact graph requires tools to check
    for known weak points. These tools can develop their full potential only if they
    can recognize and represent the interrelationships across technology boundaries.
    Without considering a full impact graph, it is easy to focus on just one technology,
    which can quickly lead to dangerous pseudosecurity.
  prefs: []
  type: TYPE_NORMAL
- en: As an example, let’s say we are building a JAR with Maven; this JAR is used
    inside a WAR to be deployed inside a servlet container. Additionally, it is a
    best practice to pack this JAR inside a Docker image to deploy to production.
    The production configuration is also stored in Helm charts that are used to organize
    the Docker deployment. Suppose we can identify this compromised JAR inside the
    WAR that is part of the Docker image deployed by the Helm chart that is part of
    the active production environment. Tracing the vulnerability from a Helm chart
    through to the encapsulated JAR requires knowledge about the full impact graph.
  prefs: []
  type: TYPE_NORMAL
- en: The SolarWinds hack demonstrates the need to analyze a full impact graph in
    order to discover vulnerabilities in a supply chain. If you find a vulnerability
    in a binary file, the relevance of this vulnerability depends on how the file
    is used. You need to know where this file is used, and the potential risk caused
    by this weak point if used in an operational environment. If you don’t use this
    binary anywhere, the vulnerability can’t do any harm; however, if the use occurs
    in critical areas within a company, significant risk arises.
  prefs: []
  type: TYPE_NORMAL
- en: Assume that we are focusing on scanning Docker images only. We will get the
    information that the Docker image contains vulnerabilities and can mitigate the
    vulnerability in the Docker image. But we are missing information about all other
    places where this infected binary is used as well. We need to know the usage of
    this binary in all different layers and technologies. Just focusing on the usage
    inside Docker images could lead to open security holes in other parts of our environment
    where the binary is used directly.
  prefs: []
  type: TYPE_NORMAL
- en: In [“The Common Vulnerability Scoring System”](#common-vulnerability-sect),
    we will show you how to use the environmental metric to precisely assess the context
    and use this information to make more-informed risk assessments.
  prefs: []
  type: TYPE_NORMAL
- en: Securing Your DevOps Infrastructure
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Now that you understand the impact of security vulnerabilities, it is time to
    look at countermeasures we can utilize to improve the security of our full software
    development lifecycle. First, let’s shed some light on the procedures and roles
    used in a DevOps environment.
  prefs: []
  type: TYPE_NORMAL
- en: The Rise of DevSecOps
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Let’s briefly go over how development and operations merged to become DevOps,
    because it plays a central role in introducing security. DevOps started with the
    basic recognition that the two areas of developers and operations have to work
    closer together in order to improve productivity. The fundamental stages of DevOps
    map directly to the process of building and delivering software to production.
  prefs: []
  type: TYPE_NORMAL
- en: Before DevOps, a big split existed in responsibilities, with a release build
    used as the handover point between groups. DevOps changes the roles to be more
    inclusive; developers need to understand the intricacies of doing production deployments,
    and vice versa. This change requires more-advanced automated tooling and repositories,
    as well as shared knowledge and processes.
  prefs: []
  type: TYPE_NORMAL
- en: But what about security? Security is not and should never be an explicit step
    in software development. Safety is a crosscutting issue that goes through all
    phases of production through operation. This, in turn, brings the realization
    that no dedicated safety officer can do this work alone. The team as a whole is
    entrusted with the issue of safety, just as they are, for example, with the issue
    of quality.
  prefs: []
  type: TYPE_NORMAL
- en: The outcome of this realization was the creation of the term *DevSecOps*. However,
    some subtleties here cannot be ignored. Not everyone in the production chain can
    do all things equally well. Everyone has their own idiosyncrasies and is more
    efficient in some areas. Accordingly, even in a DevSecOps organization, some team
    members care more about the dev area, and others have their strengths in the ops
    area.
  prefs: []
  type: TYPE_NORMAL
- en: The Role of SREs in Security
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: An exception to the dev and ops specialization is the *site reliability engineer*
    (SRE) role. The term originally comes from Google and describes the people on
    a team who deal with the reliability of services. The metric against which an
    SRE works is called the *failure budget*. It is assumed that the software has
    failures and that this is exactly what leads to downtimes. A service has a specific
    failure budget, or downtime budget. The SRE aims to keep service uptime within
    the defined budget by reducing downtime due to bugs, damage, or cyberattacks.
    To meet these goals, the SRE may choose to invest downtime on upgrades that can
    be used to deploy quality and security improvements to the system.
  prefs: []
  type: TYPE_NORMAL
- en: 'Therefore, an SRE is a team member whose role is to ensure the balance between
    the robustness of the systems and the introduction of new features. For this purpose,
    the SRE is given up to a maximum of 50% of their working time to focus on the
    operations tasks and responsibilities. This time should be used to automate the
    systems and improve quality and security. The rest of the SRE’s time is spent
    working as a developer and involved in implementing new features. And now we come
    to the exciting question: is an SRE also responsible for security?'
  prefs: []
  type: TYPE_NORMAL
- en: This role of an SRE can be in the middle of a DevSecOps structure since the
    working hours and skills are almost evenly split between the dev and ops areas,
    so both concepts can coexist inside the same organization.
  prefs: []
  type: TYPE_NORMAL
- en: SREs are usually developers with many years of experience who now specialize
    in the ops area, or an administrator with many years of professional experience
    who is now deliberately entering into software development. With this in mind,
    the position of an SRE is a perfect place to merge the dev and ops strategies
    for crosscutting issues.
  prefs: []
  type: TYPE_NORMAL
- en: Considering the example of SolarWinds again, the question arises of who has
    the most influence within the value chain to take action against vulnerabilities.
    For this purpose, we will look at the two areas dev and ops and the options available
    there.
  prefs: []
  type: TYPE_NORMAL
- en: Static and Dynamic Security Analysis
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Two main types of security analysis exist: static application security testing
    and dynamic application security testing. Let’s examine what these mean and how
    the two approaches differ.'
  prefs: []
  type: TYPE_NORMAL
- en: Static Application Security Testing
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '*Static application security testing* (SAST) analyzes an application at a specific
    point in time. It’s static. The focus is on recognizing and localizing the known
    vulnerabilities.'
  prefs: []
  type: TYPE_NORMAL
- en: 'SAST is a so-called clear-testing process in which you look at the system internals
    to do the analysis. For this procedure, you need to have access to the source
    code of the application to be tested. However, an operational runtime environment
    does not have to be available. The application does not have to be executed for
    this procedure, which is why the term *static* is also used. Three types of security
    threats can be identified using SAST:'
  prefs: []
  type: TYPE_NORMAL
- en: Does the source code have gaps in the functional area that allow, for example,
    “tainted code” to be smuggled in? These are lines that can later infiltrate malware.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Do any source code lines allow you to connect to files or certain object classes?
    The focus is also on detecting and preventing the introduction of malware.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Do gaps exist on the application level that allow you to interact with other
    programs unnoticed?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: However, it should be noted that the analysis of the source code is itself a
    complex matter. The area of static security analysis also includes the tools that
    enable you to determine and evaluate all contained direct and indirect dependencies.
  prefs: []
  type: TYPE_NORMAL
- en: As a rule, various SAST tools should check the source code at regular intervals.
    The SAST source code scanners must also be adapted to your organizational needs
    with an initial implementation to adjust the scanner to your respective domain.
    The Open Web Application Security Project (OWASP) Foundation offers assistance;
    it not only lists typical security vulnerabilities, but also recommends suitable
    SAST tools.
  prefs: []
  type: TYPE_NORMAL
- en: Advantages of the SAST approach
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'In comparison with security tests done at later stages in the software delivery
    process, a static security analysis approach offers the following advantages:'
  prefs: []
  type: TYPE_NORMAL
- en: Because vulnerability detection testing takes place in the development phase,
    removing the weak points can be carried out much more cost-effectively compared
    to detection that takes place only at runtime. By accessing the source code, you
    can also understand how this vulnerability came about and prevent it from recurring
    in the future. These findings cannot be obtained using an opaque-testing process.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Partial analysis can be done, which means that even non-executable source text
    can be analyzed. The static security analysis can be carried out by the developers
    themselves, which significantly reduces the need for security experts.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A 100% analysis of the system at the source code level is also possible, which
    cannot be guaranteed with a dynamic approach. Opaque-testing systems can perform
    only penetration tests, which are an indirect analysis.
  prefs: []
  type: TYPE_NORMAL
- en: Disadvantages of the SAST approach
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Since you are starting with the source code, SAST seems like it has the potential
    to be the most comprehensive security scanning approach. However, in practice
    it has fundamental problems:'
  prefs: []
  type: TYPE_NORMAL
- en: The programming work often suffers, which in turn manifests itself in domain-specific
    bugs. The developers focus too much on the security tests and related bug fixes.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The tools can be problematic. This happens especially if the scanners have not
    been adapted to your entire tech stack. Most systems are polyglot these days.
    To get a complete list of known vulnerabilities, you need a tool that supports
    all direct or indirect technologies.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: SAST often replaces the subsequent security tests completely. However, all problems
    that are directly related to an application in operation remain undetected.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Focusing on your source code is not enough. The static scan must analyze the
    binaries and additionally the source code if possible.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In [“How Much Is Enough?”](#how-much-scanning-sect), we will show why you should
    focus on scanning binaries first.
  prefs: []
  type: TYPE_NORMAL
- en: Dynamic Application Security Testing
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '*Dynamic application security testing* (DAST) is security analysis of a running
    application (usually a running web application). A wide variety of attack scenarios
    are performed in order to identify as many of the weak points as possible in the
    application. The term *dynamic* indicates that a running application must be available
    to carry out the tests. It is critical that the test system behaves the same as
    the production environment. Even minor variations can represent serious differences,
    including different configurations or upstream load balancers and firewalls.'
  prefs: []
  type: TYPE_NORMAL
- en: DAST is an opaque-testing process in which the application is viewed only from
    the outside. The technologies used do not play a role in the type of security
    check, as the application is accessed only generically and externally. This means
    that all information that could be obtained from the source code is invisible
    for this type of test. It is, therefore, possible for the person testing to test
    for the typical problems with a generic set of tools. The benchmark OWASP project
    offers reasonable assistance for selecting a scanner for your own project. This
    evaluates the performance of the individual tools in relation to the specific
    application background.
  prefs: []
  type: TYPE_NORMAL
- en: Advantages of DAST
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The DAST process has the following advantages:'
  prefs: []
  type: TYPE_NORMAL
- en: Security analysis works in a technology-neutral manner.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The scanners find errors in the runtime environment in which the test is carried
    out.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The rate of false positives is low.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The tools find faulty configurations in basically functional applications. For
    example, you can identify performance problems that other scanners cannot.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The DAST programs can be used in all phases of development and in a later operation.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: DAST scanners are based on the same concepts that real attackers use for their
    malware. They, therefore, provide reliable feedback on weaknesses. Tests have
    consistently shown that the majority of DAST tools can identify [the top 10 most
    common threats](https://oreil.ly/3MmBn) listed by the OWASP Foundation.
  prefs: []
  type: TYPE_NORMAL
- en: Disadvantages of DAST
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Using DAST tools has several disadvantages:'
  prefs: []
  type: TYPE_NORMAL
- en: The scanners are programmed to carry out specific attacks on functional web
    apps and can usually be adapted only by security experts with the necessary product
    knowledge. They, therefore, offer little space for individual scaling.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: DAST tools are slow; they can take several days to complete their analysis.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: DAST tools find some security gaps very late in the development cycle that could
    have been discovered earlier via SAST. The costs of fixing the related problems
    are therefore higher than they should be.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: DAST scans are based on known bugs. Scanning for new types of attacks takes
    a relatively long time. Therefore, modifying the existing tool is often not possible.
    If it is doable, it requires in-depth knowledge about the attack vector itself
    and how to implement it inside the DAST tool.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Comparing SAST and DAST
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[Table 7-1](#sast_vs_dast) summarizes the differences between the SAST and
    DAST testing approaches.'
  prefs: []
  type: TYPE_NORMAL
- en: Table 7-1\. SAST versus DAST
  prefs: []
  type: TYPE_NORMAL
- en: '| SAST | DAST |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| Clear security testing• The tester has access to the underlying framework,
    design, and implementation.• The application is tested from the inside out.• This
    type of testing represents the developer approach. | Opaque security testing•
    The tester has no knowledge of the technologies or framework that the application
    is built on.• The application is tested from the outside in.• This type of testing
    represents the hacker approach. |'
  prefs: []
  type: TYPE_TB
- en: '| Requires source code• SAST doesn’t require a deployed application.• It analyzes
    the source code or binary without executing the application. | Requires a running
    application• DAST doesn’t require source code or binaries.• It analyzes by executing
    the application. |'
  prefs: []
  type: TYPE_TB
- en: '| Find vulnerabilities earlier in the SDLC• The scan can be executed as soon
    as code is deemed feature complete. | Finds vulnerabilities toward the end of
    the SDLC• Vulnerabilities can be discovered after the development cycle is complete.
    |'
  prefs: []
  type: TYPE_TB
- en: '| Less expensive to fix vulnerabilities• Since vulnerabilities are found earlier
    in the SDLC, remediating them is easier and faster.• Finding can often be fixed
    before the code enters the QA cycle. | More expensive to fix vulnerabilities•
    Since vulnerabilities are found toward the end of the SDLC, remediation often
    gets pushed into the next development cycle.• Critical vulnerabilities may be
    fixed as an emergency release. |'
  prefs: []
  type: TYPE_TB
- en: '| Can’t discover runtime and environmental issues• Since the tool scans static
    code, it cannot discover runtime vulnerabilities. | Can discover runtime and environmental
    issues• Since the tool uses dynamic analysis on a running application, it is able
    to find runtime vulnerabilities. |'
  prefs: []
  type: TYPE_TB
- en: '| Typically supports all kinds of software• Examples include web applications,
    web services, and thick clients. | Typically scans only web apps and web services•
    DAST is not useful for other types of software. |'
  prefs: []
  type: TYPE_TB
- en: If you look at the advantages and disadvantages of these two types of security
    testing, you can see that they are not mutually exclusive. On the contrary, these
    approaches complement each other perfectly. SAST can be used to identify known
    vulnerabilities. DAST can be used to identify vulnerabilities that are not yet
    known. This is primarily the case if the new attack is based on the pattern of
    common vulnerabilities. You also gain knowledge about the overall system if you
    carry out these tests on the production system. However, as soon as you run DAST
    on test systems, you lose these last-mentioned capabilities again.
  prefs: []
  type: TYPE_NORMAL
- en: Interactive Application Security Testing
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '*Interactive application security testing* (IAST) uses software tools to evaluate
    application performance and identify vulnerabilities. IAST takes an “agent-like”
    approach; agents and sensors run to continuously analyze application functions
    during automated tests, manual tests, or a mixture of both.'
  prefs: []
  type: TYPE_NORMAL
- en: 'The process and feedback occur in real-time in the IDE, CI or QA environment,
    or during production. The sensors have access to the following:'
  prefs: []
  type: TYPE_NORMAL
- en: All source code
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Data and control flow
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: System configuration data
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Web components
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Backend connection data
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The main difference between IAST, SAST, and DAST is that IAST runs inside the
    application. Access to all static components as well as the runtime information
    enables a comprehensive picture. It is a combination of static and dynamic analysis.
    However, the part of the dynamic analysis is not a pure opaque test, as it is
    implemented at DAST.
  prefs: []
  type: TYPE_NORMAL
- en: IAST helps identify potential problems earlier, so IAST minimizes the cost of
    eliminating potential costs and delays. This is due to a *shift left* approach,
    meaning it is carried out in the early stages of the project lifecycle. Similar
    to SAST, the IAST analysis provides complete lines of data-rich code so that security
    teams can immediately look out for a specific bug. With the wealth of information
    that the tool has access to, the source of vulnerabilities can be precisely identified.
    Unlike other dynamic software tests, IAST can be easily integrated into CI/CD
    pipelines. The evaluations take place in real time in the production environment.
  prefs: []
  type: TYPE_NORMAL
- en: On the other hand, IAST tools can slow the operation of the application. This
    is because the agents change the bytecode themselves. This leads to a lower performance
    of the overall system. The change itself can also lead to problems in the production
    environment. The use of agents represents a potential source of danger since these
    agents can also be compromised as happened in the SolarWinds hack.
  prefs: []
  type: TYPE_NORMAL
- en: Runtime Application Self-Protection
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '*Runtime application self-protection* (RASP) is the approach to secure the
    application from within. The check takes place at runtime and generally consists
    of looking for suspicious commands when they are executed.'
  prefs: []
  type: TYPE_NORMAL
- en: With the RASP approach, you can examine the entire application context on the
    production machine in real time. Here all commands that are processed are examined
    for possible attack patterns. Therefore, this procedure aims to identify existing
    security gaps and attack patterns and those that are not yet known. Here it goes
    clearly into the use of AI and machine learning (ML) techniques.
  prefs: []
  type: TYPE_NORMAL
- en: RASP tools can usually be used in two operating modes. The first operating mode
    (monitoring) is limited to observing and reporting possible attacks. The second
    operating mode (protection) then includes implementing defensive measures in real
    time and directly on the production environment. RASP aims to fill the gap left
    by application security testing and network perimeter controls. SAST and DAST
    do not have sufficient visibility into real-time data and event flows to prevent
    vulnerabilities from sliding through the verification process or to block new
    threats that were overlooked during development.
  prefs: []
  type: TYPE_NORMAL
- en: RASP is similar to IAST. The main difference is that IAST focuses on identifying
    vulnerabilities in the applications, and RASP focuses on protecting against cybersecurity
    attacks that can exploit these vulnerabilities or other attack vectors.
  prefs: []
  type: TYPE_NORMAL
- en: 'The RASP technology has the following advantages:'
  prefs: []
  type: TYPE_NORMAL
- en: RASP complements SAST and DAST with an additional layer of protection after
    the application is started (usually in production).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: RASP can be easily applied with faster development cycles.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Unexpected entries are checked and identified in RASP.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: RASP enables you to react quickly to an attack by providing comprehensive analysis
    and information about the possible vulnerabilities.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: However, since RASP tools sit on the application server, they can adversely
    affect application performance. In addition, the RASP technology may not be compliant
    with regulations or internal guidelines, because it allows the installation of
    other software or the automatic blocking of services. The use of this technology
    can also give a false sense of security and is not a substitute for application
    security testing, because it cannot provide comprehensive protection. Finally,
    the application must also be switched offline until the vulnerability is eliminated.
  prefs: []
  type: TYPE_NORMAL
- en: While RASP and IAST have similar methods and uses, RASP does not perform extensive
    scans but instead runs as part of the application to examine traffic and activity.
    Both report attacks as soon as they occur; with IAST, this happens at the time
    of the test, whereas with RASP, it takes place at runtime in production.
  prefs: []
  type: TYPE_NORMAL
- en: SAST, DAST, IAST, and RASP Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: All approaches result in a wide range of options for arming yourself against
    known and unknown security gaps. Reconciling your own needs and those of the company
    is essential when choosing your approach.
  prefs: []
  type: TYPE_NORMAL
- en: With RASP, the application can protect itself against attacks at runtime. The
    permanent monitoring of your activities and the data transferred to the application
    enable an analysis based on the runtime environment. Here you can choose between
    pure monitoring or alerting, and active self-protection. However, software components
    are added to the runtime environment with RASP approaches to manipulate the system
    independently. This has an impact on performance. With this approach, RASP concentrates
    on the detection and defense of current cyberattacks. So it analyzes the data
    and user behavior in order to identify suspicious activities.
  prefs: []
  type: TYPE_NORMAL
- en: The IAST approach combines the SAST and DAST approaches and is already used
    within the SDLC—that is, within the development itself. This means that the IAST
    tools are already further “to the left” compared to the RASP tools. Another difference
    to the RASP tools is that IAST consists of static, dynamic, and manual tests.
    Here it also becomes clear that IAST is more in the development phase. The combination
    of dynamic, static, and manual tests promises a comprehensive security solution.
    However, we should not underestimate the complexity of the manual and dynamic
    security tests at this point.
  prefs: []
  type: TYPE_NORMAL
- en: The DAST approach focuses on how a hacker would approach the system. The overall
    system is viewed as opaque, and the attacks occur without knowing the technologies
    used. The point here is to harden the production system against the most common
    vulnerabilities. However, we must not forget at this point that this technology
    can be used only at the end of the production cycle.
  prefs: []
  type: TYPE_NORMAL
- en: If you have access to all system components, the SAST approach can be used effectively
    against known security gaps and license problems. This procedure is the only guarantee
    that the entire tech stack can be subjected to direct control. The focus of the
    SAST approach is on static semantics and, in turn, is completely blind to security
    holes in the dynamic context. A huge advantage is that this approach can be used
    with the first line of source code.
  prefs: []
  type: TYPE_NORMAL
- en: In my experience, if you start with DevSecOps or security in IT in general,
    the SAST approach makes the most sense. This is where the greatest potential threat
    can be eliminated with minimal effort. It is also a process that can be used in
    all steps of the production line. Only when all components in the system are secured
    against known security gaps do the following methods show their highest potential.
    After introducing SAST, I would use the IAST approach and, finally, the RASP approach.
    This also ensures that the respective teams can grow with the task and that no
    obstacles or delays occur in production.
  prefs: []
  type: TYPE_NORMAL
- en: The Common Vulnerability Scoring System
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The basic idea behind the *Common Vulnerability Scoring System* (CVSS) is to
    provide a general classification of the severity of a security vulnerability.
    The weak points found are evaluated from various points of view. These elements
    are weighed against each other to obtain a standardized number from 0 to 10.
  prefs: []
  type: TYPE_NORMAL
- en: A rating system, like CVSS, allows us to evaluate various weak points abstractly
    and derive follow-up actions from them. The focus is on standardizing the handling
    of these weak points. As a result, you can define actions based on the value ranges.
  prefs: []
  type: TYPE_NORMAL
- en: In principle, CVSS can be described so that the probability and the maximum
    possible damage are related using predefined factors. The basic formula for this
    is risk = probability of occurrence × damage.
  prefs: []
  type: TYPE_NORMAL
- en: These CVSS metrics are divided into three orthogonal areas that are weighted
    differently from one another, called Basic Metrics, Temporal Metrics, and Environmental
    Metrics. Different aspects are queried in each area, which must be assigned a
    single value. The weighting and the subsequent composition of the three group
    values gives the final result. The next section explores these metrics in detail.
  prefs: []
  type: TYPE_NORMAL
- en: CVSS Basic Metrics
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The *basic metrics* form the foundation of the CVSS rating system. The aim of
    querying aspects in this area is to record technical details of the vulnerability
    that will not change over time, so the assessment is independent of other changing
    elements. Different parties can carry out the calculation of the base value. It
    can be done by the discoverer, the manufacturer of the project or product concerned,
    or by a computer emergency response team (CERT) charged with eliminating this
    weak point. We can imagine that, based on this initial decision, the value itself
    will turn out different since the individual groups pursue different goals.
  prefs: []
  type: TYPE_NORMAL
- en: The base value evaluates the prerequisites necessary for a successful attack
    via this security gap. This is the distinction between whether a user account
    must be available on the target system or whether the system can be compromised
    without the knowledge about a system user. These prerequisites play a significant
    role in whether a system is vulnerable over the internet or whether physical access
    to the affected component is required.
  prefs: []
  type: TYPE_NORMAL
- en: The base value should also reflect how complex the attack is to carry out. In
    this case, the complexity relates to the necessary technical steps and includes
    assessing whether the interaction with a regular user is essential. Is it sufficient
    to encourage any user to interact, or does this user have to belong to a specific
    system group (e.g., administrator)? The correct classification is not a trivial
    process; the assessment of a new vulnerability requires exact knowledge of this
    vulnerability and the systems concerned.
  prefs: []
  type: TYPE_NORMAL
- en: 'The basic metrics also take into account the damage that this attack could
    cause to the affected component. The three areas of concern are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Confidentiality
  prefs: []
  type: TYPE_NORMAL
- en: Possibility of extracting the data from the system
  prefs: []
  type: TYPE_NORMAL
- en: Integrity
  prefs: []
  type: TYPE_NORMAL
- en: Possibility of manipulating the system
  prefs: []
  type: TYPE_NORMAL
- en: Availability
  prefs: []
  type: TYPE_NORMAL
- en: Completely preventing the system’s use
  prefs: []
  type: TYPE_NORMAL
- en: However, you have to be careful concerning the weighting of these areas of concern.
    In one case, having stolen data can be worse than changed data. In another case,
    the unusability of a component can be the worst damage to be assumed.
  prefs: []
  type: TYPE_NORMAL
- en: The *scope metric* has also been available since CVSS version 3.0\. This metric
    looks at the effects of an affected component on other system components. For
    example, a compromised element in a virtualized environment enables access to
    the carrier system. A successful change of this scope represents a greater risk
    for the overall system and is therefore also evaluated using this factor. This
    demonstrates that the interpretation of the values also requires adjusting to
    one’s situation, which brings us to the temporal and environment metrics.
  prefs: []
  type: TYPE_NORMAL
- en: CVSS Temporal Metrics
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The time-dependent components of the vulnerability assessment are brought together
    in the *temporal metrics* group.
  prefs: []
  type: TYPE_NORMAL
- en: The elements that change over time influence these temporal metrics. For example,
    the availability of tools that support the exploitation of the vulnerability may
    change. These can be exploits code or step-by-step instructions. A distinction
    must be made on whether a vulnerability is theoretical or whether a manufacturer
    has officially confirmed it. All of these events change the base value.
  prefs: []
  type: TYPE_NORMAL
- en: Temporal metrics are unique in that the base value can be only reduced and not
    increased. The initial rating is intended to represent the worst-case scenario.
    This has both advantages and disadvantages if you bear in mind that it is during
    the initial assessment of a vulnerability that interests are competing.
  prefs: []
  type: TYPE_NORMAL
- en: The influence on the initial evaluation comes about through external framework
    conditions. These take place over an undefined time frame and are not relevant
    for the actual basic assessment. Even if an exploit is already in circulation
    during the base values survey, this knowledge will not be included in the primary
    assessment. However, the base value can only be reduced by the temporal metrics.
  prefs: []
  type: TYPE_NORMAL
- en: And this is where a conflict arises. The person or group who has found a security
    gap tries to set the base value as high as possible. A high-severity loophole
    will sell for a higher price and receive more media attention. The reputation
    of the person/group who found this gap increases as a result. The affected company
    or the affected project is interested in exactly the opposite assessment. Therefore,
    it depends on who finds the security gap, how the review process should take place,
    and by which body the first evaluation is carried out. This value is further adjusted
    by the environmental metrics.
  prefs: []
  type: TYPE_NORMAL
- en: CVSS Environmental Metrics
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: For *environmental metrics*, your own system landscape is used to evaluate the
    risk of the security gap. The evaluation is adjusted based on the real situation.
    In contrast to temporal metrics, environmental metrics can correct the base value
    in both directions. The environment can therefore lead to a higher classification
    and must also be constantly adapted to your own environment changes.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s take an example of a security hole that has an available patch from the
    manufacturer. The mere presence of this modification leads to a reduction of the
    total value in the temporal metrics. However, as long as the patch has not been
    activated in your own systems, the overall value must be drastically corrected
    upward again via the environmental metrics. This is because as soon as a patch
    is available, it can be used to better understand the security gap and its effects.
    The attacker has more detailed information that can be exploited, which reduces
    the resistance of the not-yet-hardened systems.
  prefs: []
  type: TYPE_NORMAL
- en: At the end of an evaluation, the final score is obtained, calculated from the
    three previously mentioned values. The resulting value is then assigned to a value
    group. But one more point is often overlooked. In many cases, the final score
    is simply carried over without individual adjustments utilizing the environmental
    score. This behavior leads to a dangerous evaluation that is incorrect for the
    overall system concerned.
  prefs: []
  type: TYPE_NORMAL
- en: CVSS in Practice
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: With CVSS, we have a system for evaluating and rating security gaps in software.
    Since there are no alternatives, CVSS has become a de facto standard; the system
    has been in use worldwide for over 10 years and is constantly being developed.
    The evaluation consists of three components.
  prefs: []
  type: TYPE_NORMAL
- en: First, the basic score depicts a purely technical worst-case scenario. The second
    component is the evaluation of the time-dependent corrections based on external
    influences—including further findings, tools, or patches for this security gap—which
    can be used to reduce the value. The third component of the assessment is your
    own system environment with regard to this vulnerability. With this consideration,
    the security gap is adjusted in relation to the real situation on site. Last but
    not least, an overall evaluation is made from these three values, which results
    in a number from 0.0 to 10.0.
  prefs: []
  type: TYPE_NORMAL
- en: This final value can be used to control your own organizational response to
    defend against the security gap. At first glance, everything feels quite abstract,
    so it takes some practice to get a feel for the application of CVSS, which can
    be developed through experience with your own systems.
  prefs: []
  type: TYPE_NORMAL
- en: Scoping Security Analysis
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'As soon as we deal with security, the following questions always come up: how
    much effort is enough, where should you start, and how quickly can you get the
    first results? In this section, we deal with how to take these first steps. For
    this, we look at two concepts and consider the associated effects.'
  prefs: []
  type: TYPE_NORMAL
- en: Time to Market
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: You have probably heard of the term *time to market*, but how does this relate
    to security? In general terms, this expression means that the desired functionality
    is transferred as quickly as possible from conception through development into
    the production environment. This allows the customer to start benefiting from
    the new functionality, which increases business value.
  prefs: []
  type: TYPE_NORMAL
- en: At first glance, time to market seems focused on business use cases only, but
    it is equally relevant when applied to security remediation. Activating the required
    modifications to the overall system as quickly as possible is also optimal. In
    short, the term *time to market* is a common and worthwhile goal for security
    implementation.
  prefs: []
  type: TYPE_NORMAL
- en: The process for business use cases should be the same as remediating security
    vulnerabilities. They both require as much automation as possible, and all human
    interaction must be as short as possible. All interactions that waste time increase
    the potential that the vulnerability will be used against the production system.
  prefs: []
  type: TYPE_NORMAL
- en: Make or Buy
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Across all layers of a cloud native stack, the majority of the software and
    technology is bought or acquired rather than made. We will go through the layers
    in [Figure 7-1](#make_or_buy) and talk about the software composition at each.
  prefs: []
  type: TYPE_NORMAL
- en: '![Architecture diagram of a DevSecOps implementation](Images/dtjd_0701.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 7-1\. DevSecOps components that you can decide to build or purchase
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: The first layer is the development of the application itself. Assuming that
    we are working with Java and using Maven as a dependency manager, we are most
    likely adding more lines of code indirectly as dependencies compared to the number
    of lines we are writing ourselves. The dependencies are the more prominent part,
    and third parties develop them. We have to be careful, and it is good advice to
    check these external binaries for known vulnerabilities. We should have the same
    behavior regarding compliance and license usage.
  prefs: []
  type: TYPE_NORMAL
- en: The next layer is the operating system, which is typically Linux. And again,
    we are adding configuration files, and the rest are existing binaries. The result
    is an application running inside the operating system that is a composition of
    external binaries based on our configuration.
  prefs: []
  type: TYPE_NORMAL
- en: The two following layers, Docker and Kubernetes, lead us to the same result.
    Until now, we are not looking at the tool stack for the production line itself.
    All programs and utilities that are directly or indirectly used under the hood
    for DevSecOps create dependencies. All layers’ dependencies are the most significant
    part by far. Checking these binaries against known vulnerabilities is the first
    logical step.
  prefs: []
  type: TYPE_NORMAL
- en: One-Time and Recurring Efforts
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Comparing the effort of scanning against known vulnerabilities and for compliance
    issues, we see a few differences. Let’s start with the compliance issues.
  prefs: []
  type: TYPE_NORMAL
- en: Compliance issues
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The first step in scoping compliance is defining which licenses are allowed
    at which part of the production line. This definition of allowed licenses includes
    the dependencies during development and the usage of tools and runtime environments.
    Defining the noncritical license types should be checked by a specialized compliance
    process. With this list of allowed license types, we can start using the build
    automation to scan the full tool stack on a regular basis. After the machine has
    found a violation, we have to remove this element, and it must be replaced by
    another that is licensed.
  prefs: []
  type: TYPE_NORMAL
- en: Vulnerabilities
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The ongoing effort to scan for vulnerabilities is low compared to the amount
    of work required to fix vulnerabilities. A slightly different workflow is needed
    for the handling of discovered vulnerabilities. With more significant preparations,
    the build automation can do the work on a regular basis as well. The identification
    of a vulnerability will trigger a workflow that includes human interaction. The
    vulnerability must be classified internally, which leads to a decision about the
    next action to take.
  prefs: []
  type: TYPE_NORMAL
- en: How Much Is Enough?
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: So let’s come back to the initial question in this section. How much scanning
    is enough? No change is too small, because all changes that have to do with adding
    or changing dependencies will cause you to reevaluate the security and run a new
    scan. Checking for known vulnerabilities or checking the license being used can
    be carried out efficiently by automation.
  prefs: []
  type: TYPE_NORMAL
- en: Another point that should not be underestimated is that the quality with which
    such an examination is carried out is constant, as nobody is involved at this
    point. If the value chain’s speed is not slowed by constantly checking all dependencies,
    this is a worthwhile investment.
  prefs: []
  type: TYPE_NORMAL
- en: Compliance Versus Vulnerabilities
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: One other difference exists between compliance issues and vulnerabilities. If
    a compliance issue exists, it is a singular point inside the overall environment.
    Just this single part is a defect and is not influencing other elements of the
    environment, as shown in [Figure 7-2](#compliance).
  prefs: []
  type: TYPE_NORMAL
- en: '![Circle diagram showing compliance issues in single layers of an application](Images/dtjd_0702.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 7-2\. Layers of an application where compliance issues can be found
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Vulnerabilities Can Be Combined into Different Attack Vectors
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Vulnerabilities are a bit different. They do not exist only at the point where
    they are located. Additionally, they can be combined with other existing vulnerabilities
    in any additional layer of the environment, as shown in [Figure 7-3](#vulnerabilities).
    Vulnerabilities can be combined into different attack vectors. Every possible
    attack vector itself must be seen and evaluated. A set of minor vulnerabilities
    in different layers of the application can be combined into a highly critical
    risk.
  prefs: []
  type: TYPE_NORMAL
- en: '![Circle diagram showing attack vectors across multiple layers of an application](Images/dtjd_0703.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 7-3\. Vulnerabilities in multiple layers of an application
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'Vulnerabilities: Timeline from Inception Through Production Fix'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Again and again, we read something in the IT news about security gaps that have
    been exploited. The more severe the classification of this loophole, the more
    attention this information will get in the general press. Most of the time, we
    hear and read nothing about all the security holes found that are not as well-known
    as the SolarWinds hack. The typical timeline of a vulnerability is shown in [Figure 7-4](#vulnerability-timeline).
  prefs: []
  type: TYPE_NORMAL
- en: '![Timeline showing the lifecycle of a vulnerability](Images/dtjd_0704.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 7-4\. Timeline of a vulnerability
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Creation of a vulnerability
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Let’s start with the birth of a vulnerability. This can be done in two ways.
    On the one hand, it can happen to any developer who has an unfortunate combination
    of source code pieces that creates a security hole. On the other hand, it can
    also be based on targeted manipulation. However, this has essentially no effect
    on the further course of the lifeline of a security vulnerability. In the following,
    we assume that a security hole has been created and that it is now active in some
    software. These can be executable programs or libraries integrated into other
    software projects as a dependency.
  prefs: []
  type: TYPE_NORMAL
- en: Discovery of the vulnerability
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In most cases, it is not possible to understand precisely when a security hole
    was created, but let’s assume that a security hole exists and that at some point
    it will be discovered. A few different scenarios could occur, depending on who
    finds the security hole first.
  prefs: []
  type: TYPE_NORMAL
- en: If a malicious actor finds the security hole, they will probably try to keep
    it a secret so they can profit from it. The two ways to profit are either to exploit
    the security hole themselves or to sell information about the security hole to
    an interested party. In either case, the quicker they are able to profit from
    the security hole, the less likely it is discovered and patched.
  prefs: []
  type: TYPE_NORMAL
- en: Conversely, if the security hole is found by ethical attackers, they will first
    verify that the security hole can be exploited without doing any damage, and then
    disclose it to the affected parties. Often a financial motivation exists for this
    as well. These can be driven by bug bounties and rewards by companies aware of
    their potential for security holes and willing to pay to have them disclosed to
    the company rather than to attackers. Also, companies that maintain vulnerability
    databases are incentivized to find security holes and disclose them to their customer
    base in advance of making them publicly known.
  prefs: []
  type: TYPE_NORMAL
- en: And yet another possibility is that the company discovers the security vulnerability
    by itself. In this case, the company may be inclined to either hide the vulnerability
    or present it as harmless. However, the best approach is to fix the vulnerability
    as soon as possible, because a malicious actor could soon discover the vulnerability
    or perhaps already knows about it and is waiting to exploit it.
  prefs: []
  type: TYPE_NORMAL
- en: Regardless of the route via which the knowledge comes to the vulnerability databases,
    only when the information has reached one of these points can we assume that this
    knowledge will be available to the general public over time.
  prefs: []
  type: TYPE_NORMAL
- en: Public availability of the vulnerability
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Each provider of security vulnerabilities has a subset of all publicly disclosed
    vulnerabilities. To get a more holistic set of vulnerabilities, you need to aggregate
    multiple sources. Furthermore, since the vulnerability databases are constantly
    being updated, this needs to be an automated process.
  prefs: []
  type: TYPE_NORMAL
- en: It is also crucial that the vulnerabilities are processed in such a way that
    further processing by machines is possible. Critical meta-information such as
    the CVE or the CVSS value needs to be included. For example, the CVSS value can
    be used in CI environments to interrupt further processing when a specific threshold
    value is reached.
  prefs: []
  type: TYPE_NORMAL
- en: As an end user, there is really only one way to go here. Instead of contacting
    the providers directly, you should rely on services that integrate a wide variety
    of sources and offer a processed and merged database. Since the information generally
    represents a considerable financial value, commercial providers of such data sets
    invest a lot of resources to make sure it is accurate and up-to-date.
  prefs: []
  type: TYPE_NORMAL
- en: Fixing the vulnerability in production
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Once the information is publicly disclosed and made available to you through
    one of many security providers, you can start to take action. The key factor is
    the amount of time it takes for your organization to identify and mitigate the
    security vulnerability.
  prefs: []
  type: TYPE_NORMAL
- en: The first step is the consumption of the vulnerability from your chosen security
    provider. This is hopefully fully automated with an API that you can use to consume
    vulnerabilities, security scanners that are continuously scanning your production
    deployments, and reporting that notifies you quickly about any new vulnerabilities.
  prefs: []
  type: TYPE_NORMAL
- en: The next step is to develop, test, and deploy a fix that solves the security
    vulnerability. Only those who have implemented a high degree of automation can
    enable short response times in the delivery processes. It is also an advantage
    if the team concerned can easily make the necessary decisions. Lengthy approval
    processes are counterproductive at this point and can also cause extensive damage
    to the company.
  prefs: []
  type: TYPE_NORMAL
- en: Another point that can improve the response time is to catch security vulnerabilities
    in earlier stages of development. By providing security information in all production
    stages, vulnerabilities can be caught earlier, lowering the cost of mitigation.
    We’ll come back to this in more detail in [“Shift Security Left”](#shift-left-sect).
  prefs: []
  type: TYPE_NORMAL
- en: Test Coverage Is Your Safety Belt
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The best knowledge of security gaps is of no use if this knowledge cannot be
    put to use. But what tools do you have in software development to take efficient
    action against known security gaps? I want to highlight one metric in particular:
    the test coverage of your own source code parts. If you have strong test coverage,
    you can make changes to the system and rely on the test suite. If a smooth test
    of all affected system components has taken place, nothing stands in the way of
    making the software available from a technical point of view.'
  prefs: []
  type: TYPE_NORMAL
- en: But let’s take a closer look at the situation. In most cases, known security
    vulnerabilities are removed by changing the version used for the same dependency.
    Therefore, efficient version management gives you the agility you need to be able
    to react quickly. In very few cases, the affected components have to be replaced
    by semantic equivalents from other manufacturers. And to classify the new composition
    of versions of the same components as valid, strong test coverage is required.
    Manual tests would go far beyond the time frame and cannot be carried out with
    the same quality in every run. Mutation testing gives you much more concrete test
    coverage than is usually the case with the conventional line or branch coverage.
  prefs: []
  type: TYPE_NORMAL
- en: To get a picture of the full impact graph based on all known vulnerabilities,
    it is crucial to understand all package managers included by the dependencies.
    Focusing on just one layer in the tech stack is by far not enough. Package managers
    like Artifactory provide information, including vendor-specific metadata. This
    can be augmented with security scanning tools like JFrog Xray that consume this
    knowledge and can scan all binaries hosted inside the repositories managed by
    your package manager.
  prefs: []
  type: TYPE_NORMAL
- en: Quality Gate Methodology
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: With respect to a security response, the success of IT projects is dependent
    on participation and involvement of end users as early as possible, the support
    of higher management, and the formulation of clear business goals. By managing
    these factors, a software project can quickly address security vulnerabilities
    and mitigate risk to the corporation.
  prefs: []
  type: TYPE_NORMAL
- en: 'The demand for comprehensive support from higher management provides, among
    other things, systematic control of the quality and progress of IT projects in
    good time by using criteria in order to be able to intervene. By specifying criteria,
    management has two ways of controlling the software development process:'
  prefs: []
  type: TYPE_NORMAL
- en: The criteria are project management specifications that the developer must adhere
    to.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Project management can intervene in the event of a deviation from the defined
    target.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The group responsible for setting and enforcing these criteria can be different
    depending on the management system. The distribution of roles is also controversially
    discussed again and again. However, it turns out that a more substantial involvement
    of all team members leads to dynamic and successful structures.
  prefs: []
  type: TYPE_NORMAL
- en: In the context of project control, measures can be taken to counteract undesirable
    developments within a project. The ideal case for project participants is that
    security risks do not impact the continuation of the project. In extreme cases,
    however, it is also possible to cancel the project. Timeliness means being able
    to take action before significant financial damage can occur.
  prefs: []
  type: TYPE_NORMAL
- en: At the same time, however, this presupposes that relevant and measurable results
    are available to make effective project control sensible and possible. The end
    of activity within a project is a suitable time for this, as results are available
    that can be checked. However, because of the large number of activities within
    a project, too frequent checks by the project management team would slow the project’s
    progress. In addition, there would be a more significant burden on project management
    with many parallel projects (which would all have to be monitored).
  prefs: []
  type: TYPE_NORMAL
- en: A middle ground is to establish control and steering at specific significant
    points as binding for each project. For this purpose, quality gates offer an opportunity
    to check the degree of fulfillment of the individual quality goals. A *quality
    gate* is a special point in time in a project at which a decision about the continuation
    or termination of a project is made based on a formal examination of quality-related
    criteria.
  prefs: []
  type: TYPE_NORMAL
- en: 'Metaphorically speaking, quality gates are barriers between the various process
    steps of a project: once the quality gate has been reached, a project can be continued
    only if all criteria, or at least a sufficiently large number of criteria, are
    met. This ensures that all results of the project at the time of the quality gate
    are good enough to be able to continue working with them. Using the criteria of
    a quality gate, the results on the one hand and the qualitative requirements for
    the results on the other can be determined. They can then be used to define the
    interfaces between individual project phases. To establish quality gates, certain
    structures, activities, roles, documents, and resources are necessary, which are
    summarized in a quality gate reference process.'
  prefs: []
  type: TYPE_NORMAL
- en: The precise design of the quality gate reference process is based on the company’s
    needs. Quality gates have their origins in automobile development and in the production
    of technical goods, but they have increasingly found their way into system development
    projects and recently also into pure software development projects.
  prefs: []
  type: TYPE_NORMAL
- en: Quality gates in series production rely on statistically determined values that
    can be used as a target for control activities in future projects. Such a starting
    position does not exist in software development, since software development projects
    are highly individual. As a result, a quality gate reference process practiced
    in assembly-line production can be transferred to software development to only
    a limited extent. Instead, a suitable quality gate reference process must be designed
    differently in order to do justice to the particular problems of software development.
    However, it makes sense to use the quality gate reference processes from other
    domains as they have been developed and optimized over the years.
  prefs: []
  type: TYPE_NORMAL
- en: Quality Gate Strategies
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: When using quality gates, two basic strategies have been identified. Depending
    on the objective, a company can choose one of these two strategies, described
    next, when designing a quality gate reference process.
  prefs: []
  type: TYPE_NORMAL
- en: Quality gates as uniform quality guideline
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In the first approach, every project has to go through the same quality gates
    and is measured against the same criteria. The adaptation of a quality gate reference
    process that follows this strategy is permissible to a minimal extent (if at all).
    The aim is to achieve at least the same level of quality in every project; a qualitative
    guideline is thus established for every project.
  prefs: []
  type: TYPE_NORMAL
- en: Quality gates can therefore be used as a uniform measure of progress. We can
    compare progress between projects by checking which tasks have already passed
    a particular quality gate and which have not. Management can easily recognize
    when a project is behind another project (qualitatively) and act accordingly.
    Quality gates can thus easily be used as an instrument for multiproject management.
  prefs: []
  type: TYPE_NORMAL
- en: Quality gates as a flexible quality strategy
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In the second approach, the number, arrangement, and selection of quality gates
    or criteria can be adapted to the needs of a project. Quality gates and standards
    can thus be tailored more precisely to a project’s qualitative requirements, improving
    the quality of results. However, this makes comparing multiple projects more difficult.
    Fortunately, similar projects will have comparable quality gates and can be measured
    against similar criteria.
  prefs: []
  type: TYPE_NORMAL
- en: Researching the topic of quality gates on the internet and in the literature
    (dissertations, standard works, and conference volumes) reveals a wide range of
    terms. Because synonymous terms are used in many places, quality gates are often
    mistakenly equated with various other concepts. A *review* or *milestone*, for
    example, should not be equated with a quality gate.
  prefs: []
  type: TYPE_NORMAL
- en: Fit with Project Management Procedures
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The question arises whether this methodology can be applied to other project
    management processes. The answer here is a resounding yes. The quality gate methodology
    can be integrated into cyclical as well as acyclical project methods. The time
    sequence is irrelevant at this point and can therefore also be used in classic
    waterfall projects at the milestone level.
  prefs: []
  type: TYPE_NORMAL
- en: The significant advantage is that this method can still be used in the case
    of a paradigm shift in project management. The knowledge built up in a team can
    continue to be used and does not lose its value. This means that the measures
    described here can be introduced and used regardless of the current project implementation.
  prefs: []
  type: TYPE_NORMAL
- en: Implementing Security with the Quality Gate Method
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We will introduce, define, and use a greatly simplified approach to integrate
    the crosscutting issue of security. In the following, we assume that the quality
    gate methodology is suitable for implementing any cross-sectional topic. The temporal
    component is also irrelevant and can therefore be used in any cyclical project
    management methodology. This approach is therefore ideally suited for integration
    into the DevSecOps project organization methodology.
  prefs: []
  type: TYPE_NORMAL
- en: The DevOps process is divided into stages. The individual phases are seamlessly
    connected to one another. It makes no sense to install something at these points
    that interferes with the entire process. However, there are also much better places
    where cross-cutting issues are located. We are talking about the automated process
    derivation that can be found in a CI route. Assuming that the necessary process
    steps to go through a quality gate can be fully automated, a CI route is ideal
    for doing this regularly occurring work.
  prefs: []
  type: TYPE_NORMAL
- en: Assuming that the CI line carries out an automated process step, two results
    can occur.
  prefs: []
  type: TYPE_NORMAL
- en: 'Green: Quality gate has passed'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: One possible result of this processing step is that all checks have passed successfully.
    Processing can continue uninterrupted at this point. Only a few log entries are
    made to ensure complete documentation.
  prefs: []
  type: TYPE_NORMAL
- en: 'Red: Failed the quality gate'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Another possible result is that the check has found something indicating a failure.
    This interrupts the process, and the cause of the failure must be identified,
    as well as a way to remediate it. The automatic process usually ends at this point
    and is replaced by a manual process.
  prefs: []
  type: TYPE_NORMAL
- en: Risk Management in Quality Gates
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Since the quality gate is blocked by identifying a defect, someone needs to
    be responsible for the following steps:'
  prefs: []
  type: TYPE_NORMAL
- en: Risk assessment (identification, analysis, assessment, and prioritization of
    risks)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Design and initiation of countermeasures
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Tracking of risks in the course of the project
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The risk determination was already completed with the creation of the criteria
    and their operationalization by weighing the requirements on a risk basis. This
    takes place during the gate review itself.
  prefs: []
  type: TYPE_NORMAL
- en: The conception and initiation of countermeasures is an essential activity of
    a gate review, at least in the event that a project is not postponed or canceled
    before going to production. The countermeasures to be taken primarily counteract
    the risks that arise from criteria that are not met.
  prefs: []
  type: TYPE_NORMAL
- en: The countermeasures of risk management can be divided into preventive measures
    and emergency measures. The *preventive measures* include meeting the criteria
    as quickly as possible. If this is not possible, appropriate countermeasures must
    be designed. The design of the countermeasures is a creative act; it depends on
    the risk, its assessment, and the possible alternatives.
  prefs: []
  type: TYPE_NORMAL
- en: The effectiveness of the countermeasures must be tracked to ensure that they
    are successful. This spans all phases of the project and is critical to ensuring
    that security vulnerabilities are caught and addressed early in the process.
  prefs: []
  type: TYPE_NORMAL
- en: Practical Applications of Quality Management
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Let’s go through a practical example of quality management in the context of
    a software release. For this purpose, all required components are generated and
    collected in the repository, and every binary has an identity and version. All
    elements necessary for a release are put together in a deployment bundle after
    they have been created successfully. In this case, a release is a composition
    of different binaries in their respective versions. The technology plays a subordinate
    role here, as the most diverse artifacts can come together in a release.
  prefs: []
  type: TYPE_NORMAL
- en: You can also imagine that all crucial documents are part of this compilation
    at this point. This can include documents such as the release notes and build
    information that provides information about the manufacturing process itself—for
    example, which JDK was used on which platform and much more. All information that
    can be automatically collated at this point increases the traceability and reproduction
    quality if a postmortem analysis has to be carried out.
  prefs: []
  type: TYPE_NORMAL
- en: We now have everything together and would like to start making the artifacts
    available. We are talking about promoting the binaries here. This can be done
    in your own repositories or generally available global repositories. Now the last
    time has come when you can still make changes.
  prefs: []
  type: TYPE_NORMAL
- en: We are talking about a security check as a promotional gateway. The tools used
    here should finally check two things. First, known vulnerabilities in the binaries
    need to be removed. Second, all the licenses used in all the artifacts contained
    must be adequate for the purpose. What becomes immediately clear here is the need
    for the check to be carried out independently of the technology used. This brings
    us back to the full impact graph. At this point, we have to get the full impact
    graph in order to be able to achieve a high-quality result. The repository manager,
    who is responsible for providing all dependent artifacts, must be seamlessly integrated
    with the binary scanner. One example is the combination of Artifactory and Xray.
  prefs: []
  type: TYPE_NORMAL
- en: But is a security check a gateway for the promotion of binaries at the earliest
    possible time? Where can you start earlier? We now come to the concept of shift
    left.
  prefs: []
  type: TYPE_NORMAL
- en: Shift Security Left
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Agile development, DevOps, and the implementation of security have long been
    considered mutually exclusive. Classic development work was always confronted
    with the problem that the security of a software product could not be adequately
    defined as a final, static, end state. This is the *security paradox* in software
    development.
  prefs: []
  type: TYPE_NORMAL
- en: It may seem that Agile development is too dynamic to be able to carry out a
    detailed security analysis of the software product to be developed in every development
    cycle. The opposite is the case because Agile and secure development techniques
    complement each other very well. One of the key points of Agile development is
    the ability to implement changes on short notice as well as changes to requirements
    within a short period of time.
  prefs: []
  type: TYPE_NORMAL
- en: In the past, security has tended to be viewed as a static process. Accordingly,
    application of Agile concepts to the security domain is required. The general
    handling of security requirements must adapt to this development in order to be
    able to be implemented efficiently. However, we must note that Agile development
    is feature-oriented. Security requirements are mostly from the category of nonfunctional
    features, though, and are therefore available in only an implicitly formulated
    form in most cases. The consequence of this, in combination with faulty security
    requirements engineering results, is miscalculated development cycles with increased
    time pressure; the sprint is canceled because of incorrect budget calculations,
    increased technical debts, persistent weak points, or specific security gaps within
    the codebase.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s now focus on how the necessary conditions can be created in an Agile development
    team that improves the codebase’s security level as early as possible. Regardless
    of the specific project management method used, the following approaches are not
    restricted in their validity.
  prefs: []
  type: TYPE_NORMAL
- en: It is essential to set the security level so that the respective development
    team should achieve a security increment when performing a product increment.
    A team with an implicit and pronounced security focus can immediately gain a different
    level of security than a team without this focus. Regardless of the experience
    of each team, a general minimum standard must be defined and adhered to.
  prefs: []
  type: TYPE_NORMAL
- en: The [OWASP Top 10](https://owasp.org/Top10) is a list of general security vulnerabilities
    that developers can avoid with simple measures. Accordingly, they serve as an
    introduction to the topic and should be part of every developer’s security repertoire.
    However, code reviews often reveal that teams are not adequately considering the
    top 10, so this is a good area to focus teams on improvement.
  prefs: []
  type: TYPE_NORMAL
- en: It should also be recognized that developers can do an excellent job in their
    field but are not security experts. In addition to different levels of experience,
    developers and security experts have different approaches and ways of thinking
    that are decisive for their respective tasks. Therefore, the development team
    must be aware of their limitations with regard to the assessment of attack methods
    and security aspects. When developing critical components or in the event of problems,
    the organizational option of calling in a security expert must therefore be determined
    in advance. Nevertheless, developers should generally be able to evaluate typical
    security factors and take simple steps to improve the security of the code.
  prefs: []
  type: TYPE_NORMAL
- en: Ideally, each team has a member who has both development and detailed security
    knowledge. In the context of supported projects, the relevant employees are referred
    to as security managers (SecMs). They monitor the security aspects of the developed
    code sections, define the attack surface and attack vectors in each development
    cycle, support you in assessing the user stories’ effort, and implement mitigation
    strategies.
  prefs: []
  type: TYPE_NORMAL
- en: To get a global overview of the codebase and its security level, aiming for
    a regular exchange between the SecMs of the teams involved makes sense. Since
    a company-wide synchronization of the development cycle phases is unrealistic,
    SecMs should meet at regular, fixed times. In small companies or with synchronized
    sprints, the teams particularly benefit from an exchange during development cycle
    planning. In this way, cross-component security aspects and the effects of the
    development cycle on the security of the product increment can be assessed. The
    latter can currently be achieved only through downstream tests. Based on the development
    cycle review, a SecM meeting should also occur after implementing new components.
    In preparation for the next sprint, the participants evaluate the security level
    according to the increment.
  prefs: []
  type: TYPE_NORMAL
- en: OWASP Security Champions are implemented differently. These are often developers,
    possibly junior developers, who acquire additional security knowledge that can
    be very domain-specific depending on experience. Conceptual overlap occurs with
    the SecMs; however, a key difference is that a SecM is a full-fledged security
    expert with development experience who acts on the same level as the senior developer.
    When implementing secure software, however, it is crucial to take into account
    the security-relevant effects of implementation decisions and cross-thematic specialist
    knowledge.
  prefs: []
  type: TYPE_NORMAL
- en: Regardless of whether a team can create a dedicated role, basic measures should
    be taken to support the process of developing secure software. These are the following
    best practice recommendations and empirical values.
  prefs: []
  type: TYPE_NORMAL
- en: Not All Clean Code Is Secure Code
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '*Clean Code* by Robert Martin (Pearson), also known as Uncle Bob, coined the
    term *clean code*. However, a common misconception among decision makers is that
    clean code also covers the security of the code.'
  prefs: []
  type: TYPE_NORMAL
- en: Safe and clean code overlap but are not the same. *Clean code* promotes understandability,
    maintainability, and reusability of code. *Secure code*, on the other hand, also
    requires predefined specifications and compliance with them. However, clean code
    is often a requirement for safe code. The code can be written cleanly without
    any security features. However, only a clean implementation opens up the full
    potential for security measures.
  prefs: []
  type: TYPE_NORMAL
- en: Well-written code is also easier to secure because the relationships between
    components and functions are clearly defined and delimited. Any development team
    looking for reasons to promote adherence to and implementation of the clean code
    principles will find good arguments in the security of the code, which can also
    be explained economically to decision makers in cost and time savings for security
    hardening.
  prefs: []
  type: TYPE_NORMAL
- en: Effects on Scheduling
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In general, and particularly in Agile development, teams do not allow enough
    time to improve the codebase when planning the next version. In sprint planning,
    the focus on effort assessment is primarily on time to develop a new function.
    Hardening is considered explicitly only when a special requirement exists.
  prefs: []
  type: TYPE_NORMAL
- en: The amount of time teams need to implement a function safely depends on the
    functionality, the status of the product increment, the existing technical debt,
    and the prior knowledge of the developer. However, as intended in Agile development,
    it should be up to the team to estimate the actual time required. Since miscalculations
    are to be expected, especially at the beginning, it can make sense to reduce the
    number of user stories adopted compared to the previous sprints.
  prefs: []
  type: TYPE_NORMAL
- en: The Right Contact Person
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Every team must have access to security professionals, but it can be hard to
    find the right contact person in large organizations. IT security is divided into
    numerous, sometimes highly specific and complex, subareas for which full-time
    security experts are responsible. Good programmers are full-time developers and
    even after IT security training, cannot replace dedicated security experts.
  prefs: []
  type: TYPE_NORMAL
- en: It is the responsibility of project management to ensure that organizational,
    structural, and financial requirements are met so that teams can quickly draw
    on technical expertise when needed and during an assessment. This is not the case
    by default in most organizations.
  prefs: []
  type: TYPE_NORMAL
- en: Dealing with Technical Debt
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Technical debt is an integral part of development, and project owners should
    treat it as such—both in terms of time and budget. Technical debt has a negative
    impact on the maintainability, development, and security of the codebase. This
    means a significant increase in individual (new) implementation costs and a sustained
    slowdown in overall production by blocking developers for a more extended period
    of time with individual projects. Therefore, it is in the interest of everyone
    involved—especially management—to keep the technical debt of a codebase low and
    to continuously reduce it.
  prefs: []
  type: TYPE_NORMAL
- en: Alternatively, the substrategy is to set a fixed portion of the estimated project
    time for servicing technical debt. The approach is minor, as there is a risk that
    teams will use the time spent processing technical debt to implement a function
    instead and misjudge the extent of technical debt under the development cycle
    pressure.
  prefs: []
  type: TYPE_NORMAL
- en: Advanced Training on Secure Coding
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: A misconception exists that security can be learned in passing and that everyone
    has access to the necessary materials. Typically, a list of secure coding guidelines
    is in a public folder somewhere. In addition, the OWASP Top 10 is often published
    to the general public. As a rule, however, employees do not read such documents
    or, at best, skim them. Often, after a while, teams no longer know where such
    documents are, let alone what use they should get from them. Admonitions to encourage
    reading the guidelines are not very helpful if companies cannot create extra time
    to focus on secure coding.
  prefs: []
  type: TYPE_NORMAL
- en: Milestones for Quality
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Quality gates in development help check compliance with quality requirements.
    Analogous to the *definition of done* (DoD), the team-wide definition of when
    a task can be viewed as completed, quality gates should not be available only
    in stationary paper form. Ideally, automated checks are integrated into the CI/CD
    pipeline through static code analyses (SAST) or the evaluation of all dependencies.
  prefs: []
  type: TYPE_NORMAL
- en: For developers, however, it can be helpful to receive feedback on the code and
    its dependencies in addition to feedback from the CI/CD pipeline during programming.
    Language- and platform-dependent IDE plug-ins and separate code analysis tools
    are available, such as FindBugs/SpotBugs, Checkstyle, and PMD. When using JFrog
    Xray, the IDE plug-in can be used to make it easier to compare against known vulnerabilities
    and compliance issues.
  prefs: []
  type: TYPE_NORMAL
- en: An additional upstream process for checking the code in the IDE pursues the
    goal of familiarizing developers with security aspects during development. As
    a result, the code security is improved at the points identified by the plug-in
    and in the entire code since developers are given a security orientation. Another
    side effect is the reduction in the number of false positives on the build server.
    The latter is exceptionally high for security quality gates, as security gaps
    in the code are often context-dependent and require manual verification, which
    leads to a considerable increase in the development effort.
  prefs: []
  type: TYPE_NORMAL
- en: The Attacker’s Point of View
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '*Evil user stories* (also called *bad user stories*) present the desired functionality
    from an attacker’s perspective. Analogous to user stories, they are designed so
    that their focus is not on the technical implementation. Accordingly, people with
    a limited technical background in IT security can write bad user stories. However,
    this increases the effort required to generate tasks from the possibly unspecific
    (bad) user stories.'
  prefs: []
  type: TYPE_NORMAL
- en: Ideally, bad user stories try to depict the attack surface. They enable the
    development team to process identified attack methods in a familiar workflow.
    This creates awareness of possible attack vectors, but these are limited. Evil
    user stories are limited not only by the knowledge and experience of their respective
    authors and their imagination, but also by the developer’s ability to fend off
    the attack vector in the context of the sprint. It’s not just about whether the
    developers develop the right damage-control strategy, but also about correctly
    and comprehensively identifying the use case in the code.
  prefs: []
  type: TYPE_NORMAL
- en: Like conventional user stories, the evil variants are not always easy to write.
    Teams with little experience in developing secure software, in particular, can
    encounter difficulties creating meaningful nasty user stories. If a SecM is on
    the team, that person should take on the task or offer support. Teams without
    a SecM should either look for external technical expertise or plan a structured
    process for creating the evil user stories.
  prefs: []
  type: TYPE_NORMAL
- en: Methods of Evaluation
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: To establish security as a process within Agile development, regular code reviews
    must be carried out, with the focus on the security level of the code, both component
    by component and across segments. Ideally, errors that are easy to avoid and can
    cause security breaches can be identified and corrected as part of the CI/CD pipeline
    through quality gates and automated tests. In this case, the component-by-component
    test is primarily concerned with the investigation of the attack surface of the
    respective component and the weakening of attack vectors. A cheat sheet for analyzing
    the attack surface can be found on the [OWASP Cheat Sheet Series on GitHub](https://oreil.ly/kHLm1).
  prefs: []
  type: TYPE_NORMAL
- en: The teams must regularly redefine the attack surface, as it can change with
    each development cycle. The cross-component check is used to monitor the attack
    surface of the overall product, as it can also change with every development cycle.
    Ultimately, only a cross-component view enables the search for attack vectors
    that result from interactions between components or even dependencies.
  prefs: []
  type: TYPE_NORMAL
- en: If SecMs are not available, a security assessment can be carried out through
    a structured approach and joint training in the team. The [OWASP Cornucopia card
    game](https://oreil.ly/dhQK3) can, among other things, promote such an approach.
    The players try to apply the attack scenarios depicted on the cards to a domain
    selected in advance by the team or, if necessary, only to individual methods,
    such as the codebase. The team must then decide whether the attack scenario of
    the card played is conceivable. Therefore, the focus is on identifying attack
    vectors; because of time constraints, mitigation strategies should be discussed
    elsewhere. The winner of the card game is the one who can successfully play the
    most difficult cards. The team must document the resulting security analysis at
    the end.
  prefs: []
  type: TYPE_NORMAL
- en: One benefit of Cornucopia is that it increases awareness of code vulnerabilities
    across the team. The game also improves the developer’s expertise in IT security.
    The focus is on the ability of the developer and thus reflects Agile guidelines.
    Cornucopia sessions are an excellent tool to generate evil user stories afterward.
  prefs: []
  type: TYPE_NORMAL
- en: The problem with Cornucopia sessions is that they present especially inexperienced
    teams with a steep learning curve at the beginning. There is also a risk that
    the team will incorrectly discard a potential attack vector. If the preparation
    is poor (e.g., components are too large, or the team doesn’t have enough technical
    knowledge about possible attack vectors), Cornucopia can be inefficient in terms
    of time. Therefore, it is advisable, especially in the first few sessions, to
    examine small independent components and, if necessary, to consult security experts.
  prefs: []
  type: TYPE_NORMAL
- en: Be Aware of Responsibility
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Overall, developers should not allow the code security scepter to be taken out
    of their hands. Ideally, the team should jointly insist on sufficient time and
    financial resources to implement basic security aspects.
  prefs: []
  type: TYPE_NORMAL
- en: Current developers will largely define and shape the world for the years to
    come. Because of expected digitization and networking, security must not fall
    victim to budget and time constraints. According to the Agile Manifesto, the codebase
    remains the product of the team responsible for the outcome.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: With the proliferation of supply chain attacks in the industry, addressing security
    is more critical than ever for the success of your project and organization. The
    best way to mitigate vulnerabilities quickly is to shift left and start addressing
    security as a primary concern from day one of every software development project.
    This chapter introduced you to the basics of security, including various analysis
    approaches, such as SAST, DAST, IAST, and RASP. You also learned about basic scoring
    systems like the CVSS. With this knowledge, you will be able to put the right
    quality gates and criteria in place to improve the security of every project that
    you work on going forward.
  prefs: []
  type: TYPE_NORMAL
