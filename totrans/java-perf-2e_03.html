<html><head></head><body><section data-pdf-bookmark="Chapter 3. A Java Performance Toolbox" data-type="chapter" epub:type="chapter"><div class="chapter" id="Tools">&#13;
<h1><span class="label">Chapter 3. </span>A Java Performance Toolbox</h1>&#13;
&#13;
&#13;
<p><a data-primary="performance tools" data-seealso="specific tools" data-type="indexterm" id="ix_ch03-asciidoc0"/>Performance analysis is all about visibility—knowing what is going on&#13;
inside an application and in the application’s environment. Visibility&#13;
is all about tools.&#13;
And so performance tuning is all about tools.</p>&#13;
&#13;
<p>In <a data-type="xref" href="ch02.html#SampleApplications">Chapter 2</a>, we looked at the importance of taking a data-driven&#13;
approach to performance: you must measure the application’s performance&#13;
and understand what those measurements mean. Performance analysis must&#13;
be similarly data-driven: you must have data about what, exactly, the&#13;
program is doing in order to make it perform better. How to obtain and&#13;
understand that data is the subject of this chapter.</p>&#13;
&#13;
<p>Hundreds of tools can provide information about what a Java&#13;
application is doing, and looking at all of&#13;
them would be impractical. Many of the most important tools come with the Java Development Kit (JDK),&#13;
and although those tools have other&#13;
open source and commercial competitors, this chapter focuses mostly&#13;
on the JDK tools as&#13;
a matter of expedience.</p>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Operating System Tools and Analysis" data-type="sect1"><div class="sect1" id="idm45775557073128">&#13;
<h1>Operating System Tools and Analysis</h1>&#13;
&#13;
<p><a data-primary="OS (operating system) tools/analysis" data-type="indexterm" id="ix_ch03-asciidoc1"/><a data-primary="performance tools" data-secondary="OS tools/analysis" data-type="indexterm" id="ix_ch03-asciidoc2"/>The starting point for program analysis is not Java-specific at&#13;
all: it is the basic set of monitoring tools that come with the&#13;
operating system. On Unix-based systems, these are <code>sar</code> (System Accounting&#13;
Report) and its constituent tools like&#13;
<code class="keep-together">vmstat</code>,&#13;
<code class="keep-together">iostat</code>,&#13;
<code class="keep-together">prstat</code>,&#13;
and so on. Windows has graphical&#13;
resource monitors as well as command-line utilities like&#13;
<span class="keep-together"><code>typeperf</code></span>.</p>&#13;
&#13;
<p>Whenever performance tests are run, data should be gathered from the&#13;
operating system. At a minimum, information on CPU,&#13;
memory, and disk usage should be collected; if the program uses the&#13;
network, information on&#13;
network usage should be gathered&#13;
as well. If performance tests are automated, this means&#13;
relying on command-line tools (even on Windows). But even if tests are&#13;
running interactively, it is better to have a command-line tool that&#13;
captures output, rather than eyeballing a GUI graph and guessing what it means.&#13;
The output can always be graphed later when doing analysis.</p>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="CPU Usage" data-type="sect2"><div class="sect2" id="idm45775557064536">&#13;
<h2>CPU Usage</h2>&#13;
&#13;
<p><a data-primary="CPU usage" data-type="indexterm" id="ix_ch03-asciidoc3"/><a data-primary="OS (operating system) tools/analysis" data-secondary="CPU usage" data-type="indexterm" id="ix_ch03-asciidoc4"/>Let’s look first at monitoring the CPU and what it tells us about Java&#13;
programs. CPU usage is typically divided into two categories: user time&#13;
and system time (Windows refers to this as <em>privileged time</em>). <a data-primary="system time" data-type="indexterm" id="idm45775557059832"/><a data-primary="user time" data-type="indexterm" id="idm45775557059096"/><em>User time</em> is&#13;
the percentage of time the CPU is executing application code, while&#13;
<em>system time</em> is the percentage of time the CPU is executing kernel code.&#13;
System time is related to the application; if the application performs&#13;
I/O, for example, the kernel will execute the code to read the file from&#13;
disk, or write the buffered data to the network, and so on. Anything that uses an underlying&#13;
system resource will cause the application to use more system time.</p>&#13;
&#13;
<p>The goal in performance is to drive CPU usage as high as&#13;
possible for as short a time as possible. That may sound a little&#13;
counterintuitive; you’ve doubtless sat&#13;
at your desktop and watched it struggle because the CPU is 100% utilized.&#13;
So let’s consider what the CPU usage actually tells us.</p>&#13;
&#13;
<p>The first thing to keep in mind is that the CPU usage number is an average&#13;
over an interval—5 seconds, 30 seconds, perhaps even as little as 1&#13;
second (though never really less than that). Say that the average CPU&#13;
usage of a program is 50% for the 10 minutes it takes to execute. This means&#13;
that the CPU is idle for half the time; if we can restructure the program&#13;
to not have idle patches (nor other bottlenecks), we can double the&#13;
performance and run&#13;
in 5 minutes (with the CPU 100% busy).</p>&#13;
&#13;
<p>If then we improve the algorithm used by the program and double performance&#13;
again, the&#13;
CPU will still be at 100% during the 2.5 minutes it takes the program to&#13;
complete. The CPU usage number is an indication of how effectively the program&#13;
is using the CPU, and so the higher the number, the better.</p>&#13;
&#13;
<p>If I run&#13;
<span class="keep-together"><code>vmstat 1</code></span> on&#13;
my Linux desktop, I will get a series of lines (one every second)&#13;
that look like this:</p>&#13;
<pre data-type="programlisting">&#13;
% <strong>vmstat 1</strong>&#13;
procs -----------memory---------- ---swap-- -----io---- -system-- ----cpu----&#13;
 r  b   swpd   free   buff  cache   si   so    bi    bo   in   cs us sy id wa&#13;
 2  0      0 1797836 1229068 1508276 0    0     0     9 2250 3634 41  3 55  0&#13;
 2  0      0 1801772 1229076 1508284 0    0     0     8 2304 3683 43  3 54  0&#13;
 1  0      0 1813552 1229084 1508284 0    0     3    22 2354 3896 42  3 55  0&#13;
 1  0      0 1819628 1229092 1508292 0    0     0    84 2418 3998 43  2 55  0&#13;
</pre>&#13;
&#13;
<p>This example comes from running an application with one active thread—that&#13;
makes the example easier to follow—but the concepts apply even if there&#13;
are multiple threads.</p>&#13;
&#13;
<p>During each second, the CPU is busy for 450 ms (42% of the time&#13;
executing user code, and 3% of the time executing system code). Similarly,&#13;
the CPU is idle for 550 ms. The CPU can be idle for multiple reasons:</p>&#13;
&#13;
<ul>&#13;
<li>&#13;
<p>The application might be blocked on a synchronization primitive and unable to execute until that lock is released.</p>&#13;
</li>&#13;
<li>&#13;
<p>The application might be waiting for something, such as a response to come back from a call to the database.</p>&#13;
</li>&#13;
<li>&#13;
<p>The application might have nothing to do.</p>&#13;
</li>&#13;
</ul>&#13;
&#13;
<p>These first two situations are always indicative of something that can be&#13;
addressed. If contention on the lock can be reduced or the&#13;
database can be tuned so that it sends the answer back more quickly, then&#13;
the program will run faster, and the average CPU use of&#13;
the application will go up (assuming, of course, that there isn’t another such&#13;
issue that will continue to block the application).</p>&#13;
&#13;
<p>That third point is where confusion often lies. If the application has&#13;
something to do (and is not prevented from doing it because it is waiting&#13;
for a lock or another resource), then the CPU will spend cycles executing the&#13;
application code. This is a general principle, not specific to Java. Say that&#13;
you write a simple script containing an infinite loop.&#13;
When that script is executed, it will consume 100% of a CPU. The following&#13;
batch job will do just that in Windows:</p>&#13;
&#13;
<pre data-type="programlisting">ECHO OFF&#13;
:BEGIN&#13;
ECHO LOOPING&#13;
GOTO BEGIN&#13;
REM We never get here...&#13;
ECHO DONE</pre>&#13;
&#13;
<p>Consider what it would mean if this script did not consume 100% of a CPU. It&#13;
would mean that the operating system had something it could do—it could&#13;
print yet another line saying <code>LOOPING</code>—but it chose instead to be idle.&#13;
Being idle doesn’t help anyone in that case, and if we were doing a useful&#13;
(lengthy) calculation, forcing the CPU to be periodically idle would mean&#13;
that it would take longer&#13;
to get the answer we are after.</p>&#13;
&#13;
<p>If you run this command on a single-CPU machine or container, much of the&#13;
time you are unlikely to&#13;
notice that it is running. But if you attempt to start a new program, or time&#13;
the performance of another application, then you will certainly see the effect.&#13;
Operating systems are good at time-slicing programs that are competing for&#13;
CPU cycles, but less CPU will be available for the new program, and it will&#13;
run more slowly. That experience sometimes leads people to think it would be&#13;
a good idea to leave some idle CPU cycles just in case something else needs them.</p>&#13;
&#13;
<p>But the operating system cannot guess what you want to do next; it will (by default)&#13;
execute everything it can rather than leaving the CPU idle.</p>&#13;
<aside class="less_space pagebreak-before" data-type="sidebar" epub:type="sidebar"><div class="sidebar" id="idm45775557042056">&#13;
<h5>Limiting CPU for a Program</h5>&#13;
<p>Running a program whenever CPU cycles are available&#13;
maximizes the performance of that program. At times you&#13;
might not want that behavior. If, for example, you run <em>SETI@home</em>, it will&#13;
consume all available CPU cycles on your machine. That may be fine when&#13;
you aren’t working, or if you’re just surfing the web or writing documents,&#13;
but it could otherwise hamper your productivity. (And let’s not consider&#13;
what might happen if you are playing a CPU-intensive game!)</p>&#13;
&#13;
<p>Several operating-system-specific mechanisms can artificially&#13;
throttle the amount of CPU that a program uses—in effect, forcing the&#13;
CPU to leave idle cycles just in case something might want to&#13;
take advantage of them. The priority of processes can also be changed so&#13;
that those background jobs don’t take CPU from what you want to run but still&#13;
don’t leave idle CPU cycles. Those techniques are beyond the scope of our&#13;
discussion (and for the record, <em>SETI@home</em> will let you configure those; it&#13;
won’t really take up all the spare cycles on your machine unless you tell it&#13;
to do so).</p>&#13;
</div></aside>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Java and single-CPU usage" data-type="sect3"><div class="sect3" id="idm45775557037896">&#13;
<h3>Java and single-CPU usage</h3>&#13;
&#13;
<p><a data-primary="CPU usage" data-secondary="Java and single-CPU usage" data-type="indexterm" id="idm45775557036440"/>To return to the discussion of the Java application—what does periodic,&#13;
idle CPU mean in that case?&#13;
It depends on the type of application.&#13;
If the code in question is a batch-style application that has a fixed&#13;
amount of work, you should never see idle CPU, because that would mean&#13;
there is no work to&#13;
do. Driving the CPU usage higher is always the goal for batch jobs, because&#13;
the job will be completed faster. If the CPU is already at 100%,&#13;
you can still look for optimizations that allow the work to&#13;
be completed faster (while trying also to keep the CPU at 100%).</p>&#13;
&#13;
<p>If the measurement involves a server-style application that accepts requests&#13;
from a source, idle time may occur because no work is available:&#13;
for example, when a web server has processed all outstanding HTTP requests and is&#13;
waiting for the next request.&#13;
This is where the average time comes in. The sample&#13;
<span class="keep-together"><code>vmstat</code></span>&#13;
output was taken during execution of a server that was receiving&#13;
one request every second.&#13;
It took 450 ms for&#13;
the application server to process that request—meaning that the CPU was 100% busy for&#13;
450 ms, and 0% busy for 550 ms. That was reported as the&#13;
CPU being 45% busy.</p>&#13;
&#13;
<p>Although it usually happens at a level of granularity that is&#13;
too small to visualize, the expected behavior of the CPU when running&#13;
a load-based application is to&#13;
operate in short bursts like this. The same macro-level pattern will be seen&#13;
from the reporting if the CPU received one request every half-second and&#13;
the average time to process the request was 225 ms. The CPU would&#13;
be busy for 225 ms, idle for 275 ms, busy again for&#13;
225 ms, and idle for 275 ms: on average, 45% busy and&#13;
55% idle.</p>&#13;
&#13;
<p>If the application is optimized so that each request takes only 400&#13;
ms, the overall CPU usage will also be reduced (to 40%).&#13;
This is the only case where driving the CPU usage lower makes sense—when&#13;
a fixed amount of load is coming into the system and the application&#13;
is not constrained by external resources. On the other hand, that optimization&#13;
also gives you the opportunity to add more load into the system, ultimately&#13;
increasing the CPU utilization. And at a micro level, optimizing in this case&#13;
is still a matter of getting the CPU usage to 100% for a short period of&#13;
time (the 400 ms it takes to execute the request)—it’s just that&#13;
the duration of the CPU spike is too short to effectively register as 100%&#13;
using most tools.</p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Java and multi-CPU usage" data-type="sect3"><div class="sect3" id="idm45775557030664">&#13;
<h3>Java and multi-CPU usage</h3>&#13;
&#13;
<p><a data-primary="CPU usage" data-secondary="Java and multi-CPU usage" data-type="indexterm" id="idm45775557029416"/>This example has assumed a single thread running on a single CPU, but the&#13;
concepts are the same in the general case of multiple threads running on&#13;
multiple CPUs. Multiple threads can skew the average of the CPU in interesting&#13;
ways—one such example is shown in <a data-type="xref" href="ch05.html#GC">Chapter 5</a>, which shows the&#13;
effect of the multiple GC threads on CPU usage. But in general, the goal&#13;
for multiple threads on a multi-CPU machine is still to drive the CPU higher&#13;
by making sure individual threads are not blocked, or to drive the CPU&#13;
lower (over a long interval) because the threads have completed their work&#13;
and are waiting for more work.</p>&#13;
&#13;
<p>In a multithreaded, multi-CPU case, there is one important addition regarding&#13;
when CPUs could be idle: CPUs can be idle&#13;
even when there is work to do. This occurs if no threads are available&#13;
in the program to handle that work. The typical case is an application&#13;
with a fixed-size thread pool running various tasks. Tasks for the&#13;
threads get placed onto a queue; when a thread is idle and a task in&#13;
the queue, the thread picks up that task and executes it.&#13;
However, each thread can execute only&#13;
one task at a time, and if that particular task blocks (e.g., is waiting for&#13;
a response from the database), the thread cannot pick up a new task to execute in&#13;
the meantime. Hence, at times we may have periods where there are tasks to be&#13;
executed (work to be done) but no thread available to execute them; the&#13;
result is idle CPU time.</p>&#13;
&#13;
<p>In that specific example, the size of the thread pool should be increased. However,&#13;
don’t assume that just because idle CPU is available,&#13;
the size of the thread pool should be increased in order to&#13;
accomplish more work. The program may not be getting CPU&#13;
cycles for the other two reasons previously mentioned—because of bottlenecks&#13;
in locks or external resources. It is important to understand <em>why</em> the&#13;
program isn’t getting CPU before determining a course of&#13;
action. (See <a data-type="xref" href="ch09.html#ThreadPerformance">Chapter 9</a> for more details on this topic.)</p>&#13;
&#13;
<p>Looking at the CPU usage is a first step in understanding application&#13;
performance, but it is only that: use it to see if the code is using all the&#13;
CPU that can be expected, or if it points to a synchronization or&#13;
resource issue.</p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="The CPU Run Queue" data-type="sect2"><div class="sect2" id="idm45775557063976">&#13;
<h2>The CPU Run Queue</h2>&#13;
&#13;
<p><a data-primary="CPU run queue" data-type="indexterm" id="idm45775557021624"/><a data-primary="OS (operating system) tools/analysis" data-secondary="CPU run queue" data-type="indexterm" id="idm45775557020696"/><a data-primary="run queue" data-type="indexterm" id="idm45775557019784"/>Both Windows and Unix systems allow you to monitor the number of threads&#13;
that can be run (meaning that they are not blocked on I/O, or sleeping,&#13;
and so on). Unix systems refer to this as the <em>run queue</em>, and several tools&#13;
include the run queue length in their output. That includes the&#13;
<span class="keep-together"><code>vmstat</code></span>&#13;
output&#13;
in the previous section: the first number in each line is the length of the&#13;
run queue.  <a data-primary="processor queue" data-type="indexterm" id="idm45775557017432"/>Windows refers to this number as the <em>processor queue</em> and&#13;
reports it (among other ways) via&#13;
<span class="keep-together"><code>typeperf</code></span>:</p>&#13;
<pre data-type="programlisting">&#13;
C:&gt; <strong>typeperf -si 1 "\System\Processor Queue Length"</strong>&#13;
"05/11/2019 19:09:42.678","0.000000"&#13;
"05/11/2019 19:09:43.678","0.000000"&#13;
</pre>&#13;
&#13;
<p>There is an important difference in this output: the run queue length&#13;
number on a Unix system (which was either 1 or 2 in the sample&#13;
<span class="keep-together"><code>vmstat</code></span> output) is&#13;
the number of all&#13;
threads that <em>are</em> running or that <em>could run</em> if there were an available CPU.&#13;
In that example, there was always at least one thread&#13;
that wanted to run: the single thread doing application work. Hence, the run&#13;
queue length was always at least 1. Keep in mind that&#13;
the run queue represents everything on the machine, so sometimes&#13;
there are other threads&#13;
(from completely separate processes) that want to run, which is why the run&#13;
queue length sometimes was 2 in that sample output.</p>&#13;
&#13;
<p>In Windows, the processor queue length does not include the number of threads&#13;
that are currently running. Hence, in the&#13;
<span class="keep-together"><code>typeperf</code></span>&#13;
sample output, the&#13;
processor queue number was 0, even though the machine was running the&#13;
same single-threaded&#13;
application with one thread always executing.</p>&#13;
&#13;
<p>If there are more threads to run than available CPUs, performance begins to degrade. In general, then, you want the processor queue length to be 0&#13;
on Windows and equal to (or less than) the number of CPUs on Unix systems.&#13;
That isn’t a hard-and-fast rule; system processes and other things&#13;
will come along periodically and briefly raise that value without any&#13;
significant performance impact. But if the run queue length is too high for&#13;
any significant period of time, it’s an indication that the machine is&#13;
overloaded, and you should look into reducing the amount of work the machine&#13;
is doing (either by moving jobs to another machine or by optimizing the code).</p>&#13;
<div data-type="tip"><h1>Quick Summary</h1>&#13;
<ul>&#13;
<li>&#13;
<p>CPU time is the first thing to examine when looking at the performance of an application.</p>&#13;
</li>&#13;
<li>&#13;
<p>The goal in optimizing code is to drive the CPU usage up (for a shorter period of time), not down.</p>&#13;
</li>&#13;
<li>&#13;
<p>Understand why CPU usage is low before diving in and attempting to tune an application.<a data-startref="ix_ch03-asciidoc4" data-type="indexterm" id="idm45775557005144"/><a data-startref="ix_ch03-asciidoc3" data-type="indexterm" id="idm45775557004440"/></p>&#13;
</li>&#13;
</ul>&#13;
</div>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Disk Usage" data-type="sect2"><div class="sect2" id="idm45775557003256">&#13;
<h2>Disk Usage</h2>&#13;
&#13;
<p><a data-primary="disk usage, monitoring" data-type="indexterm" id="ix_ch03-asciidoc5"/><a data-primary="I/O performance" data-secondary="disk usage monitoring" data-type="indexterm" id="ix_ch03-asciidoc6"/><a data-primary="OS (operating system) tools/analysis" data-secondary="disk usage" data-type="indexterm" id="ix_ch03-asciidoc7"/>Monitoring disk usage has two important goals. The first pertains to&#13;
the application itself: if the application is doing a lot of disk I/O,&#13;
that I/O can easily become a <span class="keep-together">bottleneck.</span></p>&#13;
&#13;
<p>Knowing when disk I/O is a bottleneck is tricky, because it depends on the&#13;
behavior of the application. If the application is not efficiently buffering&#13;
the data it writes to disk (an example is in <a data-type="xref" href="ch12.html#Misc">Chapter 12</a>), the disk I/O&#13;
statistics will be low. But&#13;
if the application is performing more I/O than the disk can handle, the&#13;
disk I/O statistics will be high. In either situation,&#13;
performance can be improved; be on the lookout for&#13;
both.</p>&#13;
&#13;
<p>The basic I/O monitors on some systems are better than on others. Here is&#13;
partial output of&#13;
<span class="keep-together"><code>iostat</code></span>&#13;
on a Linux system:</p>&#13;
<pre data-type="programlisting">&#13;
% <strong>iostat -xm 5</strong>&#13;
avg-cpu:  %user   %nice %system %iowait  %steal   %idle&#13;
          23.45    0.00   37.89    0.10    0.00   38.56&#13;
&#13;
          Device:         rrqm/s   wrqm/s     r/s     w/s    rMB/s&#13;
          sda               0.00    11.60    0.60   24.20     0.02&#13;
&#13;
          wMB/s avgrq-sz avgqu-sz   await r_await w_await  svctm  %util&#13;
          0.14    13.35     0.15    6.06    5.33    6.08   0.42   1.04&#13;
</pre>&#13;
&#13;
<p>This application is writing data to disk <code>sda</code>. At first glance, the&#13;
disk statistics look good. The <code>w_await</code>—the time to service each&#13;
I/O write—is fairly low (6.08 ms), and the disk is only 1.04%&#13;
utilized. (The acceptable values for that depend on the physical disk, but the 5200 RPM disk in my desktop system behaves well when the service time is under 15 ms.) But a clue is indicating that something is wrong: the system is&#13;
spending 37.89% of its time in the kernel. If the system is doing other&#13;
I/O (in other programs), that’s one thing; but if all that system time&#13;
is from the application being tested, something inefficient is happening.</p>&#13;
&#13;
<p>The fact that the system is doing 24.2 writes per second is another&#13;
clue: that is a lot when writing only 0.14 MB per second (MBps). I/O has&#13;
become a bottleneck, and the next step would be to look into how the application is performing its writes.</p>&#13;
&#13;
<p>The other side of the coin comes if the disk cannot keep up with the I/O&#13;
requests:</p>&#13;
<pre data-type="programlisting">&#13;
% <strong>iostat -xm 5</strong>&#13;
avg-cpu:  %user   %nice %system %iowait  %steal   %idle&#13;
          35.05    0.00    7.85   47.89    0.00    9.20&#13;
&#13;
          Device:         rrqm/s   wrqm/s     r/s     w/s    rMB/s&#13;
          sda               0.00     0.20    1.00  163.40     0.00&#13;
&#13;
          wMB/s avgrq-sz avgqu-sz   await r_await w_await  svctm  %util&#13;
          81.09  1010.19   142.74  866.47   97.60  871.17   6.08 100.00&#13;
</pre>&#13;
&#13;
<p>The nice thing about Linux is that it tells us immediately that the disk is&#13;
100% utilized; it also tells us that processes are spending 47.89% of their&#13;
time in&#13;
<span class="keep-together"><code>iowait</code></span>&#13;
(that is, waiting for the disk).</p>&#13;
&#13;
<p>Even on other systems with only raw data available, that data will tell&#13;
us something is amiss: the time to complete the I/O (<code>w_await</code>) is 871&#13;
ms, the queue size is quite large, and the disk is writing&#13;
81 MB of data per second. This all points to disk I/O as a&#13;
problem and that the amount of I/O in the application (or,&#13;
possibly, elsewhere in the system) must be reduced.</p>&#13;
&#13;
<p>A second reason to monitor disk usage—even if the application is not&#13;
expected to perform a significant amount of I/O—is to help monitor if&#13;
the system is swapping. Computers have a fixed amount of physical memory,&#13;
but they can run a set of applications that use a much larger amount of&#13;
virtual memory. Applications tend to&#13;
reserve more memory than they need, and they usually operate on&#13;
only a subset of their memory. In both cases, the operating system can&#13;
keep the unused parts of memory on disk, and page it into physical memory&#13;
only if it is needed.</p>&#13;
&#13;
<p>For the most part, this kind of memory management works well,&#13;
especially for interactive and GUI programs (which is good, or your laptop&#13;
would require much more memory than it has). It works less well for&#13;
server-based applications, since those applications tend to use more of&#13;
their memory. And it works particularly badly for any kind of Java&#13;
application (including a Swing-based GUI application running on your&#13;
desktop) because of the Java heap. More details about that appear&#13;
in <a data-type="xref" href="ch05.html#GC">Chapter 5</a>.</p>&#13;
&#13;
<p>System&#13;
tools can also report if the system is swapping; for example, the&#13;
<span class="keep-together"><code>vmstat</code></span>&#13;
output has two columns (<code>si</code>, for <em>swap in</em>, and <code>so</code>,&#13;
for <em>swap out</em>) that alert us if the system is swapping. Disk activity is&#13;
another indicator that swapping might be occurring.&#13;
Pay close attention to those, because&#13;
a system that is swapping—moving pages of data from main memory to&#13;
disk, and vice versa—will have quite bad performance. Systems must be&#13;
configured so that swapping never occurs.</p>&#13;
<div data-type="tip"><h1>Quick Summary</h1>&#13;
<ul>&#13;
<li>&#13;
<p>Monitoring disk usage is important for all applications. For applications that don’t directly write to disk, system swapping can still affect their performance.</p>&#13;
</li>&#13;
<li>&#13;
<p>Applications that write to disk can be bottlenecked both because they are writing data inefficiently (too little throughput) or because they are writing too much data (too much throughput).<a data-startref="ix_ch03-asciidoc7" data-type="indexterm" id="idm45775556976264"/><a data-startref="ix_ch03-asciidoc6" data-type="indexterm" id="idm45775556975560"/><a data-startref="ix_ch03-asciidoc5" data-type="indexterm" id="idm45775556974888"/></p>&#13;
</li>&#13;
</ul>&#13;
</div>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Network Usage" data-type="sect2"><div class="sect2" id="idm45775557002664">&#13;
<h2>Network Usage</h2>&#13;
&#13;
<p><a data-primary="network usage, monitoring" data-type="indexterm" id="idm45775556972264"/><a data-primary="OS (operating system) tools/analysis" data-secondary="network usage" data-type="indexterm" id="idm45775556971544"/>If you are running an application that uses the network—for example,&#13;
a REST <span class="keep-together">server—you</span> must monitor the network traffic&#13;
as well. Network usage is similar to disk&#13;
traffic: the application might be inefficiently using the network so that&#13;
bandwidth is too low, or the total amount of data written to a particular&#13;
network interface might be more than the interface is able to handle.</p>&#13;
&#13;
<p>Unfortunately, standard system tools are less than ideal for monitoring&#13;
network traffic because they typically show only the number of packets&#13;
and number of bytes that are sent and received over a particular network&#13;
interface. That is useful information, but it doesn’t tell us if the&#13;
network is under- or overutilized.</p>&#13;
&#13;
<p><a data-primary="netstat" data-type="indexterm" id="idm45775556968456"/>On Unix systems, the basic network monitoring tool is&#13;
<span class="keep-together"><code>netstat</code></span>&#13;
(and on most&#13;
Linux distributions,&#13;
<span class="keep-together"><code>netstat</code></span>&#13;
is not even included and must be obtained&#13;
separately). <a data-primary="typeperf" data-type="indexterm" id="idm45775556965992"/>On Windows,&#13;
<span class="keep-together"><code>typeperf</code></span>&#13;
can be used in scripts to monitor&#13;
the network usage—but here is a case where the GUI has an advantage: the&#13;
standard Windows resource monitor will display a graph showing what percentage&#13;
of the network is in use. Unfortunately, the GUI is of little help in an automated&#13;
performance-testing scenario.</p>&#13;
&#13;
<p>Fortunately, many open source and commercial tools&#13;
monitor network bandwidth. <a data-primary="nicstat" data-type="indexterm" id="idm45775556963640"/>On Unix systems, one popular command-line&#13;
tool is <a href="http://sourceforge.net/projects/nicstat"><code>nicstat</code></a>, which presents&#13;
a summary of the traffic on each interface, including the degree to which the&#13;
interface is utilized:</p>&#13;
<pre data-type="programlisting">&#13;
% <strong>nicstat 5</strong>&#13;
Time      Int       rKB/s   wKB/s   rPk/s   wPk/s   rAvs    wAvs   %Util  Sat&#13;
17:05:17  e1000g1   225.7   176.2   905.0   922.5   255.4   195.6  0.33   0.00&#13;
</pre>&#13;
&#13;
<p>The <code>e1000g1</code> interface is a 1,000 MB interface; it is not utilized very&#13;
much (0.33%)&#13;
in this example. The usefulness of this tool (and others like it) is that it calculates the utilization of the interface. In this output,&#13;
225.7 Kbps of data are being written, and 176.2 Kbps of data are being read&#13;
over the interface. Doing the division for a 1,000 MB&#13;
network yields the 0.33% utilization figure, and the&#13;
<span class="keep-together"><code>nicstat</code></span>&#13;
tool was able to figure out the bandwidth of the interface automatically.</p>&#13;
&#13;
<p>Tools such as&#13;
<span class="keep-together"><code>typeperf</code></span>&#13;
or&#13;
<span class="keep-together"><code>netstat</code></span>&#13;
will report the amount of data read and written,&#13;
but to figure out the network utilization, you must determine the bandwidth&#13;
of the interface and&#13;
perform the calculation in your own scripts. Be sure to remember that the bandwidth&#13;
is measured in bits per second (bps), although tools generally report bytes per second (Bps).&#13;
A 1,000-megabit network yields 125 megabytes (MB) per second. In this example,&#13;
0.22 MBps are read and 0.16 MBps are written;&#13;
adding those and dividing by 125 yields a 0.33% utilization rate. So there&#13;
is no magic to&#13;
<span class="keep-together"><code>nicstat</code></span>&#13;
(or similar) tools; they are just more&#13;
convenient to use.</p>&#13;
&#13;
<p>Networks cannot sustain a 100% utilization rate. For local-area&#13;
Ethernet networks, a sustained utilization rate over 40% indicates that the&#13;
interface is saturated.&#13;
If the network is packet-switched or utilizes&#13;
a different medium, the maximum possible sustained rate will be different;&#13;
consult a network architect to determine the appropriate goal. This goal&#13;
is independent of Java, which will simply use the networking parameters&#13;
and interfaces of the operating system.</p>&#13;
<div data-type="tip"><h1>Quick Summary</h1>&#13;
<ul>&#13;
<li>&#13;
<p>For network-based applications, monitor the network to make sure it hasn’t become a bottleneck.</p>&#13;
</li>&#13;
<li>&#13;
<p>Applications that write to the network can be bottlenecked because they are writing data inefficiently (too little throughput) or because they are writing too much data (too much throughput).<a data-startref="ix_ch03-asciidoc2" data-type="indexterm" id="idm45775556950568"/><a data-startref="ix_ch03-asciidoc1" data-type="indexterm" id="idm45775556949864"/></p>&#13;
</li>&#13;
</ul>&#13;
</div>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Java Monitoring Tools" data-type="sect1"><div class="sect1" id="idm45775556973240">&#13;
<h1>Java Monitoring Tools</h1>&#13;
&#13;
<p><a data-primary="Java monitoring tools" data-type="indexterm" id="ix_ch03-asciidoc8"/><a data-primary="Java Virtual Machine (JVM)" data-secondary="monitoring tools" data-type="indexterm" id="ix_ch03-asciidoc9"/><a data-primary="performance testing" data-secondary="Java monitoring tools" data-type="indexterm" id="ix_ch03-asciidoc10"/><a data-primary="performance tools" data-secondary="Java monitoring tools" data-type="indexterm" id="ix_ch03-asciidoc11"/>To gain insight into the JVM itself, Java monitoring tools are required.&#13;
These tools come with the JDK:</p>&#13;
<dl>&#13;
<dt><code>jcmd</code></dt>&#13;
<dd>&#13;
&#13;
<p><a data-primary="jcmd" data-type="indexterm" id="idm45775556940552"/>Prints basic class, thread, and JVM information for a Java process. This is suitable for use in scripts; it is executed like this:</p>&#13;
<pre data-type="programlisting">&#13;
% <strong>jcmd process_id command optional_arguments</strong>&#13;
</pre>&#13;
&#13;
<p>Supplying the command <code>help</code> will list all possible commands, and supplying <code>help &lt;<em>command</em>&gt;</code> will give the syntax for a particular command.</p>&#13;
</dd>&#13;
<dt><code>jconsole</code></dt>&#13;
<dd>&#13;
<p><a data-primary="jconsole" data-type="indexterm" id="idm45775556935304"/>Provides a graphical view of JVM activities, including thread usage, class usage, and GC activities.</p>&#13;
</dd>&#13;
<dt><code>jmap</code></dt>&#13;
<dd>&#13;
<p><a data-primary="jmap" data-type="indexterm" id="idm45775556933080"/>Provides heap dumps and other information about JVM memory usage. Suitable for scripting, though the heap dumps must be used in a postprocessing tool.</p>&#13;
</dd>&#13;
<dt><code>jinfo</code></dt>&#13;
<dd>&#13;
<p><a data-primary="jinfo" data-type="indexterm" id="idm45775556930808"/>Provides visibility into the system properties of the JVM, and allows some system properties to be set dynamically. Suitable for <span class="keep-together">scripting.</span></p>&#13;
</dd>&#13;
<dt><code>jstack</code></dt>&#13;
<dd>&#13;
<p><a data-primary="jstack" data-type="indexterm" id="idm45775556927992"/>Dumps the stacks of a Java process. Suitable for scripting.</p>&#13;
</dd>&#13;
<dt><code>jstat</code></dt>&#13;
<dd>&#13;
<p><a data-primary="jstat" data-type="indexterm" id="idm45775556851288"/>Provides information about GC and class-loading activities. Suitable for <span class="keep-together">scripting.</span></p>&#13;
</dd>&#13;
<dt><code>jvisualvm</code></dt>&#13;
<dd>&#13;
<p><a data-primary="jvisualvm" data-type="indexterm" id="idm45775556848616"/>A GUI tool to monitor a JVM, profile a running application, and analyze JVM heap dumps (which is a postprocessing activity, though <code>jvisualvm</code> can also take the heap dump from a live program).</p>&#13;
</dd>&#13;
</dl>&#13;
&#13;
<p>All of these tools are easy to run from the same machine as the JVM. <a data-primary="Docker container" data-type="indexterm" id="idm45775556846584"/>If the JVM&#13;
is running inside a Docker container, the nongraphical tools (i.e.,&#13;
those except <code>jconsole</code> and <code>jvisualvm</code>) can be run via the <code>docker exec</code>&#13;
command, or if you use <code>nsenter</code> to enter the Docker container. However, either&#13;
case assumes that you have installed those tools into the Docker image,&#13;
which is definitely recommended. It’s typical to pare down Docker images&#13;
to the bare necessities of your application and hence to include only the&#13;
JRE, but sooner or later in&#13;
production you will need insight into that application, so it’s better&#13;
to have the necessary tools (which are bundled with the JDK) within&#13;
the Docker image.</p>&#13;
&#13;
<p><code>jconsole</code> requires a fair amount of system resources, so running it on a&#13;
production system can interfere with that system. You can set up <code>jconsole</code>&#13;
so that it can be run locally and attach to a remote system, which won’t&#13;
interfere with that remote system’s performance. In a production environment,&#13;
that requires installing certificates to enable <code>jconsole</code> to run over SSL,&#13;
and setting up a secure authentication system.</p>&#13;
&#13;
<p>These tools fits into these broad areas:</p>&#13;
&#13;
<ul>&#13;
<li>&#13;
<p>Basic VM information</p>&#13;
</li>&#13;
<li>&#13;
<p>Thread information</p>&#13;
</li>&#13;
<li>&#13;
<p>Class information</p>&#13;
</li>&#13;
<li>&#13;
<p>Live GC analysis</p>&#13;
</li>&#13;
<li>&#13;
<p>Heap dump postprocessing</p>&#13;
</li>&#13;
<li>&#13;
<p>Profiling a JVM</p>&#13;
</li>&#13;
</ul>&#13;
&#13;
<p>As you likely noticed, there is no one-to-one mapping here; many tools&#13;
perform functions in multiple areas. So rather than exploring each tool&#13;
individually, we’ll take a look at the functional areas of visibility that&#13;
are important to Java and discuss how various tools provide that information.&#13;
Along the way, we’ll discuss other tools (some open source, some commercial)&#13;
that provide the same basic functionality but have&#13;
advantages over the basic JDK tools.</p>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Basic VM Information" data-type="sect2"><div class="sect2" id="VMInformation">&#13;
<h2>Basic VM Information</h2>&#13;
&#13;
<p><a data-primary="Java monitoring tools" data-secondary="basic VM information" data-type="indexterm" id="ix_ch03-asciidoc12"/>JVM tools can provide basic information about a running JVM process: how&#13;
long it has been up, what JVM flags are in use, JVM system properties, and so on:</p>&#13;
<dl>&#13;
<dt>Uptime</dt>&#13;
<dd>&#13;
<p>The length of time the JVM has been up can be found via this command:</p>&#13;
</dd>&#13;
</dl>&#13;
<pre data-type="programlisting">&#13;
% <strong>jcmd process_id VM.uptime</strong>&#13;
</pre>&#13;
<dl>&#13;
<dt>System properties</dt>&#13;
<dd>&#13;
<p>The set of items in <span class="keep-together"><code>System.getProperties()</code></span>&#13;
can be displayed with either of these commands:</p>&#13;
<pre data-type="programlisting">&#13;
% <strong>jcmd process_id VM.system_properties</strong>&#13;
</pre>&#13;
&#13;
<p>or</p>&#13;
<pre data-type="programlisting">&#13;
% <strong>jinfo -sysprops process_id</strong>&#13;
</pre>&#13;
&#13;
<p>This includes all properties set on the command line with a <code>-D</code> option,&#13;
any properties dynamically added by the application, and the set of&#13;
default properties for the JVM.</p>&#13;
</dd>&#13;
<dt>JVM version</dt>&#13;
<dd>&#13;
<p>The version of the JVM is obtained like this:</p>&#13;
</dd>&#13;
</dl>&#13;
<pre data-type="programlisting">&#13;
% <strong>jcmd process_id VM.version</strong>&#13;
</pre>&#13;
<dl>&#13;
<dt>JVM command line</dt>&#13;
<dd>&#13;
<p>  The command line can be displayed in the VM summary tab of <code>jconsole</code>, or&#13;
via <code>jcmd</code>:</p>&#13;
</dd>&#13;
</dl>&#13;
<pre data-type="programlisting">&#13;
% <strong>jcmd process_id VM.command_line</strong>&#13;
</pre>&#13;
<dl>&#13;
<dt>JVM tuning flags</dt>&#13;
<dd>&#13;
<p>The tuning flags in effect for an application can be obtained like this:</p>&#13;
</dd>&#13;
</dl>&#13;
<pre data-type="programlisting">&#13;
% <strong>jcmd process_id VM.flags [-all]</strong>&#13;
</pre>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Working with tuning flags" data-type="sect3"><div class="sect3" id="idm45775556812088">&#13;
<h3>Working with tuning flags</h3>&#13;
&#13;
<p><a data-primary="flags" data-secondary="JVM and" data-type="indexterm" id="ix_ch03-asciidoc13"/><a data-primary="Java monitoring tools" data-secondary="working with tuning flags" data-type="indexterm" id="ix_ch03-asciidoc14"/><a data-primary="Java Virtual Machine (JVM)" data-secondary="tuning flags" data-type="indexterm" id="ix_ch03-asciidoc15"/>A lot of tuning flags can be given to a JVM, and many of those&#13;
flags are a major focus of this book. Keeping track of those flags and their&#13;
default values can be a little daunting; those last two examples of <code>jcmd</code> are&#13;
useful in that regard. The&#13;
<span class="keep-together"><code>command_line</code></span>&#13;
command shows which flags were specified directly on the command line. The <code>flags</code>&#13;
command shows which flags were set on the command line, plus&#13;
some flags that were set directly by the JVM (because their value&#13;
was determined ergonomically). Including the <code>-all</code> option lists every&#13;
flag within the JVM.</p>&#13;
&#13;
<p>Hundreds of JVM tuning flags exist, and most are&#13;
obscure; it is recommended that most of them never be changed (see <a data-type="xref" href="#toomuchinfo-sb">“Too Much Information?”</a>).&#13;
Figuring out which flags are in effect is a frequent task when diagnosing&#13;
performance issues, and the <code>jcmd</code> commands can do that for a running JVM.&#13;
<a data-primary="-XX:+PrintFlagsFinal" data-type="indexterm" id="idm45775556801816"/>Often, you’d rather figure out the platform-specific defaults&#13;
for a particular JVM, in which case using the&#13;
<span class="keep-together"><code>-XX:+PrintFlagsFinal</code></span>&#13;
option on the command line is more useful. This easiest way to do that is to execute this command:</p>&#13;
<pre data-type="programlisting">&#13;
% <strong>java <em><code>other_options</code></em> -XX:+PrintFlagsFinal -version</strong>&#13;
...Hundreds of lines of output, including...&#13;
uintx InitialHeapSize                          := 4169431040     {product}&#13;
intx InlineSmallCode                           = 2000            {pd product}&#13;
</pre>&#13;
&#13;
<p>You should include any other options  you intend to use on the command line because setting some options (particularly when setting GC-related flags) will affect the final value of other options. This will print out the entire list of JVM flags and their values (the same as is printed via the <code>VM.flags -all</code> option to <code>jcmd</code> for a live JVM).</p>&#13;
&#13;
<p>Flag data from these commands&#13;
is printed in one of the two ways shown.&#13;
The colon in the first line of included output indicates that a&#13;
nondefault value is in use&#13;
for the flag in question. This can happen for the following reasons:</p>&#13;
&#13;
<ul>&#13;
<li>&#13;
<p>The flag’s value was specified directly on the command line.</p>&#13;
</li>&#13;
<li>&#13;
<p>Some other option indirectly changed that option.</p>&#13;
</li>&#13;
<li>&#13;
<p>The JVM calculated the default value ergonomically.</p>&#13;
</li>&#13;
</ul>&#13;
&#13;
<p>The second line (without a colon) indicates that value is the default&#13;
value for this version of the JVM. Default values for some flags&#13;
may be different&#13;
on different platforms, which is shown in the final column of this&#13;
output.&#13;
<span class="keep-together"><code>product</code></span>&#13;
means that the default setting of&#13;
the flag is uniform across all platforms; <code>pd product</code> indicates that the&#13;
default setting of the flag is platform-dependent.</p>&#13;
&#13;
<p>Other possible values for&#13;
the last column include&#13;
<span class="keep-together"><code>manageable</code></span>&#13;
(the flag’s value can be changed&#13;
dynamically during runtime) and&#13;
<span class="keep-together"><code>C2 diagnostic</code></span>&#13;
(the flag provides diagnostic&#13;
output for the compiler engineers to understand how the compiler is&#13;
<span class="keep-together">functioning).</span></p>&#13;
&#13;
<p>Yet another way to see this information for a running application is with&#13;
<code>jinfo</code>. The advantage of <code>jinfo</code> is that it allows certain flag values&#13;
to be changed during execution of the program.</p>&#13;
&#13;
<p>Here is how to retrieve the values of all the flags in the process:</p>&#13;
<pre data-type="programlisting">&#13;
% <strong>jinfo -flags process_id</strong>&#13;
</pre>&#13;
&#13;
<p>With the <code>-flags</code> option, <code>jinfo</code> will provide information about all flags;&#13;
otherwise, it prints only those specified on the command line. The output&#13;
from either of these commands isn’t as easy to read as that from the&#13;
<span class="keep-together"><code>-XX:+PrintFlagsFinal</code></span>&#13;
option, but <code>jinfo</code> has other features to keep in mind.</p>&#13;
&#13;
<p><code>jinfo</code> can inspect the value of an&#13;
individual flag:</p>&#13;
<pre data-type="programlisting">&#13;
% <strong>jinfo -flag PrintGCDetails process_id</strong>&#13;
-XX:+PrintGCDetails&#13;
</pre>&#13;
&#13;
<p>Although <code>jinfo</code> does not itself indicate whether a flag is manageable,&#13;
flags that are manageable (as identified when using the&#13;
<span class="keep-together"><code>PrintFlagsFinal</code></span>&#13;
argument) can be turned on or off via <code>jinfo</code>:</p>&#13;
<pre data-type="programlisting">&#13;
% <strong>jinfo -flag -PrintGCDetails process_id</strong>  # turns off PrintGCDetails&#13;
% <strong>jinfo -flag PrintGCDetails process_id</strong>&#13;
-XX:-PrintGCDetails&#13;
</pre>&#13;
<aside data-type="sidebar" epub:type="sidebar"><div class="sidebar" id="toomuchinfo-sb">&#13;
<h5>Too Much Information?</h5>&#13;
<p><a data-primary="PrintFlagsFinal command" data-type="indexterm" id="idm45775556774136"/>The <code>PrintFlagsFinal</code> command will print out hundreds of available tuning&#13;
flags for the JVM (there are 729 possible flags in JDK 8u202, for example). The vast majority of these flags are designed to enable support engineers to gather more information from running (and misbehaving) applications.&#13;
<a data-primary="-XX:+AllocatePrefetchLines=&lt;N&gt;" data-type="indexterm" id="idm45775556772600"/>It is tempting, upon learning that there is a flag called&#13;
<span class="keep-together"><code>AllocatePrefetchLines</code></span>&#13;
(which has a default value of 3), to assume that value can be changed so that&#13;
instruction prefetching might work better on a particular processor. But&#13;
that kind of hit-or-miss tuning is not worthwhile in a vacuum; none of&#13;
those flags should be changed without a compelling reason to do so. In the&#13;
case of the&#13;
<span class="keep-together"><code>AllocatePrefetchLines</code></span>&#13;
flag, that would include knowledge of the&#13;
application’s prefetch performance, the characteristics of the CPU running&#13;
the application, and the effect that changing the number will have on the JVM&#13;
code itself.</p>&#13;
</div></aside>&#13;
&#13;
<p><a data-primary="jinfo" data-type="indexterm" id="idm45775556768968"/>Be aware that in JDK 8, <code>jinfo</code> can change the value of any flag, but that&#13;
doesn’t&#13;
mean that the JVM will respond to that change.&#13;
For example, most flags that affect the behavior of a GC&#13;
algorithm are used at startup time to determine various ways that the collector&#13;
will behave.&#13;
Altering a flag later via <code>jinfo</code> does not cause&#13;
the JVM to change its behavior; it will continue executing based on&#13;
how the algorithm was initialized. So this technique works only for those&#13;
flags marked&#13;
<span class="keep-together"><code>manageable</code></span>&#13;
in the output of the&#13;
<span class="keep-together"><code>PrintFlagsFinal</code></span>&#13;
command. In JDK 11, <code>jinfo</code> will report an error if you attempt to change the&#13;
value of a flag that cannot be changed.<a data-startref="ix_ch03-asciidoc15" data-type="indexterm" id="idm45775556764408"/><a data-startref="ix_ch03-asciidoc14" data-type="indexterm" id="idm45775556763704"/><a data-startref="ix_ch03-asciidoc13" data-type="indexterm" id="idm45775556763032"/></p>&#13;
<div data-type="tip"><h1>Quick Summary</h1>&#13;
<ul>&#13;
<li>&#13;
<p><code>jcmd</code> can be used to find the basic JVM information—including the value of all the tuning flags—for a running application.</p>&#13;
</li>&#13;
<li>&#13;
<p>Default flag values can be found by including <code>-XX:+PrintFlagsFinal</code> on a command line. This is useful for determining the default ergonomic settings of flags on a particular <span class="keep-together">platform.</span></p>&#13;
</li>&#13;
<li>&#13;
<p><code>jinfo</code> is useful for inspecting (and in some cases changing) individual flags.<a data-startref="ix_ch03-asciidoc12" data-type="indexterm" id="idm45775556756872"/></p>&#13;
</li>&#13;
</ul>&#13;
</div>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Thread Information" data-type="sect2"><div class="sect2" id="idm45775556833688">&#13;
<h2>Thread Information</h2>&#13;
&#13;
<p><a data-primary="Java monitoring tools" data-secondary="thread information" data-type="indexterm" id="idm45775556754888"/><a data-primary="threads" data-secondary="thread information" data-type="indexterm" id="idm45775556753912"/><code>jconsole</code> and <code>jvisualvm</code> display information (in real time) about the&#13;
number of threads&#13;
running in an application. It can be useful to look at the stack of running threads to determine&#13;
if they are blocked. <a data-primary="jstack" data-type="indexterm" id="idm45775556751944"/>The stacks can be obtained via <code>jstack</code>:</p>&#13;
<pre data-type="programlisting">&#13;
% <strong>jstack process_id</strong>&#13;
... Lots of output showing each thread's stack ...&#13;
</pre>&#13;
&#13;
<p>Stack information can also be obtained from <code>jcmd</code>:</p>&#13;
<pre data-type="programlisting">&#13;
% <strong>jcmd process_id Thread.print</strong>&#13;
... Lots of output showing each thread's stack ...&#13;
</pre>&#13;
&#13;
<p>See <a data-type="xref" href="ch09.html#ThreadPerformance">Chapter 9</a> for more details on monitoring thread stacks.</p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Class Information" data-type="sect2"><div class="sect2" id="idm45775556745992">&#13;
<h2>Class Information</h2>&#13;
&#13;
<p><a data-primary="classes" data-secondary="class information" data-type="indexterm" id="idm45775556744824"/><a data-primary="Java monitoring tools" data-secondary="class information" data-type="indexterm" id="idm45775556743848"/>Information about the number of classes in use by an application can be&#13;
obtained from <code>jconsole</code> or <code>jstat</code>. <code>jstat</code> can also provide&#13;
information about class compilation.</p>&#13;
&#13;
<p>See <a data-type="xref" href="ch12.html#Misc">Chapter 12</a> for more details on class usage by applications, and see <a data-type="xref" href="ch04.html#JustInTimeCompilation">Chapter 4</a> for details on monitoring class compilation.</p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Live GC Analysis" data-type="sect2"><div class="sect2" id="idm45775556739032">&#13;
<h2>Live GC Analysis</h2>&#13;
&#13;
<p><a data-primary="garbage collection (GC)" data-secondary="live GC analysis" data-type="indexterm" id="idm45775556737864"/><a data-primary="Java monitoring tools" data-secondary="live GC analysis" data-type="indexterm" id="idm45775556736664"/>Virtually every monitoring tool reports something about GC activity.&#13;
<code>jconsole</code> displays live graphs of the heap usage; <code>jcmd</code> allows&#13;
GC operations to be performed; <code>jmap</code> can print heap summaries or information&#13;
on the permanent generation or create a heap dump; and <code>jstat</code> produces a lot&#13;
of views of what the garbage collector is doing.</p>&#13;
&#13;
<p>See <a data-type="xref" href="ch05.html#GC">Chapter 5</a> for examples of how these programs monitor GC activities.</p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Heap Dump Postprocessing" data-type="sect2"><div class="sect2" id="idm45775556732216">&#13;
<h2>Heap Dump Postprocessing</h2>&#13;
&#13;
<p><a data-primary="heap dumps" data-type="indexterm" id="idm45775556731000"/>Heap dumps can be captured from the <code>jvisualvm</code> GUI or from the command line&#13;
using <code>jcmd</code> or <code>jmap</code>. The <em>heap dump</em> is a snapshot&#13;
of the heap that can be analyzed with various tools, including <code>jvisualvm</code>.&#13;
Heap dump processing is one area where third-party tools have&#13;
traditionally been a step ahead of what comes with the JDK, so&#13;
<a data-type="xref" href="ch07.html#Memory">Chapter 7</a> uses a third-party tool—the Eclipse Memory Analyzer&#13;
Tool (mat)—to provide examples of how to postprocess heap dumps.<a data-startref="ix_ch03-asciidoc11" data-type="indexterm" id="idm45775556726712"/><a data-startref="ix_ch03-asciidoc10" data-type="indexterm" id="idm45775556726040"/><a data-startref="ix_ch03-asciidoc9" data-type="indexterm" id="idm45775556725368"/><a data-startref="ix_ch03-asciidoc8" data-type="indexterm" id="idm45775556724696"/></p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Profiling Tools" data-type="sect1"><div class="sect1" id="idm45775556948216">&#13;
<h1>Profiling Tools</h1>&#13;
&#13;
<p><a data-primary="performance testing" data-secondary="profiling tools" data-type="indexterm" id="ix_ch03-asciidoc16"/><a data-primary="performance tools" data-secondary="profiling tools" data-type="indexterm" id="ix_ch03-asciidoc17"/><a data-primary="profilers" data-type="indexterm" id="ix_ch03-asciidoc18"/><em>Profilers</em> are the most important tool in a performance analyst’s toolbox.&#13;
Many profilers are available for Java, each with its own advantages&#13;
and disadvantages. Profiling is one area where it often makes sense to use&#13;
different tools—particularly if they are sampling profilers. Sampling&#13;
profilers tend to show issues differently, so one may pinpoint performance&#13;
issues better on some applications and worse on others.</p>&#13;
&#13;
<p>Many common Java profiling tools are themselves written in Java and work&#13;
by “attaching” themselves to the application to be profiled. <a data-primary="JVM Tool Interface (JVMTI)" data-type="indexterm" id="idm45775556717816"/>This attachment&#13;
is via a socket or via a native Java interface called the JVM Tool Interface (JVMTI).&#13;
The target application and the profiling tool&#13;
then exchange information about the behavior of the target application.</p>&#13;
&#13;
<p>This means you must pay attention to tuning the profiling tool just as&#13;
you would tune any other Java application. In particular, if the&#13;
application being profiled is large, it can transfer quite a lot&#13;
of data to the profiling tool, so the profiling tool must have a&#13;
sufficiently large heap to handle the data. It is often a good idea to&#13;
run the profiling tool with a concurrent GC algorithm as well; ill-timed&#13;
full GC pauses in the profiling tool can cause the buffers holding the data&#13;
to overflow.</p>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Sampling Profilers" data-type="sect2"><div class="sect2" id="idm45775556715704">&#13;
<h2>Sampling Profilers</h2>&#13;
&#13;
<p><a data-primary="profilers" data-secondary="sampling profilers" data-type="indexterm" id="ix_ch03-asciidoc19"/><a data-primary="sampling profilers" data-type="indexterm" id="ix_ch03-asciidoc20"/>Profiling happens in one of two modes: sampling mode or instrumented mode.&#13;
<em>Sampling mode</em> is the basic mode of profiling and carries the least amount of&#13;
overhead. That’s important, since one of the pitfalls of profiling is that by&#13;
introducing <span class="keep-together">measurement</span> into the application, you are altering its performance&#13;
characteristics.<sup><a data-type="noteref" href="ch03.html#idm45775556710120" id="idm45775556710120-marker">1</a></sup> Limiting the impact of profiling will lead&#13;
to results that more closely model the way the application behaves under usual&#13;
circumstances.</p>&#13;
&#13;
<p>Unfortunately, sampling profilers can be subject to all sorts of errors.&#13;
Sampling profilers work when a timer periodically fires;&#13;
the profiler then looks at each thread and determines which method the&#13;
thread is executing. That method is then charged with having been executed since&#13;
the timer previously fired.</p>&#13;
&#13;
<p>The most common sampling error is illustrated by <a data-type="xref" href="#FigureProfile">Figure 3-1</a>. The&#13;
thread here is alternating between executing&#13;
<span class="keep-together"><code>methodA</code></span>&#13;
(shown in the shaded&#13;
bars) and&#13;
<span class="keep-together"><code>methodB</code></span>&#13;
(shown in the clear bars). If&#13;
the timer fires only when the thread happens to be in&#13;
<span class="keep-together"><code>methodB</code></span>,&#13;
the profile&#13;
will report that the thread spent all its time executing&#13;
<span class="keep-together"><code>methodB</code></span>;&#13;
in&#13;
reality, more time was actually spent in&#13;
<span class="keep-together"><code>methodA</code></span>.</p>&#13;
&#13;
<figure><div class="figure" id="FigureProfile">&#13;
<img alt="Figure of Methods Executing Alternately" src="assets/jp2e_0301.png"/>&#13;
<h6><span class="label">Figure 3-1. </span>Alternate method execution</h6>&#13;
</div></figure>&#13;
&#13;
<p>This is the most common sampling error, but it is by no means the only one.&#13;
The way to minimize this error is to profile over a longer period of time and to reduce the time interval between samples. Reducing the interval between&#13;
samples is counterproductive to the goal of minimizing the impact of&#13;
profiling on the application; there is a balance here. Profiling&#13;
tools resolve that balance differently, which is one reason that one profiling&#13;
tool may happen to report much different data than another tool.</p>&#13;
&#13;
<p>That kind of error is inherent to all sampling profilers, but is worse in many&#13;
Java profilers (particularly older ones). This is due to <em>safepoint bias</em>.&#13;
In the common Java interface for profilers, the profiler can get&#13;
the stack trace of a thread only when the thread is at a safepoint. Threads&#13;
automatically go into a safepoint when they are:</p>&#13;
&#13;
<ul>&#13;
<li>&#13;
<p>Blocked on a synchronized lock</p>&#13;
</li>&#13;
<li>&#13;
<p>Blocked waiting for I/O</p>&#13;
</li>&#13;
<li>&#13;
<p>Blocked waiting for a monitor</p>&#13;
</li>&#13;
<li>&#13;
<p>Parked</p>&#13;
</li>&#13;
<li>&#13;
<p>Executing Java Native Interface (JNI) code (unless they perform a GC locking function)</p>&#13;
</li>&#13;
</ul>&#13;
&#13;
<p>In addition, the JVM can set a flag asking for threads to go into a safepoint.&#13;
Code to check this flag (and go to a safepoint if necessary) is inserted into&#13;
the JVM code at key locations, including during certain memory allocations&#13;
and at loop or method transitions in compiled code. No specification&#13;
indicates when these safepoint checks occur, and they vary between releases.</p>&#13;
&#13;
<p>The effect of this safepoint bias on sampling profilers can be profound:&#13;
because the stack can be sampled only when the thread is at a safepoint, the sampling becomes even less&#13;
reliable. In <a data-type="xref" href="#FigureProfile">Figure 3-1</a>, it would be unlikely that a random profiler&#13;
without safepoint bias would fire the thread samples only during the execution&#13;
of <code>methodB</code>. But with safepoint bias, it is easier to see scenarios where&#13;
<code>methodA</code> never goes to a safepoint and all work is therefore charged to&#13;
<code>methodB</code>.</p>&#13;
&#13;
<p>Java 8 provides a different way for tools to gather stack traces (which is one&#13;
reason older tools have safepoint bias, and newer tools tend not to have&#13;
safepoint bias, though that does require that the newer tool be rewritten&#13;
to use the new mechanism). In&#13;
programmatic terms, this is done by using the <code>AsyncGetCallTrace</code> interface.&#13;
<a data-primary="async profilers" data-type="indexterm" id="idm45775556688424"/>Profilers that use this interface tend to be called <em>async profilers</em>.&#13;
The <em>async</em> here refers to the way the JVM provides the stack information,&#13;
and not anything about how the profiling tool works; it’s called&#13;
<em>async</em> because the JVM can provide the stack at any point in time, without&#13;
waiting for the thread to come to a (synchronous) <span class="keep-together">safepoint.</span></p>&#13;
&#13;
<p>Profilers that use this async interface hence have fewer sampling artifacts&#13;
than other sampling profilers (though they’re still subject to errors like&#13;
that in <a data-type="xref" href="#FigureProfile">Figure 3-1</a>). The async interface was made public in Java 8&#13;
but existed as a private interface well before that.</p>&#13;
&#13;
<p><a data-type="xref" href="#FigureSampleProfile">Figure 3-2</a> shows a basic sampling profile taken to measure the&#13;
performance of a REST server that provides sample stock data from the&#13;
application described in <a data-type="xref" href="ch02.html#SampleApplications">Chapter 2</a>. The REST call is configured&#13;
to return a byte stream containing the compressed, serialized form of the&#13;
stock object (part of an example we’ll explore in <a data-type="xref" href="ch12.html#Misc">Chapter 12</a>).&#13;
We’ll use that sample program&#13;
for examples throughout this section.</p>&#13;
&#13;
<figure><div class="figure" id="FigureSampleProfile">&#13;
<img alt="A profile from a sampling profiler." src="assets/jp2e_0302.png"/>&#13;
<h6><span class="label">Figure 3-2. </span>A sample-based profile</h6>&#13;
</div></figure>&#13;
&#13;
<p>This screenshot is from the Oracle Developer Studio profiler. This tool uses&#13;
the async profiling interface, though it is not usually called an async&#13;
profiler (likely for historical reasons, since it began using that interface&#13;
when the interface was private and hence predates the popular use of the&#13;
async profiler term). It provides various views into the data; in this view,&#13;
we see the methods that consumed the most CPU cycles. Several of those&#13;
methods are related to object serialization (e.g., the&#13;
<span class="keep-together"><code>ObjectOutputStream.writeObject0()</code></span> method), and many are related to calculating the actual data&#13;
(e.g., the&#13;
<span class="keep-together"><code>Math.pow()</code></span>&#13;
method).<sup><a data-type="noteref" href="ch03.html#idm45775556676248" id="idm45775556676248-marker">2</a></sup>&#13;
Still, the object serialization is dominating this profile; to improve&#13;
performance, we’ll need to improve the serialization performance.</p>&#13;
&#13;
<p>Note carefully the last statement: it is the performance of serialization that&#13;
must be improved, and not the performance of the&#13;
<span class="keep-together"><code>writeObject0()</code></span>&#13;
method itself.&#13;
The common assumption when looking at a profile is that improvements&#13;
must come from optimizing the top method in the profile. However, that approach is&#13;
often too limiting. In this case, the&#13;
<span class="keep-together"><code>writeObject0()</code></span>&#13;
method is&#13;
part of the JDK; its performance isn’t going to&#13;
be improved without rewriting the JVM.&#13;
But we do know from the profile that the serialization path is where our&#13;
performance bottleneck lies.</p>&#13;
&#13;
<p>So the top method(s) in a profile should point you to the area in&#13;
which to search for optimizations. Performance engineers aren’t&#13;
going to attempt to make JVM methods faster, but they can figure out&#13;
how to speed up object serialization in general.</p>&#13;
&#13;
<p>We can visualize the sampling output in two additional ways; both visually display the call stack. <a data-primary="flame graph" data-type="indexterm" id="idm45775556670520"/>The newest approach is called a <em>flame graph</em>, which is an interactive diagram of the call stacks within an application.</p>&#13;
&#13;
<p><a data-type="xref" href="#FigureFlameGraph">Figure 3-3</a> shows a portion of a flame graph from using the&#13;
open source&#13;
<a href="https://oreil.ly/DbNSL"><code>async-profiler</code> project</a>.&#13;
A flame graph&#13;
is a bottom-up diagram of the methods using the most CPU. In this section&#13;
of the graph, the <code>getStockObject()</code> method is taking all the time. Roughly&#13;
60% of that time is spent in the <code>writeObject()</code> call, and 40% of the time&#13;
in the constructor of the <code>StockPriceHistoryImpl</code> object. Similarly, we can&#13;
read up the stack of each of those methods and locate our performance&#13;
bottlenecks. The graph itself is interactive, so you can click lines&#13;
and see information about the <span class="keep-together">method—including</span> the full name where that gets cut off, the CPU cycles, and so on.</p>&#13;
&#13;
<p>The older (though still useful) approach to visualizing the performance&#13;
is a top-down approach known as the <em>call tree</em>. <a data-type="xref" href="#FigureCallTree">Figure 3-4</a> shows an example.</p>&#13;
&#13;
<figure><div class="figure" id="FigureFlameGraph">&#13;
<img alt="A flame graph from a sampling profiler." src="assets/jp2e_0303.png"/>&#13;
<h6><span class="label">Figure 3-3. </span>A flame graph from a sampling profiler</h6>&#13;
</div></figure>&#13;
&#13;
<figure><div class="figure" id="FigureCallTree">&#13;
<img alt="A call tree from a sampling profiler." src="assets/jp2e_0304.png"/>&#13;
<h6><span class="label">Figure 3-4. </span>A call tree from a sampling profiler</h6>&#13;
</div></figure>&#13;
&#13;
<p>In this case, we have similar data starting with the top: of 100% of time,&#13;
44% was spent by the <code>Errors.process()</code> method and its descendants. Then we&#13;
drill into a parent and see where its children are spending time. For example,&#13;
of the 17% of total time spent in the <code>getStockObject()</code> method, 10% of that&#13;
time was spent in <span class="keep-together"><code>writeObject0</code></span> and 7% in the constructor.</p>&#13;
<div data-type="tip"><h1>Quick Summary</h1>&#13;
<ul>&#13;
<li>&#13;
<p>Sampling-based profilers are the most common kind of profiler.</p>&#13;
</li>&#13;
<li>&#13;
<p>Because of their relatively low performance impact, sampling profilers introduce fewer measurement artifacts.</p>&#13;
</li>&#13;
<li>&#13;
<p>Sampling profilers that can use asynchronous stack collection will have fewer measurement artifacts.</p>&#13;
</li>&#13;
<li>&#13;
<p>Different sampling profiles behave differently; each may be better for a particular application.<a data-startref="ix_ch03-asciidoc20" data-type="indexterm" id="idm45775556651208"/><a data-startref="ix_ch03-asciidoc19" data-type="indexterm" id="idm45775556650504"/></p>&#13;
</li>&#13;
</ul>&#13;
</div>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Instrumented Profilers" data-type="sect2"><div class="sect2" id="idm45775556714760">&#13;
<h2>Instrumented Profilers</h2>&#13;
&#13;
<p><a data-primary="instrumented profilers" data-type="indexterm" id="idm45775556648344"/><a data-primary="profilers" data-secondary="instrumented profilers" data-type="indexterm" id="idm45775556647640"/><em>Instrumented profilers</em> are much more intrusive than sampling profilers, but&#13;
they can also give more beneficial information about what’s happening inside&#13;
a program.</p>&#13;
&#13;
<p>Instrumented profilers work by&#13;
altering the bytecode sequence of classes as they are loaded (inserting&#13;
code to count the invocations, and so on). They are much more likely to&#13;
introduce performance differences into the application than are sampling&#13;
profilers.&#13;
For example, the JVM will inline small methods (see&#13;
<a data-type="xref" href="ch04.html#JustInTimeCompilation">Chapter 4</a>) so that no method invocation is needed when the&#13;
small-method code is executed. The compiler makes that decision based on the&#13;
size of the code; depending on how the code is instrumented, it may no&#13;
longer be eligible to be inlined.&#13;
This may cause the instrumented profiler to overestimate the contribution&#13;
of certain methods. And inlining is just one example of a decision that&#13;
the compiler makes based on the layout of the code; in general, the more&#13;
the code is instrumented (changed), the more likely it is that its execution&#13;
profile will change.</p>&#13;
&#13;
<p>Because of the changes introduced into the code via instrumentation, it is&#13;
best to limit its use to a few classes. This means it is best used for&#13;
second-level analysis: a sampling profiler can point to a package or section&#13;
of code, and then the instrumented profiler can be used to drill into that&#13;
code if needed.</p>&#13;
&#13;
<p><a data-type="xref" href="#FigureInstrumentedProfile">Figure 3-5</a> uses an instrumenting profiler (which is not&#13;
using the async interfaces)&#13;
to look at the sample REST server.</p>&#13;
&#13;
<figure><div class="figure" id="FigureInstrumentedProfile">&#13;
<img alt="A profile from an instrumented profiler." src="assets/jp2e_0305.png"/>&#13;
<h6><span class="label">Figure 3-5. </span>An instrumented profile</h6>&#13;
</div></figure>&#13;
&#13;
<p>A few things are different about this profiler. First, the dominant time&#13;
is attributed to the <code>writeObject()</code> method and not the <code>writeObject0()</code> method.&#13;
That’s because private methods are filtered out of the instrumentation.&#13;
Second, a new method from the entity manager appears; this&#13;
didn’t appear earlier because it was inlined into the constructor in the&#13;
sampling case.</p>&#13;
&#13;
<p>But the more important thing about this kind of profile is the invocation count:&#13;
we executed a whopping 33 million calls to that entity manager method, and&#13;
166 million calls to calculate a random number. We can have a much greater&#13;
performance impact by reducing the total number of calls to these methods&#13;
rather than speeding up their implementations, but we wouldn’t necessarily&#13;
know that without the instrumentation count.</p>&#13;
&#13;
<p>Is this a better profile than the sampled version? It depends; there is&#13;
no way to know in a given situation which is the more accurate profile.&#13;
The invocation count of an instrumented profile is certainly accurate, and&#13;
that additional information is often helpful in determining where the&#13;
code is spending more time and which things are more fruitful to&#13;
optimize.</p>&#13;
&#13;
<p>In this example, both the instrumented and sampled profiles point to the&#13;
same general area of the code: object serialization.&#13;
In practice, it is possible for different profilers to point&#13;
to completely different areas of the code. Profilers are good estimators,&#13;
but they are only making estimates: some of them will be wrong some of the&#13;
time.</p>&#13;
<div data-type="tip"><h1>Quick Summary</h1>&#13;
<ul>&#13;
<li>&#13;
<p>Instrumented profilers yield more information about an application but could have a greater effect on the application than a sampling profiler.</p>&#13;
</li>&#13;
<li>&#13;
<p>Instrumented profilers should be set up to instrument small sections of the code—a few classes or packages. That limits their impact on the application’s performance.</p>&#13;
</li>&#13;
</ul>&#13;
</div>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Blocking Methods and Thread Timelines" data-type="sect2"><div class="sect2" id="idm45775556649192">&#13;
<h2>Blocking Methods and Thread Timelines</h2>&#13;
&#13;
<p><a data-primary="blocking methods" data-type="indexterm" id="ix_ch03-asciidoc21"/><a data-primary="profilers" data-secondary="blocking methods/thread timelines" data-type="indexterm" id="ix_ch03-asciidoc22"/><a data-primary="thread timelines" data-type="indexterm" id="ix_ch03-asciidoc23"/><a data-type="xref" href="#FigureBlockProfile">Figure 3-6</a> shows the REST server using a different&#13;
instrumented profiling tool: the profiler built into <code>jvisualvm</code>. Now the execution&#13;
time is dominated by the&#13;
<span class="keep-together"><code>select()</code></span>&#13;
methods (and to a lesser extent, the&#13;
<span class="keep-together"><code>run()</code></span>&#13;
methods of the <code>TCPTransport</code> connection handler).</p>&#13;
&#13;
<figure><div class="figure" id="FigureBlockProfile">&#13;
<img alt="A profile that shows blocked methods." src="assets/jp2e_0306.png"/>&#13;
<h6><span class="label">Figure 3-6. </span>A profile with blocked methods</h6>&#13;
</div></figure>&#13;
&#13;
<p>Those methods (and similar blocking methods) do not consume CPU time, so&#13;
they are not contributing to the overall CPU usage of the application.&#13;
Their execution cannot necessarily be optimized. Threads in the application are&#13;
not spending 673 seconds executing code in the&#13;
<span class="keep-together"><code>select()</code></span>&#13;
method; they are&#13;
spending 673 seconds waiting for a selection event to occur.</p>&#13;
&#13;
<p class="pagebreak-before">For that reason, most profilers will not report methods that are blocked;&#13;
those threads are shown as being idle.&#13;
In this&#13;
particular example, that is&#13;
a good thing. Threads wait in the <code>select()</code> method because no data is flowing&#13;
into the server; they are not being inefficient.&#13;
That is their normal state.</p>&#13;
&#13;
<p>In other cases, you do want to see the time spent in those blocking calls.&#13;
The time that a thread spends inside the&#13;
<span class="keep-together"><code>wait()</code></span>&#13;
method—waiting for another thread to notify it—is a significant determinant of the overall&#13;
execution time of many applications. Most Java-based profilers have filter&#13;
sets and other options that can be tweaked to show or hide these blocking&#13;
calls.</p>&#13;
&#13;
<p>Alternately, it is usually more fruitful to examine the execution patterns&#13;
of threads rather than the amount of time a profiler attributes to the&#13;
blocking method itself. <a data-type="xref" href="#FigureStudioTimeline">Figure 3-7</a> shows a thread display&#13;
from the Oracle Developer Studio profiling tool.</p>&#13;
&#13;
<figure><div class="figure" id="FigureStudioTimeline">&#13;
<img alt="A profile showing per-thread execution information" src="assets/jp2e_0307.png"/>&#13;
<h6><span class="label">Figure 3-7. </span>A thread timeline profile</h6>&#13;
</div></figure>&#13;
&#13;
<p>Each horizontal area here is a different thread (so the figure shows nine threads: thread 1.14 to thread 1.22).&#13;
The colored (or different grayscale) bars represent <span class="keep-together">execution</span> of&#13;
different methods;&#13;
blank areas represent places where&#13;
the thread is not executing. At a high level, observe that thread&#13;
1.14 executed code and then waited for something.</p>&#13;
&#13;
<p>Notice too the blank areas where no thread appears to be&#13;
executing. The image shows only nine of many threads in the application, so&#13;
it is possible that these threads are waiting for one of those other threads&#13;
to do something, or the thread could be&#13;
executing a blocking <code>read()</code> (or similar) call.</p>&#13;
<div data-type="tip"><h1>Quick Summary</h1>&#13;
<ul>&#13;
<li>&#13;
<p>Threads that are blocked may or may not be a source of a performance issue; it is necessary to examine why they are blocked.</p>&#13;
</li>&#13;
<li>&#13;
<p>Blocked threads can be identified by the method that is blocking or by a timeline analysis of the thread.<a data-startref="ix_ch03-asciidoc23" data-type="indexterm" id="idm45775556608264"/><a data-startref="ix_ch03-asciidoc22" data-type="indexterm" id="idm45775556607560"/><a data-startref="ix_ch03-asciidoc21" data-type="indexterm" id="idm45775556606888"/></p>&#13;
</li>&#13;
</ul>&#13;
</div>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Native Profilers" data-type="sect2"><div class="sect2" id="idm45775556631720">&#13;
<h2>Native Profilers</h2>&#13;
&#13;
<p><a data-primary="native profilers" data-type="indexterm" id="ix_ch03-asciidoc24"/><a data-primary="profilers" data-secondary="native profilers" data-type="indexterm" id="ix_ch03-asciidoc25"/>Tools like <code>async-profiler</code> and Oracle Developer Studio have the&#13;
capability to profile native code in addition to Java code. This has&#13;
two advantages.</p>&#13;
&#13;
<p>First, significant operations occur in native code, including&#13;
within native libraries and native memory allocation. In <a data-type="xref" href="ch08.html#NativeMemory">Chapter 8</a>,&#13;
we’ll use a native profiler to see an example of a native memory allocation&#13;
that caused a real-world issue. Using the native profiler to track memory usage&#13;
quickly pinpointed the root cause.</p>&#13;
&#13;
<p>Second, we typically profile to find bottlenecks in application code, but&#13;
sometimes the native code is unexpectedly dominating performance. We would&#13;
prefer to find out our code is spending too much time in GC by examining GC&#13;
logs (as we’ll do in <a data-type="xref" href="ch06.html#Collectors">Chapter 6</a>), but if we forget that path, a profiler&#13;
that understands native code will quickly show us we’re spending too much time&#13;
in GC. Similarly, we would generally limit a profile to the period after the&#13;
program has warmed up, but if compilation threads (<a data-type="xref" href="ch04.html#JustInTimeCompilation">Chapter 4</a>)&#13;
are running and taking too much CPU, a native-capable profiler will show us&#13;
that.</p>&#13;
&#13;
<p>When you looked at the flame graph for our sample REST server, I showed only a&#13;
small portion for readability. <a data-type="xref" href="#FigureNativeFlameGraph">Figure 3-8</a> shows the entire&#13;
graph.</p>&#13;
&#13;
<p>At the bottom of this graph are five components. The first two (from&#13;
JAX-RS code) are application threads and Java code. The third, though, is the GC for the process, and the fourth is the compiler.<sup><a data-type="noteref" href="ch03.html#idm45775556595416" id="idm45775556595416-marker">3</a></sup></p>&#13;
&#13;
<figure><div class="figure" id="FigureNativeFlameGraph">&#13;
<img alt="A profile showing per-thread execution information" src="assets/jp2e_0308.png"/>&#13;
<h6><span class="label">Figure 3-8. </span>A flame graph including native code</h6>&#13;
</div></figure>&#13;
<div data-type="tip"><h1>Quick Summary</h1>&#13;
<ul>&#13;
<li>&#13;
<p>Native profilers provide visibility into both the JVM code and the application code.</p>&#13;
</li>&#13;
<li>&#13;
<p>If a native profiler shows that time in GC dominates the CPU usage, tuning the collector is the right thing to do. If it shows significant time in the compilation threads, however, that is usually not affecting the application’s performance<a data-startref="ix_ch03-asciidoc25" data-type="indexterm" id="idm45775556589080"/><a data-startref="ix_ch03-asciidoc24" data-type="indexterm" id="idm45775556588376"/>.<a data-startref="ix_ch03-asciidoc18" data-type="indexterm" id="idm45775556587576"/><a data-startref="ix_ch03-asciidoc17" data-type="indexterm" id="idm45775556586872"/><a data-startref="ix_ch03-asciidoc16" data-type="indexterm" id="idm45775556586200"/></p>&#13;
</li>&#13;
</ul>&#13;
</div>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Java Flight Recorder" data-type="sect1"><div class="sect1" id="JFR">&#13;
<h1>Java Flight Recorder</h1>&#13;
&#13;
<p><a data-primary="Java Flight Recorder (JFR)" data-type="indexterm" id="ix_ch03-asciidoc26"/><a data-primary="performance testing" data-secondary="Java Flight Recorder" data-type="indexterm" id="ix_ch03-asciidoc27"/><a data-primary="performance tools" data-secondary="Java Flight Recorder" data-type="indexterm" id="ix_ch03-asciidoc28"/><em>Java Flight Recorder</em> (JFR) is a feature of the JVM that performs lightweight&#13;
performance analysis of applications while they are running.&#13;
As its name suggests, JFR data is a history of events in the JVM that can&#13;
be used to diagnose the past performance and operations of the JVM.</p>&#13;
&#13;
<p>JFR was originally a feature of the JRockit JVM from&#13;
BEA Systems. It eventually made its way into Oracle’s HotSpot JVM;&#13;
in JDK 8, only the Oracle JVM supports JFR (and it is licensed for use only by&#13;
Oracle customers). In JDK 11, however, JFR is&#13;
available in open source JVMs including the AdoptOpenJDK JVMs. Because JFR is&#13;
open source in JDK 11, it is possible for it to be backported in open source&#13;
to JDK 8, so AdoptOpenJDK and other versions of JDK 8 may someday include&#13;
JFR (though that is not the case at least through 8u232).</p>&#13;
&#13;
<p>The basic operation of JFR is that a set of events is enabled (for example,&#13;
one event is that a thread is blocked waiting for a lock), and each time a selected&#13;
event occurs, data about that event is saved (either in memory or to a file).&#13;
The data stream is held in a circular buffer, so only the most recent&#13;
events are available. Then you can use a tool to display those events—either&#13;
taken from a live JVM or read from a saved file—and you can perform analysis&#13;
on those events to diagnose performance issues.</p>&#13;
&#13;
<p>All of that—the kind of events, the size of the circular buffer, where&#13;
it is stored, and so on—is controlled via various arguments to the JVM, or via tools, including <code>jcmd</code> commands as the program runs. By&#13;
default, JFR is set up so that it has very low overhead: an impact&#13;
below 1% of the program’s performance. That overhead will change as more events are enabled, as the threshold at which events are reported is changed, and so on.&#13;
The details of all that configuration are discussed later in this section,&#13;
but first we’ll examine&#13;
what the display of these events look like, since that makes it easier&#13;
to understand how JFR works.</p>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Java Mission Control" data-type="sect2"><div class="sect2" id="idm45775556575608">&#13;
<h2>Java Mission Control</h2>&#13;
&#13;
<p><a data-primary="Java Flight Recorder (JFR)" data-secondary="Java Mission Control" data-type="indexterm" id="ix_ch03-asciidoc29"/><a data-primary="Java Mission Control (jmc)" data-type="indexterm" id="ix_ch03-asciidoc30"/><a data-primary="jmc (Java Mission Control)" data-type="indexterm" id="ix_ch03-asciidoc31"/>The usual tool to examine JFR recordings is <em>Java Mission Control</em> (<code>jmc</code>),&#13;
though other tools exist, and you can use toolkits to write your own&#13;
analysis&#13;
tools. In the shift to a full open source JVM, <code>jmc</code> was moved out of the&#13;
OpenJDK source base and into a separate project. This allows <code>jmc</code> to evolve on&#13;
a separate release schedule and path, though at first it can be a little&#13;
confusing to deal with the separate releases.</p>&#13;
&#13;
<p>In JDK 8, <code>jmc</code> version 5 is bundled with Oracle’s JVM (the only JVM for&#13;
which JFR is available). JDK 11 can use <code>jmc</code> version 7, though for now,&#13;
the binaries for that must be obtained from the&#13;
<a href="http://openjdk.java.net/projects/jmc">OpenJDK project page</a>. The plan&#13;
is that eventually JDK builds will&#13;
consume and bundle the appropriate <code>jmc</code> binaries.</p>&#13;
&#13;
<p>The Java Mission Control program (<code>jmc</code>) starts a window that displays&#13;
the JVM processes on the machine and lets you select one or more processes to&#13;
monitor. <a data-primary="Java Management Extension (JMX)" data-type="indexterm" id="idm45775556565368"/><a data-primary="JMX (Java Management Extension)" data-type="indexterm" id="idm45775556564600"/><a data-type="xref" href="#FigureJMCMonitor">Figure 3-9</a> shows the Java Management Extensions (JMX) console of Java Mission Control monitoring our example REST server.</p>&#13;
&#13;
<figure><div class="figure" id="FigureJMCMonitor">&#13;
<img alt="A Java Mission Control window." src="assets/jp2e_0309.png"/>&#13;
<h6><span class="label">Figure 3-9. </span>Java Mission Control monitoring</h6>&#13;
</div></figure>&#13;
&#13;
<p>This display shows basic information that Java Mission Control is monitoring:&#13;
CPU usage, heap usage, and GC time. Note, though, that the CPU graph includes&#13;
the total&#13;
CPU on the machine. The JVM itself is using about 38% of the CPU, though all&#13;
processes on the machine are consuming about 60% of the CPU.&#13;
That is a key feature&#13;
of the monitoring: via the JMX console, Java Mission Control has the ability&#13;
to monitor the entire system, not just the JVM&#13;
that has been selected. The upper dashboard can be configured to display JVM&#13;
information (all kinds of statistics about GC, <span class="keep-together">classloading,</span> thread usage,&#13;
heap usage, and so on) as well as OS-specific information (total machine&#13;
CPU and memory usage, swapping, load averages, and so on).</p>&#13;
&#13;
<p>Like other monitoring tools, Java Mission Control can make Java Management&#13;
Extensions calls into whatever&#13;
managed beans the application has available.<a data-startref="ix_ch03-asciidoc31" data-type="indexterm" id="idm45775556558600"/><a data-startref="ix_ch03-asciidoc30" data-type="indexterm" id="idm45775556557896"/><a data-startref="ix_ch03-asciidoc29" data-type="indexterm" id="idm45775556557224"/></p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="JFR Overview" data-type="sect2"><div class="sect2" id="idm45775556556424">&#13;
<h2>JFR Overview</h2>&#13;
&#13;
<p><a data-primary="Java Flight Recorder (JFR)" data-secondary="overview" data-type="indexterm" id="ix_ch03-asciidoc32"/>With the appropriate tool, we can then look into how JFR works.&#13;
This example uses a JFR recording taken from our REST server&#13;
over a 6-minute period.&#13;
As the recording is loaded into Java Mission Control,&#13;
the first thing it displays is a basic monitoring overview (<a data-type="xref" href="#FigureJFRGeneral">Figure 3-10</a>).</p>&#13;
&#13;
<figure><div class="figure" id="FigureJFRGeneral">&#13;
<img alt="Basic Data Display from a JFR" src="assets/jp2e_0310.png"/>&#13;
<h6><span class="label">Figure 3-10. </span>Java Flight Recorder general information</h6>&#13;
</div></figure>&#13;
&#13;
<p>This display is similar to what Java Mission Control displays when doing&#13;
basic monitoring. Above the gauges showing CPU and heap usage is a timeline of events (represented by a series of vertical bars). The&#13;
timeline allows us to zoom into a particular region of interest; although&#13;
in this example the recording was taken over a 6-minute period, I zoomed&#13;
into a 38-second interval near the end of the recording.</p>&#13;
&#13;
<p>This graph for CPU usage more clearly shows what is going on:&#13;
the REST server is the bottom portion of the graph (averaging about 20%&#13;
usage), and the machine is running at 38% CPU usage. Along&#13;
the bottom, other tabs allow us to explore information about system&#13;
properties and how the JFR recording was made.&#13;
The icons that run down the left side of the window are more&#13;
interesting: those icons&#13;
provide visibility into the application behavior.</p>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="JFR Memory view" data-type="sect3"><div class="sect3" id="idm45775556548760">&#13;
<h3>JFR Memory view</h3>&#13;
&#13;
<p><a data-primary="Java Flight Recorder (JFR)" data-secondary="memory view" data-type="indexterm" id="idm45775556547320"/>The information gathered here is extensive. <a data-type="xref" href="#FigureJFRMemory">Figure 3-11</a> shows&#13;
just one panel of the Memory view.</p>&#13;
&#13;
<figure><div class="figure" id="FigureJFRMemory">&#13;
<img alt="A display of the Java Flight Recorder Memory Panel" src="assets/jp2e_0311.png"/>&#13;
<h6><span class="label">Figure 3-11. </span>Java Flight Recorder Memory panel</h6>&#13;
</div></figure>&#13;
&#13;
<p>This graph shows that memory is fluctuating fairly regularly as the&#13;
young generation is cleared (and we see that the heap overall is growing&#13;
during this time: it started at about 340 MB and ends about at 2 GB).&#13;
The lower-left panel shows all the collections that occurred&#13;
during the recording, including their duration and type of collection&#13;
(always a&#13;
<span class="keep-together"><code>ParallelScavenge</code></span>&#13;
in this example). When one of those events is&#13;
selected, the bottom-right panel breaks that down even further, showing all&#13;
the specific phases of that collection and how long each took.</p>&#13;
&#13;
<p>The various tabs on this page provide a wealth of&#13;
other information: how long and how many&#13;
reference objects were cleared, whether there are promotion or evacuation&#13;
failures from the concurrent collectors, the configuration of the GC&#13;
algorithm itself (including the sizes of the generations and the survivor&#13;
space configurations), and even information on the specific kinds of&#13;
objects that were allocated. As you read through Chapters <a data-type="xref" data-xrefstyle="select: labelnumber" href="ch05.html#GC">5</a> and <a data-type="xref" data-xrefstyle="select: labelnumber" href="ch06.html#Collectors">6</a>, keep in mind how&#13;
this tool can diagnose the problems that are discussed there.&#13;
If you need to understand why the G1 GC collector bailed out and performed a&#13;
full GC&#13;
(was it due to promotion failure?), how the JVM has <span class="keep-together">adjusted</span> the&#13;
tenuring threshold, or virtually any other piece of data about how and why&#13;
GC behaved as it did, JFR will be able to tell you.</p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="JFR Code view" data-type="sect3"><div class="sect3" id="idm45775556536840">&#13;
<h3>JFR Code view</h3>&#13;
&#13;
<p><a data-primary="Java Flight Recorder (JFR)" data-secondary="code view" data-type="indexterm" id="idm45775556535400"/>The Code page in Java Mission Control shows basic profiling information from the&#13;
recording (<a data-type="xref" href="#FigureJFRCode">Figure 3-12</a>).</p>&#13;
&#13;
<figure><div class="figure" id="FigureJFRCode">&#13;
<img alt="A JFR showing where the application spent its time executing." src="assets/jp2e_0312.png"/>&#13;
<h6><span class="label">Figure 3-12. </span>Java Flight Recorder Code panel</h6>&#13;
</div></figure>&#13;
&#13;
<p>The first tab on this page shows an aggregation by package name, which is&#13;
an interesting feature not found in many profilers.&#13;
At the bottom, other tabs present the traditional&#13;
profile views: the hot methods and call tree of the profiled code.</p>&#13;
&#13;
<p>Unlike other profilers, JFR offers other modes of visibility&#13;
into the code. The Exceptions tab provides a view into the exception&#13;
processing of the application (<a data-type="xref" href="ch12.html#Misc">Chapter 12</a> discusses why excessive&#13;
exception processing can be bad for performance). Other tabs&#13;
provide information on what the compiler is doing, including a view into the&#13;
code cache (see <a data-type="xref" href="ch04.html#JustInTimeCompilation">Chapter 4</a>).</p>&#13;
&#13;
<p>On the other hand, note that the&#13;
packages here didn’t really show up in the previous profiles we looked at;&#13;
conversely, the previous hot spots we saw don’t appear here. Because it is&#13;
designed to have very low overhead, the profile sampling of JFR (at least&#13;
in the default configuration) is quite low, and so the profiles are not as&#13;
accurate as what we’d see from a more intrusive sampling.</p>&#13;
&#13;
<p>There are other displays like this—for threads, I/O, and system events—but&#13;
for the most part, these displays simply provide nice views into the&#13;
actual events in the JFR recording.</p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Overview of JFR events" data-type="sect3"><div class="sect3" id="idm45775556526776">&#13;
<h3>Overview of JFR events</h3>&#13;
&#13;
<p><a data-primary="events, JFR" data-secondary="overview" data-type="indexterm" id="ix_ch03-asciidoc33"/><a data-primary="Java Flight Recorder (JFR)" data-secondary="events overview" data-type="indexterm" id="ix_ch03-asciidoc34"/>JFR produces a stream of events that are saved as a recording. The&#13;
displays seen so far provide views of those events, but the most&#13;
powerful way to look at the events is on the Event panel itself, as shown&#13;
in <a data-type="xref" href="#FigureJFREvent">Figure 3-13</a>.</p>&#13;
&#13;
<figure><div class="figure" id="FigureJFREvent">&#13;
<img alt="A display of events from a JFR." src="assets/jp2e_0313.png"/>&#13;
<h6><span class="label">Figure 3-13. </span>Java Flight Recorder Event panel</h6>&#13;
</div></figure>&#13;
&#13;
<p>The events to display can be filtered in the left panel of this window;&#13;
here, application-level and JVM-level events are selected. Be aware that&#13;
when the&#13;
recording is made, only certain kinds of events are included in the first&#13;
place: at this point, we are doing postprocessing filtering (the&#13;
next section shows how to filter the events included in the recording).</p>&#13;
&#13;
<p>Within the 34-second interval in this example, the application produced 878&#13;
events from the JVM and 32 events from the JDK libraries, and the event&#13;
types generated&#13;
in that period are shown near the bottom of the window. When we looked at&#13;
this example with profilers, we&#13;
saw why the thread-park and monitor-wait events for this example&#13;
will be high; those can be ignored (and the thread park events are&#13;
filtered out here in the left panel). What about the other events?</p>&#13;
&#13;
<p>Over the 34-second period, multiple threads in the application spent 34&#13;
seconds reading from sockets.&#13;
That number doesn’t sound good, particularly because it will show up&#13;
in JFR only if the socket read takes longer than 10 milliseconds. We need to look&#13;
at that further, which can be done by visiting the log tab shown in <a data-type="xref" href="#FigureJFRLog">Figure 3-14</a>.</p>&#13;
&#13;
<figure><div class="figure" id="FigureJFRLog">&#13;
<img alt="A log of events from a JFR." src="assets/jp2e_0314.png"/>&#13;
<h6><span class="label">Figure 3-14. </span>Java Flight Recorder Event Log panel</h6>&#13;
</div></figure>&#13;
&#13;
<p>It is worthwhile&#13;
to look at the traces involved with those events, but it turns out that&#13;
several threads use blocking I/O to read administrative&#13;
requests that are expected to arrive periodically. Between those&#13;
requests—for long periods of time—the threads sit blocked on the <code>read()</code>&#13;
method. So the read time here turns out to be acceptable: just as when&#13;
using a profiler, it is up to you to determine whether a lot of&#13;
threads blocked in I/O is expected or indicates a performance issue.</p>&#13;
&#13;
<p>That leaves the monitor-blocked events. As discussed in <a data-type="xref" href="ch09.html#ThreadPerformance">Chapter 9</a>,&#13;
contention for locks goes through two levels: first the thread spins waiting&#13;
for the lock, <a data-primary="lock inflation" data-type="indexterm" id="idm45775556511592"/>and then it uses (in a process called <em>lock inflation</em>) some&#13;
CPU- and OS-specific code to wait for&#13;
the lock. A standard profiler can give hints about that situation, since&#13;
the spinning time is included in the CPU time charged to a method. A native&#13;
profiler can give information about the locks subject to inflation,&#13;
but that can be hit or miss. The JVM, though, can provide all this data directly&#13;
to JFR.</p>&#13;
&#13;
<p>An example of using lock visibility is shown in <a data-type="xref" href="ch09.html#ThreadPerformance">Chapter 9</a>, but&#13;
the general takeaway about JFR events is that, because they come directly&#13;
from the JVM, they offer a level of visibility into an application that&#13;
no other tool can provide. In Java 11, about 131 event types&#13;
can be monitored with JFR. The exact number and types of events will vary slightly&#13;
depending on release, but the following list details some of the more useful ones.</p>&#13;
&#13;
<p>Each event type in the following list displays two bullet points.&#13;
Events can collect basic information that can be collected with other tools like&#13;
<code>jconsole</code> and <code>jcmd</code>; that kind of information is described in the first&#13;
bullet. The second bullet describes information the event provides that&#13;
is difficult to obtain outside JFR.</p>&#13;
<dl>&#13;
<dt>Classloading</dt>&#13;
<dd>&#13;
&#13;
<ul>&#13;
<li>&#13;
<p>Number of classes loaded and unloaded</p>&#13;
</li>&#13;
<li>&#13;
<p>Which classloader loaded the class; time required to load an individual class</p>&#13;
</li>&#13;
</ul>&#13;
</dd>&#13;
<dt>Thread statistics</dt>&#13;
<dd>&#13;
&#13;
<ul>&#13;
<li>&#13;
<p>Number of threads created and destroyed; thread dumps</p>&#13;
</li>&#13;
<li>&#13;
<p>Which threads are blocked on locks (and the specific lock they are blocked on)</p>&#13;
</li>&#13;
</ul>&#13;
</dd>&#13;
<dt>Throwables</dt>&#13;
<dd>&#13;
&#13;
<ul>&#13;
<li>&#13;
<p>Throwable classes used by the application</p>&#13;
</li>&#13;
<li>&#13;
<p>Number of exceptions and errors thrown and the stack trace of their <span class="keep-together">creation</span></p>&#13;
</li>&#13;
</ul>&#13;
</dd>&#13;
<dt>TLAB allocation</dt>&#13;
<dd>&#13;
&#13;
<ul>&#13;
<li>&#13;
<p>Number of allocations in the heap and size of thread-local allocation buffers (TLABs)</p>&#13;
</li>&#13;
<li>&#13;
<p>Specific objects allocated in the heap and the stack trace where they are allocated</p>&#13;
</li>&#13;
</ul>&#13;
</dd>&#13;
<dt>File and socket I/O</dt>&#13;
<dd>&#13;
&#13;
<ul>&#13;
<li>&#13;
<p>Time spent performing I/O</p>&#13;
</li>&#13;
<li>&#13;
<p>Time spent per read/write call, the specific file or socket taking a long time to read or write</p>&#13;
</li>&#13;
</ul>&#13;
</dd>&#13;
<dt>Monitor blocked</dt>&#13;
<dd>&#13;
&#13;
<ul>&#13;
<li>&#13;
<p>Threads waiting for a monitor</p>&#13;
</li>&#13;
<li>&#13;
<p>Specific threads blocked on specific monitors and the length of time they are blocked</p>&#13;
</li>&#13;
</ul>&#13;
</dd>&#13;
<dt>Code cache</dt>&#13;
<dd>&#13;
&#13;
<ul>&#13;
<li>&#13;
<p>Size of code cache and how much it contains</p>&#13;
</li>&#13;
<li>&#13;
<p>Methods removed from the code cache; code cache configuration</p>&#13;
</li>&#13;
</ul>&#13;
</dd>&#13;
<dt>Code compilation</dt>&#13;
<dd>&#13;
&#13;
<ul>&#13;
<li>&#13;
<p>Which methods are compiled, on-stack replacement (OSR) compilation (see <a data-type="xref" href="ch04.html#JustInTimeCompilation">Chapter 4</a>), and length of time to compile</p>&#13;
</li>&#13;
<li>&#13;
<p>Nothing specific to JFR, but unifies information from several sources</p>&#13;
</li>&#13;
</ul>&#13;
</dd>&#13;
<dt>Garbage collection</dt>&#13;
<dd>&#13;
&#13;
<ul>&#13;
<li>&#13;
<p>Times for GC, including individual phases; sizes of generations</p>&#13;
</li>&#13;
<li>&#13;
<p>Nothing specific to JFR, but unifies the information from several tools</p>&#13;
</li>&#13;
</ul>&#13;
</dd>&#13;
<dt>Profiling</dt>&#13;
<dd>&#13;
&#13;
<ul>&#13;
<li>&#13;
<p>Instrumenting and sampling profiles</p>&#13;
</li>&#13;
<li>&#13;
<p>Not as much as you’d get from a true profiler, but the JFR profile provides a good high-order <a data-startref="ix_ch03-asciidoc34" data-type="indexterm" id="idm45775556472360"/><a data-startref="ix_ch03-asciidoc33" data-type="indexterm" id="idm45775556471656"/>overview<a data-startref="ix_ch03-asciidoc32" data-type="indexterm" id="idm45775556470856"/></p>&#13;
</li>&#13;
</ul>&#13;
</dd>&#13;
</dl>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Enabling JFR" data-type="sect2"><div class="sect2" id="idm45775556526152">&#13;
<h2>Enabling JFR</h2>&#13;
&#13;
<p><a data-primary="Java Flight Recorder (JFR)" data-secondary="enabling" data-type="indexterm" id="ix_ch03-asciidoc35"/>JFR is initially disabled. <a data-primary="-XX:+FlightRecorder" data-type="indexterm" id="idm45775556467480"/>To enable&#13;
it, add the flag&#13;
<span class="keep-together"><code>-XX:+FlightRecorder</code></span>&#13;
to the command line of the application. This enables JFR as a feature, but no&#13;
recordings will be made until the recording process itself is enabled. That can occur&#13;
either through a GUI or via the command line.</p>&#13;
&#13;
<p><a data-primary="-XX:+UnlockCommercialFeatures" data-type="indexterm" id="idm45775556465336"/>In Oracle’s JDK 8, you must also specify this flag (prior to the&#13;
<code>FlightRecorder</code> flag):&#13;
<span class="keep-together"><code>-XX:+UnlockCommercialFeatures</code></span> (default: <code>false</code>).</p>&#13;
&#13;
<p><a data-primary="jinfo" data-type="indexterm" id="idm45775556462472"/>If you forget to include these flags, remember that&#13;
you can use <code>jinfo</code> to change their values and enable JFR. If you use&#13;
<code>jmc</code> to start a recording, it will automatically change these values in the&#13;
target JVM if necessary.</p>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Enabling JFR via Java Mission Control" data-type="sect3"><div class="sect3" id="idm45775556460520">&#13;
<h3>Enabling JFR via Java Mission Control</h3>&#13;
&#13;
<p><a data-primary="Java Flight Recorder (JFR)" data-secondary="enabling via Java Mission Control" data-type="indexterm" id="idm45775556459064"/><a data-primary="Java Mission Control (jmc)" data-type="indexterm" id="idm45775556458008"/><a data-primary="jmc (Java Mission Control)" data-type="indexterm" id="idm45775556457320"/>The easiest way to enable recording of a local application is through the Java Mission Control GUI (<code>jmc</code>).&#13;
When <code>jmc</code> is started, it displays a list of all the JVM processes running&#13;
on the current system. The JVM processes are displayed in a tree-node&#13;
configuration; expand the node under the Flight Recorder label to bring&#13;
up the flight recorder window shown in <a data-type="xref" href="#FigureJFRStart">Figure 3-15</a>.</p>&#13;
&#13;
<figure><div class="figure" id="FigureJFRStart">&#13;
<img alt="The Wizard to start a flight recording and control its parameters." src="assets/jp2e_0315.png"/>&#13;
<h6><span class="label">Figure 3-15. </span>JFR Start Flight Recording window</h6>&#13;
</div></figure>&#13;
&#13;
<p>Flight recordings are made in one of two modes: either for a fixed duration (1 minute in this case) or continuously. For continuous recordings, a&#13;
circular buffer is utilized; the buffer will contain the most recent events&#13;
that are within the desired duration and size.</p>&#13;
&#13;
<p>To perform proactive analysis—meaning that you will start a&#13;
recording and then generate some work or start a recording during a load-testing experiment after the JVM has warmed up—a fixed-duration&#13;
recording should be used. That recording will give a good indication of&#13;
how the JVM responded during the test.</p>&#13;
&#13;
<p>The continuous recording is best for reactive analysis. This lets the JVM&#13;
keep the most recent events and then dump out a recording in response to&#13;
an event. For example, the WebLogic application server can trigger that&#13;
a recording be dumped out in response to an abnormal event in the application&#13;
server (such as a request that takes more than 5 minutes to process). You&#13;
can set up your own monitoring tools to dump out the recording in response to&#13;
any sort of event.</p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Enabling JFR via the command line" data-type="sect3"><div class="sect3" id="idm45775556449992">&#13;
<h3>Enabling JFR via the command line</h3>&#13;
&#13;
<p><a data-primary="Java Flight Recorder (JFR)" data-secondary="enabling via command line" data-type="indexterm" id="ix_ch03-asciidoc37"/>After enabling JFR (with the&#13;
<span class="keep-together"><code>-XX:+FlightRecorder</code></span>&#13;
option), there are different&#13;
ways to control how and when the actual recording should happen.</p>&#13;
&#13;
<p><a data-primary="-XX:+FlightRecorderOptions" data-type="indexterm" id="ix_ch03-asciidoc38"/>In JDK 8, the default recording parameters can be controlled when the&#13;
JVM starts by using&#13;
the&#13;
<span class="keep-together"><code>-XX:+FlightRecorderOptions=</code><em><code>string</code></em></span>&#13;
parameter; this is most useful&#13;
for reactive recordings. The <em><code>string</code></em> in that parameter is a list of&#13;
comma-separated name-value pairs taken from these options:</p>&#13;
<dl>&#13;
<dt><code>name=<em>name</em></code></dt>&#13;
<dd>&#13;
<p>The name used to identify the recording.</p>&#13;
</dd>&#13;
<dt><code>defaultrecording=<em>&lt;true|false&gt;</em></code></dt>&#13;
<dd>&#13;
<p>Whether to start the recording initially. The default value is <code>false</code>; for reactive analysis, this should be set to <code>true</code>.</p>&#13;
</dd>&#13;
<dt><code>settings=<em>path</em></code></dt>&#13;
<dd>&#13;
<p>Name of the file containing the JFR settings (see the next section).</p>&#13;
</dd>&#13;
<dt><code>delay=<em>time</em></code></dt>&#13;
<dd>&#13;
<p>The amount of time (e.g., <code>30s</code>, <code>1h</code>) before the recording should start.</p>&#13;
</dd>&#13;
<dt><code>duration=<em>time</em></code></dt>&#13;
<dd>&#13;
<p>The amount of time to make the recording.</p>&#13;
</dd>&#13;
<dt><code>filename=<em>path</em></code></dt>&#13;
<dd>&#13;
<p>Name of the file to write the recording to.</p>&#13;
</dd>&#13;
<dt><code>compress=<em>&lt;true|false&gt;</em></code></dt>&#13;
<dd>&#13;
<p>Whether to compress (with gzip) the recording; the default is <code>false</code>.</p>&#13;
</dd>&#13;
<dt><code>maxage=<em>time</em></code></dt>&#13;
<dd>&#13;
<p>Maximum time to keep recorded data in the circular buffer.</p>&#13;
</dd>&#13;
<dt><code>maxsize=<em>size</em></code></dt>&#13;
<dd>&#13;
<p>Maximum size (e.g., <code>1024K</code>, <code>1M</code>) of the recording’s circular buffer.</p>&#13;
</dd>&#13;
</dl>&#13;
&#13;
<p><code>-XX:+FlightRecorderOptions</code> only sets the defaults for any options; individual&#13;
recordings can override those settings.</p>&#13;
&#13;
<p><a data-primary="-XX:+StartFlightRecorder" data-type="indexterm" id="idm45775556421496"/>In both JDK 8 and JDK 11, you can start a JFR when the program initially&#13;
begins by using the&#13;
<span class="keep-together"><code>-XX:+StartFlightRecording=<em>string</em></code></span>&#13;
flag with a similar comma-separated list of options.</p>&#13;
&#13;
<p>Setting up a default recording like that can be useful in some circumstances,&#13;
but for more flexibility, all options can be controlled with <code>jcmd</code> during a&#13;
run.</p>&#13;
&#13;
<p>To start a flight recording:</p>&#13;
<pre data-type="programlisting">&#13;
% <strong>jcmd process_id JFR.start [options_list]</strong>&#13;
</pre>&#13;
&#13;
<p>The <code>options_list</code> is a series of comma-separated&#13;
name-value pairs that&#13;
control how the recording is made. The possible options are exactly the&#13;
same as those that can be specified on the command line with the&#13;
<span class="keep-together"><code>-XX:+FlightRecorderOptions=</code><em><code>string</code></em></span>&#13;
flag.</p>&#13;
&#13;
<p>If a continuous recording has been enabled, the current data in the&#13;
circular buffer can be dumped to a file at any time via this command:</p>&#13;
<pre data-type="programlisting">&#13;
% <strong>jcmd process_id JFR.dump [options_list]</strong>&#13;
</pre>&#13;
&#13;
<p>The list of options includes the following:</p>&#13;
<dl>&#13;
<dt><code>name=<em>name</em></code></dt>&#13;
<dd>&#13;
<p>The name under which the recording was started (see the next example for <code>JFR.check</code>).</p>&#13;
</dd>&#13;
<dt><code>filename=<em>path</em></code></dt>&#13;
<dd>&#13;
<p>The location to dump the file to.</p>&#13;
</dd>&#13;
</dl>&#13;
&#13;
<p>It is possible that multiple JFR recordings have been enabled for a given&#13;
process. To see the available recordings:</p>&#13;
<pre data-type="programlisting">&#13;
% <strong>jcmd 21532 JFR.check [verbose]</strong>&#13;
21532:&#13;
Recording 1: name=1 maxsize=250.0MB (running)&#13;
&#13;
Recording 2: name=2 maxsize=250.0MB (running)&#13;
</pre>&#13;
&#13;
<p>In this example, process ID 21532 has two active JFR recordings that&#13;
are named 1 and 2. That name can be used to identify them in other <code>jcmd</code>&#13;
commands.</p>&#13;
&#13;
<p>Finally, to abort a recording in process:</p>&#13;
<pre data-type="programlisting">&#13;
% <strong>jcmd process_id JFR.stop [options_list]</strong>&#13;
</pre>&#13;
&#13;
<p>That command takes the following options:</p>&#13;
<dl>&#13;
<dt><code>name=<em>name</em></code></dt>&#13;
<dd>&#13;
<p>The recording name to stop.</p>&#13;
</dd>&#13;
<dt><code>discard=<em>boolean</em></code></dt>&#13;
<dd>&#13;
<p>If <code>true</code>, discard the data rather than writing it to the previously provided filename (if any).</p>&#13;
</dd>&#13;
<dt><code>filename=<em>path</em></code></dt>&#13;
<dd>&#13;
<p>Write the data to the given path.</p>&#13;
</dd>&#13;
</dl>&#13;
&#13;
<p>In an automated performance-testing system, running these command-line tools&#13;
and producing a recording is useful when it comes time to examine&#13;
those runs for <a data-startref="ix_ch03-asciidoc38" data-type="indexterm" id="idm45775556395816"/><span class="keep-together">regressions</span><a data-startref="ix_ch03-asciidoc37" data-type="indexterm" id="idm45775556394584"/>.<a data-startref="ix_ch03-asciidoc35" data-type="indexterm" id="idm45775556393752"/></p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Selecting JFR Events" data-type="sect2"><div class="sect2" id="idm45775556449048">&#13;
<h2>Selecting JFR Events</h2>&#13;
&#13;
<p><a data-primary="events, JFR" data-secondary="selecting" data-type="indexterm" id="ix_ch03-asciidoc39"/><a data-primary="Java Flight Recorder (JFR)" data-secondary="selecting JFR events" data-type="indexterm" id="ix_ch03-asciidoc40"/>As mentioned earlier, JFR supports many events. Often, these&#13;
are periodic events: they occur every few milliseconds (e.g., the profiling&#13;
events work on a sampling basis). Other events are triggered only when the&#13;
duration of the event exceeds a certain threshold (e.g., the event for reading a&#13;
file is triggered only if the <code>read()</code> method has taken more than a&#13;
specified amount of time).</p>&#13;
<aside data-type="sidebar" epub:type="sidebar"><div class="sidebar" id="OtherJFREvents">&#13;
<h5>Other JFR Events</h5>&#13;
<p>JFR is extensible: applications can define their own events. Hence, your&#13;
JFR implementation may show many more available event types depending on the&#13;
application in question. For example, the WebLogic application server enables&#13;
multiple application server events: JDBC operations, HTTP operations,&#13;
and so on. These events are treated just like the other JFR events discussed&#13;
here: they can be individually enabled, may have a threshold associated&#13;
with them, and so on. Similarly, later versions of the JVM may have additional&#13;
events that are not discussed here.</p>&#13;
&#13;
<p>Consult the up-to-date product documentation for the most detailed information.</p>&#13;
</div></aside>&#13;
&#13;
<p>Collecting events naturally involves overhead. The threshold at which&#13;
events are collected—since it increases the number of events—also plays a&#13;
role in the overhead that comes from enabling a JFR recording. In the&#13;
default recording, not all events are collected (the six most-expensive&#13;
events are not enabled), and the threshold for the time-based events is&#13;
somewhat high.&#13;
This keeps the overhead of the default recording to less than 1%.</p>&#13;
&#13;
<p>Sometimes extra overhead is worthwhile. Looking at TLAB events,&#13;
for example, can help you determine if objects are being allocated directly&#13;
to the old generation, but those events&#13;
are not enabled in the default recording. Similarly, the profiling&#13;
events are enabled in the default recording, but only every 20 ms—that gives a good overview, but it can also lead to sampling errors.<sup><a data-type="noteref" href="ch03.html#idm45775556384040" id="idm45775556384040-marker">4</a></sup></p>&#13;
&#13;
<p>The events (and the threshold for events) that JFR captures are defined in&#13;
a template (which is selected via the&#13;
<span class="keep-together"><code>settings</code></span>&#13;
option on the command line). JFR ships&#13;
with two templates: the default template (limiting events&#13;
so that the overhead will be less than 1%) and a profile template (which&#13;
sets most threshold-based events to be triggered every 10 ms). The estimated&#13;
overhead of the profiling template is 2% (though, as always, your mileage&#13;
may vary, and typically overhead is lower than that).</p>&#13;
&#13;
<p>Templates are managed by the <code>jmc</code> template manager; you may have noticed a&#13;
button to start the template manager in <a data-type="xref" href="#FigureJFRStart">Figure 3-15</a>. Templates are&#13;
stored in two locations: under the <em>$HOME/.jmc/&lt;release&gt;</em> directory (local&#13;
to a user) and in the <em>$JAVA_HOME/jre/lib/jfr</em> directory (global for a JVM).&#13;
The template manager allows you to select a global template (the template&#13;
will say that it is “on server”), select a local template, or define a new&#13;
template. To define a template, cycle through the available events,&#13;
and enable (or disable) them as desired, optionally setting the threshold&#13;
at which the event kicks in.</p>&#13;
&#13;
<p><a data-type="xref" href="#FigureJFRTemplate">Figure 3-16</a> shows that the File Read&#13;
event is enabled with a threshold of 15 ms: file reads that take longer than&#13;
that will cause an event to be triggered. This event has also been configured&#13;
to generate a stack trace for the File Read events. That increases the&#13;
overhead—which in turn is why taking a stack trace for events is a&#13;
configurable option.</p>&#13;
&#13;
<figure><div class="figure" id="FigureJFRTemplate">&#13;
<img alt="The wizard to enable a JFR event." src="assets/jp2e_0316.png"/>&#13;
<h6><span class="label">Figure 3-16. </span>A sample JFR event template</h6>&#13;
</div></figure>&#13;
&#13;
<p>The event templates are simple XML files, so the best way to determine which&#13;
events are enabled in a template (and their thresholds and stack-trace&#13;
configurations) is to read the XML file. Using an XML file also allows&#13;
the local template&#13;
file to be defined on one machine and then copied to the global template&#13;
directory for use by others on the team.<a data-startref="ix_ch03-asciidoc40" data-type="indexterm" id="idm45775556374312"/><a data-startref="ix_ch03-asciidoc39" data-type="indexterm" id="idm45775556373608"/></p>&#13;
<div data-type="tip"><h1>Quick Summary</h1>&#13;
<ul>&#13;
<li>&#13;
<p>Java Flight Recorder provides the best possible visibility into the JVM, since it is built into the JVM itself.</p>&#13;
</li>&#13;
<li>&#13;
<p>Like all tools, JFR introduces some level of overhead into an application. For routine use, JFR can be enabled to gather a substantial amount of information with low overhead.</p>&#13;
</li>&#13;
<li>&#13;
<p>JFR is useful in performance analysis, but it is also useful when enabled on a production system so that you can examine the events that led up to a failure.<a data-startref="ix_ch03-asciidoc28" data-type="indexterm" id="idm45775556368616"/><a data-startref="ix_ch03-asciidoc27" data-type="indexterm" id="idm45775556367912"/><a data-startref="ix_ch03-asciidoc26" data-type="indexterm" id="idm45775556367240"/></p>&#13;
</li>&#13;
</ul>&#13;
</div>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Summary" data-type="sect1"><div class="sect1" id="idm45775556584712">&#13;
<h1>Summary</h1>&#13;
&#13;
<p>Good tools are key to good performance analysis; in this chapter, we’ve&#13;
just scratched the surface of what tools can tell us. Here are the key things to&#13;
keep in mind:</p>&#13;
&#13;
<ul>&#13;
<li>&#13;
<p>No tool is perfect, and competing tools have relative strengths. Profiler X may be a good fit for many applications, but in some cases it will miss something that Profiler Y points out quite clearly. Always be flexible in your approach.</p>&#13;
</li>&#13;
<li>&#13;
<p>Command-line monitoring tools can gather important data automatically; be sure to include gathering this monitoring data in your automated performance testing.</p>&#13;
</li>&#13;
<li>&#13;
<p>Tools rapidly evolve: some of the tools mentioned in this chapter are probably already obsolete (or at least have been superseded by new, superior tools). Keeping up-to-date in this area is important.<a data-startref="ix_ch03-asciidoc0" data-type="indexterm" id="idm45775556361368"/></p>&#13;
</li>&#13;
</ul>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<div data-type="footnotes"><p data-type="footnote" id="idm45775556710120"><sup><a href="ch03.html#idm45775556710120-marker">1</a></sup> Still, you must profile: how else will you know if the cat inside your program is still alive?</p><p data-type="footnote" id="idm45775556676248"><sup><a href="ch03.html#idm45775556676248-marker">2</a></sup> You’ll see references to native C++ code like <span class="keep-together"><code>InstanceKlass::oop_push_contents</code></span>; we’ll look at that more in the next section.</p><p data-type="footnote" id="idm45775556595416"><sup><a href="ch03.html#idm45775556595416-marker">3</a></sup> This particular graph is again from the Oracle Developer Studio tool, though <code>async-profiler</code> produced the identical set of native calls.</p><p data-type="footnote" id="idm45775556384040"><sup><a href="ch03.html#idm45775556384040-marker">4</a></sup> That’s why the JFR profile we looked at didn’t necessarily match the more intrusive profiles from previous sections.</p></div></div></section></body></html>