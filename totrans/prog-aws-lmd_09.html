<html><head></head><body><section data-pdf-bookmark="Chapter 9. Advanced Serverless Architecture" data-type="chapter" epub:type="chapter"><div class="chapter" id="ch09">&#13;
<h1><span class="label">Chapter 9. </span>Advanced Serverless Architecture</h1>&#13;
&#13;
&#13;
<p>In <a data-type="xref" href="ch08.html#ch08">Chapter 8</a> we looked at some more advanced aspects of Lambda that are important once you start thinking about productionizing your applications.&#13;
In this chapter, we continue that theme, looking more broadly at the impact of Lambda on architecture.</p>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Serverless Architecture “Gotchas”" data-type="sect1"><div class="sect1" id="idm46222411920568">&#13;
<h1>Serverless Architecture “Gotchas”</h1>&#13;
&#13;
<p>First we look at areas of serverless architecture that might cause you problems if you don’t consider them, and we offer different solutions for addressing these problems depending on your situation.</p>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="At-Least-Once Delivery" data-type="sect2"><div class="sect2" id="at-least-once-delivery">&#13;
<h2>At-Least-Once Delivery</h2>&#13;
&#13;
<p>The<a data-primary="task repetition, avoiding" data-secondary="issues with at-least-once-delivery" data-type="indexterm" id="idm46222411916776"/><a data-primary="event sources" data-secondary="at-least-once delivery and" data-type="indexterm" id="ESonce09"/><a data-primary="Lambda functions" data-secondary="at-least-once delivery and" data-type="indexterm" id="LFonce09"/><a data-primary="at-least-once-delivery" data-secondary="defined" data-type="indexterm" id="idm46222411913416"/><a data-primary="serverless architecture" data-secondary="dealing with at-least-once delivery" data-type="indexterm" id="SAatleastonce09"/> Lambda platform guarantees that when an upstream event source triggers a Lambda function, or if another application explicitly calls the Lambda <a href="https://oreil.ly/p1OWt"><em>invoke</em> API call</a>, then the corresponding Lambda function will be called.&#13;
But one thing the platform doesn’t guarantee is <em>how many times the function will be called</em>: “Occasionally, your function may receive the same event multiple times, even if no error occurs.”&#13;
This is known as “at-least-once delivery,” and it exists due to the fact that the Lambda platform is a distributed system.</p>&#13;
&#13;
<p>The vast majority of the time a Lambda function will be called only once per event.&#13;
But sometimes, very occasionally (far less than 1% of the time), a Lambda function will be called multiple times.&#13;
Why is this a problem? And how do you deal with this behavior? Let’s take a look.</p>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Example: Lambda “cron jobs”" data-type="sect3"><div class="sect3" id="lambda-cron-jobs">&#13;
<h3>Example: Lambda “cron jobs”</h3>&#13;
&#13;
<p>If<a data-primary="task repetition, avoiding" data-secondary="pitfalls of using Lambda as a cron platform" data-type="indexterm" id="idm46222411906728"/><a data-primary="cron jobs" data-type="indexterm" id="idm46222411905608"/><a data-primary="at-least-once-delivery" data-secondary="using Lambda as a cron platform" data-type="indexterm" id="idm46222411904936"/> you’ve been developing software in industry long enough, you’ve probably come across a server host that runs multiple “cron jobs”—scheduled tasks that run perhaps every hour or every day.&#13;
Because these tasks typically don’t run all the time it would be inefficient to run only one on each host, so it’s very typical to run multiple types of job on just one host.&#13;
This is more efficient, but can cause operational headaches—dependency clashes, ownership uncertainties, security concerns, etc.</p>&#13;
&#13;
<p>You<a data-primary="CloudWatch Scheduled Events" data-type="indexterm" id="idm46222411902936"/> can implement many kinds of activity that would otherwise be performed in a cron job as a Lambda function.&#13;
To get the schedule behavior of cron, you can use a <em>CloudWatch Scheduled Event</em> as a trigger. SAM gives you a <a href="https://oreil.ly/vFPnk">concise syntax</a> to specify this as a trigger for a function, and you can even use cron syntax to specify a <a href="https://oreil.ly/488um">schedule expression</a>.&#13;
There are various benefits to using Lambda as a cron platform—including improving all the operational headaches from the previous paragraph.</p>&#13;
&#13;
<p>The<a data-primary="Lambda functions" data-secondary="timeouts" data-type="indexterm" id="idm46222411899416"/><a data-primary="timeouts" data-type="indexterm" id="idm46222411898408"/> chief drawbacks to using Lambda to implement a cron task are if the function takes longer than 15 minutes to run (Lambda’s maximum timeout) or if it needs more than 3GB memory.&#13;
In either of these situations, if you can’t break up your task into smaller chunks, then you may want to look at <a href="https://oreil.ly/YDDyY">Step Functions</a> and/or <a href="https://oreil.ly/NP0Sq">Fargate</a> instead.</p>&#13;
&#13;
<p>But there is one other drawback to using Lambda: <em>very, very,</em> occasionally your cron job may run more than once at or near its scheduled time.&#13;
Often this won’t be a problem worth considering—maybe your task is a cleanup job where performing the same cleanup twice is slightly inefficient but functionally correct.&#13;
Other times, though, this might be a big problem—what if your task is calculating mortgage interest for the month—you wouldn’t want to charge that twice to a customer.</p>&#13;
&#13;
<p>This <em>at-least-once delivery</em> characteristic of Lambda applies to all event sources and invocations, not just scheduled events.&#13;
Fortunately, there are a number of ways to tackle this problem.</p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Solution: Build an idempotent system" data-type="sect3"><div class="sect3" id="idm46222411893448">&#13;
<h3>Solution: Build an idempotent system</h3>&#13;
&#13;
<p>The<a data-primary="task repetition, avoiding" data-secondary="building idempotent systems" data-type="indexterm" id="idm46222411891976"/><a data-primary="at-least-once-delivery" data-secondary="building idempotent systems" data-type="indexterm" id="idm46222411890888"/><a data-primary="idempotent systems" data-type="indexterm" id="idm46222411889928"/> first, and typically the best, solution to this concern is to build an <a href="https://oreil.ly/rmaFI"><em>idempotent</em></a> system.&#13;
We say that this is “typically the best” solution because it embraces the idea that we are building distributed systems when we use Lambda.&#13;
Instead of working around, or ignoring, the attributes of distributed systems, we actively design to work with them.</p>&#13;
&#13;
<p>A system is idempotent when a specific operation can be applied one or more times, and have the same effect no matter how many times it was applied.&#13;
Idempotence is a very common requirement when considering any distributed architecture, let alone a serverless one.</p>&#13;
&#13;
<p>An example of an idempotent operation is uploading a file to S3 (ignoring any possible triggers!).&#13;
Whether you upload the same file to the same location once or ten times, the net result is that the correct bytes will be stored in S3 at the expected key.</p>&#13;
&#13;
<p>We<a data-primary="side effects" data-secondary="idempotent" data-type="indexterm" id="idm46222411886024"/> can build an idempotent system with Lambda when any significant <em>side effects</em> of a function are, themselves, idempotent.&#13;
For example, if our Lambda function uploads a file to S3, then the complete system of Lambda + S3 is idempotent.&#13;
Similarly<a data-primary="upsert operations" data-type="indexterm" id="idm46222411884328"/> if you are writing to a database you can use an <em>upsert</em> operation (“update or insert”), like DynamoDB’s <a href="https://oreil.ly/OTfZP"><code>UpdateItem</code></a> method, to create idempotence.&#13;
Finally, if you are calling any external APIs, you will likely want to look to see if they offer idempotent <span class="keep-together">operations</span>.</p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Solution: Accept duplicates, and perhaps deal with problems if/when they come up" data-type="sect3"><div class="sect3" id="idm46222411881320">&#13;
<h3>Solution: Accept duplicates, and perhaps deal with problems if/when they come up</h3>&#13;
&#13;
<p>Sometimes<a data-primary="task repetition, avoiding" data-secondary="accepting duplicates" data-type="indexterm" id="idm46222411880024"/><a data-primary="duplicate tasks" data-type="indexterm" id="idm46222411879048"/><a data-primary="at-least-once-delivery" data-secondary="accepting duplicates" data-type="indexterm" id="idm46222411878376"/> a perfectly reasonable way to deal with possible multiple invocations is to be aware that it can happen, and accept it, especially since it happens so rarely.&#13;
For example, say you have a scheduled task that generates a report and then emails it to a company-internal mailing list.&#13;
Do you care if that email occasionally goes out twice? Perhaps not.</p>&#13;
&#13;
<p>Similarly, maybe the work to build an idempotent system would be significant, but dealing with the impact of very occasional task repetition is actually simple and cheap.&#13;
In this case, rather than building in idempotence, it might be better to monitor for a job being run multiple times for one event and then have a manual or automated task that performs cleanup if it ever occurs.</p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Solution: Check for previous processing" data-type="sect3"><div class="sect3" id="idm46222411875896">&#13;
<h3>Solution: Check for previous processing</h3>&#13;
&#13;
<p>If<a data-primary="previous process, checking for" data-type="indexterm" id="previour09"/><a data-primary="at-least-once-delivery" data-secondary="checking for previous processing" data-type="indexterm" id="ALODprevious09"/><a data-primary="task repetition, avoiding" data-secondary="checking for previous processing" data-type="indexterm" id="TRprevious09"/> repeated side effects aren’t ever acceptable, but your Lambda function is also using downstream systems that don’t have idempotent operations, then you have another way to solve this problem.&#13;
The idea is to make your Lambda function itself idempotent, rather than relying on downstream components to provide idempotence.</p>&#13;
&#13;
<p>But how do you do this, knowing that Lambda may call a function multiple times for the same event?&#13;
The key here is to also know that even if Lambda calls a function more than once for the same event, then the <em>AWS request ID</em> that Lambda attaches to an event will be the same for each call.&#13;
We can read the AWS request ID by calling <code>.getAwsRequestId()</code> on the <a href="https://oreil.ly/gh-Bw"><code>Context</code></a> object that we can choose to accept in our handler method.</p>&#13;
&#13;
<p>Assuming we can keep track of these request IDs, we’ll know if we’ve seen one before, and if we have we can choose to discard the second call, guaranteeing “exactly-once” overall semantics.</p>&#13;
&#13;
<p>All we need now is a way of checking, for each invocation of our function, to see if the function has already seen the request ID before.&#13;
Because multiple function invocations for an event could in theory overlap, we need a source of <em>atomicity</em> to provide this capability, and this suggests that using a database would help.</p>&#13;
&#13;
<p>DynamoDB<a data-primary="DynamoDB" data-secondary="conditional writes" data-type="indexterm" id="idm46222411865832"/> can provide this for us by way of its <a href="https://oreil.ly/DBne-"><em>conditional writes</em></a> feature.&#13;
In a simple scenario, we could have a table with just a primary key of <code>request_id</code>; we could attempt to write to that table at the beginning of our handler with the event’s request ID; immediately stop execution if the DynamoDB operation failed; and otherwise continue our Lambda’s functionality as normal, knowing that this is the first time an event has been processed (see <a data-type="xref" href="#checking-for-previous-event-with-dynamodb">Figure 9-1</a>).</p>&#13;
&#13;
<figure><div class="figure" id="checking-for-previous-event-with-dynamodb">&#13;
<img alt="images/ch09_image01.png" src="assets/awsl_0901.png"/>&#13;
<h6><span class="label">Figure 9-1. </span>Checking for a previous event with DynamoDB</h6>&#13;
</div></figure>&#13;
&#13;
<p>If you choose to go down this path, your actual solution will likely have some nuance.&#13;
For example, you may choose to delete the row in DynamoDB if an error occurred (so as to continue to be able to use Lambda’s retry semantics—the retried event will also have the same AWS request ID!).&#13;
And/or you may choose to have a more complicated “lock with timeout” style of behavior to allow for overlapping calls where the first could fail.</p>&#13;
&#13;
<p>There<a data-primary="DynamoDB" data-secondary="Time-to-Live (TTL) property" data-type="indexterm" id="idm46222411858632"/> are also a few DynamoDB concerns to think about with this solution. For example, you probably want to set up a <a href="https://oreil.ly/JFDQg">Time to Live (TTL) property</a> on the table to automatically delete rows after a certain period of time to keep things clean, typically set to a day or to a week.&#13;
Also, you may want to consider the expected throughput of your Lambda function and use that to analyze costs of the DynamoDB table—if the costs are too high, you may want to choose an alternative solution.&#13;
Such alternatives include using a SQL database; building your own (non-Lambda) service to manage this repetition; or, in extreme cases, replacing Lambda entirely for this particular function with a more traditional compute platform.<a data-primary="" data-startref="SAatleastonce09" data-type="indexterm" id="idm46222411856056"/><a data-primary="" data-startref="LFonce09" data-type="indexterm" id="idm46222411855112"/><a data-primary="" data-startref="ALODprevious09" data-type="indexterm" id="idm46222411854168"/><a data-primary="" data-startref="ESonce09" data-type="indexterm" id="idm46222411853224"/><a data-primary="" data-startref="previour09" data-type="indexterm" id="idm46222411852280"/><a data-primary="" data-startref="TRprevious09" data-type="indexterm" id="idm46222411851336"/></p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Impacts of Lambda Scaling on Downstream Systems" data-type="sect2"><div class="sect2" id="idm46222411850392">&#13;
<h2>Impacts of Lambda Scaling on Downstream Systems</h2>&#13;
&#13;
<p>In <a data-type="xref" href="ch08.html#ch08">Chapter 8</a> we<a data-primary="scaling" data-secondary="impacts of scaling on downstream systems" data-type="indexterm" id="Sdownstream09"/><a data-primary="serverless architecture" data-secondary="impacts of scaling on downstream systems" data-type="indexterm" id="SAdown09"/><a data-primary="auto-scaling" data-secondary="impacts on downstream systems" data-type="indexterm" id="idm46222411845304"/><a data-primary="scaling" data-secondary="auto-scaling feature" data-type="indexterm" id="idm46222411844392"/> looked at Lambda’s “magical” auto-scaling (<a data-type="xref" href="ch08.html#lambda-scaling">“Scaling”</a>).&#13;
To quickly summarize, Lambda will automatically create just as many instances as necessary of your function, and its environment, to handle all events to be processed.&#13;
It will do this, by default, up to one thousand Lambda instances per account, and more than that if you ask AWS to increase your limit.</p>&#13;
&#13;
<p>This is, in general, a very useful feature, and one of the key reasons people find Lambda valuable.&#13;
However, if your Lambda function interacts with downstream systems (and most do!), then you need to consider how such scaling could impact those systems.&#13;
As an exercise, let’s consider the examples in <a data-type="xref" href="ch05.html#ch05">Chapter 5</a>.</p>&#13;
&#13;
<p>In<a data-primary="serverless APIs, building" data-secondary="impacts of scaling on downstream systems" data-type="indexterm" id="SAPIscale09"/> <a data-type="xref" href="ch05.html#serverless-api-example">“Example: Building a Serverless API”</a>, we had two functions—<code>WeatherEventLambda</code> and <code>WeatherQueryLambda</code>—that both called DynamoDB.&#13;
We would need to know that DynamoDB could handle the load of however many upstream Lambda instances existed.&#13;
Since we used DynamoDB’s <a href="https://oreil.ly/SHRmW">“on-demand” capacity mode</a>, we know that this is, in fact, the case.</p>&#13;
&#13;
<p>In<a data-primary="serverless data pipelines, building" data-secondary="impacts of scaling on downstream systems" data-type="indexterm" id="SDPscale09"/> <a data-type="xref" href="ch05.html#serverless-data-pipeline-example">“Example: Building a Serverless Data Pipeline”</a>, we also had two functions—<code>BulkEventsLambda</code> and <code>SingleEventLambda</code>.&#13;
<code>BulkEventsLambda</code> calls SNS, specifically to publish messages, so we can look at the <a href="https://oreil.ly/rv4GW">AWS service limits documentation</a> to see how many publish calls we can make to the SNS API.&#13;
That page says that the limit is between 300 and 30,000 “transactions per second,” depending on the region we’re in.</p>&#13;
&#13;
<p>We can use that data to make a judgment call as to whether we think SNS can handle the load we may put on it from our Lambda function.&#13;
Also, the documentation says that this is a <em>soft limit</em>—in other words, we can ask AWS to increase it for us.&#13;
It’s<a data-primary="unhandled errors" data-type="indexterm" id="idm46222411830024"/><a data-primary="error handling" data-secondary="unhandled errors" data-type="indexterm" id="idm46222411829240"/> worth knowing that should we exceed the limit, then our use of SNS will be throttled—we could pass this error back up through our Lambda function as an <em>unhandled error</em> and therefore use Lambda’s retry mechanism.&#13;
It’s also useful to know that this is an account-wide limit, so any other components using SNS in the same account would also be throttled if our Lambda function caused us to hit the SNS API limit.</p>&#13;
&#13;
<p><code>SingleEventLambda</code> only calls CloudWatch Logs indirectly via the Lambda runtime.&#13;
CloudWatch Logs has limits, but they’re very high, so for now we’ll assume it has sufficient capacity.</p>&#13;
&#13;
<p>In summary, the services that we’ve used in these examples scale up to high throughputs.&#13;
That shouldn’t be surprising—these examples were designed to be good examples of serverless architecture.</p>&#13;
&#13;
<p>However, what happens if you’re using downstream systems that either (a) don’t scale as <em>much</em> as your Lambda function may scale or (b) don’t scale as <em>quickly</em> as your Lambda function may scale? An example of (a) might be a downstream relational database—it may only be designed for one hundred concurrent connections, and five hundred connections might cause it serious problems.&#13;
An example of (b) might be a downstream microservice using EC2-based auto-scaling—here the service may eventually scale wide enough to handle unexpected load, but Lambda can scale in <em>seconds</em>, as opposed to EC2, which will scale in <em>minutes</em>.</p>&#13;
&#13;
<p>In either of these cases, unplanned scaling of your Lambda functions can cause performance impacts on downstream systems.&#13;
Often times if such problems occur then the effects will also be felt by other clients of those systems, not just the Lambda function inflicting the load. Because of this concern, you should always consider Lambda’s impact on downstream systems with regards to scaling. There are multiple possible solutions to dealing with this.</p>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Solution: Use like-scaling infrastructure" data-type="sect3"><div class="sect3" id="idm46222411822072">&#13;
<h3>Solution: Use like-scaling infrastructure</h3>&#13;
&#13;
<p>One<a data-primary="like-scaling infrastructure" data-type="indexterm" id="idm46222411820712"/> solution is, where possible, to use downstream systems that have similar scaling behaviors and capacities to Lambda itself.&#13;
We chose DynamoDB and SNS in the <a data-type="xref" href="ch05.html#ch05">Chapter 5</a> examples partly due to this design motivation.&#13;
Similarly, sometimes we may choose to actively migrate away from certain solutions precisely because of scaling concerns. For example, if we can easily switch to using DynamoDB from an RDS database, it may make sense to do so.</p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Solution: Manage scaling upstream" data-type="sect3"><div class="sect3" id="idm46222411818312">&#13;
<h3>Solution: Manage scaling upstream</h3>&#13;
&#13;
<p>Another way to solve the problem of Lambda scaling too wide for downstream systems is to make sure it never needs to scale in the first place, or in other words to restrict the number of events that trigger execution.&#13;
If you’re implementing a company-internal serverless API, then this might mean making sure the API’s clients do not make too many requests.</p>&#13;
&#13;
<p>Some Lambda event sources also offer functionality to help manage scale.&#13;
API Gateway has rate limiting (with <a href="https://oreil.ly/FR4eX"><em>usage plans</em></a> and <em>throttling limits</em>), and<a data-primary="Simple Que Service (SQS)" data-secondary="configuring batch size" data-type="indexterm" id="idm46222411814664"/> Lambda’s SQS integration allows you to <a href="https://oreil.ly/LxNTp">configure a batch size</a>.</p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Solution: Manage scaling with reserved concurrency" data-type="sect3"><div class="sect3" id="manage-scaling-with-reserved-concurrency">&#13;
<h3>Solution: Manage scaling with reserved concurrency</h3>&#13;
&#13;
<p>If<a data-primary="reserved concurrency" data-type="indexterm" id="idm46222411810616"/> you can’t manage scale upstream, but still want to restrict how wide your function will scale, you can use Lambda’s reserved concurrency feature that we looked at in <a data-type="xref" href="ch08.html#reserved-concurrency">“Reserved concurrency”</a>.</p>&#13;
&#13;
<p>When using reserved concurrency, the Lambda platform will only scale out your function at most as wide as the configured amount you have given.&#13;
For example, if you set reserved concurrency to 10, then you’ll have at most 10 instances of your Lambda function running at any one time.&#13;
In this case, if 10 instances of your Lambda are already processing events when another event arrives, then your function is throttled, just as we looked at in <a data-type="xref" href="ch08.html#ch08">Chapter 8</a>.</p>&#13;
&#13;
<p>This kind of scale limitation is great when you have event sources like SNS or S3 where you may easily have a “burst” of events—using reserved concurrency means that these events are processed over a period of time, rather than all immediately.&#13;
And because of Lambda’s retrying capability for throttling errors and asynchronous <span class="keep-together">sources</span>, you’re guaranteed that all of the events will eventually get processed, as long as processing can occur within six hours.</p>&#13;
&#13;
<p>One behavior you should know about reserved concurrency is that it doesn’t just limit concurrency—it <em>guarantees</em> concurrency by removing the configured amount from the account-global Lambda concurrency pool.&#13;
If you have 20 functions all with a reserved concurrency of 50, then you won’t have any more capacity for other Lambda functions, assuming an account-wide concurrency limit of 1,000.&#13;
This account-wide limit can be increased, but that’s a manual task that you’ll need to remember to perform.</p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Solution: Architect deliberately hybrid solutions" data-type="sect3"><div class="sect3" id="idm46222411803944">&#13;
<h3>Solution: Architect deliberately hybrid solutions</h3>&#13;
&#13;
<p>A<a data-primary="deliberately hybrid solutions" data-type="indexterm" id="idm46222411802248"/><a data-primary="hybrid solutions, deliberate versus accidental" data-type="indexterm" id="idm46222411801544"/> final idea is to build <em>deliberately</em> “hybrid” solutions (as opposed to <em>accidentally</em> hybrid solutions) consisting of serverless and traditional components.</p>&#13;
&#13;
<p>For example, if you used Lambda and Amazon’s (nonserverless) RDS SQL database service, without considering the scaling concerns, we’d call this an “accidentally” hybrid solution.&#13;
However, if you put thought into how your RDS database could be used more effectively with Lambda, then we’d call this “deliberately” hybrid.&#13;
And to be clear—we think that some architectural solutions are going to be better with a mixture of serverless and nonserverless components, due to the nature of services like DynamoDB, and Lambda itself.</p>&#13;
&#13;
<p>Let’s consider an example where you are ingesting data into a relational database via a Lambda function, perhaps behind an API Gateway (<a data-type="xref" href="#lambda-relational-direct">Figure 9-2</a>).</p>&#13;
&#13;
<figure><div class="figure" id="lambda-relational-direct">&#13;
<img alt="images/ch09_image02.png" src="assets/awsl_0902.png"/>&#13;
<h6><span class="label">Figure 9-2. </span>Direct writes to a relational database from a Lambda function</h6>&#13;
</div></figure>&#13;
&#13;
<p>A concern with this design is that if you have too many inbound requests, then you may end up overloading your downstream database.</p>&#13;
&#13;
<p>The first solution you may consider is to add reserved concurrency to the Lambda function backing the API, but the problem here is now your upstream clients will have to deal with throttling caused by your concurrency restrictions.</p>&#13;
&#13;
<p>A better solution, therefore, might be to introduce a messaging topic, a new Lambda function, and use reserved concurrency on the second Lambda function (<a data-type="xref" href="#lambda-relational-indirect">Figure 9-3</a>).</p>&#13;
&#13;
<figure><div class="figure" id="lambda-relational-indirect">&#13;
<img alt="images/ch09_image03.png" src="assets/awsl_0903.png"/>&#13;
<h6><span class="label">Figure 9-3. </span>Indirect writes to a relational database from a Lambda function via a topic</h6>&#13;
</div></figure>&#13;
&#13;
<p>With this design, your API Lambda function can still, for example, perform input validation, returning an error message to the client if necessary.&#13;
However, instead of writing directly to the database, it would instead publish a message to a topic, for example, with SNS, under the assumption that your messaging system can handle sudden load more effectively than your database.&#13;
The listener of that message would then be another Lambda function, whose job is purely to perform the database write (or “upsert” to handle duplicate invocations!).&#13;
But this time the Lambda function can have reserved concurrency applied to protect the database, while at the same time making use of the retry semantics within AWS itself, rather than requiring the original external client to perform a retry.</p>&#13;
&#13;
<p>While this resulting design has more moving parts, it successfully solves the scaling concerns while still mixing serverless and nonserverless components.</p>&#13;
<div data-type="tip"><h6>Tip</h6>&#13;
<p>In<a data-primary="RDS Proxy" data-type="indexterm" id="idm46222411787736"/> late 2019 Amazon announced the <a href="https://oreil.ly/alAqq">RDS Proxy</a> service.&#13;
At the time of writing, it is still in “Preview” and so many of the details and capabilities it will have when it is released to general availability (GA) aren’t yet known.&#13;
However, it certainly should help with some of the concerns discussed in this chapter in connecting Lambda to RDS.</p>&#13;
</div>&#13;
<aside data-type="sidebar" epub:type="sidebar"><div class="sidebar" id="cache-to-improve-costs">&#13;
<h5>Lambda Runtime Model and Cost Impact on Downstream Systems</h5>&#13;
<p>This<a data-primary="costs" data-secondary="impact of runtime model on downstream systems" data-type="indexterm" id="idm46222411783656"/> section has been about the functional impacts of Lambda’s scaling.&#13;
It’s also useful to consider how scale, external systems, and Lambda’s runtime model impact overall system financial costs.</p>&#13;
&#13;
<p>Say, for example, that you have the following piece of Lambda code.&#13;
This particular handler uses the AWS service <a href="https://aws.amazon.com/kms">KMS</a> to decrypt an encrypted environment variable:</p>&#13;
&#13;
<pre data-code-language="java" data-type="programlisting"><code class="kd">public</code> <code class="kd">class</code> <code class="nc">LambdaWithApiKey</code> <code class="o">{</code>&#13;
  <code class="kd">public</code> <code class="kt">void</code> <code class="nf">handler</code><code class="o">(</code><code class="n">Object</code> <code class="n">event</code><code class="o">)</code> <code class="o">{</code>&#13;
    <code class="kd">final</code> <code class="n">String</code> <code class="n">encryptedAPIKey</code> <code class="o">=</code> <code class="n">System</code><code class="o">.</code><code class="na">getenv</code><code class="o">(</code><code class="s">"ENCRYPTED_API_KEY"</code><code class="o">);</code>&#13;
    <code class="kd">final</code> <code class="n">String</code> <code class="n">apiKey</code> <code class="o">=</code> <code class="n">decryptWithKms</code><code class="o">(</code><code class="n">encryptedAPIKey</code><code class="o">);</code>&#13;
    <code class="c1">// ... use apiKey to process event</code>&#13;
  <code class="o">}</code>&#13;
&#13;
  <code class="kd">private</code> <code class="n">String</code> <code class="nf">decryptWithKms</code><code class="o">(</code><code class="n">String</code> <code class="n">encryptedCypherText</code><code class="o">)</code> <code class="o">{</code>&#13;
    <code class="c1">// Use AWS to decrypt encryptedCypherText, and return the value</code>&#13;
  <code class="o">}</code>&#13;
<code class="o">}</code></pre>&#13;
&#13;
<p>We’re leaving out the actual KMS service implementation here for brevity’s sake.</p>&#13;
&#13;
<p>This Lambda function would work correctly. But say we changed the code to the <span class="keep-together">following</span>:</p>&#13;
&#13;
<pre data-code-language="java" data-type="programlisting"><code class="kd">public</code> <code class="kd">class</code> <code class="nc">LambdaWithApiKey</code> <code class="o">{</code>&#13;
  <code class="kd">private</code> <code class="kd">final</code> <code class="n">String</code> <code class="n">apiKey</code><code class="o">;</code>&#13;
&#13;
  <code class="kd">public</code> <code class="nf">LambdaWithApiKey</code><code class="o">()</code> <code class="o">{</code>&#13;
    <code class="kd">final</code> <code class="n">String</code> <code class="n">encryptedAPIKey</code> <code class="o">=</code> <code class="n">System</code><code class="o">.</code><code class="na">getenv</code><code class="o">(</code><code class="s">"ENCRYPTED_API_KEY"</code><code class="o">);</code>&#13;
    <code class="n">apiKey</code> <code class="o">=</code> <code class="n">decryptWithKms</code><code class="o">(</code><code class="n">encryptedAPIKey</code><code class="o">);</code>&#13;
  <code class="o">}</code>&#13;
&#13;
  <code class="kd">public</code> <code class="kt">void</code> <code class="nf">handler</code><code class="o">(</code><code class="n">Object</code> <code class="n">event</code><code class="o">)</code> <code class="o">{</code>&#13;
    <code class="c1">// ... use apiKey to process event</code>&#13;
  <code class="o">}</code>&#13;
&#13;
  <code class="kd">private</code> <code class="n">String</code> <code class="nf">decryptWithKms</code><code class="o">(</code><code class="n">String</code> <code class="n">encryptedCypherText</code><code class="o">)</code> <code class="o">{</code>&#13;
    <code class="c1">// USE AWS KMS TO DECRYPT, AND RETURN</code>&#13;
  <code class="o">}</code>&#13;
<code class="o">}</code></pre>&#13;
&#13;
<p>This code, functionally, does precisely what the first version did—we just moved some code to the constructor.&#13;
So what is the difference?&#13;
One difference is that at an average of 200 events per second the first version increases your AWS costs nearly $20,000/year in comparison to the second version!&#13;
This is because the first version calls KMS to decrypt the API key on every event, but the second version calls KMS only once per function instance.&#13;
AWS charges for KMS by the number of times we call its API, so KMS costs increase linearly with how many times the Lambda function calls it.</p>&#13;
&#13;
<p>This is not a hypothetical situation—we’ve seen an example of the first version of the code.&#13;
We recommended switching to the second version, saving one of our clients approximately $20,000/year.</p>&#13;
&#13;
<p>While Lambda has a simple runtime model, how you use it can still have substantive impacts on other components and services, and also your AWS bill.<a data-primary="" data-startref="Sdownstream09" data-type="indexterm" id="idm46222411647256"/><a data-primary="" data-startref="SDPscale09" data-type="indexterm" id="idm46222411646376"/><a data-primary="" data-startref="SAPIscale09" data-type="indexterm" id="idm46222411645432"/></p>&#13;
</div></aside>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="The “Fine Print” of Lambda Event Sources" data-type="sect2"><div class="sect2" id="lambda-event-sources-fine-print">&#13;
<h2>The “Fine Print” of Lambda Event Sources</h2>&#13;
&#13;
<p>The<a data-primary="event sources" data-secondary="event notification failures" data-type="indexterm" id="idm46222411643256"/><a data-primary="serverless architecture" data-secondary="event notification failures" data-type="indexterm" id="idm46222411642280"/> first couple of sections in this chapter have been about architectural concerns that come about because of nuances of Lambda itself.&#13;
There are other areas that can impact a serverless design because of the services that exist upstream of Lambda.&#13;
Just like the fact that “at-least-once” delivery isn’t front and center of the first document you read about Lambda, you’ll only find some of these nuances with upstream services through deep exploration of documentation, or hard-earned experience.</p>&#13;
&#13;
<p>When you start to get beyond the “tinkering” stage with any Lambda event source, read as much AWS documentation as you can on the services you’re using.&#13;
Seek out non-AWS articles too—while they’re not authoritative, and sometimes wrong, occasionally they can nudge you in a direction, architecturally, that you may not have considered otherwise.</p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="New Patterns of Architecture Enabled by Serverless Thinking" data-type="sect1"><div class="sect1" id="idm46222411639720">&#13;
<h1>New Patterns of Architecture Enabled by Serverless Thinking</h1>&#13;
&#13;
<p>Sometimes when we’re building serverless systems, our architecture, viewed from a certain distance, might not look that different than how we could have designed it using containers or virtual machines (VMs).&#13;
“Cloud-native” architecture is not the sole domain of Kubernetes, no matter what you may have otherwise heard!</p>&#13;
&#13;
<p>For example, our serverless API that we built back in <a data-type="xref" href="ch05.html#serverless-api-example">“Example: Building a Serverless API”</a>, from a “black-box” point of view, looked just like any other microservice-style API.&#13;
In fact, we could replace the Lambda functions with an application running in a container and, architecturally, the system would have been very similar.</p>&#13;
&#13;
<p>As serverless starts to mature, however, we’re seeing new architectural patterns that either wouldn’t make sense with traditional services, or wouldn’t even be possible.&#13;
We alluded to one of these earlier in <a data-type="xref" href="ch05.html#ch05">Chapter 5</a> when we talked about <a data-type="xref" href="ch05.html#serverless-without-lambda">“Serverless Without Lambda”</a>. To close out this chapter, we’ll look at a couple of other patterns, using Lambda, that break into new territory.</p>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Published Components with the Serverless Application Repository" data-type="sect2"><div class="sect2" id="idm46222411633848">&#13;
<h2>Published Components with the Serverless Application Repository</h2>&#13;
&#13;
<p>We’ve<a data-primary="serverless architecture" data-secondary="Serverless Application Repository (SAR)" data-type="indexterm" id="SAsar09"/><a data-primary="Serverless Application Repository (SAR)" data-type="indexterm" id="sar00"/> talked a few times through the book about “serverless applications”—groups of components that we collectively deploy as one unit.&#13;
We had our serverless API, using API Gateway, two Lambda functions, and a DynamoDB table, all grouped as a unit.&#13;
We defined this collection of resources using a Serverless Application Model (SAM) template.</p>&#13;
&#13;
<p>AWS provides a way to reuse and share these SAM applications, via the <a href="https://oreil.ly/Oa8HO">Serverless Application Repository (SAR)</a>.&#13;
With SAR you <em>publish</em> your application, and you can then <em>deploy</em> it later, multiple times, to different regions, accounts, or even different organizations if you choose to make the SAR application publicly available.</p>&#13;
&#13;
<p>Traditionally you likely have either distributed code or a shipped environment–agnostic deployment configuration.&#13;
With SAR the code (by way of packaged Lambda functions), the infrastructure definitions, and the (parameterizable) deployment configuration are all wrapped up in one shareable, <em>versioned</em>, component.</p>&#13;
&#13;
<p>There are a couple of different ways that SAR apps can be deployed that make them useful in different situations.</p>&#13;
&#13;
<p>First, they can be deployed as <em>standalone applications</em>, just as if you had called <code>sam deploy</code> directly on them, rather than using SAR.&#13;
This is useful when you want to deploy the same application in multiple locations or across multiple accounts or organizations.&#13;
In this case, SAR acts somewhat like a repository of application deployment templates, but by bundling the code, it also includes the actual application code.</p>&#13;
&#13;
<p>Examples of SAR application suited to this type of usage abound in the <a href="https://oreil.ly/QyOkD">public SAR repository</a>—it’s especially useful for third-party software providers who want to make it easier for customers to deploy integration components to their AWS account. A good example is this <a href="https://oreil.ly/z-s8e">log forwarder from DataDog</a>.</p>&#13;
&#13;
<p>SAR applications can also be used as <em>embedded</em> components within other, <em>parent</em>, serverless applications via <a href="https://oreil.ly/1sJjI">CloudFormation nested stacks</a>.&#13;
SAM enables nesting SAR components via the <a href="https://oreil.ly/aY0-G"><code>AWS::Serverless::Application</code> resource type</a>.&#13;
When using SAR in this way, you are abstracting higher-level components as SAR apps, and instantiating those components within multiple applications.&#13;
Using SAR in this way is a little like using a <a href="https://oreil.ly/9k3Xl">“sidecar”</a> in container-oriented applications, but without the low-level network-oriented communication patterns that sidecars require.</p>&#13;
&#13;
<p>These nested components may include Lambda functions that may be invoked directly, or indirectly (e.g., via SNS topic, perhaps also included in the SAR), by the parent application.&#13;
Alternatively, these nested components may not contain any functions at all, and instead solely define infrastructural resources. A good example here are SAR applications that standardize monitoring resources.</p>&#13;
&#13;
<p>We prefer the embedded deployment scheme in general, even if there are no other components in the parent application.&#13;
This is because deploying SAR apps, along with their parameter values that can be defined as part of the <code>AWS::Serverless::Application</code> resource in your template file, is no different than deploying any other SAM-defined serverless application.&#13;
Further, if you choose to update the <em>version</em> of a deployed SAR app, then that too can be tracked in version control just like any other template update.</p>&#13;
&#13;
<p>SAR apps can be secured so that they are accessible only to accounts within a particular AWS organization, and therefore they are a great way of defining standard components that can be used across a whole company.&#13;
Examples of using this with the embedded component deployment scheme are custom authorizers for API Gateway, standard operational components (e.g., alarms, log filters, and dashboards), and common patterns of message-based inter-service communication.</p>&#13;
&#13;
<p>SAR does have some limitations. For example, you can’t use all CloudFormation resource types within it (for example, EC2 instances).&#13;
However, this is an interesting way of building, deploying, and composing Lambda-based applications.</p>&#13;
&#13;
<p>For details on how to publish SAM applications to SAR, see the <a href="https://oreil.ly/nhOUb">documentation</a>, and for details of deploying SAR apps see the previous link for the <code>AWS::Serverless::Application</code> resource type.<a data-primary="" data-startref="SAsar09" data-type="indexterm" id="idm46222411612056"/><a data-primary="" data-startref="sar00" data-type="indexterm" id="idm46222411611080"/></p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Globally Distributed Applications" data-type="sect2"><div class="sect2" id="globally-distributed-applications">&#13;
<h2>Globally Distributed Applications</h2>&#13;
&#13;
<p>In<a data-primary="globally distributed applications" data-secondary="regional versus global availability" data-type="indexterm" id="idm46222411608136"/><a data-primary="serverless architecture" data-secondary="globally distributed applications" data-type="indexterm" id="SAglobal09"/> days of yore (i.e., about 15 years ago), most of us building server-based applications often had a fairly good idea where our software was physically running, at least to within one hundred meters or so, and often closer than that.&#13;
We could pinpoint the data centers, server rooms, and perhaps even the racks or individual machines where our code was humming along.</p>&#13;
&#13;
<p>Along came the “cloud,” and our understanding of the geographic deployment of our apps got a little, well, cloudy.&#13;
With EC2, for example, we know, roughly, that our code is running in the region of “Northern Virginia” or “Ireland” and we also know when two servers are running in the same data center, via their Availability Zone (AZ) location.&#13;
But it’s extremely unlikely that we’d be able to point on a map to the building where our software is running.</p>&#13;
&#13;
<p>Serverless computing immediately expands our radius of consideration a little further.&#13;
Now we’re <em>only</em> thinking of the region—the AZ concept is hidden in abstraction.</p>&#13;
&#13;
<p>One of the reasons to know where your applications are running is when you consider availability. When we run applications in a data center, we would need to know that if the data center lost internet connectivity, then our applications would be unavailable.</p>&#13;
&#13;
<p>For many companies, certainly those who are used to deploying to one data center, this regional level of availability we get with the cloud is sufficient, especially since serverless services guarantee high availability across a region.</p>&#13;
&#13;
<p>But what if you want to think bigger?&#13;
For example, what if you want to guarantee resilience of your application even if an entire region of AWS becomes unstable?&#13;
This happens—just talk to anyone that’s used us-east-1 for at least a couple of years.&#13;
The good news is that it’s very rare that AWS has any kind of <em>cross-region</em> outage.&#13;
The vast majority of AWS downtime is constrained to one region.</p>&#13;
&#13;
<p>Alternatively, looking beyond just availability, what if your users are spread around the world, from Sao Paulo to Seoul, and you want all of them to have low-latency access to your applications?</p>&#13;
&#13;
<p>Solving these problems has been <em>possible</em> in the cloud ever since multiple regions became available.&#13;
However, running applications in multiple regions is complicated, and can get expensive, especially as you add more regions.</p>&#13;
&#13;
<p>Serverless, however, makes this problem significantly easier and cheaper. It’s now possible to deploy your application to multiple regions around the world, without much added complexity, and without breaking your budget.</p>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Global deployment" data-type="sect3"><div class="sect3" id="idm46222411562664">&#13;
<h3>Global deployment</h3>&#13;
&#13;
<p>When<a data-primary="globally distributed applications" data-secondary="global deployment" data-type="indexterm" id="idm46222411561192"/> you define your application in a SAM template, you don’t typically hardcode any region-specific resources.&#13;
If you need to refer to the region in which a stack is deployed in a CloudFormation string (as we did in the data pipeline example in <a data-type="xref" href="ch05.html#ch05">Chapter 5</a>), we recommend using the <code>AWS::Region</code> <a href="https://oreil.ly/7Xe9-"><em>pseudo parameter</em></a>.&#13;
For any region-specific resources that you need to access, we recommend passing those by reference as a CloudFormation parameter.</p>&#13;
&#13;
<p>With these techniques you can define your application template in a <em>region-neutral</em> way, and you can deploy it to as many AWS regions as you like.</p>&#13;
&#13;
<p>Actually deploying your application to multiple regions isn’t quite as easy as we’d like it to be.&#13;
For example, when you deploy an application with CloudFormation (e.g., using <code>sam deploy</code>) any packages that you refer to in the <code>CodeUri</code> properties in the template file must be available in a S3 bucket that is located <em>within the same region you are deploying to</em>.&#13;
Therefore, if you want to deploy an application to multiple regions, then its packaged artifacts need to be available in multiple S3 buckets, one per region.&#13;
This is nothing a little scripting can’t solve, but it’s something that you have to think about.</p>&#13;
&#13;
<p>AWS<a data-primary="CodePipeline" data-type="indexterm" id="idm46222411554088"/> has improved the experience of multiregion deployment by enabling “cross-region actions” in <a href="https://oreil.ly/E_DJr">CodePipeline</a>.&#13;
CodePipeline is Amazon’s “continuous delivery” orchestration tool and allows us to define the source control repository for a project; build and package an application by calling out to <a href="https://oreil.ly/fSD1_">CodeBuild</a>; and finally deploy it using SAM/CloudFormation.&#13;
CodePipeline is effectively an automation system on top of the commands we’ve been running manually in this book.&#13;
It will do a lot more than this too—the flow here is just an example.</p>&#13;
&#13;
<p><a href="https://oreil.ly/6X5vB">“Cross-region actions”</a> within<a data-primary="cross-region actions" data-type="indexterm" id="idm46222411550408"/> CodePipeline allow you to deploy to multiple regions, in parallel, to as many regions as currently support CodePipeline at the current time.&#13;
This means that one CD pipeline can deploy an application to the US, Europe, Japan, and South America.</p>&#13;
&#13;
<p>There’s still some trickiness to setting all of this up. For more, please see our <a href="https://oreil.ly/xzWiI">example project on Github</a>.</p>&#13;
&#13;
<p>Another tool that helps multiregion deployment is the Serverless Application Repository, which we described in the previous section.&#13;
When you publish an application to SAR via one region, it is made available globally to all regions.&#13;
At the time of writing, this is only the case for publicly shared applications, but we hope that this feature will be enabled for private apps before too long.</p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Localized connectivity, with failover" data-type="sect3"><div class="sect3" id="idm46222411547240">&#13;
<h3>Localized connectivity, with failover</h3>&#13;
&#13;
<p>Once<a data-primary="globally distributed applications" data-secondary="localized connectivity with fail-over" data-type="indexterm" id="idm46222411545768"/> you’ve deployed your application around the world, how do your users connect to a version that’s near to them?&#13;
One of the points of global deployment, after all, is to accept that the speed of light is limited, and therefore to route user requests to the closest geographic version of your application to their client, giving users the lowest latency experience you can.</p>&#13;
&#13;
<p>One way is to hardcode the region-specific location, typically a DNS hostname, within the client itself.&#13;
It’s crude, but sometimes effective, especially for organization-internal apps.</p>&#13;
&#13;
<p>An alternative that’s usually better, because it adapts <em>dynamically</em> to the user’s location, is to embrace Amazon’s Route53 DNS Service, and specifically its <a href="https://oreil.ly/4RCb2"><em>Geolocation</em></a> feature.&#13;
For example, if users connect to your application via an API Gateway deployed in parallel to three different regions, then you can set up your DNS in Route53 such that the user is connected to the API Gateway in the region closest to them.</p>&#13;
&#13;
<p>Since you’re already using some advanced features of Route53 by this point, you may as well go one step further and use <a href="https://oreil.ly/XlUX9"><em>Health Checks and DNS Failover</em></a>.&#13;
With this feature of Route53, if the version of your application nearest to a user becomes unavailable, then Route53 will instead reroute that user to the <em>next</em> nearest, available, version of the application.</p>&#13;
&#13;
<p>Now we have active-active versions of our applications <em>and</em> localized routing.&#13;
We have built an application that is resilient <em>and</em> has better performance.&#13;
And so far there have been no updates to our application architecture, only operational updates.&#13;
However, we should really address the elephant in the room.</p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Global state" data-type="sect3"><div class="sect3" id="idm46222411537656">&#13;
<h3>Global state</h3>&#13;
&#13;
<p>We<a data-primary="globally distributed applications" data-secondary="global state" data-type="indexterm" id="GDAstate09"/> said earlier that serverless makes it possible to deploy your application to multiple regions around the world, without much added complexity.&#13;
We just described the deployment process itself, and we talked about how users can access your application over the internet.</p>&#13;
&#13;
<p>A big concern, however, with global applications is how to treat state.&#13;
The simplest solution is to have your state in only one region and have your service using that state deployed to multiple regions (<a data-type="xref" href="#multiple-compute-regions-one-database-region">Figure 9-4</a>).</p>&#13;
&#13;
<figure><div class="figure" id="multiple-compute-regions-one-database-region">&#13;
<img alt="images/ch09_image04.png" src="assets/awsl_0904.png"/>&#13;
<h6><span class="label">Figure 9-4. </span>Multiple compute regions and one database region</h6>&#13;
</div></figure>&#13;
&#13;
<p>This<a data-primary="content delivery networks (CDNs)" data-type="indexterm" id="idm46222411530328"/> is the same model that <a href="https://oreil.ly/UaAj5">content delivery networks (CDNs)</a> use—there is one “origin” somewhere in the world, and then CDNs cache state in tens, or hundreds, of “points of presence” around the globe.</p>&#13;
&#13;
<p>This is fine for cacheable state, but what about noncacheable situations?</p>&#13;
&#13;
<p>In this case, the single-region-for-state model breaks down since all of your regions will be calling the centralized database region for <em>every request</em>.&#13;
You’ve lost the benefit of localized latency, and you run the risk of a regional outage.</p>&#13;
&#13;
<p>Fortunately, AWS<a data-primary="DynamoDB" data-secondary="globally replicated database" data-type="indexterm" id="idm46222411526456"/> and the other major cloud providers now provide globally replicated databases.&#13;
A good example of this on AWS is <a href="https://oreil.ly/fEZAG">DynamoDB global tables</a>.&#13;
Say you’re using the serverless API pattern from <a data-type="xref" href="ch05.html#ch05">Chapter 5</a>—you can replace the DynamoDB table in your design from that example with a <em>global</em> table.&#13;
You can then happily deploy your API to multiple regions around the world, and AWS will do the hard work of moving your data safely around the planet.&#13;
This gives you resilience, and improved user latency, since the table replication is performed by DynamoDB asynchronously (<a data-type="xref" href="#multiple-regions-with-replicated-database">Figure 9-5</a>).</p>&#13;
&#13;
<figure><div class="figure" id="multiple-regions-with-replicated-database">&#13;
<img alt="images/ch09_image05.png" src="assets/awsl_0905.png"/>&#13;
<h6><span class="label">Figure 9-5. </span>Multiple regions with a replicated database</h6>&#13;
</div></figure>&#13;
&#13;
<p>AWS does charge a premium for global tables, but they’re not too much more expensive than having a table per region, especially when compared with building a state replication system yourself.<a data-primary="" data-startref="GDAstate09" data-type="indexterm" id="idm46222411519368"/></p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Pay-per-use" data-type="sect3"><div class="sect3" id="idm46222411537064">&#13;
<h3>Pay-per-use</h3>&#13;
&#13;
<p>On<a data-primary="costs" data-secondary="pay-per-use of globally distributed applications" data-type="indexterm" id="idm46222411516984"/><a data-primary="globally distributed applications" data-secondary="pay-per-use arrangement" data-type="indexterm" id="idm46222411515880"/> the subject of costs, this is where serverless computing really clinches the deal when it comes to multiregion deployment.&#13;
Back in <a data-type="xref" href="ch01.html#ch01">Chapter 1</a> we said that a specific differentiator of a serverless service is that it “has costs that are based on precise usage, up from and down to zero usage.”&#13;
This applies not just to one region but across regions.</p>&#13;
&#13;
<p>Say, for example, you have deployed a Lambda application to three regions because you want to have two backup regions for disaster recovery.&#13;
If you are using only one of those regions, then you are <em>paying</em> only for the Lambda usage in that one region—the backup versions you have in the other two regions are free!&#13;
This is a huge difference from any other computing paradigm.</p>&#13;
&#13;
<p>On the other hand, say you start off with an application deployed to one region, but then you deploy your API Gateway + Lambda application to ten regions, using the Geolocation DNS routing we discussed earlier.&#13;
If you do this, your Lambda bill won’t change—whether you run in one region or ten—because Lambda still only charges you by the amount of activity that occurs in your functions.&#13;
Your previous usage hasn’t increased; it’s now just distributed across ten regions.</p>&#13;
&#13;
<p>We think that this vastly different cost model, in comparison to traditional platforms, will make globally distributed applications much more common than they’ve been in the past.</p>&#13;
<div data-type="note" epub:type="note"><h6>Note</h6>&#13;
<p>There’s a slight caveat here to the “no change in costs” point for Lambda.&#13;
AWS may charge slightly differently for Lambda for different regions.&#13;
That’s an element of region-specific pricing, however, not because of running your application across multiple regions.</p>&#13;
</div>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Edge computing/&quot;regionless”" data-type="sect3"><div class="sect3" id="idm46222411509368">&#13;
<h3>Edge computing/"regionless”</h3>&#13;
&#13;
<p>The<a data-primary="regionless computing" data-type="indexterm" id="idm46222411507896"/><a data-primary="globally distributed applications" data-secondary="edge computing (regionless)" data-type="indexterm" id="idm46222411507160"/><a data-primary="edge computing" data-type="indexterm" id="idm46222411506280"/><a data-primary="Lambda@Edge" data-type="indexterm" id="idm46222411505608"/> examples we’ve talked about in this section so far are all about deploying to multiple regions around the world, but they do still require us to understand that Amazon’s entire cloud is broken up into those different regions.</p>&#13;
&#13;
<p>What if you didn’t need to think about regions at all?&#13;
What if you were able to deploy your code to a global service, and then AWS just did whatever it needed to run your code, giving users the best latency possible, and guaranteeing availability even if one location went offline?</p>&#13;
&#13;
<p>It turns out that this wild idea of the future is already here.&#13;
Sort of.&#13;
First, AWS already has some services that are “global services”—IAM and Route53 are two of them.&#13;
But so is <a href="https://oreil.ly/_0EUS">CloudFront: AWS’s CDN</a>.&#13;
While CloudFront does the thing you’d expect of any other CDN—caching HTTP traffic to enable faster websites—it also has the capability of being able to invoke a special class of Lambda functions via a service named <a href="https://oreil.ly/6D4yw">Lambda@Edge</a>.</p>&#13;
&#13;
<p>Lambda@Edge functions are mostly similar to Lambda functions—they have the same runtime model and mostly the same deployment tooling.&#13;
When you deploy a Lambda@Edge function, AWS replicates your code around the world, so your application truly becomes “regionless.”</p>&#13;
&#13;
<p>There are, however, a number of significant limitations to Lambda@Edge, including:</p>&#13;
&#13;
<ul>&#13;
<li>&#13;
<p>The only event source available is CloudFront itself—so you can only run Lambda@Edge as part of processing an HTTP request within a CloudFront <span class="keep-together">distribution</span>.</p>&#13;
</li>&#13;
<li>&#13;
<p>Lambda@Edge functions, at the time of writing, can be written only in Node or Python.</p>&#13;
</li>&#13;
<li>&#13;
<p>The Lambda@Edge environment has more restrictions with regard to memory, CPU, and timeout than regular Lambda functions.</p>&#13;
</li>&#13;
</ul>&#13;
&#13;
<p>Lambda@Edge functions are fascinating, and even at the time of writing are great for solving certain problems.&#13;
But more than that, they point to a future of <em>truly</em> global cloud computing, where locality is completely abstracted.&#13;
If AWS can bring Lambda@Edge closer in capability to regular Lambda, then as architects and developers we are well on the road to leaving region-thinking behind us.&#13;
We might still need to think about locality when people are running applications on Mars, but we’re a few years away from that yet. Lambda promises to be serverless, not planetless!<a data-primary="" data-startref="SAglobal09" data-type="indexterm" id="idm46222411494696"/></p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Summary" data-type="sect1"><div class="sect1" id="idm46222411609544">&#13;
<h1>Summary</h1>&#13;
&#13;
<p>When we’re building serverless systems, the amount of effort that we spend on code and operations decreases, but some of that effort needs to be exchanged for more architectural thinking than we have done in the past, especially about the capabilities and limitations of the managed services we’re using.&#13;
In this chapter, you learned more detail of some of these concerns, and examined a number of mitigation approaches.</p>&#13;
&#13;
<p>Serverless computing also presents entirely new ways of architecting software.&#13;
You learned about two such ideas—the Serverless Application Repository, and globally distributed applications.&#13;
As Lambda, and serverless more generally, evolves over the coming years, we expect to see many more new models of architecting applications.</p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Exercises" data-type="sect1"><div class="sect1" id="idm46222411491048">&#13;
<h1>Exercises</h1>&#13;
<ol>&#13;
<li>&#13;
<p>Update<a data-primary="exercises" data-secondary="serverless architecture" data-type="indexterm" id="idm46222411488984"/> the data pipeline example from <a data-type="xref" href="ch05.html#serverless-data-pipeline-example">“Example: Building a Serverless Data Pipeline”</a>—set <code>SingleEventLambda</code> to have a reserved concurrency of 1.&#13;
Now upload the sample data—you should see throttling occur (if necessary, add a few more elements to the <em>sampledata.json</em> file).&#13;
Use the “Throttle” behavior from the Lambda web console to set reserved concurrency to zero.</p>&#13;
</li>&#13;
<li>&#13;
<p>Update <a data-type="xref" href="ch05.html#serverless-api-example">“Example: Building a Serverless API”</a> to use a DynamoDB global table—make sure to separate the table itself into its own CloudFormation stack!&#13;
Then deploy just the API component (with its Lambda functions) to multiple regions.&#13;
Are you able to write data to one region and then read it from another?</p>&#13;
</li>&#13;
&#13;
</ol>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
</div></section></body></html>