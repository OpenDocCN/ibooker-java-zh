- en: Chapter 6\. Data Processing with Streams
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第6章\. 使用 Streams 进行数据处理
- en: Almost any program has to deal with processing data, most likely in the form
    of collections. An imperative approach uses loops to iterate over elements, working
    with each element in sequence. Functional languages, though, prefer a declarative
    approach and sometimes don’t even have a classical loop statement, to begin with.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 几乎任何程序都必须处理数据，通常以集合的形式出现。命令式方法使用循环按顺序迭代元素，每次处理一个元素。而函数式语言则更倾向于声明式方法，有时甚至没有传统的循环语句起始。
- en: The *Streams API*, introduced in Java 8, provides a fully declarative and lazily
    evaluated approach to processing data that benefits from Java’s functional additions
    by utilizing higher-order functions for most of its operations.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: '*Streams API*，引入于Java 8，提供了一种完全声明式和惰性评估的数据处理方法，通过利用Java的函数式添加，利用高阶函数来执行大部分操作。'
- en: This chapter will teach you the differences between imperative and declarative
    data processing. You will then have a visual introduction to Streams that highlights
    their underlying concepts and shows you how to get the most out of their flexibility
    to achieve a more functional approach to data processing.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将教你区分命令式和声明式数据处理的差异。然后，你将通过视觉介绍 Streams，突出它们的基本概念，并展示如何充分利用它们的灵活性，实现更加功能化的数据处理方法。
- en: Data Processing with Iteration
  id: totrans-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用迭代进行数据处理
- en: Processing data is an everyday task you’ve probably encountered a million times
    before and will continue to do so in the future.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 处理数据是你可能之前已经遇到过并且将来也会继续遇到的日常任务。
- en: From a broad point of view, any type of data processing works like a pipeline,
    with a data structure like a collection providing elements, one or more operations
    like filtering or transforming elements, and finally, delivering some form of
    a result. The result might be another data structure or even using it to run another
    task.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 从宏观角度来看，任何类型的数据处理都像是一个管道，数据结构如集合提供元素，一个或多个操作如过滤或转换元素，最终提供某种形式的结果。结果可以是另一个数据结构，甚至是用它来运行另一个任务。
- en: Let’s start with a simple data processing example.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们从一个简单的数据处理示例开始。
- en: External Iteration
  id: totrans-8
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 外部迭代
- en: Say that we need to find the three science-fiction books before 1970 sorted
    by title from a collection of `Book` instances. [Example 6-1](#_02-data-processing_for-loop)
    shows how to do this using a typical imperative approach with a `for`-loop.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们需要在 `Book` 实例集合中找到1970年之前的前三本科幻书籍按标题排序的例子。[示例 6-1](#_02-data-processing_for-loop)
    展示了如何使用典型的命令式方法和 `for` 循环来实现这一点。
- en: Example 6-1\. Finding books with a `for`-loop
  id: totrans-10
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 6-1\. 使用 `for` 循环查找书籍
- en: '[PRE0]'
  id: totrans-11
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: '[![1](assets/1.png)](#co_data_processing_with_streams_CO1-1)'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: '[![1](assets/1.png)](#co_data_processing_with_streams_CO1-1)'
- en: An unsorted Collection of books. It must be mutable, so it can be sorted in-place
    in the next step.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 一个未排序的书籍集合。它必须是可变的，以便可以在下一步中就地排序。
- en: '[![2](assets/2.png)](#co_data_processing_with_streams_CO1-2)'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: '[![2](assets/2.png)](#co_data_processing_with_streams_CO1-2)'
- en: The collection has to be sorted first, or the elements in `result` won’t be
    the first three titles in alphabetical order of the original collection.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 集合必须先排序，否则`result`中的元素将不是原始集合中按字母顺序排列的前三个标题。
- en: '[![3](assets/3.png)](#co_data_processing_with_streams_CO1-3)'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: '[![3](assets/3.png)](#co_data_processing_with_streams_CO1-3)'
- en: Ignore any unwanted books, like the ones not published before 1970 or non-science-fiction.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 忽略任何不需要的书籍，比如那些在1970年以后出版的或非科幻小说。
- en: '[![4](assets/4.png)](#co_data_processing_with_streams_CO1-5)'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: '[![4](assets/4.png)](#co_data_processing_with_streams_CO1-5)'
- en: The book title is all we are interested in.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 我们只对书名感兴趣。
- en: '[![5](assets/5.png)](#co_data_processing_with_streams_CO1-6)'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: '[![5](assets/5.png)](#co_data_processing_with_streams_CO1-6)'
- en: Restrict the found titles to a maximum of three.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 将找到的标题限制为最多三个。
- en: Although the code works for what it needs to do, it has several shortcomings
    compared to other approaches. The most obvious downside is the amount of boilerplate
    code required for an iteration-based loop.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管该代码对需要完成的任务有效，但与其他方法相比存在多个缺点。最明显的缺点是基于迭代循环需要大量样板代码。
- en: Loop statements, either a `for`- or `while`-loop, contain their data processing
    logic in their body, to create a new scope for each iteration. Depending on your
    requirements, the loop’s body contains multiple statements, including decision-making
    about the iteration process itself in the form of `continue` and `break`. Overall,
    the data processing code is obscured by all this boilerplate and doesn’t present
    itself fluently or is easily followable, especially for a more complex loop than
    the previous example.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 循环语句，无论是 `for`- 还是 `while`- 循环，都包含它们的数据处理逻辑在它们的主体中，为每次迭代创建了一个新的作用域。根据你的要求，循环的主体包含多个语句，包括关于迭代过程本身的决策，以
    `continue` 和 `break` 的形式。总的来说，数据处理代码被所有这些样板代码遮掩，并不流畅地呈现出来，尤其是对于一个比前面示例更复杂的循环来说。
- en: The origin of these problems is blending “what you are doing” (working with
    data) and “how it’s done” (iterating over elements). This kind of iteration is
    called *external iteration*. Behind the scenes, the `for`-loop, in this case,
    the `for-each` variant, uses a `java.util.Iterator<E>` to traverse the collection.
    The traversal process calls `hasNext` and `next` to control the iteration, as
    illustrated in [Figure 6-1](#_02-data-processing_external-iteration).
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 这些问题的根源在于将“你正在做什么”（处理数据）和“它是如何完成的”（遍历元素）混为一谈。这种迭代叫做*外部迭代*。在幕后，`for`-循环，即 `for-each`
    变体，使用 `java.util.Iterator<E>` 来遍历集合。遍历过程调用 `hasNext` 和 `next` 来控制迭代，如 [图 6-1](#_02-data-processing_external-iteration)
    中所示。
- en: '![External iteration](assets/afaj_0601.png)'
  id: totrans-25
  prefs: []
  type: TYPE_IMG
  zh: '![外部迭代](assets/afaj_0601.png)'
- en: Figure 6-1\. External iteration
  id: totrans-26
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图6-1\. 外部迭代
- en: In the case of a “traditional” `for`-loop, you have to manage going over the
    elements until an end condition is reached yourself, which in a way is similar
    to an `Iterator<E>` and the `hasNext` and `next` method.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 在“传统”的 `for`-循环中，你必须自行管理遍历元素直到达到结束条件，这在某种程度上类似于 `Iterator<E>` 和 `hasNext` 以及
    `next` 方法。
- en: If you count the number of code lines that have to do with “what you’re doing”
    and “how it’s done,” you’d notice that it spends more time on traversal management
    than data processing, as listed in, as detailed in [Table 6-1](#_02-data-processing_loc-imp).
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你数一数关于“你正在做什么”和“它是如何完成的”的代码行数，你会注意到它花费了更多时间在遍历管理上，而不是数据处理上，如 [表 6-1](#_02-data-processing_loc-imp)
    中详细列出的那样。
- en: Table 6-1\. Lines of code per data processing per task
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 表6-1\. 每个任务的数据处理代码行数
- en: '| Task | Lines of code |'
  id: totrans-30
  prefs: []
  type: TYPE_TB
  zh: '| 任务 | 代码行数 |'
- en: '| --- | --- |'
  id: totrans-31
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| **Data preparation** Sorting the initial data and preparing a result Collection
    | 2 |'
  id: totrans-32
  prefs: []
  type: TYPE_TB
  zh: '| **数据准备** 对初始数据进行排序并准备结果收集 | 2 |'
- en: '| **Traversal process** Looping and controlling the loop with `continue` and
    `break` | 4 |'
  id: totrans-33
  prefs: []
  type: TYPE_TB
  zh: '| **遍历过程** 循环并使用 `continue` 和 `break` 控制循环 | 4 |'
- en: '| **Data processing** Choosing, transforming, and gathering the correct elements
    and data | 4 |'
  id: totrans-34
  prefs: []
  type: TYPE_TB
  zh: '| **数据处理** 选择、转换和收集正确的元素和数据 | 4 |'
- en: However, requiring a lot of boilerplate code to traverse isn’t the only drawback
    associated with external iteration. Another downside is the inherent serial traversal
    process. You need to rework the whole loop if you require parallel data processing
    and deal with all the associated gotchas, like the dreaded `ConcurrentModificationException`.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，需要大量样板代码来进行遍历不是与外部迭代相关的唯一缺点。另一个缺点是固有的串行遍历过程。如果需要并行数据处理，并要处理所有相关的烦心事，比如可怕的
    `ConcurrentModificationException`，那么你需要重新设计整个循环。
- en: Internal Iteration
  id: totrans-36
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 内部迭代
- en: The opposite approach to *external* iteration is, predictably, *internal* iteration.
    With internal iteration, you give up explicit control of the traversal process
    and let the data source itself handle “how it’s done,” as illustrated in [Figure 6-2](#_02-data-processing_internal-iteration).
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 与*外部*迭代相对的方法是，可预测的，*内部*迭代。使用内部迭代，你放弃了对遍历过程的显式控制，并让数据源本身处理“它是如何完成的”，如 [图 6-2](#_02-data-processing_internal-iteration)
    所示。
- en: '![Internal iteration](assets/afaj_0602.png)'
  id: totrans-38
  prefs: []
  type: TYPE_IMG
  zh: '![内部迭代](assets/afaj_0602.png)'
- en: Figure 6-2\. Internal iteration
  id: totrans-39
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图6-2\. 内部迭代
- en: Instead of using an iterator to control the traversal, the data processing logic
    is prepared beforehand to build a pipeline that does the iteration by itself.
    The iteration process becomes more opaque, but the logic influences which elements
    traverse the pipeline. This way, you can focus your energy and code on “what you
    want to do” rather than on the tedious and often repetitive details of “how it’s
    done.”
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 不使用迭代器来控制遍历，数据处理逻辑事先准备好以构建一个自行迭代的管道。迭代过程变得更加不透明，但逻辑影响哪些元素遍历管道。这样，你可以把精力和代码集中在“想要做什么”而不是“如何做”这些繁琐且常重复的细节上。
- en: Streams are such data pipelines with internal iteration.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 流是具有内部迭代的数据管道。
- en: Streams as Functional Data Pipelines
  id: totrans-42
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 流作为功能性数据管道
- en: 'Streams, as a data processing approach, get the job done like any other one
    but have specific advantages due to having an internal iterator. These advantages
    are especially beneficial from a functional point of view. The advantages are
    as follows:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 流作为一种数据处理方法，像其他方法一样完成工作，但由于具有内部迭代器，具有特定优势。这些优势在功能上尤其有益。优势如下：
- en: Declarative approach
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 声明性方法
- en: Build concise and comprehensible multi-step data processing pipelines with a
    single fluent call chain.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 用一个流畅的调用链构建简洁而易懂的多步数据处理管道。
- en: Composability
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 可组合性
- en: Stream operations provide a scaffold made of higher-order functions to be filled
    with data processing logic. They can be mixed as needed. If you design their logic
    in a functional way, you automatically gain all their advantages, like composability.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 流操作提供了一个由高阶函数组成的框架，用于填充数据处理逻辑。它们可以按需混合使用。如果以函数式的方式设计它们的逻辑，你就能自动获得它们的所有优势，如可组合性。
- en: Laziness
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 懒加载
- en: Instead of iteration over all elements, they get pulled one by one through the
    pipeline after the last operation is attached to it, reducing the required amount
    of operations to a minimum.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 它们不是迭代所有元素，而是在最后一个操作附加到它们后逐个拉入管道，将所需操作最小化。
- en: Performance optimization
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 性能优化
- en: Streams optimize the traversal process automatically depending on their data
    source and different kinds of operations used, including short-circuiting operations
    if possible.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 流根据它们的数据源和使用的不同操作自动优化遍历过程，包括可能的短路操作。
- en: Parallel data processing
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 并行数据处理
- en: Built-in support for parallel processing is used by simply changing a single
    call in the call chain.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 内置支持并行处理，只需更改调用链中的一个调用即可使用。
- en: In concept, Streams could be considered just another alternative to traditional
    loop constructs for data processing. In reality, though, Streams are special in
    *how* they go about providing those data processing capabilities.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 在概念上，流可以被认为只是传统循环结构用于数据处理的另一种选择。然而，在现实中，流在*如何*提供这些数据处理能力方面是特殊的。
- en: The first thing to consider is the overall Stream workflow. Streams can be summed
    up as *lazy sequential data pipelines*. Such pipelines are a higher-level abstraction
    for traversing sequential data. They are sequences of higher-order functions to
    process their elements in a fluent, expressive, and functional way. The general
    workflow is representable by three steps, as seen in [Figure 6-3](#_02-data-processing_concept).
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 首先要考虑的是整体的流工作流程。流可以总结为*惰性顺序数据管道*。这样的管道是遍历顺序数据的更高级抽象。它们是处理其元素的高阶函数序列，以流畅、表达和函数式的方式。一般的工作流程可以通过三个步骤来表示，如在[图 6-3](#_02-data-processing_concept)中所见。
- en: '![Different aspects of Java Streams](assets/afaj_0603.png)'
  id: totrans-56
  prefs: []
  type: TYPE_IMG
  zh: '![Java Streams的不同方面](assets/afaj_0603.png)'
- en: Figure 6-3\. The Basic Concept of Java Streams
  id: totrans-57
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 6-3\. Java Streams的基本概念
- en: (1) Creating a Stream
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: (1) 创建一个流
- en: The first step is creating a Stream out of an existing data source. Streams
    aren’t limited to collection-like types, though. Any data source that can provide
    sequential elements is a possible data source for a Stream.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 第一步是从现有数据源创建一个流。流不仅限于类似集合的类型。任何能够提供连续元素的数据源都可以作为流的数据源。
- en: (2) Doing the Work
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: (2) 进行工作
- en: So-called *intermediate operations* — higher-order functions available as methods
    on the `java.util.stream.Stream<T>` — work on the elements passing through the
    pipeline, doing different tasks, like filtering, mapping, sorting, etc. Each one
    returns a new Stream, which can be connected with as many intermediate operations
    as needed.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 所谓的*中间操作* —— 在 `java.util.stream.Stream<T>` 上作为方法可用的高阶函数 —— 在通过管道传递的元素上工作，执行不同的任务，如过滤、映射、排序等。每个操作都返回一个新的
    Stream，可以连接到尽可能多的中间操作。
- en: (3) Getting a Result
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: (3) 获取结果
- en: To finish the data processing pipeline, a final — *terminal* — operation is
    needed to get back a result instead of a Stream. Such a terminal operation completes
    the Stream pipeline blueprint and starts the actual data processing.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 要完成数据处理流水线，需要一个最终的 —— *终端* —— 操作，以获取结果而不是 Stream。这样的终端操作完成了 Stream 流水线的蓝图，并开始实际的数据处理。
- en: To see this in action, let’s revisit the earlier task of finding three science-fiction
    book titles from 1999. This time, instead of using a `for`-loop as we did in [Example 6-1](#_02-data-processing_for-loop),
    we will use a Stream pipeline in [Example 6-2](#_02-data-processing_stream). Don’t
    worry too much about the Stream code yet; I’ll explain the various methods shortly.
    Read through it, and you should be able to get the gist of it for now.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 要看到它的运行情况，让我们重新访问早期任务，找出 1999 年的三本科幻书的标题。这一次，我们将使用 [示例 6-2](#_02-data-processing_stream)
    中的 Stream 流水线，而不是像在 [示例 6-1](#_02-data-processing_for-loop) 中使用 `for` 循环。现在先不要太担心
    Stream 代码，我会很快解释各种方法。阅读一遍，你现在应该能够大致理解它。
- en: Example 6-2\. Finding books with a Stream
  id: totrans-65
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 6-2\. 使用 Stream 查找书籍
- en: '[PRE1]'
  id: totrans-66
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: '[![1](assets/1.png)](#co_data_processing_with_streams_CO2-1)'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: '[![1](assets/1.png)](#co_data_processing_with_streams_CO2-1)'
- en: An unsorted collection of books.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 一组未排序的书籍。
- en: '[![2](assets/2.png)](#co_data_processing_with_streams_CO2-2)'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: '[![2](assets/2.png)](#co_data_processing_with_streams_CO2-2)'
- en: Ignore any books not published in 1999.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 忽略任何非 1999 年出版的书籍。
- en: '[![3](assets/3.png)](#co_data_processing_with_streams_CO2-3)'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: '[![3](assets/3.png)](#co_data_processing_with_streams_CO2-3)'
- en: Ignore any non-science-fiction books.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 忽略任何非科幻书籍。
- en: '[![4](assets/4.png)](#co_data_processing_with_streams_CO2-4)'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: '[![4](assets/4.png)](#co_data_processing_with_streams_CO2-4)'
- en: Transform the element from the whole `Book` element to its `title` value.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 将整个 `Book` 元素转换为其 `title` 值。
- en: '[![5](assets/5.png)](#co_data_processing_with_streams_CO2-5)'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: '[![5](assets/5.png)](#co_data_processing_with_streams_CO2-5)'
- en: Sort the titles.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 对标题进行排序。
- en: '[![6](assets/6.png)](#co_data_processing_with_streams_CO2-6)'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: '[![6](assets/6.png)](#co_data_processing_with_streams_CO2-6)'
- en: Restrict the found titles to a maximum of three.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 限制找到的标题最多为三个。
- en: '[![7](assets/7.png)](#co_data_processing_with_streams_CO2-7)'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: '[![7](assets/7.png)](#co_data_processing_with_streams_CO2-7)'
- en: Aggregate the titles into a `List<String>`.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 将标题聚合成 `List<String>`。
- en: From a high-level point of view, both implementations shown in [Example 6-1](#_02-data-processing_for-loop)
    and [Example 6-2](#_02-data-processing_stream) represent pipelines that elements
    can traverse, with multiple exit points for unneeded data. But, notice how the
    functionality of the `for`-loop with its multiple statements is now condensed
    into a singular fluent Stream call?
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 从高层次的角度来看，[示例 6-1](#_02-data-processing_for-loop) 和 [示例 6-2](#_02-data-processing_stream)
    中展示的两种实现都代表了元素可以遍历的流水线，其中包含多个不需要的数据的退出点。但请注意，`for` 循环的功能及其多个语句现在被压缩成了一个单一的流畅 Stream
    调用？
- en: This leads us to how Streams optimize the flow of their elements. You don’t
    have to explicitly manage the traversal with `continue` or `break` because the
    elements will traverse the pipeline depending on the result of the operations.
    [Figure 6-4](#_02-data-processing_albums-stream-steps) illustrates how the different
    Stream operations affect the element flow of [Example 6-2](#_02-data-processing_stream).
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 这引导我们了解 Stream 如何优化其元素的流动。您不必使用 `continue` 或 `break` 明确管理遍历，因为元素将根据操作的结果在管道中遍历。[图
    6-4](#_02-data-processing_albums-stream-steps) 阐明了不同的 Stream 操作如何影响 [示例 6-2](#_02-data-processing_stream)
    的元素流。
- en: '![Element Flow of Book Stream](assets/afaj_0604.png)'
  id: totrans-83
  prefs: []
  type: TYPE_IMG
  zh: '![书籍流的元素流动](assets/afaj_0604.png)'
- en: Figure 6-4\. Element Flow of Book Stream
  id: totrans-84
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 6-4\. 书籍流的元素流动
- en: The elements flow one by one through the Stream and are funneled to the least
    amount needed to process the data.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 元素逐个通过 Stream 流动，并被漏斗到处理数据所需的最少量。
- en: Instead of needing to prepare the data beforehand and wrapping the processing
    logic in a loop statement’s body, Streams are built with a fluent class of the
    different processing steps. Like other functional approaches, Stream code reflects
    “what” is happening in a more expressive and declarative fashion, without the
    typical verbiage of “how” it’s actually done.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 与需要预先准备数据并将处理逻辑包装在循环语句体中的方式不同，流是通过不同处理步骤的流畅类构建的。与其他函数式方法类似，流代码以更具表现力和声明性的方式反映了“发生了什么”，而不是典型的“如何实际完成”的冗长表述。
- en: Stream Features
  id: totrans-87
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 流特性
- en: Streams are a functional API with specific behaviors and expectations built
    in. In a way, this confines their possibilities, at least, compared to the blank
    canvas of traditional loops. By being non-blank canvases, though, they provide
    you with lots of pre-defined building blocks and guaranteed properties that you
    would have to do yourself with alternative approaches.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 流是具有特定行为和预期的函数式 API。在某种程度上，这限制了它们的可能性，至少与传统循环的空白画布相比如此。但通过不是空白画布，它们为你提供了许多预定义的构建块和保证属性，这些属性如果使用其他方法，你将不得不自己实现。
- en: Lazy Evaluation
  id: totrans-89
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 惰性求值
- en: The most significant advantage of Streams over loops is their laziness. Each
    time you call an intermediate operation on a Stream, it’s not applied immediately.
    Instead, the call simply “extends” the pipeline further and returns a new lazily
    evaluated Stream. The pipeline accumulates all operations, and no work starts
    before you call its terminal operation, which will trigger the actual element
    traversal, as seen in [Figure 6-5](#_02-streams_laziness).
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 流相对于循环最显著的优势是它们的惰性。每次在流上调用一个中间操作时，并不会立即应用它。相反，这个调用只是“扩展”了管道，并返回一个新的惰性评估的流。管道累积所有操作，直到你调用它的终端操作才会触发实际的元素遍历，就像在[图
    6-5](#_02-streams_laziness)中所见。
- en: '![Lazy Evaluation of Streams](assets/afaj_0605.png)'
  id: totrans-91
  prefs: []
  type: TYPE_IMG
  zh: '![流的惰性求值](assets/afaj_0605.png)'
- en: Figure 6-5\. Lazy evaluation of Streams
  id: totrans-92
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 6-5\. 流的惰性求值
- en: Instead of providing all elements to a code block, like a loop, the terminal
    operation is asking for more data as needed, and the Stream tries to comply. Streams,
    as a data source, don’t have to “over-provide” or buffer any elements if no one
    is requesting more elements. If you look back at [Figure 6-4](#_02-data-processing_albums-stream-steps),
    that means not every element will traverse through every operation.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 终端操作不是将所有元素提供给代码块（如循环），而是根据需要请求更多数据，并且流会尽力满足这些请求。作为数据源，如果没有人请求更多元素，流就不需要“过度提供”或缓冲任何元素。如果回顾[图
    6-4](#_02-data-processing_albums-stream-steps)，这意味着并不是每个元素都会通过每个操作。
- en: The flow of Stream elements follows a “depth-first” approach, reducing the required
    CPU cycles, memory footprint, and stack depth. This way, even infinite data sources
    are possible because the pipeline is responsible for requesting the required elements
    and terminating the Stream.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 流元素的流动遵循“深度优先”的方法，减少了所需的 CPU 周期、内存占用和堆栈深度。因此，即使是无限数据源也是可能的，因为管道负责请求所需的元素并终止流。
- en: You can read more about the importance of laziness in functional programming
    in [Chapter 11](ch11.xhtml#_02-lazy-evaluation).
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以在[第 11 章](ch11.xhtml#_02-lazy-evaluation)中详细了解函数式编程中惰性求值的重要性。
- en: (Mostly) Stateless and Non-Interfering
  id: totrans-96
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: （大部分）无状态且不干涉
- en: As you’ve learned in [Chapter 4](ch04.xhtml#_02-data-structures), an immutable
    state is an essential functional programming concept, and Streams do their best
    to adhere. Almost all intermediate operations are stateless and detached from
    the rest of the pipeline, only having access to the current element they’re processing.
    Certain intermediate operations, however, require some form of state to fulfill
    their purpose, like `limit` or `skip`.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 正如你在[第 4 章](ch04.xhtml#_02-data-structures)中学到的那样，不可变状态是函数式编程中的一个重要概念，而流（Streams）尽力遵循这一概念。几乎所有的中间操作都是无状态的，并且与管道的其余部分分离，只能访问它们当前正在处理的元素。然而，某些中间操作需要某种形式的状态来完成它们的目的，比如`limit`或`skip`。
- en: Another advantage of using Streams is their separation of the data source and
    the elements themselves. That way, operations won’t affect the underlying data
    source in any way, nor does the Stream store any elements itself.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 使用流的另一个优势是它们将数据源与元素本身分离。这样一来，操作不会以任何方式影响底层数据源，流本身也不会存储任何元素。
- en: Warning
  id: totrans-99
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 警告
- en: Even though you can create Java stateful lambdas with side effects, you should
    strive to design the behavioral arguments of your data manipulation pipelines
    stateless and as pure functions. Any dependence on an out-of-scope state can severely
    impact safety and performance and make the whole pipeline nondeterministic and
    incorrect due to unintended side effects. One exception is certain terminal operations
    for doing “side-effect only” code, which can help immensely fit functional Stream
    pipelines in existing imperative designs.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管你可以创建具有副作用的Java状态型lambda函数，但是你应该努力设计数据操作管道的行为参数为无状态且纯函数。任何依赖于超出范围状态的行为都可能严重影响安全性和性能，并使整个管道因意外副作用而变得不确定和不正确。其中一种例外是用于执行“仅副作用”的终端操作代码，这有助于在现有的命令式设计中极好地适配功能型流管道。
- en: Streams are *non-interfering* and *pass-through* pipelines that will let their
    elements traverse as freely as possible without interference, if not absolutely
    necessary.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 流是*非干扰*和*直通*管道，将其元素尽可能自由地穿越，除非绝对必要。
- en: Optimizations included
  id: totrans-102
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 包括优化
- en: 'The internal iteration and fundamental design of higher-order functions allow
    Streams to optimize themselves quite efficiently. They utilize multiple techniques
    to improve their performance:'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 内部迭代和高阶函数的基本设计使得流能够相当高效地优化自身。它们利用多种技术来提升性能：
- en: Fusion^([1](ch06.xhtml#idm45115238989296)) of (stateless) operations
  id: totrans-104
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: （无状态）操作的融合^([1](ch06.xhtml#idm45115238989296))
- en: Removal of redundant operations
  id: totrans-105
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 移除冗余操作
- en: Short-circuiting pipeline paths
  id: totrans-106
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 短路管道路径
- en: Iteration-related code optimizations aren’t restricted to Streams, though. Traditional
    loops get optimized by the JVM, too, if possible^([2](ch06.xhtml#idm45115238985136)).
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 与流相关的迭代代码优化并不限于流。如果可能的话，传统循环也会被JVM优化^([2](ch06.xhtml#idm45115238985136))。
- en: Also, loops like `for` and `while` are language features, and can therefore
    be optimized to another degree. Streams are ordinary types with all the costs
    affiliated with them. They still need to be created by wrapping a data source,
    and the pipeline is a call chain requiring a new stack frame for each call. In
    most real-world scenarios, their general advantages outweigh the possible performance
    impact of such an overhead compared to a built-in statement like `for` or `while`.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，像`for`和`while`这样的循环是语言特性，因此可以被进一步优化。流是普通类型，具有相关的所有成本。它们仍然需要通过包装数据源来创建，并且管道是一个调用链，每次调用都需要一个新的堆栈帧。在大多数实际场景中，它们的总体优势超过了与内置语句`for`或`while`相比可能的性能影响。
- en: Less boilerplate
  id: totrans-109
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 减少样板代码
- en: As seen in [Example 6-2](#_02-data-processing_stream), Streams condense data
    processing into a singular fluent method call chain. The call is designed to consist
    of small and on-point operations like `filter`, `map`, or `findFirst`, providing
    an expressive and straightforward scaffold around the data processing logic. Call
    chains should be easy to grasp, both visually and conceptually. Therefore, a Stream
    pipeline consumes as little visual real estate and cognitive bandwidth as necessary.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 如在[示例 6-2](#_02-data-processing_stream)中所见，流将数据处理压缩为一个流畅的方法调用链。这个调用链被设计为由诸如`filter`、`map`或`findFirst`等小而精准的操作组成，为数据处理逻辑提供了一个富有表现力且直接的支架。调用链应该易于理解，无论是视觉上还是概念上。因此，流管道只消耗尽可能少的视觉空间和认知带宽。
- en: Non-Reusable
  id: totrans-111
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 不可重复使用
- en: Stream pipelines are *single-use* only. They’re bound to their data source and
    traverse them exactly once after the terminal operation is called.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 流管道仅限于单次使用。它们与其数据源绑定，在终端操作调用后遍历数据源一次。
- en: If you try to use a Stream again, an `IllegalStateException` gets thrown. You
    can’t check if a Stream is already consumed, though.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 如果尝试再次使用流，会抛出`IllegalStateException`。尽管如此，你无法检查流是否已经被消耗。
- en: As Streams don’t change or affect their underlying data source, you can always
    create another Stream from the same data source.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 由于流不会改变或影响其底层数据源，你始终可以从同一数据源创建另一个流。
- en: Primitive Streams
  id: totrans-115
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 原始类型流
- en: As with the functional interfaces introduced in [Chapter 2](ch02.xhtml#_01-functional-java),
    the Stream API contains specialized variants for dealing with primitives to minimize
    autoboxing overhead.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 与[第2章](ch02.xhtml#_01-functional-java)介绍的功能接口类似，流API包含了处理原始类型的专门变体，以最小化自动装箱的开销。
- en: Both `Stream` and the specialized variants `IntStream`, `LongStream`, and `DoubleStream`,
    share a common base interface, `BaseStream`, as illustrated in [Figure 6-6](#_02-data-processing_type-hierachy).
    Many of the available primitive Stream operations mirror their non-primitive counterpart,
    but not all of them.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: '`Stream`及其专门的变体`IntStream`、`LongStream`和`DoubleStream`共享一个公共基础接口`BaseStream`，如[图 6-6](#_02-data-processing_type-hierachy)所示。许多可用的原始流操作与其非原始对应物相似，但并非全部。'
- en: '![Stream type hierarchy](assets/afaj_0606.png)'
  id: totrans-118
  prefs: []
  type: TYPE_IMG
  zh: '![流类型层次结构](assets/afaj_0606.png)'
- en: Figure 6-6\. Stream type hierarchy
  id: totrans-119
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 6-6\. 流类型层次结构
- en: That’s why I discuss in [Chapter 7](ch07.xhtml#_02-streams) when to use a primitive
    Stream and how to switch between non-primitive and primitive Streams with a single
    operation.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是为什么我在[第 7 章](ch07.xhtml#_02-streams)中讨论何时使用原始流以及如何使用单个操作在非原始和原始流之间进行切换的原因。
- en: Easy Parallelization
  id: totrans-121
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 简单并行化
- en: Data processing with traditional loop constructs is inherently serial. Concurrency
    is hard to do right and easy to do wrong, especially if you have to do it yourself.
    Streams are designed to support parallel execution from the ground up, utilizing
    the [Fork/Join framework](https://openjdk.java.net/projects/jdk7/features/#f515)
    introduced with Java 7.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 使用传统循环结构进行数据处理固有地是串行的。并发很难做到正确，很容易做错，特别是如果您必须自己处理它。流从根本上支持并行执行，利用了Java 7引入的[Fork/Join框架](https://openjdk.java.net/projects/jdk7/features/#f515)。
- en: Parallelizing a Stream is done by simply calling the `parallel` method at any
    point of the pipeline. Although not every Stream pipeline is a good match for
    parallel processing. The Stream source must have enough elements, and the operations
    have to be costly enough to justify the overhead of multiple threads. Switching
    threads — so-called [context switches](https://en.wikipedia.org/wiki/Context_switch#Cost) — is
    an expensive task.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 通过在管道的任何点简单地调用`parallel`方法来并行化流。虽然并非每个流管道都适合并行处理。流源必须有足够的元素，并且操作必须足够昂贵，以证明多线程的开销是合理的。切换线程——所谓的[上下文切换](https://zh.wikipedia.org/wiki/%E4%B8%8A%E4%B8%8B%E6%96%87%E5%88%87%E6%8D%A2#%E6%88%90%E6%9C%AC)——是一项昂贵的任务。
- en: In [Chapter 8](ch08.xhtml#_01-parallel-streams), you’ll learn more about parallel
    Stream processing and concurrency in general.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 在[第 8 章](ch08.xhtml#_01-parallel-streams)中，您将更多地了解并行流处理和一般并发。
- en: (Lack of) Exception Handling
  id: totrans-125
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: （缺乏）异常处理
- en: Streams do a great job of reducing the verbosity of your code by introducing
    a functional approach to data processing. However, this doesn’t make them immune
    to dealing with exceptions in their operations.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 流通过引入函数式数据处理方法极大地减少了代码的冗长。然而，这并不意味着它们在操作中免于处理异常。
- en: Lambda expressions, and therefore the logic of Stream operations, don’t have
    any special considerations or syntactic sugar to handle exceptions more concisely
    than you’re used to with `try`-`catch`. You can read more about the general problem
    of exceptions in functional Java code and how to handle them in different ways
    in [Chapter 10](ch10.xhtml#_02-exception-handling).
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: Lambda表达式以及因此流操作的逻辑，没有任何特殊的考虑或语法糖来比`try`-`catch`更简洁地处理异常。您可以在[第 10 章](ch10.xhtml#_02-exception-handling)中了解有关函数式Java代码中异常的一般问题以及如何以不同方式处理它们的更多信息。
- en: Spliterator, the Backbone of Streams
  id: totrans-128
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 流的骨干Spliterator
- en: 'Just like “traditional” *for-each*-loop is built around the `Iterator<T>` type
    for traversing a sequence of elements, Streams have their own iteration interface:
    `java.util.Spliterator<T>`.'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 就像“传统”的*for-each*循环围绕`Iterator<T>`类型构建以遍历元素序列一样，流有自己的迭代接口：`java.util.Spliterator<T>`。
- en: The `Iterator<T>` interface is solely based on the concept of “next” with only
    a few methods, which makes it a universal iterator for Java’s Collection API.
    The concept behind `Spliterator<T>`, however, is that it has the ability to split
    off a subsequence of its elements into another `Spliterator<T>` based on certain
    characteristics. This particular advantage over the `Iterator<T>` type makes it
    the core of the Stream API and allows Streams to process such subsequences in
    parallel, and still be able to iterate over Java Collection API types.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: '`Iterator<T>`接口仅基于“next”概念，具有少量方法，使其成为Java集合API的通用迭代器。然而，`Spliterator<T>`背后的概念是它具有根据某些特征将其元素的子序列拆分成另一个`Spliterator<T>`的能力。这种优势使其比`Iterator<T>`类型更适合成为流API的核心，并允许流以并行方式处理这些子序列，并仍然能够迭代Java集合API类型。'
- en: '[Example 6-3](#_02-streams_spliterator-interface) shows a simplified variant
    of `java.util.Spliterator`.'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: '[示例 6-3](#_02-streams_spliterator-interface)展示了`java.util.Spliterator`的简化变体。'
- en: Example 6-3\. The `java.util.Spliterator` interface
  id: totrans-132
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 6-3\. `java.util.Spliterator` 接口
- en: '[PRE2]'
  id: totrans-133
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: For the iteration process, the `boolean tryAdvance(Consumer action)` and `Spliterator<T>
    trySplit()` methods are the most important ones. Still, a Spliterator’s characteristics
    decree the capabilities of all its operations.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 对于迭代过程，`boolean tryAdvance(Consumer action)` 和 `Spliterator<T> trySplit()` 方法是最重要的。尽管如此，Spliterator
    的特性决定了其所有操作的能力。
- en: Regarding Streams, the Spliterator’s characteristics are responsible for how
    a Stream iterates internally and what optimizations it supports. There are eight
    combinable characteristics, defined as `static int` constants on the `Spliterator<T>`
    type, as listed in [Table 6-2](#_02-data-processing-characteristics). Even though
    it looks like the characteristics match expected Stream behavior, not all of them
    are actually used in the current Stream implementations.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 关于 Streams，Spliterator 的特性负责 Stream 内部迭代的方式以及它支持的优化。有八个可组合的特性，定义为 `static int`
    常量在 `Spliterator<T>` 类型上，如 [表 6-2](#_02-data-processing-characteristics) 所列。尽管特性看起来符合预期的
    Stream 行为，但并非所有特性在当前的 Stream 实现中都实际使用。
- en: Table 6-2\. Spliterator characteristics
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 表 6-2\. Spliterator 特性
- en: '| Characteristic | Description |'
  id: totrans-137
  prefs: []
  type: TYPE_TB
  zh: '| 特性 | 描述 |'
- en: '| --- | --- |'
  id: totrans-138
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| `CONCURRENT` | The underlying data source can safely be concurrently modified
    during traversal. Only affects the data source itself and has no implications
    for Stream-behavior. |'
  id: totrans-139
  prefs: []
  type: TYPE_TB
  zh: '| `CONCURRENT` | 基础数据源在遍历过程中可以安全地并发修改。只影响数据源本身，与 Stream 行为无关。 |'
- en: '| `DISTINCT` | The data source only contains unique elements, like a `Set<T>`.
    Any pair of elements in a Stream is guaranteed to be `x.equals(y) == false`. |'
  id: totrans-140
  prefs: []
  type: TYPE_TB
  zh: '| `DISTINCT` | 数据源只包含唯一的元素，如 `Set<T>`。Stream 中的任何元素对保证 `x.equals(y) == false`。
    |'
- en: '| `IMMUTABLE` | The data source itself is immutable. No element can be added,
    replaced, or removed during traversal. Only affects the data source itself and
    has no implications for Stream-behavior. |'
  id: totrans-141
  prefs: []
  type: TYPE_TB
  zh: '| `IMMUTABLE` | 数据源本身是不可变的。遍历期间不能添加、替换或删除任何元素。只影响数据源本身，与 Stream 行为无关。 |'
- en: '| `NONNULL` | The underlying data source guarantees not to contain any `null`
    values. Only affects the data source itself and has no implications for Stream-behavior.
    |'
  id: totrans-142
  prefs: []
  type: TYPE_TB
  zh: '| `NONNULL` | 基础数据源保证不包含任何 `null` 值。只影响数据源本身，与 Stream 行为无关。 |'
- en: '| `ORDERED` | There is a defined order for the elements of the data source.
    During traversal, the encountered elements will be in that particular order. |'
  id: totrans-143
  prefs: []
  type: TYPE_TB
  zh: '| `ORDERED` | 数据源的元素有一个定义的顺序。在遍历过程中，遇到的元素将按特定顺序排列。 |'
- en: '| `SORTED` | If the `Spliterator<T>` is `SORTED`, its `getComparator()` method
    returns the associated `Comparator<T>`, or `null`, if the source is naturally
    sorted. `SORTED` `Spliterators` must also be `ORDERED`. |'
  id: totrans-144
  prefs: []
  type: TYPE_TB
  zh: '| `SORTED` | 如果 `Spliterator<T>` 是 `SORTED`，则其 `getComparator()` 方法返回关联的 `Comparator<T>`，否则返回
    `null`，如果源数据自然排序。`SORTED` 的 `Spliterators` 也必须是 `ORDERED`。 |'
- en: '| `SIZED` | The data source knows its exact size. `estimateSize()` returns
    the actual size, not an estimate. |'
  id: totrans-145
  prefs: []
  type: TYPE_TB
  zh: '| `SIZED` | 数据源知道其确切的大小。`estimateSize()` 返回实际大小，而不是估计值。 |'
- en: '| `SUBSIZED` | Signifies that all split up chunk after calling `trySplit()`
    are also `SIZED`. Only affects the data source itself and has no implications
    for Stream-behavior. |'
  id: totrans-146
  prefs: []
  type: TYPE_TB
  zh: '| `SUBSIZED` | 表示在调用 `trySplit()` 后所有拆分的块也都是 `SIZED`。只影响数据源本身，与 Stream 行为无关。
    |'
- en: Stream characteristics don’t have to be fixed and can depend on the underlying
    data source. `HashSet` is an example of a Spliterator with dynamic characteristics.
    It uses the nested `HashMap.KeySpliterator` class which depends on the actual
    data, as seen in [Example 6-4](#_02-data-processing_spliterator_characteristics-hashset).
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: Stream 的特性不必固定，并且可以依赖于基础数据源。`HashSet` 是具有动态特性的 Spliterator 的一个例子。它使用嵌套的 `HashMap.KeySpliterator`
    类，依赖于实际数据，如 [示例 6-4](#_02-data-processing_spliterator_characteristics-hashset)
    所示。
- en: Example 6-4\. Spliterator characteristics of HashSet<T>
  id: totrans-148
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 6-4\. HashSet<T> 的 Spliterator 特性
- en: '[PRE3]'
  id: totrans-149
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: The way `HashSet` creates its `KeySpliterator` shows that a Spliterator can
    use its surrounding context to make an informed decision about its capabilities.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: '`HashSet` 创建其 `KeySpliterator` 的方式表明，Spliterator 可以利用其周围的上下文做出有关其能力的明智决定。'
- en: You don’t need to think much about a Stream’s characteristics most of the time.
    Usually, the underlying capabilities of a data source won’t change *magically*
    just because it’s traversed with a Stream. A `Set<T>` will still provide distinct
    elements in an unordered fashion, regardless of being used with a `for`-loop or
    a Stream. So choose the most fitting data source for the task, no matter the form
    of traversal used.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数情况下，你不需要过多考虑流的特性。通常情况下，数据源的基本能力不会因为使用流而*神奇地*改变。例如，`Set<T>`仍然会以无序方式提供不同的元素，无论是使用`for`循环还是流。因此，选择最适合任务的数据源，不管使用的是哪种遍历形式。
- en: 'When using Streams, you usually don’t need to create a Spliterator yourself,
    as the convenience methods I’m going to discuss in the next chapter will do it
    behind the scenes for you. Still, if you need to create a Spliterator for a custom
    data structure, you don’t necessarily have to implement the interface yourself,
    either. You can use one of the many convenience methods of `java.util.Spliterators`,
    instead. The easiest variant is the following method:'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 在使用流时，通常不需要手动创建`Spliterator`，因为我将在下一章中讨论的便利方法会在后台为你完成这些操作。但是，如果你需要为自定义数据结构创建`Spliterator`，也不一定需要自己实现接口。相反，你可以使用`java.util.Spliterators`的众多便利方法之一。最简单的变体如下方法：
- en: '[PRE4]'
  id: totrans-153
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: The resulting Spliterator might not be the most optimized Spliterator with only
    limited parallel support, but it’s the simplest way to use existing `Iterator`-compatible
    data structures in Streams that don’t support them out of the box.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 生成的`Spliterator`可能不是最优化的`Spliterator`，只支持有限的并行处理，但这是在流中使用现有`Iterator`兼容数据结构的最简单方法，这些数据结构在原生不支持流的情况下使用。
- en: Check out the official [documentation](https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/util/Spliterators.xhtml)
    for more information about the 20+ convenience methods provided by the `java.util.Spliterators`
    type.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 查看官方[文档](https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/util/Spliterators.xhtml)，了解`java.util.Spliterators`类型提供的20多个便利方法的更多信息。
- en: Building Stream Pipelines
  id: totrans-156
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 构建流管道
- en: The Stream API is extensive, and a detailed explanation of each operation and
    possible use case could easily fill a book itself. Let’s take a higher-level view
    of building Stream pipelines with the available higher-order functions instead.
    This overview will still help you to replace many data processing tasks with Stream
    pipelines in your code, especially those following the *map/filter/reduce* philosophy.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 流API非常广泛，详细解释每个操作和可能的使用情况本身可能会填满一本书。我们可以从更高层次的角度来看待使用可用的高阶函数构建流管道。这个概述仍然会帮助你在代码中用流管道取代许多数据处理任务，尤其是那些遵循*映射/过滤/归约*哲学的任务。
- en: The Stream API actually has operations named `map`, `filter`, and `reduce`.
    Still, it provides a lot more operations than these three. The logic of most of
    these additional operations can be replicated by `map`/`filter`/`reduce`, and
    internally, that’s often the case. The extra operations give you a convenient
    way to avoid implementing common use cases yourself, with many different specialized
    operations readily available to you.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 流API实际上有名为`map`、`filter`和`reduce`的操作。但它提供的操作远不止这三个。大多数这些额外的操作的逻辑都可以通过`map`/`filter`/`reduce`来复制，并且在内部通常确实如此。这些额外的操作为你提供了一个方便的方式来避免自己实现常见用例，提供了许多不同的专门操作，可以轻松使用。
- en: Creating a Stream
  id: totrans-159
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 创建流
- en: Every Stream pipeline starts with creating a new Stream instance from an existing
    data source. The most commonly used data source are collection types. That’s why
    the three methods `Stream<E> stream()`, `Stream<E> parallelStream()`, and `Spliterator<E>
    spliterator()` were retrofitted to `java.util.Collection` with the introduction
    of Streams in Java 8, as seen in [Example 6-5](#_02-data-processing_how-to-create-retrofit).
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 每个流管道都始于从现有数据源创建一个新的流实例。最常用的数据源是集合类型。这就是为什么在Java 8中引入流时，`Stream<E> stream()`、`Stream<E>
    parallelStream()`和`Spliterator<E> spliterator()`这三种方法被添加到`java.util.Collection`中，正如在[示例 6-5](#_02-data-processing_how-to-create-retrofit)中所见。
- en: Example 6-5\. Simplified Stream creation for Collection types
  id: totrans-161
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 6-5\. 简化集合类型的流创建
- en: '[PRE5]'
  id: totrans-162
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: The `stream` method is the simplest way to create a new Stream instance from
    any `Collection`-based data structure, like `List` or `Set`. It utilizes an `IMMUTABLE`
    and `CONCURRENT` `Spliterator` as its default implementation. However, many `Collection`
    types provide their own implementations with optimized characteristics and behavior.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: '`stream` 方法是从任何基于 `Collection` 的数据结构（如 `List` 或 `Set`）创建新 `Stream` 实例的最简单方法。它利用了一个
    `IMMUTABLE` 和 `CONCURRENT` 的 `Spliterator` 作为其默认实现。然而，许多 `Collection` 类型提供了具有优化特性和行为的自定义实现。'
- en: Even though the `stream` method on `Collection` might be the most convenient
    method to create a Stream, the JDK provides many other ways to create Streams
    as `static` convenience methods, like `Stream.of(T…​ values)`. In [Chapter 7](ch07.xhtml#_02-streams),
    you’ll learn more ways to create Streams for different use cases, like infinite
    Streams or working with I/O.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 即使在 `Collection` 上的 `stream` 方法可能是创建 Stream 最方便的方法，JDK 还提供了许多其他创建 Stream 的静态便捷方法，如
    `Stream.of(T…​ values)`。在 [第 7 章](ch07.xhtml#_02-streams) 中，您将学习更多创建不同用例的 Stream
    的方法，如无限 Stream 或处理 I/O。
- en: Doing the Work
  id: totrans-165
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 执行工作
- en: Now that you have a Stream, the next step is working with its elements.
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 现在您已经有了一个 Stream，下一步是处理其元素。
- en: 'Working with Stream elements is done by *intermediate operations*, which fall
    into three categories: transforming (*map*) elements, selecting (*filter*) elements,
    or modifying general Stream behavior.'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 处理 Stream 元素是通过 *中间操作* 完成的，它们可以分为三类：转换（*map*）元素、选择（*filter*）元素或修改一般的 Stream
    行为。
- en: Tip
  id: totrans-168
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 提示
- en: All Stream operations are aptly named and have ample [documentation](https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/util/stream/Stream.xhtml)
    and examples. Many methods use the “not-yet a standard” addition to JavaDoc^([3](ch06.xhtml#idm45115238384128))
    `@implSpec` to refer to implementation-specific behavior. So make sure to check
    out either the online documentation or the JavaDoc itself in case of your IDE
    isn’t rendering all of the documentation correctly.
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 所有 `Stream` 操作都有合适的命名，并且有充分的 [文档](https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/util/stream/Stream.xhtml)
    和示例。许多方法使用“尚未成为标准”的 JavaDoc^([3](ch06.xhtml#idm45115238384128)) `@implSpec` 来引用特定于实现的行为。因此，请确保在您的
    IDE 无法正确呈现所有文档时，查看在线文档或 JavaDoc 本身。
- en: In this section, I will be using a simple `Shape` Record, shown in [Example 6-6](#_01-streams_operations_shape),
    to demonstrate the different operations.
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我将使用一个简单的 `Shape` 记录，如 [示例 6-6](#_01-streams_operations_shape) 所示，来演示不同的操作。
- en: Example 6-6\. A simple Shape type
  id: totrans-171
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 6-6\. 一个简单的 Shape 类型
- en: '[PRE6]'
  id: totrans-172
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: There won’t be a dedicated code example for every operation, as there are just
    too many. However, each operation and its element flow is illustrated.
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 并不会为每个操作提供专门的代码示例，因为实在太多了。不过，每个操作及其元素流都有详细说明。
- en: Selecting Elements
  id: totrans-174
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 选择元素
- en: The first common task of data processing is selecting the correct elements,
    either by filtering with a `Predicate` or by choosing based on the number of elements.
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 数据处理的第一个常见任务是选择正确的元素，可以通过 `Predicate` 进行过滤，也可以根据元素的数量进行选择。
- en: '`Stream<T> filter(Predicate<? super T> predicate)`'
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: '`Stream<T> filter(Predicate<? super T> predicate)`'
- en: The most straightforward way of filtering elements. If the `Predicate` evaluates
    to `true`, the element is considered for further processing. The `static` method
    `Predicate<T>.not(Predicate<T>)` allows for an easy negation of a Predicate without
    losing the advantage of method references. Common tasks, like `null` checks, are
    available via the `java.util.Objects` class and are usable as method references.
    See [Figure 6-7](#_02-data-processing_intermediate-ops_filter).
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 过滤元素的最简单方法。如果 `Predicate` 评估为 `true`，则将元素视为进一步处理的候选。静态方法 `Predicate<T>.not(Predicate<T>)`
    允许轻松地否定一个 Predicate，而不会失去方法引用的优势。常见任务，如 `null` 检查，可通过 `java.util.Objects` 类作为方法引用使用。参见
    [图 6-7](#_02-data-processing_intermediate-ops_filter)。
- en: '![Stream<T> filter(Predicate<? super T> predicate)](assets/afaj_0607.png)'
  id: totrans-178
  prefs: []
  type: TYPE_IMG
  zh: '![Stream<T> filter(Predicate<? super T> predicate)](assets/afaj_0607.png)'
- en: Figure 6-7\. `Stream<T> filter(Predicate<? super T> predicate)`
  id: totrans-179
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 6-7\. `Stream<T> filter(Predicate<? super T> predicate)`
- en: '`Stream<T> dropWhile(Predicate<? super T> predicate)`'
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: '`Stream<T> dropWhile(Predicate<? super T> predicate)`'
- en: Discards — or *drops* — any element passing through the operation as long as
    the `Predicate` evaluates to `true`. This operation is designed for `ORDERED`
    Streams. The dropped elements won’t be deterministic if the Stream isn’t `ORDERED`.
    For sequential Streams, dropping elements is a cheap operation. A parallel Stream,
    though, has to coordinate between the underlying threads, making the operation
    quite costly. The operation was introduced with Java 9. See [Figure 6-8](#_02-data-processing_intermediate-ops_dropWhile).
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 丢弃 — 或者*跳过* — 通过操作的任何元素，只要`Predicate`评估为`true`。该操作设计用于有序流。如果流不是有序的，则放弃的元素不是确定性的。对于顺序流，跳过元素是一种廉价的操作。然而，对于并行流，必须在底层线程之间协调，使得该操作非常昂贵。该操作在Java
    9中引入。参见[图 6-8](#_02-data-processing_intermediate-ops_dropWhile)。
- en: '![Stream<T> dropWhile(Predicate<? super T> predicate)](assets/afaj_0608.png)'
  id: totrans-182
  prefs: []
  type: TYPE_IMG
  zh: '![Stream<T> dropWhile(Predicate<? super T> predicate)](assets/afaj_0608.png)'
- en: Figure 6-8\. `Stream<T> dropWhile(Predicate<? super T> predicate)`
  id: totrans-183
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 6-8\. `Stream<T> dropWhile(Predicate<? super T> predicate)`
- en: '`Stream<T> takeWhile(Predicate<? super T> predicate)`'
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: '`Stream<T> takeWhile(Predicate<? super T> predicate)`'
- en: The antagonist to `dropWhile`, choosing elements until the `Predicate` evaluates
    to `false`. The operation was introduced with Java 9. See [Figure 6-9](#_02-data-processing_intermediate-ops_takeWhile).
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 与`dropWhile`相对，选择元素直到`Predicate`评估为`false`。该操作在Java 9中引入。参见[图 6-9](#_02-data-processing_intermediate-ops_takeWhile)。
- en: '![Stream<T> takeWhile(Predicate<? super T> predicate)](assets/afaj_0609.png)'
  id: totrans-186
  prefs: []
  type: TYPE_IMG
  zh: '![Stream<T> takeWhile(Predicate<? super T> predicate)](assets/afaj_0609.png)'
- en: Figure 6-9\. `Stream<T> takeWhile(Predicate<? super T> predicate)`
  id: totrans-187
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 6-9\. `Stream<T> takeWhile(Predicate<? super T> predicate)`
- en: '`Stream<T> limit(long maxSize)`'
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: '`Stream<T> limit(long maxSize)`'
- en: Limits the maximum amount of elements passing through this operation to `maxSize`.
    See [Figure 6-10](#_02-data-processing_intermediate-ops_limit).
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 将通过该操作的最大元素数量限制为`maxSize`。参见[图 6-10](#_02-data-processing_intermediate-ops_limit)。
- en: '![Stream<T> limit(long maxSize)](assets/afaj_0610.png)'
  id: totrans-190
  prefs: []
  type: TYPE_IMG
  zh: '![Stream<T> limit(long maxSize)](assets/afaj_0610.png)'
- en: Figure 6-10\. `Stream<T> limit(long maxSize)`
  id: totrans-191
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 6-10\. `Stream<T> limit(long maxSize)`
- en: '`Stream<T> skip(long n)`'
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: '`Stream<T> skip(long n)`'
- en: The antagonist to `limit`, skipping `n` elements before passing all remaining
    elements to the subsequent Stream operations. See [Figure 6-11](#_02-data-processing_intermediate-ops_skip).
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: '`limit`的对立面，跳过`n`个元素，然后将所有剩余元素传递给后续的流操作。参见[图 6-11](#_02-data-processing_intermediate-ops_skip)。'
- en: '![Stream<T> skip(long n)](assets/afaj_0611.png)'
  id: totrans-194
  prefs: []
  type: TYPE_IMG
  zh: '![Stream<T> skip(long n)](assets/afaj_0611.png)'
- en: Figure 6-11\. `Stream<T> skip(long n)`
  id: totrans-195
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 6-11\. `Stream<T> skip(long n)`
- en: '`Stream<T> distinct()`'
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: '`Stream<T> distinct()`'
- en: Compares elements with `Object#equals(Object)` to return only distinct elements.
    This operation needs to buffer all elements passing through to compare them. There’s
    no integrated way to provide a custom `Comparator<T>` to determine distinctness.
    See [Figure 6-12](#_02-data-processing_intermediate-ops_distinct).
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 通过`Object#equals(Object)`比较元素以返回唯一的元素。该操作需要缓冲通过的所有元素来进行比较。没有集成的方法来提供自定义的`Comparator<T>`来确定唯一性。参见[图 6-12](#_02-data-processing_intermediate-ops_distinct)。
- en: '![Stream<T> distinct()](assets/afaj_0612.png)'
  id: totrans-198
  prefs: []
  type: TYPE_IMG
  zh: '![Stream<T> distinct()](assets/afaj_0612.png)'
- en: Figure 6-12\. `Stream<T> distinct()`
  id: totrans-199
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 6-12\. `Stream<T> distinct()`
- en: '`Stream<T> sorted()`'
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: '`Stream<T> sorted()`'
- en: Sorts the elements in their natural order if they conform to `java.util.Comparable`.
    Otherwise, a `java.lang.ClassCastException` is thrown on Stream consumption. [Figure 6-13](#_02-data-processing_intermediate-ops_sorted)
    assumes the natural sorting for shapes is by their number of corners. This operation
    needs to buffer all elements passing through to sort them. See [Figure 6-13](#_02-data-processing_intermediate-ops_sorted).
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 如果符合`java.util.Comparable`，则按照其自然顺序对元素进行排序。否则，在流消耗时将抛出`java.lang.ClassCastException`。[图 6-13](#_02-data-processing_intermediate-ops_sorted)
    假设按照形状的角数进行自然排序。该操作需要缓冲通过的所有元素来进行排序。参见[图 6-13](#_02-data-processing_intermediate-ops_sorted)。
- en: '![Stream<T> sorted()](assets/afaj_0613.png)'
  id: totrans-202
  prefs: []
  type: TYPE_IMG
  zh: '![Stream<T> sorted()](assets/afaj_0613.png)'
- en: Figure 6-13\. `Stream<T> sorted()`
  id: totrans-203
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 6-9\. `Stream<T> takeWhile(Predicate<? super T> predicate)`
- en: '`Stream<T> sorted(Comparator<? super T> comparator)`'
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: '`Stream<T> sorted(Comparator<? super T> comparator)`'
- en: A more flexible version of `sorted` where you can provide a custom `comparator`.
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 更灵活的版本的`sorted`，您可以提供一个自定义的`comparator`。
- en: Mapping Elements
  id: totrans-206
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 映射元素
- en: Another significant category of operation is *mapping* — or transforming — elements.
    Not many Streams and their elements start out in the desired form. Sometimes you
    need a different representation or are only interested in a subset of an element’s
    properties.
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个重要的操作类别是*映射*——或转换——元素。并不是所有Streams及其元素都以所需的形式开始。有时你需要不同的表示形式，或者仅对元素属性的一个子集感兴趣。
- en: 'Initially, only two mapping operations were available to Streams:'
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 起初，Streams只有两种映射操作：
- en: '`Stream<R> map(Function<? super T, ? extends R> mapper)`'
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: '`Stream<R> map(Function<? super T, ? extends R> mapper)`'
- en: The `mapper` function is applied to the elements, and the new element is returned
    down the Stream. See [Figure 6-14](#_02-data-processing_intermediate-ops_map).
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 将`mapper`函数应用于元素，并将新元素返回到流中。参见[图 6-14](#_02-data-processing_intermediate-ops_map)。
- en: '![Stream<R> map(Function<? super T, ? extends R> mapper)](assets/afaj_0614.png)'
  id: totrans-211
  prefs: []
  type: TYPE_IMG
  zh: '![Stream<R> map(Function<? super T, ? extends R> mapper)](assets/afaj_0614.png)'
- en: Figure 6-14\. `Stream<R> map(Function<? super T, ? extends R> mapper)`
  id: totrans-212
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图6-14. `Stream<R> map(Function<? super T, ? extends R> mapper)`
- en: '`Stream<R> flatMap(Function<? super T, ? extends Stream<? extends R>> mapper)`'
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: '`Stream<R> flatMap(Function<? super T, ? extends Stream<? extends R>> mapper)`'
- en: The `mapper` function is still applied to the elements. However, instead of
    returning a new element, a `Stream<R>` needs to be returned. If `map` were used,
    the result would be a nested `Stream<Stream<R>>`, which is most likely not what
    you want. The `flatMap` operation “flattens” a container-like element, like a
    collection or Optional, into a new Stream of multiple elements which are used
    in subsequent operations. See [Figure 6-15](#_02-data-processing_intermediate-ops_flatMap).
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: '`mapper`函数仍然应用于元素。然而，除了返回一个新元素，必须返回一个`Stream<R>`。如果使用`map`，结果将是一个嵌套的`Stream<Stream<R>>`，这很可能不是你想要的。`flatMap`操作“扁平化”一个类似容器的元素，如集合或Optional，转换成一个新的Stream，包含多个元素，这些元素在后续操作中使用。参见[图6-15](#_02-data-processing_intermediate_ops_flatMap)。'
- en: '![Stream<R> flatMap(Function<? super T, ? extends Stream<? extends R>> mapper)](assets/afaj_0615.png)'
  id: totrans-215
  prefs: []
  type: TYPE_IMG
  zh: '![Stream<R> flatMap(Function<? super T, ? extends Stream<? extends R>> mapper)](assets/afaj_0615.png)'
- en: Figure 6-15\. `Stream<R> flatMap(Function<? super T, ? extends Stream<? extends
    R>> mapper)`
  id: totrans-216
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图6-15. `Stream<R> flatMap(Function<? super T, ? extends Stream<? extends R>>
    mapper)`
- en: 'Java 16 introduced an additional mapping method (and its three primitive counterparts)
    that has a similar role as `flatMap`:'
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: Java 16引入了一个额外的映射方法（及其三个基本类型的对应方法），其作用与`flatMap`类似：
- en: '`Stream<R> mapMulti(BiConsumer<? super T, ? super Consumer<R>> mapper)`'
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: '`Stream<R> mapMulti(BiConsumer<? super T, ? super Consumer<R>> mapper)`'
- en: The `mapMulti` operation doesn’t require the mapper to return a Stream instance.
    Instead, a `Consumer<R>` conveys the elements further down the Stream.
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: '`mapMulti`操作不要求mapper返回一个Stream实例。相反，一个`Consumer<R>`会将元素进一步传递到流中。'
- en: In its current form, the `Shape` type doesn’t lead to cleaner code when the
    `mapMulti` operation is used, as seen in [Example 6-7](#_02-data-processing_flatmap-vs-mapMulti).
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 在当前形式下，使用`mapMulti`操作的`Shape`类型不会导致更干净的代码，如[示例6-7](#_02-data-processing_flatmap-vs-mapMulti)所示。
- en: Example 6-7\. Shape `flatMap` versus `mapMulti`
  id: totrans-221
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例6-7. `flatMap`与`mapMulti`的比较
- en: '[PRE7]'
  id: totrans-222
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: The winner in terms of conciseness and readability is clearly `flatMap`. Still,
    the main advantage of `multiMap` is that it condenses two operations, `map` and
    `flatMap`, into a single one.
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: 在简洁性和可读性方面，`flatMap`显然是胜出者。尽管如此，`multiMap`的主要优势在于它将两个操作`map`和`flatMap`合并为一个操作。
- en: The default implementation of `mapMulti` actually uses `flatMap` to create a
    new Stream for you, so your mapped elements don’t need to know how to create a
    Stream themselves. By calling the downstream `Consumer` yourself, *you* decide
    which mapped elements belong to the new Stream, and the pipeline is responsible
    for creating it.
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: '`mapMulti`的默认实现实际上使用`flatMap`来为你创建一个新的Stream，因此你的映射元素不需要知道如何自己创建Stream。通过自己调用下游的`Consumer`，*你*决定哪些映射元素属于新的Stream，管道负责创建它。'
- en: 'The `mapMulti` operations aren’t supposed to replace `flatMap` operations.
    They are merely a complementary addition to Stream’s repertoire of operations.
    There are use-cases where `mapMulti` is preferable to `flatMap`, though:'
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: '`mapMulti`操作并不是为了替代`flatMap`操作。它们只是Stream操作集合中的一个补充。虽然有些情况下`mapMulti`比`flatMap`更为合适：'
- en: Only a small number of elements, or even zero, are mapped down the Stream pipeline.
    Using `mapMulti` avoids the overhead of creating a new Stream for every group
    of mapped elements, as done by `flatMap`.
  id: totrans-226
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 只有很少数的元素，甚至是零，才会在Stream管道中映射。使用`mapMulti`避免了为每组映射元素创建新Stream的开销，这正是`flatMap`所做的。
- en: When an iterative approach to providing the mapped results is more straightforward
    than creating a new Stream instance. This gives you more freedom for the mapping
    process before feeding an element to the `Consumer`.
  id: totrans-227
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当迭代方法提供映射结果比创建新的流实例更简单时。这使得在将元素提供给`Consumer`之前，你可以更自由地进行映射处理。
- en: Peeking into a Stream
  id: totrans-228
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 查看流
- en: 'One intermediate operation doesn’t fit into the *map/filter/reduce* philosophy:
    `peek`.'
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: 一个中间操作不符合*map/filter/reduce*的理念：`peek`。
- en: The conciseness of Streams can pack a lot of functionality into a singular fluent
    call. Even though that’s one of their main selling points, debugging them is way
    more challenging than traditional imperative loop constructs. To ease this pain
    point, the Stream API includes a particular operation, `peek(Consumer<? super
    T> action)`, to, well, “peek” into the Stream without interfering with the elements,
    as seen in [Example 6-8](#_02-data-processing_peek)
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: 流的简洁性可以将大量功能打包到一个单一的流畅调用中。尽管这是它们的主要卖点之一，但调试它们比传统的命令式循环结构要困难得多。为了减轻这一痛点，流API包括一个特定的操作，`peek(Consumer<?
    super T> action)`，用于在不干预元素的情况下“窥视”流，如[示例 6-8](#_02-data-processing_peek)所示。
- en: Example 6-8\. Peeking into a Stream
  id: totrans-231
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 6-8。查看流
- en: '[PRE8]'
  id: totrans-232
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: The `peek` operation is mainly intended to support debugging. It might get skipped
    for optimizing the Stream if the operation isn’t necessarily required for the
    final result, like counting elements, and the pipeline can get short-circuited.
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: '`peek`操作主要用于支持调试。如果操作对最终结果并非必需，比如计算元素数量，并且流程可以被快速终止，那么它可能会被省略以优化流。'
- en: The short-circuiting of operations will be explained more in [“The Cost of Operations”](#_02-data-processing_order-matters).
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: 关于操作的短路将在[“操作的成本”](#_02-data-processing_order-matters)中更详细地解释。
- en: Terminating the Stream
  id: totrans-235
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 终止流
- en: A *terminal* operation is the final step of a Stream pipeline that initiates
    the actual processing of the elements to produce a result or side effect. Unlike
    intermediate operations and their delayed nature, terminal operations evaluate
    eagerly.
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: '*终端*操作是流管道的最后一步，它启动实际处理元素以产生结果或副作用。与中间操作及其延迟性不同，终端操作急切地进行评估。'
- en: 'The available terminal operations fall into four different groups:'
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: 可用的终端操作分为四组不同的类型：
- en: Reductions
  id: totrans-238
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 缩减
- en: Aggregations
  id: totrans-239
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 聚合
- en: Finding and matching
  id: totrans-240
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 查找和匹配
- en: Consuming
  id: totrans-241
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 消耗
- en: Reducing Elements
  id: totrans-242
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 缩减元素
- en: '*Reduction operations*, also known as *fold* operations, reduce the Stream’s
    elements to a single result by repeatedly applying an *accumulator* operator.
    Such an operator uses the previous result to combine it with the current element
    to generate a new result, as shown in [Figure 6-16](#_02-data-processing_intermediate-ops_reduce).
    The *accumulator* is supposed to always return a new value without requiring an
    intermediate data structure.'
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: '*缩减操作*，也称为*折叠*操作，通过重复应用*累加器*运算符将流的元素减少到单个结果。这样的运算符使用前一个结果与当前元素组合，生成新结果，如[图 6-16](#_02-data-processing_intermediate-ops_reduce)所示。*累加器*应该总是返回一个新值，而不需要中间数据结构。'
- en: '![Reducing shapes by combining them next to each other](assets/afaj_0616.png)'
  id: totrans-244
  prefs: []
  type: TYPE_IMG
  zh: '![通过将形状相邻组合来减少形状](assets/afaj_0616.png)'
- en: Figure 6-16\. Reducing shapes by combining them next to each other
  id: totrans-245
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 6-16。通过将形状相邻组合来减少形状
- en: Like many functional tools, reductions often feel alien at first due to their
    nomenclature, especially if you come from an imperative background. The simplest
    way to better understand the general concept behind such tools is by looking at
    the involved parts and how they would work in a more familiar form.
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: 像许多函数工具一样，初学者经常对缩减操作感到陌生，特别是如果你来自命令式编程背景。更好地理解这类工具背后的一般概念的最简单方法是查看涉及的部分以及它们在更熟悉的形式中如何工作。
- en: 'In the case of reduction, there are three parts involved:'
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: 在缩减的情况下，涉及三个部分：
- en: The elements
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: 元素
- en: Data processing is, well, about processing data elements. The familiar equivalent
    to a Stream would be any collection type.
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: 数据处理就是处理数据元素。流的熟悉等价物将是任何集合类型。
- en: The initial value
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: 初始值
- en: The accumulation of data has to start somewhere. Sometimes this initial value
    is explicit, but certain reduction variants omit it by replacing it with the first
    element or allowing for an optional result if no element is present.
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: 数据的累积必须从某处开始。有时这个初始值是显式的，但某些缩减变体会通过用第一个元素替换它或者允许在没有元素的情况下得到一个可选结果来省略它。
- en: The accumulator function
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: 累加器函数
- en: The reduction logic solely works with the current element and the previous result
    or initial value. Depending only on its input to create a new value makes this
    a pure function.
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: 减少逻辑仅仅与当前元素和前一个结果或初始值一起工作。仅仅依靠其输入来创建新值使其成为一个纯函数。
- en: Take finding the biggest value of a `Collection<Integer>` for an example. You
    have to go through each element and compare it with the next one, returning the
    greater number at each step, as shown in [Example 6-9](#_02-data-processing_terminal-ops_reduce-for-loop-specific).
    All three parts of a reduction are represented.
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: 以查找`Collection<Integer>`中的最大值为例。您必须遍历每个元素，并将其与下一个元素进行比较，在每个步骤返回较大的数字，如[示例 6-9](#_02-data-processing_terminal-ops_reduce-for-loop-specific)所示。减少的所有三个部分都有所体现。
- en: Example 6-9\. Finding the biggest number in a `Collection<Integer>`
  id: totrans-255
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 6-9\. 在`Collection<Integer>`中找到最大数
- en: '[PRE9]'
  id: totrans-256
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: '[![1](assets/1.png)](#co_data_processing_with_streams_CO3-1)'
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: '[![1](assets/1.png)](#co_data_processing_with_streams_CO3-1)'
- en: The initial value depends on the required task. In this case, comparing against
    the smallest possible `int` value is the logical choice to find the greatest number.
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: 初始值取决于所需的任务。在这种情况下，与最小可能的`int`值进行比较是找到最大数的合理选择。
- en: '[![2](assets/2.png)](#co_data_processing_with_streams_CO3-2)'
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: '[![2](assets/2.png)](#co_data_processing_with_streams_CO3-2)'
- en: The reduction logic has to be applied to each element.
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: 减少逻辑必须应用于每个元素。
- en: '[![3](assets/3.png)](#co_data_processing_with_streams_CO3-3)'
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: '[![3](assets/3.png)](#co_data_processing_with_streams_CO3-3)'
- en: The actual reduction logic, representing the accumulator function.
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: 实际的减少逻辑，代表累加器函数。
- en: '[![4](assets/4.png)](#co_data_processing_with_streams_CO3-4)'
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: '[![4](assets/4.png)](#co_data_processing_with_streams_CO3-4)'
- en: The reduced value.
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
  zh: 减少的值。
- en: To better reflect a reduction operation in general, the previous example allows
    you to derive a generic reduction operation as shown in [Example 6-10](#_02-data-processing_terminal-ops_reduce-for-loop).
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
  zh: 为了更好地反映一般的减少操作，前面的示例允许你像在[示例 6-10](#_02-data-processing_terminal-ops_reduce-for-loop)中展示的那样推导出通用的减少操作。
- en: Example 6-10\. Reduce-like `for`-loop
  id: totrans-266
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 6-10\. 类似`for`循环的`reduce`
- en: '[PRE10]'
  id: totrans-267
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'The generic variant again highlights that a functional approach separates *how*
    a task is done from *what* the task is actually doing. This way, the previous
    example of finding the maximum value can be simplified to a single method call
    by using the generic variant:'
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
  zh: 通用变体再次强调了功能方法将任务的*执行方式*与任务*实际执行的内容*分离开来。通过使用通用变体，前面找到最大值的示例可以简化为单个方法调用：
- en: '[PRE11]'
  id: totrans-269
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'The `max` method is also an example of why the Stream API provides more than
    just a `reduce` method: specialization to cover common use cases.'
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
  zh: '`max`方法也是为什么流API提供的不仅仅是`reduce`方法的示例：专门用于覆盖常见用例。'
- en: Even though all the specialized Stream operations can be implemented with one
    of the three available `reduce` methods — some of them actually are --⁠, the specialized
    variants create a more expressive fluent Stream call for typical reduction operations.
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管所有特殊化的流操作都可以用三种可用的`reduce`方法之一来实现 — 实际上有些是这样的 --⁠，但特殊化的变体为典型的减少操作创建了更具表现力的流畅流调用。
- en: 'The Stream API has three different explicit `reduce` operations:'
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
  zh: 流API有三种不同的显式`reduce`操作：
- en: '`T reduce(T identity, BinaryOperator<T> accumulator)`'
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
  zh: '`T reduce(T identity, BinaryOperator<T> accumulator)`'
- en: The `identity` is the seed — initial — value for the chain of `accumulator`
    operations. Although it’s equivalent to [Example 6-10](#_02-data-processing_terminal-ops_reduce-for-loop),
    it’s not constrained by the sequential nature of a `for`-loop.
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
  zh: '`identity`是链式`accumulator`操作的种子 — 初始 — 值。虽然它等同于[示例 6-10](#_02-data-processing_terminal-ops_reduce-for-loop)，但它不受`for`循环顺序性的约束。'
- en: '`Optional<T> reduce(BinaryOperator<T> accumulator)`'
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
  zh: '`Optional<T> reduce(BinaryOperator<T> accumulator)`'
- en: Instead of requiring a seed value, this operation picks the first encountered
    element as its initial value. That’s why it returns an `Optional<T>`, which you
    will learn more about in [Chapter 9](ch09.xhtml#_02-optionals). An empty `Optional<T>`
    is returned if the Stream doesn’t contain any elements.
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
  zh: 这个操作不需要一个种子值，它会选择第一个遇到的元素作为初始值。这就是为什么它返回一个`Optional<T>`，你将在[第9章](ch09.xhtml#_02-optionals)学到更多关于它的内容。如果流不包含任何元素，它会返回一个空的`Optional<T>`。
- en: '`U reduce(U identity, BiFunction<U, ? super T, U> accumulator, BinaryOperator<U>
    combiner)`'
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
  zh: '`U reduce(U identity, BiFunction<U, ? super T, U> accumulator, BinaryOperator<U>
    combiner)`'
- en: This variant combines a `map` and `reduce` operation, which is required if the
    Stream contains elements of type `T`, but the desired reduced result is of type
    `U`. Alternatively, you can use an explicit `map` and `reduce` operation separately.
    Such a Stream pipeline might be more straightforward than using the combined `reduce`
    operations, as seen in [Example 6-11](#_02-data-processing_terminal-ops_reduce-map-reduce)
    for summing up all characters in a `Stream<String>`.
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
  zh: 如果流包含类型为`T`的元素，但所需的归约结果是类型为`U`的，那么这种变体结合了`map`和`reduce`操作是必需的。或者，您可以分别使用显式的`map`和`reduce`操作。这样的流管道可能比使用组合的`reduce`操作更直观，就像在[示例 6-11](#_02-data-processing_terminal-ops_reduce-map-reduce)中看到的那样，用于对`Stream<String>`中的所有字符求和。
- en: Example 6-11\. Three-arguments `reduce` operation versus `map` + two-arguments
    `reduce`
  id: totrans-279
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 6-11\. 三参数的`reduce`操作与`map` + 两参数的`reduce`操作
- en: '[PRE12]'
  id: totrans-280
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: Which to choose — a single `reduce` or separate `map` and `reduce` — depends
    on your preferences and if the lambda expressions can be generalized or refactored,
    so you could use method references instead.
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
  zh: 选择哪种方式 — 单个`reduce`还是分开的`map`和`reduce` — 取决于您的偏好以及lambda表达式是否可以被泛化或重构，因此您可以使用方法引用替代。
- en: As mentioned before, some typical reduction tasks are available as specialized
    operations, including any variants for primitive Streams, as listed in [Table 6-3](#_02-data-processing_terminal-typical-operations).
    The listed methods belong to `IntStream` but are also available for `LongStream`
    and `DoubleStream` with their related types.
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
  zh: 正如前面提到的，一些典型的归约任务作为专门的操作是可用的，包括原始流的任何变体，如[表 6-3](#_02-data-processing_terminal-typical-operations)中列出的。列出的方法属于`IntStream`，但也适用于`LongStream`和`DoubleStream`及其相关类型。
- en: Table 6-3\. Typical reduction operations
  id: totrans-283
  prefs: []
  type: TYPE_NORMAL
  zh: 表 6-3\. 典型的归约操作
- en: '| Method | Description |'
  id: totrans-284
  prefs: []
  type: TYPE_TB
  zh: '| 方法 | 描述 |'
- en: '| --- | --- |'
  id: totrans-285
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| Stream<T> |'
  id: totrans-286
  prefs: []
  type: TYPE_TB
  zh: '| Stream<T> |'
- en: '| `Optional<T> min(Comparator<? super T> comparator) Optional<T> max(Comparator<?
    super T> comparator)` | Returns the minimum/maximum element of the Stream according
    to the provided `comparator`. An empty `Optional<T>` is returned if no elements
    reach the operation. |'
  id: totrans-287
  prefs: []
  type: TYPE_TB
  zh: '| `Optional<T> min(Comparator<? super T> comparator) Optional<T> max(Comparator<?
    super T> comparator)` | 根据提供的`comparator`返回流中的最小/最大元素。如果没有元素达到操作，则返回一个空的`Optional<T>`。
    |'
- en: '| `long count()` | Returns the element count present at the end of the Stream
    pipeline. Be aware that certain Stream implementations may choose *not* to execute
    all intermediate operations if the count is determinable from the Stream itself,
    e.g., its characteristics contain `SIZED`, and no filtering is going on in the
    pipeline. |'
  id: totrans-288
  prefs: []
  type: TYPE_TB
  zh: '| `long count()` | 返回流管道末端的元素计数。请注意，如果流的特性包含`SIZED`并且管道中没有过滤操作，则某些流实现可以选择*不*执行所有中间操作。
    |'
- en: '| Primitive Streams |'
  id: totrans-289
  prefs: []
  type: TYPE_TB
  zh: '| 原始流 |'
- en: '| `int sum()` | Sums up the elements of the Stream. |'
  id: totrans-290
  prefs: []
  type: TYPE_TB
  zh: '| `int sum()` | 求和流的元素。 |'
- en: '| `OptionalDouble average()` | Calculates the arithmetic mean of the Stream
    elements. If the Stream contains no elements at the point of the terminal operation,
    an empty `OptionalDouble` is returned. |'
  id: totrans-291
  prefs: []
  type: TYPE_TB
  zh: '| `OptionalDouble average()` | 计算流元素的算术平均值。如果在终端操作时流不包含任何元素，则返回一个空的`OptionalDouble`。
    |'
- en: '| `IntSummaryStatistics summaryStatistics()` | Returns a summary of the Stream
    elements, containing the *count*, *sum*, *min*, and *max* of the Stream elements.
    |'
  id: totrans-292
  prefs: []
  type: TYPE_TB
  zh: '| `IntSummaryStatistics summaryStatistics()` | 返回包含流元素的*计数*、*总和*、*最小值*和*最大值*的摘要信息。
    |'
- en: 'Even after migrating your code towards a more functional approach, reduction
    operations might not be your go-to operations for terminating a Stream. That’s
    because there’s another type of reduction operation available that feels more
    common to the ways you’re used to: *aggregation operations*.'
  id: totrans-293
  prefs: []
  type: TYPE_NORMAL
  zh: 即使在将代码迁移到更功能化的方法后，归约操作可能并不是终止流的首选操作。这是因为还有另一种类型的归约操作可用，这种操作在您习惯的方式中更常见：*聚合操作*。
- en: Aggregating Elements with Collectors
  id: totrans-294
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 使用收集器聚合元素
- en: A ubiquitous step for every data processing task, be it Streams or an imperative
    approach with loops, is aggregating the resulting elements into a new data structure.
    Most commonly, you want the resulting elements in a new `List`, a unique `Set`,
    or some form of `Map`.
  id: totrans-295
  prefs: []
  type: TYPE_NORMAL
  zh: 对于每一个数据处理任务，无论是使用流还是使用循环的命令式方法，一个普遍的步骤是将结果元素聚合到一个新的数据结构中。最常见的情况是，您希望结果元素在一个新的`List`、一个唯一的`Set`或某种形式的`Map`中。
- en: Reducing the elements to a new value, in this case, a collection-like type,
    fits the bill of a reduction operation from the previous section, as shown in
    [Example 6-12](#_02-data-processing_aggregation-reduce).
  id: totrans-296
  prefs: []
  type: TYPE_NORMAL
  zh: 将元素归约到一个新值，例如集合类型，在前一节中显示的归约操作中符合要求，如 [示例 6-12](#_02-data-processing_aggregation-reduce)
    所示。
- en: Example 6-12\. Aggregate elements with a `reduce` operation
  id: totrans-297
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 6-12\. 使用 `reduce` 操作聚合元素
- en: '[PRE13]'
  id: totrans-298
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: '[![1](assets/1.png)](#co_data_processing_with_streams_CO4-1)'
  id: totrans-299
  prefs: []
  type: TYPE_NORMAL
  zh: '[![1](assets/1.png)](#co_data_processing_with_streams_CO4-1)'
- en: The three-argument `reduce` operation is used because the resulting type isn’t
    the same type as the Stream elements.
  id: totrans-300
  prefs: []
  type: TYPE_NORMAL
  zh: 使用三参数 `reduce` 操作是因为结果类型与流元素类型不同。
- en: '[![2](assets/2.png)](#co_data_processing_with_streams_CO4-2)'
  id: totrans-301
  prefs: []
  type: TYPE_NORMAL
  zh: '[![2](assets/2.png)](#co_data_processing_with_streams_CO4-2)'
- en: Reduce operations are supposed to return new values, so instead of using a shared
    `ArrayList` to aggregate the elements, a new `ArrayList` is created for each accumulation
    step.
  id: totrans-302
  prefs: []
  type: TYPE_NORMAL
  zh: 归约操作应返回新值，因此在聚合元素时不使用共享的 `ArrayList`，而是为每个累积步骤创建一个新的 `ArrayList`。
- en: '[![3](assets/3.png)](#co_data_processing_with_streams_CO4-3)'
  id: totrans-303
  prefs: []
  type: TYPE_NORMAL
  zh: '[![3](assets/3.png)](#co_data_processing_with_streams_CO4-3)'
- en: The combiner merges multiple `ArrayList` instances by creating a new one in
    the case of parallel processing.
  id: totrans-304
  prefs: []
  type: TYPE_NORMAL
  zh: 组合器通过在并行处理情况下创建新的 `ArrayList` 实例来合并多个 `ArrayList` 实例。
- en: That’s quite a lot of verbose code to reduce Stream down to a simple `List`,
    with new instances of `ArrayList` created for each element, plus additional `ArrayList`
    instances if run in parallel!
  id: totrans-305
  prefs: []
  type: TYPE_NORMAL
  zh: 这相当于将 Stream 缩减为一个简单的 `List` 的冗长代码，每个元素都创建一个新的 `ArrayList` 实例，如果并行运行，则还会创建额外的
    `ArrayList` 实例！
- en: 'Of course, you could *cheat* and reuse the `ArrayList acc` variable in the
    aggregator function instead of creating and returning a new one. However, that
    would go against the general concept of `reduce` of being an *immutable* reduction
    operation. That’s why there’s a better solution available: *aggregation operations*.'
  id: totrans-306
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，你可以在聚合器函数中重复使用 `ArrayList acc` 变量，而不是创建并返回新的变量。然而，这与 `reduce` 的一般概念相违背，即不可变归约操作。这就是为什么有更好的解决方案可用：*聚合操作*。
- en: Note
  id: totrans-307
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注
- en: Even though I call them “aggregation operations” throughout the chapter, technically,
    they’re known as “mutable reduction operations” to differentiate them from reduction
    operations known as “immutable reduction operations.”
  id: totrans-308
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然在本章节中我称它们为“聚合操作”，但从技术上讲，它们被称为“可变归约操作”，以区别于被称为“不可变归约操作”的归约操作。
- en: The `Stream<T>` type’s terminal operation `collect` accepts a Collector to aggregate
    elements. Instead of reducing elements by combining Stream elements to a single
    result by repeatedly applying an *accumulator* operator, these operations use
    a *mutable results container* as an intermediate data structure, as seen in [Figure 6-17](#_02-data-processing_aggregation_collect-figure).
  id: totrans-309
  prefs: []
  type: TYPE_NORMAL
  zh: '`Stream<T>` 类型的终端操作 `collect` 接受一个 Collector 来聚合元素。这些操作不是通过重复应用累加器运算符将流元素组合到单一结果中来减少元素，而是使用一个可变结果容器作为中间数据结构，如
    [图 6-17](#_02-data-processing_aggregation_collect-figure) 中所示。'
- en: '![Collection Stream elements](assets/afaj_0617.png)'
  id: totrans-310
  prefs: []
  type: TYPE_IMG
  zh: '![收集流元素](assets/afaj_0617.png)'
- en: Figure 6-17\. Collecting Stream elements
  id: totrans-311
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 6-17\. 收集流元素
- en: 'The Stream’s elements are aggregated — or collected — with the help of the
    `java.util.stream.Collector<T, A, R>` type. The interface’s generic types represent
    the different parts involved in the collection process:'
  id: totrans-312
  prefs: []
  type: TYPE_NORMAL
  zh: 利用 `java.util.stream.Collector<T, A, R>` 类型，流的元素被聚合或收集。接口的泛型类型代表了收集过程中涉及的不同部分：
- en: '`T`: The *type* of Stream elements.'
  id: totrans-313
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`T`: 流元素的类型。'
- en: '`A`: The *mutable result container* type.'
  id: totrans-314
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`A`: 可变结果容器类型。'
- en: '`R`: The final *result type* of the collection process which may differ from
    the intermediate container type.'
  id: totrans-315
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`R`: 收集过程的最终结果类型，可能与中间容器类型不同。'
- en: A `Collector` consists of multiple steps that match perfectly to its [interface
    definition](https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/util/stream/Collector.xhtml),
    as seen in [Figure 6-18](#_01-sterams-terminal-collector).
  id: totrans-316
  prefs: []
  type: TYPE_NORMAL
  zh: '`Collector` 由多个步骤组成，与其 [接口定义](https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/util/stream/Collector.xhtml)
    完美匹配，如 [图 6-18](#_01-sterams-terminal-collector) 所示。'
- en: '![Inner workings of a Collector<T,A,R>](assets/afaj_0618.png)'
  id: totrans-317
  prefs: []
  type: TYPE_IMG
  zh: '![Collector<T,A,R> 的内部工作原理](assets/afaj_0618.png)'
- en: Figure 6-18\. Inner workings of a Collector<T, A, R>
  id: totrans-318
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 6-18\. Collector<T, A, R> 的内部工作原理
- en: 'Step 1: `Supplier<A> supplier()`'
  id: totrans-319
  prefs: []
  type: TYPE_NORMAL
  zh: '步骤 1: `Supplier<A> supplier()`'
- en: The `Supplier` returns a new instance of the mutable result container used throughout
    the collection process.
  id: totrans-320
  prefs: []
  type: TYPE_NORMAL
  zh: '`Supplier` 返回在整个收集过程中使用的可变结果容器的新实例。'
- en: 'Step 2: `BiConsumer<A, T> accumulator()`'
  id: totrans-321
  prefs: []
  type: TYPE_NORMAL
  zh: 步骤 2：`BiConsumer<A, T>` 累加器
- en: The core of the `Collector`, as this `BiConsumer` is responsible for accumulating
    the Stream elements of type `T` into the container of type `A` by accepting the
    result container and the current element as its arguments.
  id: totrans-322
  prefs: []
  type: TYPE_NORMAL
  zh: 作为 Collector 的核心，这个 `BiConsumer` 负责通过接受结果容器和当前元素作为其参数，将类型为 `T` 的 Stream 元素累加到类型为
    `A` 的容器中。
- en: 'Step 3: `BinaryOperator<A> combiner()`'
  id: totrans-323
  prefs: []
  type: TYPE_NORMAL
  zh: 步骤 3：`BinaryOperator<A>` 合并器
- en: In the case of parallel Stream processing, where multiple accumulators may do
    their work, the returned combiner `BinaryOperator` merges partial results container
    into a single one.
  id: totrans-324
  prefs: []
  type: TYPE_NORMAL
  zh: 在并行流处理的情况下，多个累加器可能会执行其工作，返回的合并器 `BinaryOperator` 将部分结果容器合并为一个单一的结果容器。
- en: 'Step 4: `Function<A, R> finisher()`'
  id: totrans-325
  prefs: []
  type: TYPE_NORMAL
  zh: 步骤 4：`Function<A, R>` 完成者
- en: The finisher transforms the intermediate result container to the actual return
    object of type `R`. The necessity of this step depends on the implementation of
    the `Collector`.
  id: totrans-326
  prefs: []
  type: TYPE_NORMAL
  zh: 完成者将中间结果容器转换为实际返回类型为 `R` 的对象。这一步骤的必要性取决于 Collector 的实现。
- en: 'Step 5: The final result'
  id: totrans-327
  prefs: []
  type: TYPE_NORMAL
  zh: 步骤 5：最终结果
- en: The collected instance, e.g., a `List`, a `Map`, or even a single value.
  id: totrans-328
  prefs: []
  type: TYPE_NORMAL
  zh: 收集到的实例，例如 `List`、`Map`，甚至是单个值。
- en: The JDK comes with the `java.util.Collectors` utility class, providing a variety
    of Collectors for many use cases. Listing and explaining them all in detail could
    fill another whole chapter. That’s why I only introduce their particular use-case
    groups here. [Chapter 7](ch07.xhtml#_02-streams) will have more examples and details
    about them and how you can create your own Collectors. Also, you should check
    out the [official documentation](https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/util/stream/Collectors.xhtml)
    for more details, including intended use-cases and examples.
  id: totrans-329
  prefs: []
  type: TYPE_NORMAL
  zh: JDK 提供了 `java.util.Collectors` 实用程序类，为许多用例提供了各种 Collectors。列举并详细解释它们可能会填补另一整章的内容。这就是为什么我只在这里介绍它们的特定用例组。[第7章](ch07.xhtml#_02-streams)
    将有更多关于它们的示例和详细信息，以及如何创建自己的 Collectors。此外，您应该查看[官方文档](https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/util/stream/Collectors.xhtml)以获取更多详细信息，包括预期的用例和示例。
- en: Collect into a `java.util.Collection` type
  id: totrans-330
  prefs: []
  type: TYPE_NORMAL
  zh: 收集到 `java.util.Collection` 类型
- en: 'The most used variants, collecting Stream elements into new `Collection` types
    include:'
  id: totrans-331
  prefs: []
  type: TYPE_NORMAL
  zh: 最常用的变体，将 Stream 元素收集到新的 `Collection` 类型中包括：
- en: '`toCollection(Supplier<C> collectionFactory)`'
  id: totrans-332
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`toCollection(Supplier<C> collectionFactory)`'
- en: '`toList()`'
  id: totrans-333
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`toList()`'
- en: '`toSet()`'
  id: totrans-334
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`toSet()`'
- en: '`toUnmodifiableList()` (Java 10+)'
  id: totrans-335
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`toUnmodifiableList()`（Java 10+）'
- en: '`toUnmodifiableSet()` (Java 10+)'
  id: totrans-336
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`toUnmodifiableSet()`（Java 10+）'
- en: The original `toList()` / `toSet()` have no guarantees on the returned collection’s
    underlying type, mutability, serializability, or thread safety. That’s why the
    `Unmodifiable` variants were introduced in Java 10 to close that gap.
  id: totrans-337
  prefs: []
  type: TYPE_NORMAL
  zh: 原始的 `toList()` / `toSet()` 不保证返回集合的基础类型、可变性、可序列化性或线程安全性。这就是为什么 Java 10 中引入了
    `Unmodifiable` 变体来弥补这一缺陷。
- en: Collect into a `java.util.Map` (key-value)
  id: totrans-338
  prefs: []
  type: TYPE_NORMAL
  zh: 收集到 `java.util.Map`（键值）
- en: 'Another frequently used `Collector` task is creating a `Map<K, V>` by mapping
    the key and value from the Stream’s elements. That’s why each variant must have
    at least a key- and value mapper function: Key- and value-mapper functions must
    be provided.'
  id: totrans-339
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个经常使用的 Collector 任务是通过映射键和值从 Stream 的元素创建 `Map<K, V>`。这就是为什么每个变体必须至少有一个键和值的映射函数：必须提供键和值的映射函数。
- en: '`toMap(…​)` (3 variants)'
  id: totrans-340
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`toMap(…​)`（3种变体）'
- en: '`toConcurrentMap(…​)` (3 variants)'
  id: totrans-341
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`toConcurrentMap(…​)`（3种变体）'
- en: '`toUnmodifiableMap(…​)` (2 variants, Java 10+)'
  id: totrans-342
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`toUnmodifiableMap(…​)`（2种变体，Java 10+）'
- en: Like the collection-based Collector methods, the original `toMap()` variants
    do not guarantee the returned Map’s underlying type, mutability, serializability,
    or thread safety. That’s why the `Unmodifiable` variants were introduced in Java
    10 to close that gap. Concurrent variants are also available for a more efficient
    collection of parallel Streams.
  id: totrans-343
  prefs: []
  type: TYPE_NORMAL
  zh: 与基于集合的 Collector 方法类似，原始的 `toMap()` 变体不保证返回的 Map 的基础类型、可变性、可序列化性或线程安全性。这就是为什么
    Java 10 中引入了 `Unmodifiable` 变体来弥补这一缺陷。并发变体也可用于更高效地收集并行流。
- en: Collect into a `java.util.Map` (grouped)
  id: totrans-344
  prefs: []
  type: TYPE_NORMAL
  zh: 收集到 `java.util.Map`（分组）
- en: 'Instead of a simple key-value relationship, the following Collectors group
    the values by a key, usually with a Collection-based type as the value for the
    returned `Map`:'
  id: totrans-345
  prefs: []
  type: TYPE_NORMAL
  zh: 以下 Collector 不是简单的键值关系，而是按键对值进行分组，通常将基于集合的类型用作返回的 `Map` 的值：
- en: '`groupingBy()` (3 variants)'
  id: totrans-346
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`groupingBy()`（3种变体）'
- en: '`groupingByConcurrent()` (3 variants)'
  id: totrans-347
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`groupingByConcurrent()`（3种变体）'
- en: Collect into a `java.util.Map` (partitioned)
  id: totrans-348
  prefs: []
  type: TYPE_NORMAL
  zh: 收集到 `java.util.Map`（分区）
- en: Partitioned maps group their elements based on a provided `Predicate`.
  id: totrans-349
  prefs: []
  type: TYPE_NORMAL
  zh: 分区映射根据提供的`Predicate`对其元素进行分组。
- en: '`partitionBy(…​)` (2 variants)'
  id: totrans-350
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`partitionBy(…​)`（2种变体）'
- en: Arithmetic and comparison operations
  id: totrans-351
  prefs: []
  type: TYPE_NORMAL
  zh: 算术和比较操作
- en: There’s a certain overlap between the reduction operations and Collectors, like
    the arithmetic- and comparison-related Collectors.
  id: totrans-352
  prefs: []
  type: TYPE_NORMAL
  zh: 减少操作和收集器之间存在一定的重叠，如与算术和比较相关的收集器。
- en: '`averagingInt(ToIntFunction<? super T> mapper)`'
  id: totrans-353
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`averagingInt(ToIntFunction<? super T> mapper)`'
- en: '`summingInt(ToIntFunction<? super T> mapper)`'
  id: totrans-354
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`summingInt(ToIntFunction<? super T> mapper)`'
- en: '`summarizingInt(ToIntFunction<? super T> mapper)`'
  id: totrans-355
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`summarizingInt(ToIntFunction<? super T> mapper)`'
- en: '`counting()`'
  id: totrans-356
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`counting()`'
- en: '`minBy(Comparator<? super T> comparator)`'
  id: totrans-357
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`minBy(Comparator<? super T> comparator)`'
- en: '`maxBy(Comparator<? super T> comparator)`'
  id: totrans-358
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`maxBy(Comparator<? super T> comparator)`'
- en: String operations
  id: totrans-359
  prefs: []
  type: TYPE_NORMAL
  zh: 字符串操作
- en: 'There are three variants for joining elements together to a singular `String`:'
  id: totrans-360
  prefs: []
  type: TYPE_NORMAL
  zh: 有三种变体将元素连接到单一的`String`中：
- en: '`joining()` (3 variants)'
  id: totrans-361
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`joining()`（3种变体）'
- en: Advanced use cases
  id: totrans-362
  prefs: []
  type: TYPE_NORMAL
  zh: 高级用例
- en: In more advanced use cases, like multi-level reductions or complicated groupings/partitions,
    multiple collection steps are required with the help of “downstream” Collectors.
  id: totrans-363
  prefs: []
  type: TYPE_NORMAL
  zh: 在更高级的用例中，如多级减少或复杂的分组/分区，需要多个收集步骤，借助“下游”收集器。
- en: '`reducing(…​)` (3 variants)'
  id: totrans-364
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`reducing(…​)`（3种变体）'
- en: '`collectingAndThen(Collector<T,A,R> downstream, Function<R,RR> finisher)`'
  id: totrans-365
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`collectingAndThen(Collector<T,A,R> downstream, Function<R,RR> finisher)`'
- en: '`mapping(Function<? super T, ? extends U> mapper, Collector<? super U, A, R>
    downstream)` (Java 9+)'
  id: totrans-366
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`mapping(Function<? super T, ? extends U> mapper, Collector<? super U, A, R>
    downstream)` (Java 9+)'
- en: '`filtering(Predicate<? super T> predicate, Collector<? super T, A, R> downstream)`
    (Java 9+)'
  id: totrans-367
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`filtering(Predicate<? super T> predicate, Collector<? super T, A, R> downstream)`
    (Java 9+)'
- en: '`teeing(Collector<? super T, ?, R1> downstream1, Collector<? super T, ?, R2>
    downstream2, BiFunction<? super R1, ? super R2, R> merger)` (Java 12+)'
  id: totrans-368
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`teeing(Collector<? super T, ?, R1> downstream1, Collector<? super T, ?, R2>
    downstream2, BiFunction<? super R1, ? super R2, R> merger)`（Java 12+）'
- en: '[Chapter 7](ch07.xhtml#_02-streams) will detail how to use different Collectors
    and create complex collection workflows, including downstream collection.'
  id: totrans-369
  prefs: []
  type: TYPE_NORMAL
  zh: '[第7章](ch07.xhtml#_02-streams) 将详细介绍如何使用不同的收集器创建复杂的收集工作流程，包括下游收集。'
- en: Reducing Versus Collecting Elements
  id: totrans-370
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 减少与收集元素对比
- en: 'The terminal operations `reduce` and `collect` are two sides of the same coin:
    both are reduction — or fold — operations. The difference lies in the general
    approach to recombining the results: *immutable* versus *mutable* accumulation.
    This difference leads to quite different performance characteristics.'
  id: totrans-371
  prefs: []
  type: TYPE_NORMAL
  zh: 终端操作`reduce`和`collect`是同一个硬币的两面：都是减少——或折叠——操作。它们的区别在于重新组合结果的一般方法：*不可变*与*可变*累积。这种差异导致非常不同的性能特性。
- en: The more abstract approach of *immutable* accumulation with the `reduce` operation
    is the best fit if sub-results are cheap to create, like summing up numbers as
    shown in [Example 6-13](#_02-data-processing_immutable-reduction-stream)
  id: totrans-372
  prefs: []
  type: TYPE_NORMAL
  zh: 更抽象的不可变累积方法使用`reduce`操作，适用于子结果廉价创建的情况，比如像示例6-13中展示的数字求和。
- en: Example 6-13\. Immutable accumulation of numbers with a Stream
  id: totrans-373
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 6-13\. 使用流进行数字的不可变累积
- en: '[PRE14]'
  id: totrans-374
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: '[![1](assets/1.png)](#co_data_processing_with_streams_CO5-1)'
  id: totrans-375
  prefs: []
  type: TYPE_NORMAL
  zh: '[![1](assets/1.png)](#co_data_processing_with_streams_CO5-1)'
- en: The initial value — the *seed* — is used for every parallel reduction operation.
  id: totrans-376
  prefs: []
  type: TYPE_NORMAL
  zh: 初始值——*种子*——用于每个并行减少操作。
- en: '[![2](assets/2.png)](#co_data_processing_with_streams_CO5-2)'
  id: totrans-377
  prefs: []
  type: TYPE_NORMAL
  zh: '[![2](assets/2.png)](#co_data_processing_with_streams_CO5-2)'
- en: The method reference translates into a `BiFunction<Integer, Integer, Integer>`
    to accumulate the previous (or initial) value with the current Stream element.
  id: totrans-378
  prefs: []
  type: TYPE_NORMAL
  zh: 方法引用转换为`BiFunction<Integer, Integer, Integer>`，用于累积前一个（或初始）值与当前流元素。
- en: Every reduction operation builds upon the previous one, as seen in [Figure 6-19](#_02-data-processing_immutable-reduction).
  id: totrans-379
  prefs: []
  type: TYPE_NORMAL
  zh: 每个减少操作都建立在前一个操作的基础上，如图6-19中所示。
- en: '![Immutable accumulation of numbers](assets/afaj_0619.png)'
  id: totrans-380
  prefs: []
  type: TYPE_IMG
  zh: '![不可变数字累积](assets/afaj_0619.png)'
- en: Figure 6-19\. Immutable accumulation of numbers
  id: totrans-381
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 6-19\. 不可变数字累积
- en: This approach isn’t feasible for all scenarios, especially if creating an intermediate
    result is costly. Take the `String` type, for example. In [Chapter 4](ch04.xhtml#_02-data-structures),
    you’ve learned about its immutable nature and why performing modifications can
    be costly. That’s why it’s usually advisable to use an optimized intermediate
    container, like `StringBuilder` or `StringBuffer`, to reduce the required processing
    power.
  id: totrans-382
  prefs: []
  type: TYPE_NORMAL
  zh: 这种方法并非适用于所有情况，特别是如果创建中间结果成本高的情况下。例如，`String` 类型。在 [第四章](ch04.xhtml#_02-data-structures)
    中，您已经了解到它的不可变性质以及为什么执行修改可能成本高昂。因此，通常建议使用优化的中间容器，如 `StringBuilder` 或 `StringBuffer`，以减少所需的处理能力。
- en: Concatenating a list of `String` objects with an *immutable* reduction requires
    creating a new `String` for every step, leading to a runtime of <math alttext="upper
    O left-parenthesis n squared right-parenthesis"><mrow><mi>O</mi> <mo>(</mo> <msup><mi>n</mi>
    <mn>2</mn></msup> <mo>)</mo></mrow></math> with `n` being the number of characters.
    Let’s compare an *immutable* and *mutable* variant of `String` concatenation in
    [Example 6-14](#_02-data-processing_reduce-vs-collect-concat-strings).
  id: totrans-383
  prefs: []
  type: TYPE_NORMAL
  zh: 使用*不可变*归约连接 `String` 对象列表需要为每一步创建一个新的 `String`，导致运行时为 <math alttext="upper O
    left-parenthesis n squared right-parenthesis"><mrow><mi>O</mi> <mo>(</mo> <msup><mi>n</mi>
    <mn>2</mn></msup> <mo>)</mo></mrow></math>，其中 `n` 是字符数。让我们比较在 [示例 6-14](#_02-data-processing_reduce-vs-collect-concat-strings)
    中的*不可变*和*可变* `String` 连接。
- en: Example 6-14\. Concatenating String elements with reduce and collect
  id: totrans-384
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 6-14\. 使用 reduce 和 collect 连接 String 元素
- en: '[PRE15]'
  id: totrans-385
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: '[![1](assets/1.png)](#co_data_processing_with_streams_CO6-1)'
  id: totrans-386
  prefs: []
  type: TYPE_NORMAL
  zh: '[![1](assets/1.png)](#co_data_processing_with_streams_CO6-1)'
- en: The initial value is the first `String` creation.
  id: totrans-387
  prefs: []
  type: TYPE_NORMAL
  zh: 初始值是第一个 `String` 的创建。
- en: '[![2](assets/2.png)](#co_data_processing_with_streams_CO6-2)'
  id: totrans-388
  prefs: []
  type: TYPE_NORMAL
  zh: '[![2](assets/2.png)](#co_data_processing_with_streams_CO6-2)'
- en: Every reduction step creates another new `String`, so the required processing
    power and memory scale with element count.
  id: totrans-389
  prefs: []
  type: TYPE_NORMAL
  zh: 每个归约步骤都会创建另一个新的 `String`，因此所需的处理能力和内存随元素数量而扩展。
- en: '[![3](assets/3.png)](#co_data_processing_with_streams_CO6-3)'
  id: totrans-390
  prefs: []
  type: TYPE_NORMAL
  zh: '[![3](assets/3.png)](#co_data_processing_with_streams_CO6-3)'
- en: The first argument specifies a `Supplier<A>` for the mutable container.
  id: totrans-391
  prefs: []
  type: TYPE_NORMAL
  zh: 第一个参数指定了一个供应商 `Supplier<A>` 用于可变容器。
- en: '[![4](assets/4.png)](#co_data_processing_with_streams_CO6-4)'
  id: totrans-392
  prefs: []
  type: TYPE_NORMAL
  zh: '[![4](assets/4.png)](#co_data_processing_with_streams_CO6-4)'
- en: The second argument is the reduction `BiConsumer<A, T>` accepting the container
    and the current element.
  id: totrans-393
  prefs: []
  type: TYPE_NORMAL
  zh: 第二个参数是归约 `BiConsumer<A, T>`，接受容器和当前元素。
- en: '[![5](assets/5.png)](#co_data_processing_with_streams_CO6-5)'
  id: totrans-394
  prefs: []
  type: TYPE_NORMAL
  zh: '[![5](assets/5.png)](#co_data_processing_with_streams_CO6-5)'
- en: The third argument defines a `BinaryOperator<A>` of how to merge multiple containers
    in the case of parallel processing.
  id: totrans-395
  prefs: []
  type: TYPE_NORMAL
  zh: 第三个参数定义了在并行处理情况下如何合并多个容器的 `BinaryOperator<A>`。
- en: '[![6](assets/6.png)](#co_data_processing_with_streams_CO6-6)'
  id: totrans-396
  prefs: []
  type: TYPE_NORMAL
  zh: '[![6](assets/6.png)](#co_data_processing_with_streams_CO6-6)'
- en: And the last argument, a `Function<A, R>` tells the `Collector` how to build
    the final result of type `R`.
  id: totrans-397
  prefs: []
  type: TYPE_NORMAL
  zh: 最后一个参数是 `Function<A, R>`，告诉 `Collector` 如何构建类型为 `R` 的最终结果。
- en: '[![7](assets/7.png)](#co_data_processing_with_streams_CO6-7)'
  id: totrans-398
  prefs: []
  type: TYPE_NORMAL
  zh: '[![7](assets/7.png)](#co_data_processing_with_streams_CO6-7)'
- en: The `java.util.stream.Collectors` utility class provides many *ready-to-use*
    Collectors, making Stream pipelines more reasonable than creating a `Collector`
    inline.
  id: totrans-399
  prefs: []
  type: TYPE_NORMAL
  zh: '`java.util.stream.Collectors` 实用类提供许多*即用即得*的 `Collector`，使流管道比内联创建 `Collector`
    更合理。'
- en: The `Collector` requires more arguments than an *immutable* reduction to do
    its work. Still, these additional arguments allow it to use a *mutable* container
    and, therefore, a different approach to reducing the Stream’s elements in the
    first place. For many common tasks, in this case, concatenating Strings, you can
    use one of the pre-defined Collectors available from `java.util.stream.Collectors`.
  id: totrans-400
  prefs: []
  type: TYPE_NORMAL
  zh: '`Collector` 需要比*不可变*归约更多的参数来完成其工作。尽管如此，这些额外的参数允许它使用*可变*容器，因此在首次减少流元素时采用了不同的方法。对于许多常见任务，比如连接字符串，在这种情况下，您可以使用
    `java.util.stream.Collectors` 提供的预定义 `Collector` 之一。'
- en: 'Which type of reduction to choose — *immutable* or *mutable* — depends highly
    on your requirements. My personal *rule of thumb* is simple and stems from the
    names of the actual methods: choose `collect` if the result is a collection-based
    type, like `List` or `Map`; choose `reduce` if the result is an accumulated single
    value. But don’t forget performance and memory considerations.'
  id: totrans-401
  prefs: []
  type: TYPE_NORMAL
  zh: 选择哪种类型的归约 — *不可变*还是*可变* — 高度依赖于您的需求。我个人的*经验法则*很简单，源自实际方法的名称：如果结果是基于集合的类型，如 `List`
    或 `Map`，则选择 `collect`；如果结果是累积的单个值，则选择 `reduce`。但不要忘记性能和内存考虑。
- en: '[Chapter 7](ch07.xhtml#_02-streams) goes into more detail about Collectors
    and how to create your own.'
  id: totrans-402
  prefs: []
  type: TYPE_NORMAL
  zh: '[第7章](ch07.xhtml#_02-streams)详细介绍了收集器及其如何创建自定义收集器。'
- en: Aggregate Elements Directly
  id: totrans-403
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 直接聚合元素
- en: 'The `Collector` type is a powerful and versatile tool for collecting elements
    into new data structures. Still, sometimes, a simpler solution would suffice.
    The `Stream<T>` type provides more terminal aggregation operations for common
    tasks:'
  id: totrans-404
  prefs: []
  type: TYPE_NORMAL
  zh: '`Collector`类型是将元素收集到新数据结构中的强大且多功能的工具。但有时，简单的解决方案也足够了。`Stream<T>`类型提供了更多常用任务的终端聚合操作：'
- en: Returning a `List<T>`
  id: totrans-405
  prefs: []
  type: TYPE_NORMAL
  zh: 返回一个`List<T>`
- en: Java 16 added the terminal operation `toList()` to simplify the most commonly
    used aggregation to create a new `List<T>`. It doesn’t use a Collector-based workflow
    to aggregate the elements, leading to fewer allocations and requiring less memory.
    That makes it optimal to use when the stream size is known in advance, and a more
    concise alternative to `collect(Collectors.toList())`. There are no guarantees
    on the implementation type of the returned list or its serializability, just like
    with using `collect(Collectors.toList())`. Unlike it, however, the return list
    is an unmodifiable variant.
  id: totrans-406
  prefs: []
  type: TYPE_NORMAL
  zh: Java 16添加了终端操作`toList()`以简化创建新的`List<T>`的最常用聚合。它不使用基于收集器的工作流来聚合元素，从而减少了分配和内存需求。这使得在流大小预先知道且较简洁的情况下使用它成为最佳选择，而不是使用`collect(Collectors.toList())`。返回列表的实现类型或其可串行化性没有保证，与使用`collect(Collectors.toList())`一样。然而，返回的列表是不可修改的变体。
- en: Returning an array
  id: totrans-407
  prefs: []
  type: TYPE_NORMAL
  zh: 返回一个数组
- en: 'Returning the Stream’s elements as an array doesn’t require a reduction or
    Collector. Instead, you can use two operations:'
  id: totrans-408
  prefs: []
  type: TYPE_NORMAL
  zh: 将流的元素作为数组返回不需要缩减或收集器。您可以使用两个操作：
- en: '`Object[] toArray()`'
  id: totrans-409
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Object[] toArray()`'
- en: '`A[] toArray(IntFunction<A[]> generator)`'
  id: totrans-410
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`A[] toArray(IntFunction<A[]> generator)`'
- en: 'The second variant of `toArray` allows you to create an array of a specific
    type instead of `Object[]` by providing an “array generator,” which most likely
    is a method reference to the constructor:'
  id: totrans-411
  prefs: []
  type: TYPE_NORMAL
  zh: '`toArray`的第二种变体允许您通过提供“数组生成器”来创建特定类型的数组，该生成器很可能是对构造函数的方法引用：'
- en: '[PRE16]'
  id: totrans-412
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: Finding and Matching Elements
  id: totrans-413
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 查找和匹配元素
- en: 'Besides aggregating Stream elements into a new representation, finding a particular
    element is another common task for Streams. There are multiple terminal operations
    available to either find an element or determine its existence:'
  id: totrans-414
  prefs: []
  type: TYPE_NORMAL
  zh: 除了将流元素聚合到新表示形式中外，查找特定元素是流的另一个常见任务。有多个终端操作可用于查找元素或确定其是否存在：
- en: '`Optional<T> findFirst()`'
  id: totrans-415
  prefs: []
  type: TYPE_NORMAL
  zh: '`Optional<T> findFirst()`'
- en: Returns the first encountered element of the Stream. If the Stream is unordered,
    any element might be returned. Empty Streams return an empty `Optional<T>`.
  id: totrans-416
  prefs: []
  type: TYPE_NORMAL
  zh: 返回流的第一个遇到的元素。如果流是无序的，则可能返回任意元素。空流返回一个空的`Optional<T>`。
- en: '`Optional<T> findAny()`'
  id: totrans-417
  prefs: []
  type: TYPE_NORMAL
  zh: '`Optional<T> findAny()`'
- en: Returns any element of the Stream in a non-deterministic fashion. If the Stream
    itself is empty, an empty `Optional<T>` is returned.
  id: totrans-418
  prefs: []
  type: TYPE_NORMAL
  zh: 以非确定性方式返回流的任何元素。如果流本身为空，则返回一个空的`Optional<T>`。
- en: As you can see, both methods have no arguments, so a prior `filter` operation
    might be necessary to get the desired element.
  id: totrans-419
  prefs: []
  type: TYPE_NORMAL
  zh: 如您所见，这两个方法都没有参数，因此可能需要先进行`filter`操作以获取所需的元素。
- en: 'If you don’t require the element itself, you should use one of the matching
    operations, which matches the elements against a `Predicate<T>` instead:'
  id: totrans-420
  prefs: []
  type: TYPE_NORMAL
  zh: 如果不需要元素本身，则应使用其中一个匹配操作，该操作将元素与`Predicate<T>`匹配：
- en: '`boolean anyMatch(Predicate<? super T> predicate)`'
  id: totrans-421
  prefs: []
  type: TYPE_NORMAL
  zh: '`boolean anyMatch(Predicate<? super T> predicate)`'
- en: Returns `true` if *any* element of the Stream matches the `predicate`.
  id: totrans-422
  prefs: []
  type: TYPE_NORMAL
  zh: 返回`true`如果流的*任何*元素与`predicate`匹配。
- en: '`boolean allMatch(Predicate<? super T> predicate)`'
  id: totrans-423
  prefs: []
  type: TYPE_NORMAL
  zh: '`boolean allMatch(Predicate<? super T> predicate)`'
- en: Returns `true` if *all* elements of the Stream match the `predicate`.
  id: totrans-424
  prefs: []
  type: TYPE_NORMAL
  zh: 返回`true`如果流的*所有*元素与`predicate`匹配。
- en: '`boolean noneMatch(Predicate<? super T> predicate)`'
  id: totrans-425
  prefs: []
  type: TYPE_NORMAL
  zh: '`boolean noneMatch(Predicate<? super T> predicate)`'
- en: Returns `true` if *none* of the elements match the given `predicate`.
  id: totrans-426
  prefs: []
  type: TYPE_NORMAL
  zh: 返回`true`如果*没有*元素匹配给定的`predicate`。
- en: Consuming Elements
  id: totrans-427
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 消耗元素
- en: The last group of terminal operations is *side-effects-only* operations. Instead
    of returning a value, the `forEach` methods only accept a `Consumer<T>`.
  id: totrans-428
  prefs: []
  type: TYPE_NORMAL
  zh: 最后一组仅副作用的终端操作。`forEach`方法不返回值，而是仅接受一个`Consumer<T>`。
- en: '`void forEach(Consumer<? super T> action)`'
  id: totrans-429
  prefs: []
  type: TYPE_NORMAL
  zh: '`void forEach(Consumer<? super T> action)`'
- en: Performs the `action` for each element. The execution order is explicitly nondeterministic
    to maximize the performance, especially for parallel Streams.
  id: totrans-430
  prefs: []
  type: TYPE_NORMAL
  zh: 对每个元素执行`action`。执行顺序是显式的不确定性，以最大化性能，特别是对于并行流。
- en: '`void forEachOrdered(Consumer<? super T> action)`'
  id: totrans-431
  prefs: []
  type: TYPE_NORMAL
  zh: '`void forEachOrdered(Consumer<? super T> action)`'
- en: The `action` is performed for every element in the encountered order if the
    Stream is `ORDERED`.
  id: totrans-432
  prefs: []
  type: TYPE_NORMAL
  zh: 如果流是`ORDERED`，则按照遇到的顺序对每个元素执行`action`。
- en: From a functional point of view, these operations seem out of place. As a developer
    trying to transition imperative code into a more functional direction, however,
    they can be quite useful.
  id: totrans-433
  prefs: []
  type: TYPE_NORMAL
  zh: 从功能角度来看，这些操作似乎不合适。然而，作为试图将命令式代码转变为更功能化方向的开发人员，它们可能非常有用。
- en: Localized side effects aren’t inherently harmful. Not all code is easily refactorable
    to prevent them, if even at all. Just like with all the other operations, the
    conciseness of the contained logic determines how straightforward and readable
    the Stream pipeline will be. If more than a method reference or a simple non-block
    lambda is needed, it’s always a good idea to extract/refactor the logic into a
    new method and call it instead to maintain the conciseness and readability of
    the Stream pipeline.
  id: totrans-434
  prefs: []
  type: TYPE_NORMAL
  zh: 局部副作用本质上并不有害。并非所有代码都容易重构以防止它们，即使完全可以重构。就像所有其他操作一样，所包含逻辑的简洁性决定了流水线的直观性和可读性。如果需要的不仅仅是方法引用或简单的非阻塞
    lambda，将逻辑提取/重构到一个新方法中并调用它，始终保持流水线的简洁性和可读性是一个好主意。
- en: The Cost of Operations
  id: totrans-435
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 操作的成本
- en: 'The beauty of Streams is their ability to concatenate multiple operations into
    a single pipeline, but you have to remember one thing: every operation might get
    called until an item gets rejected downstream.'
  id: totrans-436
  prefs: []
  type: TYPE_NORMAL
  zh: 流的美妙之处在于它们能够将多个操作连接成一个单一的流水线，但你必须记住一件事：每个操作可能会被调用，直到向下游拒绝一个项目。
- en: Let’s look at the simple Stream pipeline in [Example 6-15](#_02-data-processing_order-matters-01).
  id: totrans-437
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看一下[示例 6-15](#_02-data-processing_order-matters-01)中的简单流水线。
- en: Example 6-15\. Fruit pipeline (naïve)
  id: totrans-438
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 6-15\. 水果流水线（简单）
- en: '[PRE17]'
  id: totrans-439
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: '[![1](assets/1.png)](#co_data_processing_with_streams_CO7-1)'
  id: totrans-440
  prefs: []
  type: TYPE_NORMAL
  zh: '[![1](assets/1.png)](#co_data_processing_with_streams_CO7-1)'
- en: Process elements to the desired form.
  id: totrans-441
  prefs: []
  type: TYPE_NORMAL
  zh: 处理元素以期望的形式。
- en: '[![2](assets/2.png)](#co_data_processing_with_streams_CO7-2)'
  id: totrans-442
  prefs: []
  type: TYPE_NORMAL
  zh: '[![2](assets/2.png)](#co_data_processing_with_streams_CO7-2)'
- en: Sort naturally.
  id: totrans-443
  prefs: []
  type: TYPE_NORMAL
  zh: 自然排序。
- en: '[![3](assets/3.png)](#co_data_processing_with_streams_CO7-3)'
  id: totrans-444
  prefs: []
  type: TYPE_NORMAL
  zh: '[![3](assets/3.png)](#co_data_processing_with_streams_CO7-3)'
- en: Reject unwanted elements.
  id: totrans-445
  prefs: []
  type: TYPE_NORMAL
  zh: 拒绝不需要的元素。
- en: '[![4](assets/4.png)](#co_data_processing_with_streams_CO7-4)'
  id: totrans-446
  prefs: []
  type: TYPE_NORMAL
  zh: '[![4](assets/4.png)](#co_data_processing_with_streams_CO7-4)'
- en: Finally, work with the remaining elements.
  id: totrans-447
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，处理剩余的元素。
- en: In this fruit pipeline example, you have three intermediate and one terminal
    operation, for processing five elements. How many operation calls do you guess
    are done by this simple code? Let’s count them!
  id: totrans-448
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个水果流水线示例中，你有三个中间操作和一个终端操作，用于处理五个元素。你猜这个简单代码执行了多少次操作调用？让我们来数数吧！
- en: The Stream pipeline calls `map` five times, `sorted` eight times, `filter` five
    times, and finally `forEach` two times. That’s *20* operations to output *two*
    values! Even though the pipeline does what it’s supposed to, that’s ridiculous!
    Let’s rearrange the operations to reduce the overall calls significantly, as seen
    in [Example 6-16](#_02-data-processing_order-matters-02).
  id: totrans-449
  prefs: []
  type: TYPE_NORMAL
  zh: 流水线调用`map`五次，`sorted`八次，`filter`五次，最后调用`forEach`两次。这就是进行*20*次操作来输出*两*个值！尽管流水线执行了它应该执行的操作，但这太荒谬了！让我们重新排列操作，显著减少总调用，就像在[示例 6-16](#_02-data-processing_order-matters-02)中看到的那样。
- en: Example 6-16\. Fruit pipeline (improved)
  id: totrans-450
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 6-16\. 水果流水线（优化）
- en: '[PRE18]'
  id: totrans-451
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: '[![1](assets/1.png)](#co_data_processing_with_streams_CO8-1)'
  id: totrans-452
  prefs: []
  type: TYPE_NORMAL
  zh: '[![1](assets/1.png)](#co_data_processing_with_streams_CO8-1)'
- en: Reject unwanted elements first.
  id: totrans-453
  prefs: []
  type: TYPE_NORMAL
  zh: 首先拒绝不需要的元素。
- en: '[![2](assets/2.png)](#co_data_processing_with_streams_CO8-2)'
  id: totrans-454
  prefs: []
  type: TYPE_NORMAL
  zh: '[![2](assets/2.png)](#co_data_processing_with_streams_CO8-2)'
- en: Transform elements to the desired form.
  id: totrans-455
  prefs: []
  type: TYPE_NORMAL
  zh: 将元素转换为期望的形式。
- en: '[![3](assets/3.png)](#co_data_processing_with_streams_CO8-3)'
  id: totrans-456
  prefs: []
  type: TYPE_NORMAL
  zh: '[![3](assets/3.png)](#co_data_processing_with_streams_CO8-3)'
- en: Sort naturally.
  id: totrans-457
  prefs: []
  type: TYPE_NORMAL
  zh: 自然排序。
- en: '[![4](assets/4.png)](#co_data_processing_with_streams_CO8-4)'
  id: totrans-458
  prefs: []
  type: TYPE_NORMAL
  zh: '[![4](assets/4.png)](#co_data_processing_with_streams_CO8-4)'
- en: Finally, work with the remaining elements.
  id: totrans-459
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，处理剩余的元素。
- en: 'By filtering first, the calls of the `map` operation and the work of the stateful
    `sorted` operation are reduced to a minimum: `filter` is called five times, `map`
    two times, `sorted` one time, and `forEach` two times, saving *50%* operations
    in total without changing the result.'
  id: totrans-460
  prefs: []
  type: TYPE_NORMAL
  zh: 通过首先过滤，将`map`操作的调用和有状态的`sorted`操作的工作减少到最低限度：`filter`调用五次，`map`两次，`sorted`一次，`forEach`两次，总共节省了*50%*的操作而不改变结果。
- en: Always remember that Stream elements are not being pushed through the Stream
    pipeline and its operations until they reach the terminal operation. Instead,
    the terminal operation pulls the elements through the pipeline. The fewer elements
    that flow through the pipeline, the better its performance will be. That’s why
    some operations are considered *short-circuiting* in nature, meaning they can
    cut the Stream short. Essentially, short-circuiting operations, as listed in [Table 6-4](#_02-data-processing_short-circuiting-ops),
    are operations that might carry out their intended purpose without requiring the
    Stream to traverse all of its elements.
  id: totrans-461
  prefs: []
  type: TYPE_NORMAL
  zh: 请记住，Stream元素直到达到终端操作才会被推送到Stream管道及其操作中。相反，终端操作通过管道拉取元素。流经管道的元素越少，性能就越好。这就是为什么一些操作被认为是*短路*性质的原因，意味着它们可以截断流。本质上，列在[表
    6-4](#_02-data-processing_short-circuiting-ops)中的短路流操作是可能在不需要遍历所有元素的情况下执行其预期目的的操作。
- en: Table 6-4\. Short-circuiting Stream operations
  id: totrans-462
  prefs: []
  type: TYPE_NORMAL
  zh: 表6-4\. 短路流操作
- en: '| Intermediate Operations | Terminal Operations |'
  id: totrans-463
  prefs: []
  type: TYPE_TB
  zh: '| 中间操作 | 终端操作 |'
- en: '| --- | --- |'
  id: totrans-464
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| `limit takeWhile`  | `findAny findFirst anyMatch allMatch noneMatch` |'
  id: totrans-465
  prefs: []
  type: TYPE_TB
  zh: '| `limit takeWhile`  | `findAny findFirst anyMatch allMatch noneMatch` |'
- en: This behavior allows them to even process an infinite Stream and may still produce
    a finite Stream (intermediate ops) or finish their task in finite time (terminal
    ops).
  id: totrans-466
  prefs: []
  type: TYPE_NORMAL
  zh: 这种行为允许它们甚至处理无限流，并且仍可能产生有限流（中间操作）或在有限时间内完成任务（终端操作）。
- en: 'A non-short-circuiting operation with heavily optimized behavior is the terminal
    `count()` operation. If the overall element count of a Stream terminated by `count()`
    is derivable from the Stream itself, any prior operations that won’t affect the
    count might get dropped, as the following code demonstrates:'
  id: totrans-467
  prefs: []
  type: TYPE_NORMAL
  zh: 使用高度优化的非短路操作是终端`count()`操作。如果通过`count()`终止的Stream的整体元素计数可以从Stream本身派生，那么任何不影响计数的先前操作都可能被删除，就像下面的代码所示：
- en: '[PRE19]'
  id: totrans-468
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'Even though there are three operations with a `System.out.println` call in
    the pipeline, all of them are dropped. The reasoning behind this behavior is simple:
    `map` and `peek` operations don’t inject or remove any elements in the Stream
    pipeline, so they don’t affect the final count in any way, therefore, they aren’t
    actually required.'
  id: totrans-469
  prefs: []
  type: TYPE_NORMAL
  zh: 即使管道中有三个带有`System.out.println`调用的操作，它们都被删除了。这种行为背后的推理很简单：`map`和`peek`操作不会在Stream管道中注入或移除任何元素，因此它们不会以任何方式影响最终计数，因此实际上它们并不是必需的。
- en: 'Dropping operations is at the Stream’s discretion if it deems it possible.
    For example, the preceding code runs all operations if a `filter` operation is
    added to the pipeline, shown as follows:'
  id: totrans-470
  prefs: []
  type: TYPE_NORMAL
  zh: 如果流认为可能，它就会自行决定是否删除操作。例如，如果将`filter`操作添加到管道中，则前面的代码将运行所有操作，如下所示：
- en: '[PRE20]'
  id: totrans-471
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: That doesn’t mean every kind of Stream pipeline will drop *possible* unnecessary
    operations, either. If you require “side-effects” in your Stream pipeline, you
    should use one of the two `forEach` terminal operation variants, which are intended
    as “side-effects-only” operations.
  id: totrans-472
  prefs: []
  type: TYPE_NORMAL
  zh: 这并不意味着每种类型的流管道都会删除*可能*不必要的操作。如果您的流管道需要“副作用”，则应使用两种`forEach`终端操作变体之一，这两种变体都旨在作为“仅副作用”的操作。
- en: Modifying Stream Behavior
  id: totrans-473
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 修改流行为
- en: A Stream’s characteristics, as explained in [“Spliterator, the Backbone of Streams”](#_02-data-processing_spliterator),
    are initially set on its creation. Not every Stream operation is a good match
    for every characteristic, though. Especially in parallel Streams, the encountered
    order of elements might significantly impact performance. For example, selecting
    elements with the `filter` operation is an easily parallelizable task, but `takeWhile`
    needs to synchronize between tasks if run in parallel. That’s why particular Stream
    characteristics can be switched by the intermediate operations listed in [Table 6-5](#_02-data-processing_intermediate_mod),
    which return an equivalent Stream with changed traits.
  id: totrans-474
  prefs: []
  type: TYPE_NORMAL
  zh: 如[“Spliterator, the Backbone of Streams”](#_02-data-processing_spliterator)所述，流的特性在创建时最初设置。然而，并非每个流操作都适合每种特性。特别是在并行流中，元素的遇到顺序可能会显著影响性能。例如，使用`filter`操作选择元素是一项容易并行化的任务，但如果并行运行`takeWhile`，则需要在任务之间同步。这就是为什么可以通过[表
    6-5](#_02-data-processing_intermediate_mod)中列出的中间操作切换特定流特性，这些操作返回具有改变特征的等效流。
- en: Table 6-5\. Modifying Stream Behavior
  id: totrans-475
  prefs: []
  type: TYPE_NORMAL
  zh: 表 6-5\. 修改流行为
- en: '| Operation | Description |'
  id: totrans-476
  prefs: []
  type: TYPE_TB
  zh: '| 操作 | 描述 |'
- en: '| --- | --- |'
  id: totrans-477
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| `parallel()` | Enables parallel processing. May return `this` if the Stream
    is already parallel. |'
  id: totrans-478
  prefs: []
  type: TYPE_TB
  zh: '| `parallel()` | 启用并行处理。如果流已经是并行的，则可能返回`this`。 |'
- en: '| `sequential()` | Enables sequential processing. May return `this` if the
    Stream is already sequential. |'
  id: totrans-479
  prefs: []
  type: TYPE_TB
  zh: '| `sequential()` | 启用顺序处理。如果流已经是顺序的，则可能返回`this`。 |'
- en: '| `unordered()` | Returns a Stream with unordered encounter order. May return
    `this` if the Stream is already unordered. |'
  id: totrans-480
  prefs: []
  type: TYPE_TB
  zh: '| `unordered()` | 返回遇到顺序无序的流。如果流已经是无序的，则可能返回`this`。 |'
- en: '| `onClose(Runnable closeHandler)` | Adds an additional close handler to be
    called after the Stream is finished. |'
  id: totrans-481
  prefs: []
  type: TYPE_TB
  zh: '| `onClose(Runnable closeHandler)` | 在流完成后添加额外的关闭处理程序。 |'
- en: Switching Stream behavior is just a single method call away. However, that doesn’t
    mean it’s always a good idea. In fact, switching to parallel processing is often
    a bad idea if the pipeline and the underlying Stream aren’t designed to run in
    parallel in the first place.
  id: totrans-482
  prefs: []
  type: TYPE_NORMAL
  zh: 切换流行为只需调用一个方法。然而，并不意味着这总是一个好主意。事实上，如果管道和底层流不是设计为首先并行运行的话，切换到并行处理通常是一个坏主意。
- en: See [Chapter 8](ch08.xhtml#_01-parallel-streams) to learn how to make an informed
    decision about using parallel processing for Stream pipelines.
  id: totrans-483
  prefs: []
  type: TYPE_NORMAL
  zh: 请参阅[第 8 章](ch08.xhtml#_01-parallel-streams)以了解如何就使用流管道进行并行处理做出明智决策。
- en: To Use Streams, or Not?
  id: totrans-484
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用流，还是不使用？
- en: Streams are an excellent way to make your data processing more expressive and
    utilize many of the functional features available in Java. You may feel a strong
    urge to (over)use Streams for all kinds of data processing. I know I certainly
    overdid it at first. You have to keep in mind, though, that not every data processing
    pipeline benefits equally from becoming a Stream.
  id: totrans-485
  prefs: []
  type: TYPE_NORMAL
  zh: 流是使数据处理更具表现力并利用 Java 中许多函数特性的极佳方式。你可能会强烈倾向于（过度）使用流来处理各种数据。我一开始确实有过度使用的情况。但你必须记住，并不是每个数据处理管道都能同等受益于成为流。
- en: 'Your decision to use Streams — or not to use one — should rely always be an
    informed decision based on the following intertwined factors:'
  id: totrans-486
  prefs: []
  type: TYPE_NORMAL
  zh: 您是否决定使用流——或者不使用——应始终是基于以下相互交织的因素做出的知情决策：
- en: How complex is the required task?
  id: totrans-487
  prefs: []
  type: TYPE_NORMAL
  zh: 所需任务的复杂程度有多高？
- en: A simple loop that’s a few lines long won’t benefit much from being a Stream
    with one or two small operations. It depends on how easy it is to fit the whole
    task and required logic into a mental model.
  id: totrans-488
  prefs: []
  type: TYPE_NORMAL
  zh: 几行代码的简单循环不会因为成为一个或两个小操作的流而受益太多。这取决于将整个任务和所需逻辑轻松适应到一个心理模型中的容易程度。
- en: If I can grasp what’s happening with ease, a simple *for-each*-loop might be
    the better choice. On the other hand, compressing a multi-page long loop into
    a more accessible Stream pipeline with well-defined operations will improve its
    readability and maintainability.
  id: totrans-489
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我能轻松掌握正在发生的事情，一个简单的*for-each*循环可能是更好的选择。另一方面，将多页长循环压缩成具有良好定义操作的更易访问的流管道，将提高其可读性和可维护性。
- en: How functional is the Stream pipeline?
  id: totrans-490
  prefs: []
  type: TYPE_NORMAL
  zh: 流管道的功能有多强大？
- en: Stream pipelines are mere scaffolds to be filled with your logic. If the logic
    isn’t a good fit for a functional approach, like side-effect-laden code, you won’t
    get all the benefits and safety guarantees that Streams have to offer.
  id: totrans-491
  prefs: []
  type: TYPE_NORMAL
  zh: 流管道只是要填充您的逻辑的脚手架。如果逻辑不适合功能性方法，比如带有副作用的代码，您将无法获得流可以提供的所有好处和安全保证。
- en: Refactoring or redesigning code to be more functional, pure, or immutable is
    always a good idea and makes it a better match for the Stream API. Sill, forcing
    your code to fit into a Stream pipeline without the actual need is deciding on
    a solution without really understanding the problem first. A certain degree of
    adapting your code to enable new features that benefit productivity, reasonability,
    and maintainability is good.
  id: totrans-492
  prefs: []
  type: TYPE_NORMAL
  zh: 重构或重新设计代码以使其更加函数化、纯净或不可变总是一个好主意，并使其更适配于流 API。然而，如果没有真正理解问题的需求，强行将代码适配到流管道中则是在没有必要的情况下做出解决方案的决定。适当调整代码以支持有利于生产力、合理性和可维护性的新功能是有益的。
- en: However, it should be a conscious decision on what’s best for your code and
    project in the long run, not just a “requirement” to use a feature.
  id: totrans-493
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，长远来看，应该是对代码和项目做出明智的决定，而不仅仅是使用某个功能的“要求”。
- en: How many elements are processed?
  id: totrans-494
  prefs: []
  type: TYPE_NORMAL
  zh: 处理了多少个元素？
- en: The overhead of creating the scaffold that holds the Stream pipeline together
    diminishes with the number of processed elements. For small data sources, the
    relation between the required instances, method calls, stack frames, and memory
    consumption is not as negligible as for processing more significant quantities
    of elements.
  id: totrans-495
  prefs: []
  type: TYPE_NORMAL
  zh: 创建支持流管道的脚手架的开销随着处理元素的数量减少而减少。对于小数据源来说，所需实例、方法调用、堆栈帧和内存消耗之间的关系并不像处理更大数量元素那样微不足道。
- en: In a direct comparison of raw performance, a “perfectly optimized” `for`-loop
    wins out over a sequential Stream for a simple reason. Traditional Java looping
    constructs are implemented at the language level, giving the JVM more optimization
    possibilities, especially for small loops. On the other hand, Streams are implemented
    as ordinary Java types, creating an unavoidable runtime overhead. That doesn’t
    mean their execution won’t be optimized, though! As you’ve learned in this chapter,
    a Stream pipeline can short-circuit or fuse operations to maximize pipeline throughput.
  id: totrans-496
  prefs: []
  type: TYPE_NORMAL
  zh: 在原始性能的直接比较中，“完全优化的”`for`循环胜过顺序流的一个简单原因。传统的Java循环结构是在语言级别实现的，这为JVM提供了更多的优化可能性，特别是对于小循环。另一方面，流是作为普通的Java类型实现的，这会产生不可避免的运行时开销。不过，这并不意味着它们的执行不会被优化！正如您在本章中学到的那样，流管道可以短路或合并操作以最大化管道吞吐量。
- en: None of these factors in isolation should affect your decision to use Stream,
    only in tandem. Especially the most common concern of many developers — performance — is
    seldom the most significant criterion for designing code and choosing the right
    tools.
  id: totrans-497
  prefs: []
  type: TYPE_NORMAL
  zh: 在孤立地考虑这些因素时，不应该影响您是否使用流的决定，只能是一起考虑。特别是许多开发人员最常见的担忧——性能——很少是设计代码和选择正确工具的最重要标准。
- en: Your code could always be more performant. Dismissing a tool out of performance
    anxiety before measuring and verifying the actual performance might deprive you
    of a better solution for your actual problem.
  id: totrans-498
  prefs: []
  type: TYPE_NORMAL
  zh: 您的代码始终可以更高效。在测量和验证实际性能之前，因性能焦虑而排斥某个工具可能会使您失去解决实际问题的更好方案。
- en: 'Sir Tony Hoare^([4](ch06.xhtml#idm45115235918800)) once said, “We should forget
    about small efficiencies, say about 97% of the time: premature optimization is
    the root of all evil.”'
  id: totrans-499
  prefs: []
  type: TYPE_NORMAL
  zh: 托尼·霍尔爵士^([4](ch06.xhtml#idm45115235918800))曾说过：“我们应该忘记小的效率，大约有97%的时间：过早优化是一切邪恶的根源。”
- en: This advice can be applied when deciding whether to use Streams or loops. Most
    of the time — around 97% — you do not need to concern yourself with raw performance,
    and Streams may be the most simple and straightforward solution for you with all
    the benefits the Stream API offers. Once in a while — the 3% — you will need to
    focus on raw performance to achieve your goals, and Streams might not be the best
    solution for you. Although in [Chapter 8](ch08.xhtml#_01-parallel-streams) you
    will learn how to improve processing performance by leveraging parallel Streams.
  id: totrans-500
  prefs: []
  type: TYPE_NORMAL
  zh: 在决定是否使用流或循环时，可以应用这些建议。大多数情况下——大约97%的时间——您不需要关注原始性能，流可能是最简单和直接的解决方案，同时也能享受流 API
    提供的所有好处。偶尔——那个3%的时间——您需要关注原始性能以实现您的目标，而流可能不是最好的解决方案。尽管在[第8章](ch08.xhtml#_01-parallel-streams)中，您将学习如何通过利用并行流来提高处理性能。
- en: When deciding whether or not to use Streams, you might think about how willing
    you are to use something new and unfamiliar. When you first learned to program,
    I bet all the loop constructs you’re now quite familiar with appeared to be complicated.
    Everything seemed hard at first until, over time and repeated use, you became
    familiar and more comfortable with using those loop contracts. The same is going
    to be true for using Streams. Learning the ins and outs of the Steam API will
    take some time, but it will become easier and more obvious when and how to use
    Streams efficiently to create concise and straightforward data processing pipelines.
  id: totrans-501
  prefs: []
  type: TYPE_NORMAL
  zh: 在决定是否使用流时，你可能会考虑你是否愿意使用新的和陌生的东西。当你第一次学习编程时，我敢打赌，所有你现在非常熟悉的循环结构似乎都很复杂。一开始似乎一切都很难，直到随着时间和重复使用，你变得熟悉和更舒适地使用那些循环结构。对于使用流也是如此。学习流
    API 的各个方面会花费一些时间，但当何时以及如何高效地使用流来创建简洁和直接的数据处理管道时，这将变得更容易和更明显。
- en: Another thing you have to keep in mind is that the primary goal of Streams isn’t
    to achieve the best raw performance possible or to replace all other looping constructs.
    Streams are supposed to be a more declarative and expressive way of processing
    data. They give you the equivalent of the classical map-filter-reduce pattern
    backed by Java’s strong type system but also designed with all the powerful functional
    techniques introduced in Java 8 in mind. Designing a functional Stream pipeline
    is the most straightforward and concise way to apply functional code to a sequence
    of objects.
  id: totrans-502
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个需要记住的是，流的主要目标并非达到最佳的原始性能或替代所有其他循环结构。流被设计为处理数据的更声明性和表达性方式。它们为你提供了经典的映射-过滤-归约模式，支持
    Java 强类型系统，同时还考虑了 Java 8 中引入的强大的函数技术。设计一个功能性的流管道是将功能代码应用于对象序列的最直接和简洁的方式。
- en: Finally, the general idea of combining pure functions with immutable data leads
    to a looser coupling between data structures and their data processing logic.
    Each operation only needs to know how to handle a single element in its current
    form. This decoupling enables greater reusability and maintainability of smaller
    domain-specific operations that can be composed into bigger, more sophisticated
    tasks if necessary.
  id: totrans-503
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，将纯函数与不可变数据结合的一般想法导致数据结构和其数据处理逻辑之间的松散耦合。每个操作只需要知道如何处理当前形式中的单个元素。这种解耦使得更小的领域特定操作可以更容易地重用和维护，并在必要时组合成更大、更复杂的任务。
- en: Takeaways
  id: totrans-504
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 主要观点
- en: The Stream API provides a fluent and declarative way to create *map/filter/reduce*-like
    data processing pipelines without the need for external iteration.
  id: totrans-505
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 流 API 提供了一种流畅且声明性的方式来创建类似于*map/filter/reduce*的数据处理管道，无需外部迭代。
- en: Concatenable higher-order functions are the building blocks for a Stream pipeline.
  id: totrans-506
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 可连接的高阶函数是流管道的构建块。
- en: Streams use internal iteration, which entrusts more control over the traversal
    process to the data source itself.
  id: totrans-507
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 流使用内部迭代，这将更多的控制权委托给数据源本身来处理遍历过程。
- en: Many common and specialized operations are available besides the classical *map/filter/reduce*
    operations.
  id: totrans-508
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 除了经典的*map/filter/reduce*操作之外，还提供了许多常见和专业化的操作。
- en: Streams are lazy; no work is done until a terminal operation is called.
  id: totrans-509
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 流是惰性的；直到调用终端操作之前都不会执行任何工作。
- en: Sequential processing is the default, but switching to parallel processing is
    easy.
  id: totrans-510
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 顺序处理是默认的，但切换到并行处理很容易。
- en: Parallel processing might not be the best approach to all data processing problems
    and usually needs to be verified to solve the problem more efficiently.
  id: totrans-511
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 并行处理可能不是所有数据处理问题的最佳方法，并且通常需要验证以更高效地解决问题。
- en: ^([1](ch06.xhtml#idm45115238989296-marker)) Brian Goetz, the Java Language Architect
    at Oracle, explains fusing operations [on StackOverflow](https://stackoverflow.com/questions/35069055/java-stream-operation-fusion-and-stateful-intermediate-operations/35070889#35070889).
  id: totrans-512
  prefs: []
  type: TYPE_NORMAL
  zh: ^([1](ch06.xhtml#idm45115238989296-marker)) Oracle 的 Java 语言架构师 Brian Goetz
    解释了在 [StackOverflow](https://stackoverflow.com/questions/35069055/java-stream-operation-fusion-and-stateful-intermediate-operations/35070889#35070889)
    上的操作融合和有状态中间操作。
- en: '^([2](ch06.xhtml#idm45115238985136-marker)) Newland, Chris and Ben Evans. 2019\.
    “Loop Unrolling: An elaborate mechanism for reducing loop iterations improves
    performance but can be thwarted by inadvertent coding.” [Java magazine](https://blogs.oracle.com/javamagazine/loop-unrolling).'
  id: totrans-513
  prefs: []
  type: TYPE_NORMAL
  zh: ^([2](ch06.xhtml#idm45115238985136-marker)) Newland, Chris 和 Ben Evans. 2019\.
    “循环展开：一种用于减少循环迭代次数的复杂机制可以提高性能，但可能会因无意编码而受阻。” [Java magazine](https://blogs.oracle.com/javamagazine/loop-unrolling).
- en: ^([3](ch06.xhtml#idm45115238384128-marker)) Even though there are several new
    annotations used in JavaDoc since the release of Java 8, they aren’t an *official*
    standard as of writing this book. The informal proposal is available at the official
    OpenJDK bug-tracker as [JDK-8068562](https://bugs.openjdk.java.net/browse/JDK-8068562)
  id: totrans-514
  prefs: []
  type: TYPE_NORMAL
  zh: ^([3](ch06.xhtml#idm45115238384128-marker)) 虽然自Java 8发布以来JavaDoc中使用了几种新的注释，但截至本书撰写时它们还不是*官方*标准。非正式提案可在官方OpenJDK错误跟踪器上查看，编号为[JDK-8068562](https://bugs.openjdk.java.net/browse/JDK-8068562)。
- en: ^([4](ch06.xhtml#idm45115235918800-marker)) Sir Charles Antony Richard Hoare
    is a British computer scientist and recipient of the Turing Award — regarded as
    the highest distinction in the field of computer science — who has made foundational
    contributions to programming languages, algorithms, operating systems, formal
    verification, and concurrent computing.
  id: totrans-515
  prefs: []
  type: TYPE_NORMAL
  zh: ^([4](ch06.xhtml#idm45115235918800-marker)) 英国计算机科学家**查尔斯·安东尼·理查德·霍尔**（Sir Charles
    Antony Richard Hoare）是图灵奖的获得者，这是计算机科学领域的最高荣誉，他在编程语言、算法、操作系统、形式验证和并发计算方面做出了基础性贡献。
