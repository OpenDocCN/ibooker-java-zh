- en: Chapter 12\. Java SE API Tips
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第 12 章。Java SE API 提示
- en: This chapter covers areas of the Java SE API that have implementation quirks
    affecting their performance. Many such implementation details exist throughout
    the JDK; these are the areas where I consistently uncover performance issues (even
    in my own code). This chapter includes details on the best way to handle strings
    (and especially duplicate strings); ways to properly buffer I/O; classloading
    and ways to improve startup of applications that use a lot of classes; proper
    use of collections; and JDK 8 features like lambdas and streams.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 本章涵盖了 Java SE API 的一些实现怪癖，影响其性能。JDK 中存在许多这样的实现细节；这些是我在不同地方发现性能问题的地方（甚至是在我自己的代码中）。本章包括如何处理字符串（特别是重复字符串）的最佳方式；如何正确缓冲
    I/O；类加载和如何改进使用大量类的应用程序的启动方式；正确使用集合；以及 JDK 8 的特性，如 lambda 和流。
- en: Strings
  id: totrans-2
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 字符串
- en: Strings are (unsurprisingly) the most common Java object. In this section, we’ll
    look at a variety of ways to handle all the memory consumed by string objects;
    these techniques can often significantly reduce the amount of heap your program
    requires. We’ll also cover a new JDK 11 feature of strings involving concatenation.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 字符串（不出所料地）是最常见的 Java 对象。在本节中，我们将探讨处理所有由字符串对象消耗的内存的各种方法；这些技术通常可以显著减少程序所需的堆内存量。我们还将介绍
    JDK 11 中涉及字符串连接的新特性。
- en: Compact Strings
  id: totrans-4
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 紧凑字符串
- en: 'In Java 8, all strings are encoded as arrays of 16-bit characters, regardless
    of the encoding of the string. This is wasteful: most Western locales can encode
    strings into 8-bit byte arrays, and even in a locale that requires 16 bits for
    all characters, strings like program constants often can be encoded as 8-bit bytes.'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 在 Java 8 中，所有字符串都编码为 16 位字符数组，而不考虑字符串的编码。这是不经济的：大多数西方地区可以将字符串编码为 8 位字节数组，即使在需要所有字符为
    16 位的地区，像程序常量这样的字符串通常也可以编码为 8 位字节。
- en: In Java 11, strings are encoded as arrays of 8-bit bytes unless they explicitly
    need 16-bit characters; these strings are known as *compact strings*. A similar
    (experimental) feature in Java 6 was known as *compressed strings*; compact strings
    are conceptually the same but differ greatly in implementation.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 在 Java 11 中，除非明确需要 16 位字符，否则字符串编码为 8 位字节数组；这些字符串称为*紧凑字符串*。Java 6 中的类似（实验性）特性称为*压缩字符串*；紧凑字符串在概念上是相同的，但在实现上有很大不同。
- en: 'Hence, the size of an average Java string in Java 11 is roughly half the size
    of the same string in Java 8\. This generally is a huge savings: on average, 50%
    of a typical Java heap may be consumed by string objects. Programs will vary,
    of course, but on average the heap requirement of such a program running with
    Java 11 is only 75% of that same program running in Java 8.'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，Java 11 中的平均 Java 字符串大小大约是 Java 8 中同一字符串大小的一半。这通常是巨大的节省：通常，典型 Java 堆的 50%
    可能由字符串对象占用。当然，程序会有所不同，但平均而言，使用 Java 11 运行的此类程序的堆需求仅为 Java 8 运行相同程序的 75%。
- en: 'It’s easy enough to construct examples where this has an outsize benefit. One
    can run a program in Java 8 that spends an enormous time performing garbage collection.
    Running that same program in Java 11 with the same size heap could require virtually
    no time in the collector, leading to reported gains of three to ten times in performance.
    Take claims like that with a grain of salt: you’re typically not going to run
    any Java program in such a constrained heap. All things being equal, though, you
    will see a reduction in the amount of time spent in garbage collection.'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 很容易构建出这种有着超额好处的示例。可以在 Java 8 中运行一个需要大量时间执行垃圾收集的程序。在 Java 11 中以相同大小的堆运行相同程序可能几乎不需要时间进行收集，从而导致性能提升为三到十倍。对于这样的声明要持保留态度：通常情况下，您不太可能在这样的受限堆中运行任何
    Java 程序。一切条件相同，您将看到垃圾收集所花时间减少。
- en: 'For a well-tuned application, the real benefit is in memory usage: you can
    immediately reduce the maximum heap size of the average program by 25% and still
    get the same performance. Conversely, if you leave the heap size unchanged, you
    should be able to introduce more load into the application and not experience
    any GC bottlenecks (though the rest of the application must be able to handle
    the increased load).'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 对于调优良好的应用程序，真正的好处在于内存使用：您可以立即将典型程序的最大堆大小减少 25%，并且仍然获得相同的性能。反之，如果保持堆大小不变，您应该能够将更多负载引入应用程序，而不会遇到任何
    GC 瓶颈（尽管应用程序的其他部分必须能够处理增加的负载）。
- en: 'This feature is controlled by the `-XX:+CompactStrings` flag, which is `true`
    by default. But unlike the compressed strings in Java 6, compact strings are robust
    and well-performing; you’ll almost always want to keep the default setting. One
    possible exception is in a program in which all the strings require 16-bit encodings:
    operations on those strings can be slightly longer in compacted strings than in
    uncompacted strings.'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 这一功能由 `-XX:+CompactStrings` 标志控制，默认为 `true`。但与 Java 6 中的压缩字符串不同，紧凑字符串既健壮又高效；你几乎总是希望保持默认设置。唯一的可能例外是在所有字符串都需要
    16 位编码的程序中：在紧凑字符串中，对这些字符串的操作可能比未压缩的字符串稍长。
- en: Duplicate Strings and String Interning
  id: totrans-11
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 重复字符串与字符串池化
- en: It is common to create many string objects that contain the same sequence of
    characters. These objects unnecessarily take space in the heap; since strings
    are immutable, it is often better to reuse the existing strings. We discussed
    a general case of this in [Chapter 7](ch07.html#Memory) for arbitrary objects
    with a canonical representation; this section expands on that idea in relation
    to strings.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 创建许多包含相同字符序列的字符串对象是常见的。这些对象在堆中占用了不必要的空间；由于字符串是不可变的，通常最好重用现有的字符串。我们在[第 7 章](ch07.html#Memory)讨论了一般情况，其中涉及具有规范表示的任意对象；本节扩展了这个想法，特别是与字符串相关的部分。
- en: 'Knowing if you have a large number of duplicate strings requires heap analysis.
    Here’s one way to do that with the Eclipse Memory Analyzer:'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 知道是否有大量重复的字符串需要堆分析。以下是使用 Eclipse Memory Analyzer 的方法之一：
- en: Load the heap dump.
  id: totrans-14
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 加载堆转储。
- en: From the Query Browser, select Java Basics → Group By Value.
  id: totrans-15
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从查询浏览器中选择 Java Basics → 按值分组。
- en: For the `objects` argument, type in **`java.lang.String`**.
  id: totrans-16
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 对于 `objects` 参数，输入 **`java.lang.String`**。
- en: Click the Finish button.
  id: totrans-17
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 单击完成按钮。
- en: The result is shown in [Figure 12-1](#FigureStringIntern). We have more than
    300,000 copies of each of the strings `Name`, `Memnor`, and `Parent Name`. Several
    other strings have multiple copies as well; in all, this heap has more than 2.3
    million duplicate strings.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 结果显示在[图 12-1](#FigureStringIntern)中。我们有超过 30 万个 `Name`、`Memnor` 和 `Parent Name`
    字符串的副本。还有几个其他字符串也有多个副本；总体而言，此堆中有超过 230 万个重复的字符串。
- en: '![Duplicate String and their memory sizes.](assets/jp2e_1201.png)'
  id: totrans-19
  prefs: []
  type: TYPE_IMG
  zh: '![重复字符串及其内存大小。](assets/jp2e_1201.png)'
- en: Figure 12-1\. Memory consumed by duplicate strings
  id: totrans-20
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 12-1\. 重复字符串占用的内存
- en: 'The duplicate strings can be removed in three ways:'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 可以通过三种方式去除重复的字符串：
- en: Performing automatic deduplication via G1 GC
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过 G1 GC 执行自动去重
- en: Using the `intern()` method of the `String` class to create the canonical version
    of the string
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 `String` 类的 `intern()` 方法创建字符串的规范版本
- en: Using a custom method to create a canonical version of the string
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用一种自定义方法创建字符串的规范版本
- en: String deduplication
  id: totrans-25
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 字符串去重
- en: 'The simplest mechanism is to let the JVM find the duplicate strings and *deduplicate*
    them: arrange for all references to point to a single copy and then free the remaining
    copies. This is possible only when using G1 GC and only when specifying the `-XX:+UseStringDeduplication`
    flag (which by default is `false`). This feature exists in Java 8 only after version
    20, and all releases of Java 11.'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 最简单的机制是让 JVM 找到重复的字符串并*去重*它们：安排所有引用指向单个副本，然后释放剩余的副本。这只有在使用 G1 GC 并且指定 `-XX:+UseStringDeduplication`
    标志（默认为 `false`）时才可能。此功能仅在 Java 8 的第 20 版之后和所有 Java 11 发行版中存在。
- en: This feature is not enabled by default for three reasons. First, it requires
    extra processing during the young and mixed phases of G1 GC, making them slightly
    longer. Second, it requires an extra thread that runs concurrently with the application,
    potentially taking CPU cycles away from application threads. And third, if there
    are few deduplicated strings, the memory use of the application will be higher
    (instead of lower); this extra memory comes from the bookkeeping involved in tracking
    all the strings to look for duplications.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 这一功能默认未启用，原因有三。首先，在 G1 GC 的年轻和混合阶段需要额外处理，使它们稍长。其次，它需要一个额外的线程与应用程序并发运行，可能会从应用程序线程中获取
    CPU 周期。第三，如果有很少的去重字符串，应用程序的内存使用将更高（而不是更低）；这额外的内存来自于跟踪所有字符串以查找重复所涉及的簿记。
- en: 'This is the sort of option that needs thorough testing before enabling in production:
    it may help your application, though in some cases it will make things worse.
    Odds are in your favor, though: Java engineers estimate that the expected benefit
    of enabling string deduplication is 10%.'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 这种选项在投入生产之前需要进行彻底测试：它可能会帮助你的应用，尽管在某些情况下会使情况变得更糟。不过，运气会偏向你一些：Java 工程师估计启用字符串去重的预期收益为10%。
- en: 'If you want to see how string deduplication is behaving in your application,
    run it with the `-XX:+PrintStringDeduplicationStatistics` flag in Java 8, or the
    `-Xlog:gc+stringdedup*=debug` flag in Java 11\. The resulting log will look something
    like this:'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你想查看字符串去重在你的应用中的行为，可以在Java 8中使用`-XX:+PrintStringDeduplicationStatistics`标志，或在Java
    11中使用`-Xlog:gc+stringdedup*=debug`标志来运行它。生成的日志会类似于以下内容：
- en: '[PRE0]'
  id: totrans-30
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: This pass of the string deduplication thread lasted 110 ms, during which it
    found 15,604 duplicated strings (out of the 62,420 strings that had been identified
    as candidates for deduplication). The total memory saved from that was 731.4K—around
    the 10% we would hope for from this optimization.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 这次字符串去重线程的运行时间为110毫秒，在此期间找到了15,604个重复的字符串（在被识别为去重候选项的62,420个字符串中）。由此节省的总内存为731.4K，大约是我们希望从这个优化中获得的10%。
- en: The code that produced this log was set up so that 25% of the strings were duplicates,
    which is what the JVM engineers say is typical for a Java application. (In my
    experience—as I mentioned previously—the proportion of strings in a heap is closer
    to 50%; chacun à son goût.)^([1](ch12.html#idm45775544045928)) The reason that
    we didn’t save 25% of string memory is that this optimization arranges for only
    the backing character or byte array of the string to be shared; the rest of the
    string object is not shared. A string object has a 24- to 32-byte overhead for
    its other fields (the difference is due to platform implementations). Hence, two
    identical strings of 16 characters will occupy 44 (or 52) bytes each before they
    are deduplicated for a total of 80 bytes; after deduplication, they will occupy
    64 bytes. If the strings were interned (as discussed in the following section),
    they would occupy only 40 bytes.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 生成此日志的代码设置了字符串的25%是重复的，这是JVM工程师表示Java应用程序的典型情况。 （根据我的经验，正如我之前提到的，堆中字符串的比例更接近50％；
    chacun à son goût。）^([1](ch12.html#idm45775544045928)) 之所以我们没有节省25％的字符串内存是因为此优化只安排字符串的后备字符或字节数组进行共享；
    字符串对象的其余部分不共享。 字符串对象具有24到32个字节的开销用于其其他字段（差异是由于平台实现）。 因此，两个相同的16个字符的字符串在去重之前每个占用44（或52）字节；
    在去重之后，它们将占用64字节。 如果字符串被内化（如下一节所讨论的），它们将仅占用40字节。
- en: 'As I mentioned, this processing of the strings occurred concurrently with the
    application threads. But it’s actually the last stage in the process. During a
    young collection, all strings in the young generation are examined. Those that
    are promoted into the old generation become the candidates that the background
    thread examines (once the young collection has completed). In addition, recall
    the discussion from [Chapter 6](ch06.html#Collectors) about the tenuring of objects
    within the survivor spaces of the young generation: objects can ping-pong between
    the survivor spaces for a while before being promoted to the old generation. Strings
    that have a tenuring age of (by default) three—meaning they have been copied into
    a survivor space three times—also become candidates for deduplication and will
    be processed by that background thread.'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我之前提到的，这些字符串的处理是与应用线程同时进行的。但实际上，这是处理过程的最后阶段。在年轻代收集期间，所有年轻代中的字符串都会被检查。那些晋升到老年代的字符串成为后台线程检查的候选项（一旦年轻代收集完成）。此外，请回忆一下[第6章](ch06.html#Collectors)中关于对象在年轻代幸存者空间中老化的讨论：对象在成为老年代之前可能会在幸存者空间中来回移动几次。默认情况下，寿命为3的字符串（即它们被复制到幸存者空间三次）也会成为去重的候选项，并将由后台线程处理。
- en: 'This has the effect that short-lived strings are not deduplicated, which is
    likely a good thing: you probably don’t want to spend the CPU cycles and memory
    to deduplicate something that is about to be thrown away. Like tuning the tenuring
    cycle in general, changing the point at which this happens requires a lot of testing
    and is done only in unusual circumstances. But for the record, the point at which
    the tenured string is eligible for collection is controlled via the `-XX:StringDeduplicationAgeThreshold=*N*`
    flag, which has a default value of 3.'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 这导致短暂存在的字符串不会被去重，这很可能是件好事：您可能不希望花费CPU周期和内存来去重即将被丢弃的东西。与一般调整tenuring周期类似，更改此时发生的点需要大量测试，并且仅在不寻常的情况下才会进行。但为了记录，控制老年化字符串何时可收集的点是通过`-XX:StringDeduplicationAgeThreshold=*N*`标志，其默认值为3。
- en: String interning
  id: totrans-35
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 字符串国际化
- en: The typical way to handle duplicate strings at a programmatic level is to use
    the `intern()` method of the `String` class.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 在编程级别处理重复字符串的典型方式是使用`String`类的`intern()`方法。
- en: Like most optimizations, interning strings shouldn’t be done arbitrarily, but
    it can be effective if lots of duplicate strings are occupying a significant portion
    of the heap. But it does often require special tuning (and in the next section,
    we’ll explore a custom way that is beneficial in some circumstances).
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 像大多数优化一样，字符串池的国际化不应该随意进行，但如果大量重复字符串占据了堆的重要部分，则可能是有效的。但通常需要进行特殊调整（在下一节中，我们将探讨一种在某些情况下有益的自定义方式）。
- en: 'Interned strings are held in a special hash table that is in native memory
    (though the strings themselves are in the heap). This hash table differs from
    the hash table and hash maps you are familiar with in Java because this native
    hash table has a fixed size: 60,013 in Java 8 and 65,536 in Java 11. (If you’re
    on a 32-bit Windows JVM, the size is 1,009.) That means you can store only about
    32,000 interned strings before the hash table starts to have collisions.'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 国际化字符串存储在一个特殊的哈希表中，该哈希表位于本地内存中（尽管字符串本身位于堆中）。这个哈希表与您在Java中熟悉的哈希表和哈希映射不同，因为这个本地哈希表具有固定的大小：在Java
    8中为60,013，在Java 11中为65,536。（如果您使用的是32位Windows JVM，则大小为1,009。）这意味着在哈希表开始发生碰撞之前，您只能存储大约32,000个国际化字符串。
- en: The size of this table can be set when the JVM starts by using the flag `-XX:StringTableSize=`*`N`*
    (which defaults to 1,009, 60,013, or 65,536 as previously mentioned). If an application
    will intern a lot of strings, this number should be increased. The string intern
    table will operate most efficiently if that value is a prime number.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 可以通过使用标志`-XX:StringTableSize=`*`N`*（默认为1,009、60,013或65,536，如前所述）在JVM启动时设置此表的大小。如果应用程序将会国际化大量字符串，则应增加此数字。如果该值为质数，则字符串国际化表的操作效率最高。
- en: The performance of the `intern()` method is dominated by how well the string
    table size is tuned. As an example, [Table 12-1](#TableStringIntern) shows the
    total time to create and intern 1 million randomly created strings with and without
    that tuning.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: '`intern()` 方法的性能受到字符串表大小调整的主导。例如，[表12-1](#TableStringIntern)显示了使用和不使用该调整创建和国际化100万个随机创建的字符串的总时间。'
- en: Table 12-1\. Time to intern 1 million strings
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 表12-1\. 国际化100万个字符串的时间
- en: '| Tuning | 100% hit rate | 0% hit rate |'
  id: totrans-42
  prefs: []
  type: TYPE_TB
  zh: '| 调整 | 100% 命中率 | 0% 命中率 |'
- en: '| --- | --- | --- |'
  id: totrans-43
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| String table size 60013 | 4.992 ± 2.9 seconds | 2.759 ± 0.13 seconds |'
  id: totrans-44
  prefs: []
  type: TYPE_TB
  zh: '| 字符串表大小 60013 | 4.992 ± 2.9 秒 | 2.759 ± 0.13 秒 |'
- en: '| String table size 1 million | 2.446 ± 0.6 seconds | 2.737 ± 0.36 seconds
    |'
  id: totrans-45
  prefs: []
  type: TYPE_TB
  zh: '| 字符串表大小 100 万 | 2.446 ± 0.6 秒 | 2.737 ± 0.36 秒 |'
- en: Note the severe penalty for the improperly sized string intern table when there
    is a 100% hit rate. Once the table is sized according to the expected data, performance
    is drastically improved.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，当完全命中率为100%时，未正确调整大小的字符串国际化表的严重惩罚。一旦根据预期数据调整了表的大小，性能将得到显著改善。
- en: The 0% hit rate table may be a little surprising because the performance with
    and without the tuning is essentially the same. In this test case, the strings
    are discarded immediately after being interned. The internal string table functions
    as if the keys are weak references, so when the string is discarded, the string
    table can clear it. Hence, in this test case the string table never actually fills
    up; it ends up having just a few entries (since only a few strings are strongly
    held at any time).
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 0% 命中率表可能有点令人惊讶，因为调优前后的性能基本相同。在这个测试案例中，字符串在进入表后会立即被丢弃。内部字符串表的功能就像键是弱引用一样，所以当字符串被丢弃时，字符串表可以清除它。因此，在这个测试案例中，字符串表实际上从未填满过；最终只有几个条目（因为任何时候只有少量字符串被强引用）。
- en: 'In order to see how the string table is performing, run your application with
    the `-XX:+PrintStringTableStatistics` argument (which is `false` by default).
    When the JVM exits, it will print out a table like this:'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 为了查看字符串表的性能，可以使用 `-XX:+PrintStringTableStatistics` 参数（默认为 `false`）运行应用程序。当 JVM
    退出时，它将打印出如下表格：
- en: '[PRE1]'
  id: totrans-49
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'This output is from the 100% hit rate example. After an iteration of that,
    there are 2,002,784 interned strings (2 million are from our test with one warm-up
    and one measurement cycle; the remainder are from `jmh` and the JDK classes).
    The entries that most concern us are the average and maximum bucket size: we have
    to traverse on average 33 and at most 60 entries in a linked list to search an
    entry in the hash table. Ideally, the average length should be less than one and
    the maximum close to one. That’s what we see in the 0% hit rate case:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 这个输出来自于 100% 命中率的示例。在这之后的迭代中，我们有 2,002,784 个内部化字符串（200 万来自我们进行了一个预热和一个测量周期的测试；其余来自
    `jmh` 和 JDK 类）。我们最关心的条目是平均和最大桶大小：我们平均需要遍历 33 个条目，最多需要遍历 60 个条目以搜索哈希表中的一个条目。理想情况下，平均长度应小于一，最大长度接近一。这正是我们在
    0% 命中率情况下看到的情况：
- en: '[PRE2]'
  id: totrans-51
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Because the strings are quickly freed from the table, we end up with only 2,753
    entries in the table, which is fine for the default size of 60,013.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 因为字符串很快就会从表中释放，所以我们最终只有 2,753 个表条目，对于默认大小为 60,013 来说是可以接受的。
- en: 'The number of interned strings an application has allocated (and their total
    size) can also be obtained using the `jmap` command:'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 应用程序分配的内部化字符串数（及其总大小）也可以通过 `jmap` 命令获取：
- en: '[PRE3]'
  id: totrans-54
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'The penalty for setting the size of the string table too high is minimal: each
    bucket takes only 8 bytes, so having a few thousand more entries than optimal
    is a one-time cost of a few kilobytes of native (not heap) memory.'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 设置字符串表大小过高的惩罚很小：每个桶只占用 8 字节，因此比最优状态多几千个条目只是一次性的几千字节本机（非堆）内存成本。
- en: Custom string interning
  id: totrans-56
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 自定义字符串内部化
- en: Tuning a string table is a bit awkward; could we do better by just using a custom
    interning scheme that keeps the important strings in a hash map? The code for
    that was also outlined in [Chapter 2](ch02.html#SampleApplications).
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 字符串表的调优有些尴尬；我们是否可以通过仅使用保留重要字符串的自定义内部化方案来实现更好的效果？在[第二章](ch02.html#SampleApplications)中也概述了该代码。
- en: '[Table 12-2](#TableCustomIntern) points us to the answer to that question.
    In addition to using a regular `ConcurrentHashMap` to hold the interned strings,
    that table also shows the use of a `CustomConcurrentHashMap` from the extra classes
    developed as part of JSR166\. That custom map allows us to have weak references
    for the keys, so its behavior more closely mimics the string intern table.'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: '[表 12-2](#TableCustomIntern) 指引我们找到了问题的答案。除了使用常规的 `ConcurrentHashMap` 来保存内部化字符串之外，该表还展示了使用
    JSR166 开发的额外类中的 `CustomConcurrentHashMap` 的使用。该自定义映射允许我们为键使用弱引用，因此其行为更接近字符串内部化表。'
- en: Table 12-2\. Time to intern 1 million strings via custom code
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 表 12-2\. 通过自定义代码内部化 100 万个字符串所需时间
- en: '| Implementation | 100% hit rate | 0% hit rate |'
  id: totrans-60
  prefs: []
  type: TYPE_TB
  zh: '| 实现 | 100% 命中率 | 0% 命中率 |'
- en: '| --- | --- | --- |'
  id: totrans-61
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| `ConcurrentHashMap` | 7.665 ± 6.9 seconds | 5.490 ± 2.462 seconds |'
  id: totrans-62
  prefs: []
  type: TYPE_TB
  zh: '| `ConcurrentHashMap` | 7.665 ± 6.9 秒 | 5.490 ± 2.462 秒 |'
- en: '| `CustomConcurrentHashMap` | 2.743 ± 0.4 seconds | 3.684 ± 0.5 seconds |'
  id: totrans-63
  prefs: []
  type: TYPE_TB
  zh: '| `CustomConcurrentHashMap` | 2.743 ± 0.4 秒 | 3.684 ± 0.5 秒 |'
- en: 'In the 100% hit rate test, `ConcurrentHashMap` suffers from the same issues
    we saw with the internal string table: a lot of GC pressure from the entries is
    building up over each iteration. This is from a test with a 30 GB heap; smaller
    heaps will give even worse results.'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 在 100% 命中率测试中，`ConcurrentHashMap` 遭受与内部字符串表相同的问题：每次迭代都会有大量来自条目的 GC 压力。这是在一个
    30 GB 堆上的测试结果；更小的堆将会得到更糟糕的结果。
- en: 'As with all microbenchmarks, think deeply about the use case here. The `Concurren⁠t​HashMap`
    can be explicitly managed rather than the setup we have here, which keeps stuffing
    newly created strings into it. Depending on the application, that may or may not
    be easy to do; if it is easy enough, the `ConcurrentHashMap` test will show the
    same benefits as regular interning or the `CustomConcurrentHashMap` test. And
    in a real application, the GC pressure is really the point: we’re going to use
    this method only to remove duplicate strings in an attempt to save GC cycles.'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 与所有微基准测试一样，在这里深思熟虑使用情况。`Concurren⁠t​HashMap` 可以被显式管理，而不是我们目前的设置，不断地将新创建的字符串放入其中。根据应用程序的情况，这可能很容易或很难做到；如果足够容易，`ConcurrentHashMap`
    测试将显示与常规内部化或 `CustomConcurrentHashMap` 测试相同的好处。在实际应用中，GC 压力才是关键：我们只会使用这种方法来删除重复的字符串，以尝试节省
    GC 循环。
- en: 'Still, neither case is really better than the test with a properly tuned string
    table. The advantage of the custom map is that it didn’t need to have a size set
    in advance: it could resize itself as needed. Hence, it is far more adaptable
    to a range of applications than using the `intern()` method and tuning the string
    table size in an application-dependent manner.'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，没有一种情况真的比正确调整过的字符串表的测试更好。自定义映射的优点在于不需要事先设置大小：它可以根据需要调整大小。因此，它比使用 `intern()`
    方法并根据应用程序的情况调整字符串表大小要适应更多应用程序。
- en: String Concatenation
  id: totrans-67
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 字符串连接
- en: 'String concatenation is another area of potential performance pitfalls. Consider
    a simple string concatenation like this:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 字符串连接是另一个潜在的性能陷阱。考虑一个简单的字符串连接，如下所示：
- en: '[PRE4]'
  id: totrans-69
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Special optimizations in Java can handle this construct (though the details
    differ between releases).
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: Java 中的特殊优化可以处理这种结构（尽管各版本之间的细节有所不同）。
- en: 'In Java 8, the `javac` compiler turns that statement into this code:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 在 Java 8 中，`javac` 编译器将该语句转换为以下代码：
- en: '[PRE5]'
  id: totrans-72
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: The JVM has special code to handle this kind of construct (which is controlled
    by setting the `-XX:+OptimizeStringConcat` flag, which is `true` by default).
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: JVM 有特殊的代码来处理这种类型的结构（通过设置 `-XX:+OptimizeStringConcat` 标志来控制，其默认值为 `true`）。
- en: In Java 11, the `javac` compiler produces quite different bytecode; that code
    calls a special method within the JVM itself that optimizes the string concatenation.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 在 Java 11 中，`javac` 编译器生成的字节码非常不同；该代码调用 JVM 本身内部的特殊方法来优化字符串连接。
- en: 'This is one of the few times where the bytecode between releases matter. Typically,
    when you move to a newer release, there’s no need to recompile old code: the bytecode
    will be the same. (You’ll want to compile new code with the new compiler to use
    new language features, of course.) But this particular optimization depends on
    the actual bytecode. If you compile code that performs string concatenation with
    Java 8 and run it with Java 11, the Java 11 JDK will apply the same optimization
    it did in Java 8\. The code will still be optimized and run quite fast.'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 这是少数情况之一，其中字节码在不同版本之间很重要。通常，当您迁移到较新版本时，无需重新编译旧代码：字节码将保持不变。（当然，您会希望使用新编译器编译新代码以使用新的语言特性。）但是，此特定优化取决于实际的字节码。如果您使用
    Java 8 编译并运行执行字符串连接的代码，Java 11 JDK 将应用与 Java 8 中相同的优化。代码仍将被优化并运行得相当快。
- en: If you recompile the code under Java 11, though, the bytecode will use the new
    optimizations and potentially be even faster.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您在 Java 11 下重新编译代码，字节码将使用新的优化，并且可能会更快。
- en: 'Let’s consider the following three cases that concatenate two strings:'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们考虑以下三种连接两个字符串的情况：
- en: '[PRE6]'
  id: totrans-78
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: The first method is how we would code this operation by hand. The second method
    (when compiled with Java 11) will produce the latest optimizations, and the final
    method (no matter which compiler is used) will be optimized the same way in Java
    8 and Java 11.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 第一种方法是我们手工编写此操作的方式。第二种方法（在使用 Java 11 编译时）将产生最新的优化，而最终方法（无论使用哪个编译器）在 Java 8 和
    Java 11 中将以相同方式进行优化。
- en: '[Table 12-3](#TableSingleConcat) shows the results of these operations.'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: '[表 12-3](#TableSingleConcat) 显示了这些操作的结果。'
- en: Table 12-3\. Performance of single concatenation
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 表 12-3\. 单个连接的性能
- en: '| Mode | Time per operation |'
  id: totrans-82
  prefs: []
  type: TYPE_TB
  zh: '| 模式 | 每次操作的时间 |'
- en: '| --- | --- |'
  id: totrans-83
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| JDK 11 optimization | 47.7 ± 0.3 ns |'
  id: totrans-84
  prefs: []
  type: TYPE_TB
  zh: '| JDK 11 优化 | 47.7 ± 0.3 ns |'
- en: '| JDK 8 optimization | 42.9 ± 0.3 ns |'
  id: totrans-85
  prefs: []
  type: TYPE_TB
  zh: '| JDK 8 优化 | 42.9 ± 0.3 ns |'
- en: '| String builder | 87.8 ± 0.7 ns |'
  id: totrans-86
  prefs: []
  type: TYPE_TB
  zh: '| 字符串构建器 | 87.8 ± 0.7 ns |'
- en: 'In this case, there’s little real difference between old (Java 8) and new (Java
    11) concatenation optimizations; though `jmh` tells us that the difference is
    statistically significant, they are not particularly important. The key point
    is that both optimizations are better than handcoding this simple case. This is
    somewhat surprising, since the handcoded case appears to be simpler: it contains
    one less call to the `append()` method than the JDK 8 case and so is performing
    nominally less work. But the string concatenation optimization within the JVM
    doesn’t pick up that particular pattern, so it ends up being slower.'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，旧（Java 8）和新（Java 11）连接优化之间几乎没有实质性的区别；尽管 `jmh` 告诉我们这种差异在统计上是显著的，但它们并不特别重要。关键点是这两种优化都优于手动编码这个简单的情况。这有点令人惊讶，因为手动编码的情况似乎更简单：与
    JDK 8 情况相比，它调用了一个更少的 `append()` 方法，因此执行的工作名义上较少。但是 JVM 内的字符串连接优化没有捕捉到这种特定模式，所以它最终会更慢。
- en: 'The Java 8 optimization doesn’t carry over for all concatenations, though.
    We can slightly alter our tests like this:'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: JDK 8 优化并不适用于所有连接，但我们可以略微改变我们的测试，如下所示：
- en: '[PRE7]'
  id: totrans-89
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Now the performance is different, as [Table 12-4](#TableDoubleConcat) shows.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 现在性能不同了，正如 [表 12-4](#TableDoubleConcat) 所示。
- en: Table 12-4\. Performance of concatenation with a double value
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 表 12-4\. 使用双精度值连接的性能
- en: '| Mode | Time per operation |'
  id: totrans-92
  prefs: []
  type: TYPE_TB
  zh: '| 模式 | 每次操作所需时间 |'
- en: '| --- | --- |'
  id: totrans-93
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| JDK 11 optimization | 49.4 ± 0.6 ns |'
  id: totrans-94
  prefs: []
  type: TYPE_TB
  zh: '| JDK 11 优化 | 49.4 ± 0.6 ns |'
- en: '| JDK 8 optimization | 77.0 ± 1.9 ns |'
  id: totrans-95
  prefs: []
  type: TYPE_TB
  zh: '| JDK 8 优化 | 77.0 ± 1.9 ns |'
- en: The JDK 11 time is similar to the last example, even though we’re appending
    a new value and doing slightly more work. But the JDK 8 time is much worse—it
    is about 50% slower. This is not really because of the extra concatenation; it’s
    because of the *type* of that concatenation. The JDK 8 optimization works well
    with strings and integers, but it cannot handle doubles (and most other kinds
    of data). In those cases, the JDK 8 code skips the special optimization and behaves
    like the previous handcoded test.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: JDK 11 的时间与最后一个示例类似，即使我们附加了一个新值并且做了稍微更多的工作。但是 JDK 8 的时间要糟糕得多——它慢了大约 50%。这并不完全是因为额外的连接操作；而是因为连接操作的*类型*。JDK
    8 优化对字符串和整数效果很好，但无法处理双精度（以及大多数其他类型的数据）。在这些情况下，JDK 8 代码会跳过特殊优化，并像之前手动编码的测试一样运行。
- en: 'Neither of these optimizations carries over when we do multiple concatenation
    operations, particularly those within a loop. Consider these tests:'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们进行多个连接操作时，这两种优化都不会延续，特别是在循环内部进行的操作。考虑以下测试：
- en: '[PRE8]'
  id: totrans-98
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: Now the results favor handcoding, which makes sense. The Java 8 implementation,
    in particular, has to create a new `StringBuilder` operation on each iteration
    of the loop, and even in Java 11, the overhead of creating a string on each loop
    (rather than building up in the string builder) takes its toll. These results
    are in [Table 12-5](#TableStringConcatLoop).
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 现在结果更有利于手动编码，这是有道理的。特别是 Java 8 实现，必须在每次循环迭代中创建一个新的 `StringBuilder` 操作，即使在 Java
    11 中，每次循环创建字符串的开销（而不是在字符串构建器中累加）也会产生影响。这些结果显示在 [表 12-5](#TableStringConcatLoop)
    中。
- en: Table 12-5\. Performance of multiple string concatenations
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 表 12-5\. 多个字符串连接的性能
- en: '| Mode | 10 strings | 1,000 strings |'
  id: totrans-101
  prefs: []
  type: TYPE_TB
  zh: '| 模式 | 10 个字符串 | 1,000 个字符串 |'
- en: '| --- | --- | --- |'
  id: totrans-102
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| JDK 11 code | 613 ± 8 ns | 2,463 ± 55 μs |'
  id: totrans-103
  prefs: []
  type: TYPE_TB
  zh: '| JDK 11 代码 | 613 ± 8 ns | 2,463 ± 55 μs |'
- en: '| JDK 8 code | 584 ± 8 ns | 2,602 ± 209 μs |'
  id: totrans-104
  prefs: []
  type: TYPE_TB
  zh: '| JDK 8 代码 | 584 ± 8 ns | 2,602 ± 209 μs |'
- en: '| String builder | 412 ± 2 ns | 38 ± 211 μs |'
  id: totrans-105
  prefs: []
  type: TYPE_TB
  zh: '| 字符串构建器 | 412 ± 2 ns | 38 ± 211 μs |'
- en: 'Bottom line: Don’t be afraid to use concatenation when it can be done on a
    single (logical) line, but never use string concatenation inside a loop unless
    the concatenated string is not used on the next loop iteration. Otherwise, always
    explicitly use a `StringBuilder` object for better performance. In [Chapter 1](ch01.html#Introduction),
    I argued that there are times to “prematurely” optimize, when that phrase is used
    in a context meaning simply “write good code.” This is a prime example.'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 要点：不要害怕在可以在单个（逻辑）行上完成连接时使用连接，但是除非连接的字符串不在下一次循环迭代中使用，否则永远不要在循环内部使用字符串连接。否则，始终明确使用
    `StringBuilder` 对象以获得更好的性能。在 [第 1 章](ch01.html#Introduction) 中，我提到了有时候需要“过早”进行优化，当该短语用于简单表示“编写良好的代码”时。这是一个典型的例子。
- en: Quick Summary
  id: totrans-107
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 快速摘要
- en: One-line concatenation of strings yields good performance.
  id: totrans-108
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 字符串的一行连接表现良好。
- en: For multiple concatenation operations, make sure to use `StringBuilder`.
  id: totrans-109
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于多个连接操作，请务必使用 `StringBuilder`。
- en: One-line concatenation of strings involving certain types will be significantly
    faster when recompiled in JDK 11.
  id: totrans-110
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在JDK 11中重新编译涉及某些类型的字符串一行连接将显著提高速度。
- en: Buffered I/O
  id: totrans-111
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 缓冲I/O
- en: 'When I joined the Java Performance Group in 2000, my boss had just published
    the first ever book on Java performance, and one of the hottest topics in those
    days was buffered I/O. Fourteen years later, I was prepared to assume the topic
    was old hat and leave it out of the first edition of this book. Then, in the week
    I started the outline for the first edition, I filed bugs against two unrelated
    projects in which unbuffered I/O was greatly hampering performance. A few months
    later, as I was working on an example for the first edition, I scratched my head
    as I wondered why my “optimization” was so slow. Then I realized: stupid, you
    forgot to buffer the I/O correctly.'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 当我在2000年加入Java性能组时，我的老板刚刚出版了关于Java性能的第一本书，那时最热门的话题之一是缓冲I/O。十四年后，我准备认为这个话题已经老掉牙，决定在第一版书中不再提及它。然而，就在我开始第一版大纲的那周，我在两个无关的项目中提交了缓冲I/O严重影响性能的bug报告。几个月后，当我在为第一版书编写示例时，我摸着头想知道为什么我的“优化”如此缓慢。后来我意识到：傻瓜，你忘记了正确地进行I/O缓冲。
- en: 'As for the second edition: in the two weeks before I revisited this section,
    three colleagues came to me who had made the same mistake in buffering I/O as
    I had in the example for the first edition.'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 至于第二版：在我重新审视这一部分之前的两周内，有三位同事来找我，他们在缓冲I/O方面犯了我在第一版示例中犯的同样错误。
- en: 'So let’s talk about buffered I/O performance. The `InputStream.read()` and
    `OutputStream.write()` methods operate on a single character. Depending on the
    resource they are accessing, these methods can be very slow. A `FileInputStream`
    that uses the `read()` method will be excruciatingly slow: each method invocation
    requires a trip into the kernel to fetch 1 byte of data. On most operating systems,
    the kernel will have buffered the I/O, so (luckily) this scenario doesn’t trigger
    a disk read for each invocation of the `read()` method. But that buffer is held
    in the kernel, not the application, and reading a single byte at a time means
    making an expensive system call for each method invocation.'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 那么让我们来谈谈缓冲I/O的性能。`InputStream.read()`和`OutputStream.write()`方法操作一个字符。根据它们访问的资源，这些方法可能非常慢。使用`read()`方法的`FileInputStream`将非常慢：每次方法调用都需要进入内核以获取1字节数据。在大多数操作系统上，内核将对I/O进行缓冲，因此（幸运的是）这种情况不会触发每次`read()`方法调用的磁盘读取。但是该缓冲区位于内核中，而不是应用程序中，每次逐字节读取都意味着为每个方法调用进行昂贵的系统调用。
- en: 'The same is true of writing data: using the `write()` method to send a single
    byte to a `FileOutputStream` requires a system call to store the byte in a kernel
    buffer. Eventually (when the file is closed or flushed), the kernel will write
    out that buffer to the disk.'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 写入数据也是一样的：使用`write()`方法将单个字节发送到`FileOutputStream`需要一个系统调用来将字节存储到内核缓冲区。最终（当文件关闭或刷新时），内核将把该缓冲区写入磁盘。
- en: For file-based I/O using binary data, always use `BufferedInputStream` or `BufferedOutputStream`
    to wrap the underlying file stream. For file-based I/O using character (string)
    data, always wrap the underlying stream with `BufferedReader` or `BufferedWriter`.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 对于使用二进制数据的基于文件的I/O，请始终使用`BufferedInputStream`或`BufferedOutputStream`来包装底层文件流。对于使用字符（字符串）数据的基于文件的I/O，请始终使用`BufferedReader`或`BufferedWriter`来包装底层流。
- en: Although this performance issue is most easily understood when discussing file
    I/O, it is a general issue that applies to almost every sort of I/O. The streams
    returned from a socket (via the `getInputStream()` or `getOutputStream()` methods)
    operate in the same manner, and performing I/O one byte at a time over a socket
    is quite slow. Here, too, always make sure that the streams are appropriately
    wrapped with a buffering filter stream.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管讨论文件I/O时最容易理解这个性能问题，但这是一个通用问题，几乎适用于每一种类型的I/O。从套接字返回的流（通过`getInputStream()`或`getOutputStream()`方法）以相同的方式操作，通过套接字逐字节进行I/O操作会非常慢。在这里，同样确保流适当地包装在一个缓冲过滤流中。
- en: 'There are more subtle issues when using the `ByteArrayInputStream` and `ByteArrayOutputStream`
    classes. These classes are essentially just big in-memory buffers to begin with.
    In many cases, wrapping them with a buffering filter stream means that data is
    copied twice: once to the buffer in the filter stream and once to the buffer in
    the `ByteArrayInputStream` (or vice versa for output streams). Absent the involvement
    of any other streams, buffered I/O should be avoided in that case.'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 当使用`ByteArrayInputStream`和`ByteArrayOutputStream`类时，会出现更微妙的问题。这些类本质上只是大的内存缓冲区。在许多情况下，将它们与缓冲过滤流包装在一起意味着数据被复制两次：一次到过滤流的缓冲区，一次到`ByteArrayInputStream`的缓冲区（或者对于输出流来说反过来）。在没有其他流参与的情况下，应避免缓冲I/O。
- en: When other filtering streams are involved, the question of whether to buffer
    becomes more complicated. Later in this chapter, you’ll see an example of object
    serialization that involves multiple filtering streams using the `ByteArrayOutputStream`,
    `ObjectOutputStream`, and `GZIPOutputStream` classes.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 当涉及其他过滤流时，是否进行缓冲的问题变得更加复杂。本章后面，您将看到一个涉及多个过滤流（使用`ByteArrayOutputStream`、`ObjectOutputStream`和`GZIPOutputStream`类）的对象序列化示例。
- en: 'Without the compressing output stream, the filters for that example look like
    this:'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 没有压缩输出流的情况下，该示例的过滤器如下所示：
- en: '[PRE9]'
  id: totrans-121
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: In this case, wrapping the `baos` stream in a `BufferedOutputStream` would suffer
    a performance penalty from copying the data one extra time.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，将`baos`流包装在`BufferedOutputStream`中将导致额外复制数据，从而降低性能。
- en: 'Once we add compression, though, the best way to write the code is like this:'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦我们添加了压缩，编写代码的最佳方式如下：
- en: '[PRE10]'
  id: totrans-124
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: Now it is necessary to buffer the output stream, because `GZIPOutputStream`
    operates more efficiently on a block of data than it does on single bytes of data.
    In either case, `ObjectOutputStream` will send single bytes of data to the next
    stream. If that next stream is the ultimate destination—the `ByteArrayOutputStream`—no
    buffering is necessary. If another filtering stream is in the middle (such as
    `GZIPOutputStream` in this example), buffering is often necessary.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 现在有必要对输出流进行缓冲，因为`GZIPOutputStream`在处理数据块时比单个字节的效率更高。无论哪种情况，`ObjectOutputStream`都会向下一个流发送单个字节的数据。如果下一个流是最终目的地——`ByteArrayOutputStream`，则不需要缓冲。如果在中间有另一个过滤流（比如本例中的`GZIPOutputStream`），则通常需要缓冲。
- en: No general rule exists about when to use a buffered stream interposed between
    two other streams. Ultimately, it will depend on the type of streams involved,
    but the likely cases will all operate better if they are fed a block of bytes
    (from the buffered stream) rather than a series of single bytes (from `ObjectOutputStream`).
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 关于何时在两个其他流之间使用缓冲流没有一般规则。最终将取决于涉及的流类型，但如果从缓冲流中提供数据块（而不是从`ObjectOutputStream`提供单个字节序列），则可能情况都会更好。
- en: The same situation applies to input streams. In this specific case, `GZIPInputStream`
    will operate more efficiently on a block of bytes; in the general case, streams
    that are interposed between `ObjectInputStream` and the original byte source will
    also be better off with a block of bytes.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 对于输入流也是同样的情况。在这种特定情况下，`GZIPInputStream`在数据块上的操作效率更高；在一般情况下，介于`ObjectInputStream`和原始字节源之间的流也会更喜欢数据块。
- en: Note that this case applies in particular to stream encoders and decoders. When
    you convert between bytes and characters, operating on as large a piece of data
    as possible will provide the best performance. If single bytes or characters are
    fed to encoders and decoders, they will suffer from bad performance.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，这种情况特别适用于流编码器和解码器。当在字节和字符之间转换时，尽可能处理尽可能大的数据块将提供最佳性能。如果将单个字节或字符提供给编码器和解码器，它们的性能将会受到影响。
- en: For the record, not buffering the gzip streams is exactly the mistake I made
    when writing that compression example. It was a costly mistake, as the data in
    [Table 12-6](#TableBufferedIO) shows.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 事实上，没有对gzip流进行缓冲正是我在编写该压缩示例时犯的错误。正如[表 12-6](#TableBufferedIO)中的数据所示，这是一个代价高昂的错误。
- en: Table 12-6\. Time to serialize and deserialize `Stock` object with compression
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 表 12-6\. 使用压缩序列化和反序列化`Stock`对象所需的时间
- en: '| Mode | Time |'
  id: totrans-131
  prefs: []
  type: TYPE_TB
  zh: '| 模式 | 时间 |'
- en: '| --- | --- |'
  id: totrans-132
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| Unbuffered compression/decompression | 21.3 ± 8 ms |'
  id: totrans-133
  prefs: []
  type: TYPE_TB
  zh: '| 未缓冲的压缩/解压缩 | 21.3 ± 8 ms |'
- en: '| Buffered compression/decompression | 5.7 ± 0.08 ms |'
  id: totrans-134
  prefs: []
  type: TYPE_TB
  zh: '| 缓冲压缩/解压缩 | 5.7 ± 0.08 ms |'
- en: The failure to properly buffer the I/O resulted in as much as a four times performance
    penalty.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 没有正确进行I/O缓冲导致了高达四倍的性能惩罚。
- en: Quick Summary
  id: totrans-136
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 快速总结
- en: Issues around buffered I/O are common because of the default implementation
    of the simple input and output stream classes.
  id: totrans-137
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 因为简单输入和输出流类的默认实现，围绕缓冲 I/O 的问题是很常见的。
- en: I/O must be properly buffered for files and sockets, as well as for internal
    operations like compression and string encoding.
  id: totrans-138
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于文件和套接字以及压缩和字符串编码等内部操作，I/O 必须进行适当的缓冲。
- en: Classloading
  id: totrans-139
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 类加载
- en: The performance of classloading is the bane of anyone attempting to optimize
    either program startup or deployment of new code in a dynamic system.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 类加载性能是任何试图优化程序启动或在动态系统中部署新代码的人的困扰。
- en: 'There are many reasons for that. To begin, the class data (i.e., the Java bytecode)
    is typically not quickly accessible. That data must be loaded from disk or from
    the network, it must be found in one of several JAR files on the classpath, and
    it must be found in one of several classloaders. There are some ways to help this
    along: some frameworks cache classes they read from the network into a hidden
    directory so that next time it starts the same application, it can read the classes
    more quickly. Packaging an application into fewer JAR files will also speed up
    its classloading performance.'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 有很多原因导致这种情况。首先，类数据（即 Java 字节码）通常不容易访问。这些数据必须从磁盘或网络加载，它们必须在类路径上的几个 JAR 文件中找到，并且它们必须由几个类加载器中的一个找到。有一些方法可以帮助加快这个过程：一些框架将它们从网络读取的类缓存到一个隐藏目录中，以便在下次启动同一应用程序时可以更快地读取这些类。将应用程序打包成更少的
    JAR 文件也将加快其类加载性能。
- en: In this section, we’ll look at a new feature of Java 11 to speed up classloading.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一节中，我们将看一下 Java 11 的一个新特性，以加快类加载速度。
- en: Class Data Sharing
  id: totrans-143
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 类数据共享
- en: '*Class data sharing* (*CDS*) is a mechanism whereby the metadata for classes
    can be shared between JVMs. This can be useful for saving memory when running
    multiple JVMs: normally, each JVM would have its own class metadata, and the separate
    copies would occupy some physical memory. If that metadata is shared, only one
    copy needs to reside in memory.'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: '*类数据共享*（*CDS*）是一种机制，可以在 JVM 之间共享类的元数据。当运行多个 JVM 时，这对于节省内存很有用：通常每个 JVM 都会有自己的类元数据，而这些单独的副本会占用一些物理内存。如果共享这些元数据，只需要在内存中保留一份副本。'
- en: It turns out that CDS is very useful for single JVMs because it can also improve
    their startup time.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 结果表明，对单个 JVM 来说，CDS 非常有用，因为它还可以改善启动时间。
- en: Class data sharing is available in Java 8 (and previous releases), but with
    the restriction that it applies only to the classes in *rt.jar* and only when
    the serial collector is used with the client JVM. In other words, it helps somewhat
    on 32-bit, single-CPU, Windows desktop machines.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 在 Java 8（及之前的版本）中提供了类数据共享，但有一个限制，即仅适用于 *rt.jar* 中的类，并且仅在使用客户端 JVM 的串行收集器时。换句话说，它在
    32 位单 CPU Windows 桌面机上有所帮助。
- en: 'In Java 11, CDS is generally available on all platforms, though it doesn’t
    work out of the box because there is no default shared archive of the class metadata.
    Java 12 does have a default shared archive of the common JDK classes, so all applications
    will by default get some startup (and memory) benefits. In either case, we can
    do better by generating a more complete shared archive for our application, because
    in Java 11, CDS can work with any set of classes, no matter which classloader
    loads them and which JAR or module they are loaded from. One restriction applies:
    CDS works only for classes loaded from modules or JAR files. You cannot share
    (or quickly load) classes from a filesystem or network URL.'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 在 Java 11 中，CDS 在所有平台上通常是可用的，尽管它不是开箱即用的，因为没有默认的共享类元数据存档。 Java 12 具有常见 JDK 类的默认共享存档，因此所有应用程序默认会获得一些启动（和内存）的好处。无论哪种情况，通过为我们的应用程序生成更完整的共享存档，我们可以做得更好，因为在
    Java 11 中，CDS 可以与任何一组类一起工作，无论哪个类加载器加载它们，它们从哪个 JAR 或模块加载。有一个限制：CDS 仅适用于从模块或 JAR
    文件加载的类。您不能共享（或快速加载）来自文件系统或网络 URL 的类。
- en: 'In a sense, this means there are two flavors of CDS: *regular CDS* (which shares
    the default JDK classes) and *application class data sharing*, which shares any
    set of classes. Application class data sharing was actually introduced in Java
    10, and it worked differently than regular CDS: there were different command-line
    arguments for programs to use it. That distinction is now obsolete, and CDS in
    Java 11 and beyond works the same way regardless of the classes being shared.'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 从某种意义上说，这意味着有两种 CDS：*常规 CDS*（共享默认的 JDK 类）和*应用程序类数据共享*，它可以共享任何一组类。应用程序类数据共享实际上是在
    Java 10 中引入的，并且它的工作方式与常规 CDS 不同：程序需要使用不同的命令行参数来使用它。这种区分现在已经过时，在 Java 11 及以后的版本中，不管被共享的类是什么，CDS
    的工作方式都是相同的。
- en: The first thing required to use CDS is a shared archive of classes. As I mentioned,
    Java 12 comes with a default shared archive of classes, which is located in *$JAVA_HOME/lib/server/classes.jsa*
    (or *%JAVA_HOME%\bin\server\classes.jsa* on Windows). That archive has data for
    12,000 JDK classes, so its coverage of the core classes is pretty broad. To generate
    your own archive, you will first need a list of all the classes for which you
    want to enable sharing (and hence fast loading). That list can include JDK classes
    and application-level classes.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 CDS 所需的第一件事是共享类的共享存档。正如我提到的，Java 12 自带了一个默认的 JDK 类共享存档，位于 *$JAVA_HOME/lib/server/classes.jsa*（或在
    Windows 上是 *%JAVA_HOME%\bin\server\classes.jsa*）。该存档包含 12,000 个 JDK 类的数据，因此其核心类的覆盖范围非常广泛。要生成你自己的存档，首先需要一个你想启用共享的所有类的列表（从而实现快速加载）。该列表可以包括
    JDK 类和应用程序级别的类。
- en: There are many ways to get such a list, but the easiest is to run your application
    with the `-XX:+DumpLoadedClassList=filename` flag, which will produce (in *filename*)
    a list of all the classes that your application has loaded.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 获取这样一个列表有很多方法，但最简单的是使用带有 `-XX:+DumpLoadedClassList=filename` 标志运行你的应用程序，这将在
    *filename* 中生成你的应用程序已加载的所有类的列表。
- en: 'The second step is to use that class list to generate the shared archive like
    this:'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 第二步是使用该类列表生成共享存档，像这样：
- en: '[PRE11]'
  id: totrans-152
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: This will create a new shared archive file with the given name (here, *myclasses.jsa*)
    based on the list of files. You must also set up the classpath the same as you
    would to run the application (i.e., using either the `-cp` or `-jar` argument
    you would normally use to run the application).
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 这将根据文件列表创建一个新的共享存档文件，并使用给定的名称（这里是 *myclasses.jsa*）。你必须设置类路径与正常运行应用程序时相同（即使用
    `-cp` 或 `-jar` 参数）。
- en: 'This command will generate a lot of warnings about classes it cannot find.
    That is expected since this command cannot find dynamically generated classes:
    proxy classes, reflection-based classes, and so on. If you see a warning for a
    class you expected to be loaded, try adjusting the classpath for that command.
    Not finding all the classes isn’t a problem; it just means they will be loaded
    normally (from the classpath) rather than from the shared archive. Loading that
    particular class will hence be a little slower, but a few such classes like that
    isn’t going to be noticeable, so don’t sweat everything at this step.'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 这个命令将会生成大量关于找不到的类的警告。这是预期的，因为这个命令无法找到动态生成的类：代理类，基于反射的类等等。如果你看到一个你期望加载的类的警告，试着调整该命令的类路径。不能找到所有类并不是问题；这意味着它们将会从类路径正常加载，而不是从共享存档加载。因此加载特定的类会稍慢一些，但是这样的几个类几乎不会被注意到，所以在这一步不要太过于担心。
- en: 'Finally, you use the shared archive to run the application:'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，使用共享存档来运行应用程序：
- en: '[PRE12]'
  id: totrans-156
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'A few remarks about this command. First, the `-Xshare` command has three possible
    values:'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 对于这个命令有几点备注。首先，`-Xshare` 命令有三个可能的取值：
- en: '`off`'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: '`off`'
- en: Don’t use class data sharing.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 不要使用类数据共享。
- en: '`on`'
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: '`on`'
- en: Always use class data sharing.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 一定要使用类数据共享。
- en: '`auto`'
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: '`auto`'
- en: Attempt to use class data sharing.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 尝试使用类数据共享。
- en: CDS depends on mapping the shared archive into a memory region, and under certain
    (mostly rare) circumstances, that can fail. If `-Xshare:on` is specified, the
    application will not run if that happens. Hence, the default value is `-Xshare:auto`,
    which means that CDS will normally be used, but if for some reason the archive
    cannot be mapped, the application will proceed without it. Since the default for
    this flag is `auto`, we don’t actually have to specify it in the preceding command.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: CDS 依赖于将共享存档映射到内存区域，而在某些（大多数情况下是罕见的）情况下，这可能会失败。如果指定了 `-Xshare:on`，应用程序将在此情况发生时无法运行。因此，默认值是
    `-Xshare:auto`，这意味着通常会使用 CDS，但如果由于某种原因无法映射存档，则应用程序将在没有它的情况下继续运行。由于此标志的默认值为 `auto`，因此实际上不必在前述命令中指定它。
- en: Second, this command gives the location of the shared archive. The default value
    for the `SharedArchiveFile` flag is the *classes.jsa* path mentioned earlier (within
    the JDK *server* directory). So in Java 12 (where that file is present), we needn’t
    give any command-line arguments if we just want to use the (JDK-only) default
    shared archive.
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 其次，此命令提供了共享存档的位置。`SharedArchiveFile` 标志的默认值是前面提到的 *classes.jsa* 路径（位于 JDK *server*
    目录内）。因此，在 Java 12 中（其中存在该文件），如果我们只想使用（仅限 JDK 的）默认共享存档，就不需要提供任何命令行参数。
- en: 'In one common case, loading the shared archive can fail: the classpath used
    to generate the shared archive must be a subset of the classpath used to run an
    application, and the JAR files must not have changed since the shared archive
    was created. So you don’t want to generate a shared archive of classes other than
    the JDK and put that in the default location, since the classpath for arbitrary
    commands will not match.'
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 在一种常见情况下，加载共享存档可能会失败：用于生成共享存档的类路径必须是用于运行应用程序的类路径的子集，并且自共享存档创建以来 JAR 文件不能发生更改。因此，您不希望生成除
    JDK 外的类的共享存档，并将其放在默认位置，因为任意命令的类路径将不匹配。
- en: Also beware of changing the JAR files. If you use the default setting of `-Xshare:auto`
    and the JAR file is changed, the application will still run, even though the shared
    archive is not being used. Worse, there will be no warning about that; the only
    effect you’ll see is that the application starts more slowly. That’s a reason
    to consider specifying `-Xshare:on` instead of the default, though there are other
    reasons the shared archive could fail.
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，还要注意更改 JAR 文件。如果使用 `-Xshare:auto` 的默认设置并更改了 JAR 文件，则应用程序仍将运行，尽管未使用共享存档。更糟糕的是，不会收到任何警告；您唯一能看到的影响是应用程序启动更慢。这是考虑指定
    `-Xshare:on` 而不是默认设置的原因之一，尽管共享存档可能失败的其他原因还有很多。
- en: 'To validate that classes are being loaded from the shared archive, include
    class loading logging (`-Xlog:class+load=info`) in your command line; you’ll see
    the usual classloading output, and classes that are loaded from the shared archive
    will show up like this:'
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 要验证是否从共享存档加载类，请在命令行中包含类加载日志记录（`-Xlog:class+load=info`）；您将看到通常的类加载输出，并且从共享存档加载的类将显示如下：
- en: '[PRE13]'
  id: totrans-169
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: Class data sharing benefits
  id: totrans-170
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 类数据共享的好处
- en: The benefit of class data sharing for startup time depends, obviously, on the
    number of classes to be loaded. [Table 12-7](#TableCDS) shows the time required
    to start the sample stock server application in the book examples; that requires
    loading 6,314 classes.
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 类数据共享对启动时间的好处显然取决于要加载的类的数量。[表 12-7](#TableCDS) 显示了在书籍示例中启动样本股票服务器应用程序所需的时间；需要加载
    6,314 个类。
- en: Table 12-7\. Time to start an application with CDS
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 表 12-7\. 使用 CDS 启动应用程序所需的时间
- en: '| CDS mode | Startup time |'
  id: totrans-173
  prefs: []
  type: TYPE_TB
  zh: '| CDS 模式 | 启动时间 |'
- en: '| --- | --- |'
  id: totrans-174
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| `-Xshare:off` | 8.9 seconds |'
  id: totrans-175
  prefs: []
  type: TYPE_TB
  zh: '| `-Xshare:off` | 8.9 秒 |'
- en: '| `-Xshare:on` (default) | 9.1 seconds |'
  id: totrans-176
  prefs: []
  type: TYPE_TB
  zh: '| `-Xshare:on`（默认） | 9.1 秒 |'
- en: '| `-Xshare:on` (custom) | 7.0 seconds |'
  id: totrans-177
  prefs: []
  type: TYPE_TB
  zh: '| `-Xshare:on`（自定义） | 7.0 秒 |'
- en: In the default case, we’re using only the shared archive for the JDK; the last
    row is the custom shared archive of all the application classes. In this case,
    CDS saves us 30% in startup time.
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 在默认情况下，我们仅使用 JDK 的共享存档；最后一行是所有应用程序类的自定义共享存档。在这种情况下，CDS 可以节省我们 30% 的启动时间。
- en: CDS will also save us some memory since the class data will be shared among
    processes. Overall, as you saw in the examples in [Chapter 8](ch08.html#NativeMemory),
    the class data in native memory is proportionately small, particularly compared
    to the application heap. In a large program with lots of classes, CDS will save
    more memory, though a large program is likely to need an even larger heap, making
    the proportional savings still small. Still, in an environment where you are particularly
    starved for native memory and running multiple copies of the JVM that are using
    a significant number of the same classes, CDS will offer some benefit for memory
    savings as well.
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: CDS 还会节省一些内存，因为类数据将在进程之间共享。总体而言，正如您在[第 8 章](ch08.html#NativeMemory) 中看到的例子一样，在本地内存中的类数据相对较小，特别是与应用程序堆相比。在具有大量类的大型程序中，CDS
    将节省更多内存，尽管大型程序可能需要更大的堆，使比例节省仍然很小。然而，在一个特别缺乏本机内存并且运行多个使用大量相同类的 JVM 副本的环境中，CDS 也将为内存节省提供一些好处。
- en: Quick Summary
  id: totrans-180
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 快速总结
- en: The best way to speed up classloading is to create a class data sharing archive
    for the application. Luckily, this requires no programming changes.
  id: totrans-181
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 加快类加载速度的最佳方法是为应用程序创建一个类数据共享存档。幸运的是，这不需要进行任何编程更改。
- en: Random Numbers
  id: totrans-182
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 随机数
- en: 'The next set of APIs we’ll look at involve random number generation. Java comes
    with three standard random number generator classes: `java.util.Random`, `java.util.concurrent.ThreadLocalRandom`,
    and `java.security.SecureRandom`. These three classes have important performance
    differences.'
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来我们将看一些涉及随机数生成的 API。Java 自带三个标准的随机数生成器类：`java.util.Random`、`java.util.concurrent.ThreadLocalRandom`
    和 `java.security.SecureRandom`。这三个类具有重要的性能差异。
- en: 'The difference between the `Random` and `ThreadLocalRandom` classes is that
    the main operation (the `nextGaussian()` method) of the `Random` class is synchronized.
    That method is used by any method that retrieves a random value, so that lock
    can become contended no matter how the random number generator is used: if two
    threads use the same random number generator at the same time, one will have to
    wait for the other to complete its operation. This is why the thread-local version
    is available: when each thread has its own random number generator, the synchronization
    of the `Random` class is no longer an issue. (As discussed in [Chapter 7](ch07.html#Memory),
    the thread-local version also provides significant performance benefits because
    it is reusing an expensive-to-create object.)'
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: '`Random`类和`ThreadLocalRandom`类之间的区别在于`Random`类的主要操作（`nextGaussian()`方法）是同步的。该方法被检索随机值的任何方法使用，因此无论如何使用随机数生成器，该锁定都可能成为争用点：如果两个线程同时使用相同的随机数生成器，则其中一个将不得不等待另一个完成其操作。这就是为什么有线程本地版本可用的原因：当每个线程有自己的随机数生成器时，`Random`类的同步不再是问题。（正如在[第
    7 章](ch07.html#Memory) 中讨论的那样，线程本地版本还提供显著的性能优势，因为它重用了昂贵的创建对象。）'
- en: The difference between those classes and the `SecureRandom` class lies in the
    algorithm used. The `Random` class (and the `ThreadLocalRandom` class, via inheritance)
    implements a typical pseudorandom algorithm. While those algorithms are quite
    sophisticated, they are in the end deterministic. If the initial seed is known,
    it is possible to determine the exact series of numbers the engine will generate.
    That means hackers are able to look at series of numbers from a particular generator
    and (eventually) figure out what the next number will be. Although good pseudorandom
    number generators can emit series of numbers that look really random (and that
    even fit probabilistic expectations of randomness), they are not truly random.
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 这些类与`SecureRandom`类之间的区别在于所使用的算法。`Random`类（以及通过继承的`ThreadLocalRandom`类）实现了典型的伪随机算法。虽然这些算法非常复杂，但最终是确定性的。如果初始种子是已知的，就可以确定引擎将生成的确切数字系列。这意味着黑客能够查看特定生成器的数字系列，并最终推断出下一个数字是什么。尽管良好的伪随机数生成器可以生成看起来非常随机的数字系列（甚至符合随机性的概率预期），但它们并非真正随机。
- en: The `SecureRandom` class, on the other hand, uses a system interface to obtain
    a seed for its random data. The way that data is generated is operating-system-specific,
    but in general this source provides data based on truly random events (such as
    when the mouse is moved). This is known as *entropy-based randomness* and is much
    more secure for operations that rely on random numbers.
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 另一方面，`SecureRandom`类使用系统接口获取其随机数据的种子。生成数据的方式是特定于操作系统的，但通常情况下，这个来源提供基于真正随机事件（例如鼠标移动时）的数据。这被称为*基于熵的随机性*，对依赖随机数的操作更加安全。
- en: 'Java distinguishes two sources of random numbers: one to generate seeds and
    one to generate random numbers themselves. Seeds are used to create public and
    private keys, such as the keys that you use to access a system via SSH or PuTTY.
    Those keys are long-lived, so they require the strongest possible cryptographic
    algorithm. Secure random numbers are also used to seed regular random number streams,
    including those used by default implementations of Java’s SSL libraries.'
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: Java区分两个随机数源：一个用于生成种子，一个用于生成随机数本身。种子用于创建公钥和私钥，例如通过SSH或PuTTY访问系统时使用的密钥。这些密钥长期存在，因此需要最强大的加密算法。安全随机数还用于种子常规的随机数流，包括Java的SSL库的默认实现中使用的流。
- en: 'On Linux systems, these two sources are */dev/random* (for seeds) and */dev/urandom*
    (for random numbers). These systems are both based on sources of entropy within
    the machine: truly random things, such as mouse movement or keyboard strokes.
    The amount of entropy is limited and is regenerated randomly, so it is undependable
    as a true source of randomness. The two systems handle that differently: */dev/random*
    will block until it has enough system events to generate the random data, and
    */dev/urandom* will fall back to a pseudorandom number generator (PRNG). The PRNG
    will have been initialized from a truly random source, so it is usually just as
    strong as the stream from */dev/random*. However, entropy to generate the seed
    itself may be unavailable, in which case the stream from */dev/urandom* can theoretically
    be compromised. There are arguments on both sides of this issue as to strength
    of this stream, but the common consensus—use */dev/random* for seeds and */dev/urandom*
    for everything else—is the one adopted by Java.'
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 在Linux系统上，这两个来源分别是*/dev/random*（用于种子）和*/dev/urandom*（用于随机数）。这两个系统都基于机器内的熵源：真正随机的事物，如鼠标移动或键盘击键。熵的量是有限的，会随机再生，因此作为真正随机性的来源是不可靠的。这两个系统处理方式不同：*/dev/random*会阻塞，直到有足够的系统事件生成随机数据，而*/dev/urandom*则会退而使用伪随机数生成器（PRNG）。PRNG会从一个真正随机的来源初始化，因此通常与*/dev/random*产生的数据流一样强大。然而，生成种子所需的熵可能不可用，此时从*/dev/urandom*得到的数据流理论上可能会受到影响。关于这一问题的争论有两面观点，但普遍的共识是——用*/dev/random*生成种子，用*/dev/urandom*处理其他一切——这是Java采纳的方案。
- en: 'The upshot is that getting a lot of random number seeds can take a long time.
    Calls to the `generatedSeed()` method of the `SecureRandom` class will take an
    indeterminate amount of time, based on how much unused entropy the system has.
    If no entropy is available, the call will appear to hang, possibly as long as
    seconds at a time, until the required entropy is available. That makes performance
    timing quite difficult: the performance itself becomes random.'
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 结论是获取大量随机数种子可能需要很长时间。调用`SecureRandom`类的`generateSeed()`方法将花费不确定的时间，取决于系统中未使用的熵量。如果没有可用的熵，调用可能会出现挂起的情况，可能会持续几秒钟，直到所需的熵可用。这使得性能的定时变得非常困难：性能本身变得随机起来。
- en: On the other hand, the `generateSeed()` method is used for only two operations.
    First, some algorithms use it to get a seed for future calls to the `nextRandom()`
    method. This usually needs to be done only once, or at most periodically during
    the lifetime of an application. Second, this method is used when creating a long-lived
    key, which also is a fairly rare operation.
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 另一方面，`generateSeed()`方法仅用于两个操作。首先，某些算法使用它获取未来调用`nextRandom()`方法的种子。这通常只需要在应用程序生命周期中执行一次，或者定期执行。其次，创建长期存在的密钥时也会使用此方法，这也是相当少见的操作。
- en: Since those operations are limited, most applications will not run out of entropy.
    Still, limited entropy can be a problem for applications that create ciphers at
    startup time, particularly in cloud environments where the host OS random number
    device is shared among a number of virtual machines and/or Docker containers.
    In that case, timings of program activities will have a very large amount of variance,
    and since the use of secure seeds occurs most often while programs are initializing,
    the startup of applications in this sphere can be quite slow.
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 由于这些操作受限，大多数应用程序不会耗尽熵。但对于在启动时创建密码的应用程序来说，熵的限制可能是一个问题，特别是在主机操作系统随机数设备在多个虚拟机和/或
    Docker 容器之间共享的云环境中。在这种情况下，程序活动的时间将具有非常大的差异，由于安全种子的使用通常发生在程序初始化时，因此在这个领域的应用程序启动可能会非常慢。
- en: 'We have a few ways to deal with this situation. In a pinch, and where the code
    can be changed, an alternative to this problem is to run performance tests using
    the `Random` class, even though the `SecureRandom` class will be used in production.
    If the performance tests are module-level tests, that can make sense: those tests
    will need more random seeds than the production system will need during the same
    period of time. But eventually, the expected load must be tested with the `SecureRandom`
    class to determine if the load on the production system can obtain a sufficient
    number of random seeds.'
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 我们有几种方式来处理这种情况。在紧急情况下，以及可以更改代码的情况下，解决这个问题的替代方案是使用 `Random` 类来运行性能测试，尽管生产中将使用
    `SecureRandom` 类。如果性能测试是模块级测试，这是有道理的：这些测试将需要比生产系统在同一时间段内需要的更多的随机种子。但最终，必须使用 `SecureRandom`
    类来测试预期负载，以确定生产系统的负载是否可以获得足够数量的随机种子。
- en: 'A second option is to configure Java’s secure random number generator to use
    */dev/urandom* for seeds as well as for random numbers. This can be accomplished
    in two ways: first, you can set the system property `-Djava.security​.egd=file:/dev/urandom`.^([2](ch12.html#idm45775543079160))'
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 第二个选择是配置 Java 的安全随机数生成器使用 */dev/urandom* 作为种子以及随机数。有两种方法可以实现这一点：首先，可以设置系统属性
    `-Djava.security​.egd=file:/dev/urandom`。^([2](ch12.html#idm45775543079160))
- en: 'A third option is to change this setting in *$JAVA_HOME/jre/lib/security/java.security*:'
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 第三个选项是在 *$JAVA_HOME/jre/lib/security/java.security* 中更改此设置：
- en: '[PRE14]'
  id: totrans-195
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: That line defines the interface used for seeding operations and can be set to
    */dev/urandom* if you want to ensure that the secure random number generator never
    blocks.
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 该行定义了用于种子操作的接口，并且如果您希望确保安全的随机数生成器永远不会阻塞，可以将其设置为 */dev/urandom*。
- en: However, the better solution is to set up the operating system so that it supplies
    more entropy, which is done by running the `rngd` daemon. Just make sure that
    the `rngd` daemon is configured to use reliable hardware sources of entropy (e.g.,
    */dev/hwrng* if it is available) and not something like */dev/urandom*. This solution
    has the advantage of solving entropy issues for all programs on the machine, not
    just Java programs.
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，更好的解决方案是设置操作系统以提供更多熵，通过运行 `rngd` 守护程序来完成。只需确保 `rngd` 守护程序配置为使用可靠的硬件熵源（例如，如果可用，则使用
    */dev/hwrng*），而不是像 */dev/urandom* 这样的东西。这种解决方案的优势在于解决了机器上所有程序的熵问题，而不仅仅是 Java 程序。
- en: Quick Summary
  id: totrans-198
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 快速总结
- en: Java’s default `Random` class is expensive to initialize, but once initialized,
    it can be reused.
  id: totrans-199
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Java 的默认 `Random` 类初始化昂贵，但一旦初始化完成，可重复使用。
- en: In multithreaded code, the `ThreadLocalRandom` class is preferred.
  id: totrans-200
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在多线程代码中，首选 `ThreadLocalRandom` 类。
- en: Sometimes, the `SecureRandom` class will show arbitrary, completely random performance.
    Performance tests on code using that class must be carefully planned.
  id: totrans-201
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 有时，`SecureRandom` 类会表现出任意的、完全随机的性能。对使用该类的代码进行性能测试必须谨慎计划。
- en: Issues with the `SecureRandom` class blocking can be avoided with configuration
    changes, but it is better to solve them at the OS level by adding entropy to the
    system.
  id: totrans-202
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 `SecureRandom` 类可能会遇到阻塞问题，可以通过配置更改来避免，但最好通过增加系统熵在操作系统级别解决这些问题。
- en: Java Native Interface
  id: totrans-203
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Java 本地接口
- en: Performance tips about Java SE (particularly in the early days of Java) often
    say that if you want really fast code, you should use native code. In truth, if
    you are interested in writing the fastest possible code, avoid the Java Native
    Interface (JNI).
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 关于 Java SE 的性能提示（特别是在 Java 刚开始时），通常会说如果想要真正快速的代码，应该使用本地代码。但事实上，如果你希望编写尽可能快的代码，应避免使用
    Java 本地接口（JNI）。
- en: 'Well-written Java code will run at least as fast on current versions of the
    JVM as corresponding C or C++ code (it is not 1996 anymore). Language purists
    will continue to debate the relative performance merits of Java and other languages,
    and you can find doubtless examples of an application written in another language
    that is faster than the same application written in Java (though often those examples
    contain poorly written Java code). However, that debate misses the point of this
    section: when an application is already written in Java, calling native code for
    performance reasons is almost always a bad idea.'
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 在当前 JVM 版本上，良好编写的 Java 代码至少与相应的 C 或 C++ 代码一样快（现在已不是 1996 年了）。语言纯粹主义者将继续辩论 Java
    和其他语言的相对性能优点，无疑可以找到用另一种语言编写的应用程序比用 Java 编写的同一应用程序更快的例子（尽管这些例子通常包含编写不良的 Java 代码）。然而，这种辩论忽略了本节的重点：当应用程序已经用
    Java 编写时，出于性能原因调用本地代码几乎总是一个坏主意。
- en: Still, at times JNI is quite useful. The Java platform provides many common
    features of operating systems, but if access to a special, operating-system-specific
    function is required, so is JNI. And why build your own library to perform an
    operation, when a commercial (native) version of the code is readily available?
    In these and other cases, the question becomes how to write the most efficient
    JNI code.
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 但是，有时 JNI 是非常有用的。Java 平台提供了许多操作系统的常见功能，但如果需要访问特定于操作系统的特殊功能，那么就需要 JNI。而且，如果商业（本地）版本的代码已经准备就绪，为什么要构建自己的库来执行操作呢？在这些以及其他情况下，问题就变成了如何编写最有效的
    JNI 代码。
- en: 'The answer is to avoid making calls from Java to C as much as possible. Crossing
    the JNI boundary (the term for making the cross-language call) is expensive. Because
    calling an existing C library requires writing glue code in the first place, take
    the time to create new, coarse-grained interfaces via that glue code: perform
    many, multiple calls into the C library in one shot.'
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 答案是尽可能避免从 Java 到 C 的调用。跨 JNI 边界（称为进行跨语言调用）是昂贵的。因为调用现有的 C 库本身就需要编写粘合代码，所以要花时间通过该粘合代码创建新的粗粒度接口：一次性在
    C 库中执行多个、多次调用。
- en: 'Interestingly, the reverse is not necessarily true: C code that calls back
    into Java does not suffer a large performance penalty (depending on the parameters
    involved). For example, consider the following code excerpt:'
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 有趣的是，反过来未必成立：调用 Java 返回 C 的 C 代码并不会受到很大的性能惩罚（取决于涉及的参数）。例如，请考虑以下代码摘录：
- en: '[PRE15]'
  id: totrans-209
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'This (completely nonsensical) code has two main loops: one inside the benchmark
    method and then one inside the `calcJavaJava()` method. That is all Java code,
    but we can choose instead to use a native interface and write the outer calculation
    method in C:'
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 这段（完全无意义的）代码有两个主要循环：一个在基准方法内部，然后一个在 `calcJavaJava()` 方法内部。那是全部 Java 代码，但我们可以选择使用本地接口，将外部计算方法写在
    C 中代替：
- en: '[PRE16]'
  id: totrans-211
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: Or we could just implement the inner call in C (the code for which should be
    obvious).
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 或者我们可以在 C 中实现内部调用（其代码应该是显而易见的）。
- en: '[Table 12-8](#TableJNI) shows the performance from various permutations, given
    10,000 trials and 10,000 values.'
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: '[Table 12-8](#TableJNI) 展示了在给定 10,000 次试验和 10,000 个值的各种排列情况下的性能。'
- en: Table 12-8\. Time to calculate across the JNI boundary
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 表 12-8\. 跨 JNI 边界计算时间
- en: '| `calculateError` | Calc | Random | JNI transitions | Total time |'
  id: totrans-215
  prefs: []
  type: TYPE_TB
  zh: '| `calculateError` | Calc | Random | JNI 转换 | 总时间 |'
- en: '| --- | --- | --- | --- | --- |'
  id: totrans-216
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- |'
- en: '| Java | Java | Java | 0 | 0.104 ± 0.01 seconds |'
  id: totrans-217
  prefs: []
  type: TYPE_TB
  zh: '| Java | Java | Java | 0 | 0.104 ± 0.01 秒 |'
- en: '| Java | Java | C | 10,000,000 | 1.96 ± 0.1 seconds |'
  id: totrans-218
  prefs: []
  type: TYPE_TB
  zh: '| Java | Java | C | 10,000,000 | 1.96 ± 0.1 秒 |'
- en: '| Java | C | C | 10,000 | 0.132 ± 0.01 seconds |'
  id: totrans-219
  prefs: []
  type: TYPE_TB
  zh: '| Java | C | C | 10,000 | 0.132 ± 0.01 秒 |'
- en: '| C | C | C | 0 | 0.139 ± 0.01 seconds |'
  id: totrans-220
  prefs: []
  type: TYPE_TB
  zh: '| C | C | C | 0 | 0.139 ± 0.01 秒 |'
- en: Implementing only the innermost method in C provides the most crossings of the
    JNI boundary (`numberOfTrials × numberOfLoops`, or 10 million). Reducing the number
    of crossings to `numberOfTrials` (10,000) reduces that overhead substantially,
    and reducing it further to 0 provides the best performance.
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 仅在 C 中实现最内层方法会产生 JNI 边界最多的交叉（`numberOfTrials × numberOfLoops`，即 1000 万次）。将交叉数量减少到
    `numberOfTrials`（10,000）可以大大减少这种开销，将其进一步减少到 0 可以提供最佳性能。
- en: JNI code performs worse if the parameters involved are not simple primitives.
    Two aspects are involved in this overhead. First, for simple references, an address
    translation is needed. Second, operations on array-based data are subject to special
    handling in native code. This includes `String` objects, since the string data
    is essentially a character array. To access the individual elements of these arrays,
    a special call must be made to pin the object in memory (and for `String` objects,
    to convert from Java’s UTF-16 encoding into UTF-8 in JDK 8). When the array is
    no longer needed, it must be explicitly released in the JNI code.
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: 如果涉及的参数不是简单的原始类型，则 JNI 代码的性能会变差。这种开销涉及两个方面。首先，对于简单的引用，需要地址转换。其次，对于基于数组的数据，在本地代码中需要进行特殊处理。这包括
    `String` 对象，因为字符串数据本质上是字符数组。要访问这些数组的各个元素，必须进行特殊调用以将对象固定在内存中（对于 JDK 8 中的 `String`
    对象，还要将其从 Java 的 UTF-16 编码转换为 UTF-8）。当不再需要数组时，必须在 JNI 代码中显式释放它。
- en: While the array is pinned, the garbage collector cannot run—so one of the most
    expensive mistakes in JNI code is to pin a string or array in code that is long-running.
    That prevents the garbage collector from running, effectively blocking all the
    application threads until the JNI code completes. It is extremely important to
    make the critical section where the array is pinned as short as possible.
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: 在数组被固定时，垃圾收集器无法运行——因此 JNI 代码中最昂贵的错误之一就是在长时间运行的代码中固定字符串或数组。这会阻止垃圾收集器运行，从而有效阻塞所有应用程序线程，直到
    JNI 代码完成。非常重要的是使数组被固定的关键部分尽可能短暂。
- en: Often, you will see the term `GC Locker Initiated GC` in your GC logs. That’s
    an indication that the garbage collector needed to run but it couldn’t, because
    a thread had pinned data in a JNI call. As soon as that data is unpinned, the
    garbage collector will run. If you see this GC cause frequently, look into making
    the JNI code faster; your other application threads are experiencing delays waiting
    for GC to run.
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，您会在 GC 日志中看到术语 `GC Locker Initiated GC`。这表明垃圾收集器需要运行，但由于线程在 JNI 调用中固定了数据，所以无法运行。一旦该数据解除固定，垃圾收集器就会运行。如果经常看到这个
    GC 原因，请考虑使 JNI 代码更快；其他应用程序线程正在等待 GC 运行时会出现延迟。
- en: Sometimes, the goal of pinning objects for a short period of time conflicts
    with the goal of reducing the calls that cross the JNI boundary. In that case,
    the latter goal is more important even if it means making multiple crossings of
    the JNI boundary, so make the sections that pin arrays and strings as short as
    possible.
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: 有时，为了短暂固定对象的目标与减少跨 JNI 边界调用的目标冲突。在这种情况下，后者的目标更为重要，即使这意味着在 JNI 边界上进行多次交叉调用，因此请尽可能使固定数组和字符串的部分尽可能短。
- en: Quick Summary
  id: totrans-226
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 快速总结
- en: JNI is not a solution to performance problems. Java code will almost always
    run faster than calling into native code.
  id: totrans-227
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: JNI 不是性能问题的解决方案。几乎总是比调用本地代码更快。
- en: When JNI is used, limit the number of calls from Java to C; crossing the JNI
    boundary is expensive.
  id: totrans-228
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当使用 JNI 时，限制从 Java 到 C 的调用次数；跨 JNI 边界的成本很高。
- en: JNI code that uses arrays or strings must pin those objects; limit the length
    of time they are pinned so that the garbage collector is not impacted.
  id: totrans-229
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用数组或字符串的 JNI 代码必须固定这些对象；限制它们固定的时间长度，以免影响垃圾收集器。
- en: Exceptions
  id: totrans-230
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 异常
- en: 'Java exception processing has the reputation of being expensive. It is somewhat
    more expensive than processing regular control flows, though in most cases, the
    extra cost isn’t worth the effort to attempt to bypass it. On the other hand,
    because it isn’t free, exception processing shouldn’t be used as a general mechanism
    either. The guideline is to use exceptions according to the general principles
    of good program design: mainly, code should throw an exception only to indicate
    something unexpected has happened. Following good code design means that your
    Java code will not be slowed down by exception processing.'
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: Java 异常处理以昂贵著称。尽管在大多数情况下，其额外成本并不值得尝试绕过它，但它比处理常规控制流昂贵一些。另一方面，由于它并非免费，异常处理也不应作为通用机制。指导方针是根据良好程序设计的一般原则使用异常：主要是，代码只应在发生意外情况时抛出异常。遵循良好的代码设计意味着你的
    Java 代码不会因异常处理而变慢。
- en: 'Two things can affect the general performance of exception processing. First
    is the code block itself: is it expensive to set up a try-catch block? While that
    might have been the case a long time ago, it has not been the case for years.
    Still, because the internet has a long memory, you will sometimes see recommendations
    to avoid exceptions simply because of the try-catch block. Those recommendations
    are out-of-date; modern JVMs can generate code that handles exceptions quite efficiently.'
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: 两件事可能会影响异常处理的一般性能。首先是代码块本身：设置 try-catch 块是否昂贵？虽然很久以前可能是这样，但多年来情况并非如此。不过，因为互联网记忆力强，有时您会看到建议仅因为
    try-catch 块而避免异常。这些建议已过时；现代 JVM 可以生成处理异常的代码。
- en: The second aspect is that exceptions involve obtaining a stack trace at the
    point of the exception (though you’ll see an exception to that later in this section).
    This operation can be expensive, particularly if the stack trace is deep.
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: 第二个方面是异常涉及在异常点获取堆栈跟踪（尽管在本节后面您会看到一个例外）。这个操作可能很昂贵，特别是如果堆栈跟踪很深。
- en: 'Let’s look at an example. Here are three implementations of a particular method
    to consider:'
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们来看一个例子。这里有三种特定方法的实现要考虑：
- en: '[PRE17]'
  id: totrans-235
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: Each method here creates an array of arbitrary strings from newly created objects.
    The size of that array will vary, based on the desired number of exceptions to
    be thrown.
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: 每个方法都会创建一个从新创建的对象中生成的任意字符串数组。该数组的大小将根据需要抛出的异常数目而变化。
- en: '[Table 12-9](#TableExceptions1) shows the time to complete each method for
    100,000 iterations given the worst case—a `pctError` of 1 (each call generates
    an exception, and the result is an empty list). The example code here is either
    shallow (meaning that the method in question is called when only 3 classes are
    on the stack) or deep (meaning that the method in question is called when 100
    classes are on the stack).'
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: '[表12-9](#TableExceptions1) 显示了在最坏情况下（`pctError` 为1，每次调用生成一个异常，结果是一个空列表）完成每种方法的时间，例子代码可能是浅层（意味着只有3个类在堆栈上）或者深层（意味着在堆栈上有100个类）。'
- en: Table 12-9\. Time to process exceptions at 100%
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: 表12-9\. 处理异常所需的时间（100%）
- en: '| Method | Shallow time | Deep time |'
  id: totrans-239
  prefs: []
  type: TYPE_TB
  zh: '| 方法 | 浅层时间 | 深层时间 |'
- en: '| --- | --- | --- |'
  id: totrans-240
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| Checked exception | 24031 ± 127 μs | 30613 ± 329 μs |'
  id: totrans-241
  prefs: []
  type: TYPE_TB
  zh: '| 已检查的异常 | 24031 ± 127 μs | 30613 ± 329 μs |'
- en: '| Unchecked exception | 21181 ± 278 μs | 21550 ± 323 μs |'
  id: totrans-242
  prefs: []
  type: TYPE_TB
  zh: '| 未经检查的异常 | 21181 ± 278 μs | 21550 ± 323 μs |'
- en: '| Defensive programming | 21088 ± 255 μs | 21262 ± 622 μs |'
  id: totrans-243
  prefs: []
  type: TYPE_TB
  zh: '| 防御性编程 | 21088 ± 255 μs | 21262 ± 622 μs |'
- en: This table presents three interesting points. First, in the case of checked
    exceptions, there is a significant difference of time between the shallow case
    and the deep case. Constructing that stack trace takes time, which is dependent
    on the stack depth.
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: 该表显示了三个有趣的点。首先，在检查异常的情况下，浅层情况和深层情况之间的时间差异显著。构建堆栈跟踪需要时间，这取决于堆栈深度。
- en: But the second case involves unchecked exceptions, where the JVM creates the
    exception when the null pointer is dereferenced. What’s happening is that at some
    point, the compiler has optimized the system-generated exception case; the JVM
    begins to reuse the same exception object rather than creating a new one each
    time it is needed. That object is reused each time the code in question is executed,
    no matter what the calling stack is, and the exception does not actually contain
    a call stack (i.e., the `printStackTrace()` method returns no output). This optimization
    doesn’t occur until the full stack exception has been thrown for quite a long
    time, so if your test case doesn’t include a sufficient warm-up cycle, you will
    not see its effects.
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: 但第二种情况涉及未经检查的异常，在 JVM 创建空指针解引用异常时。发生的情况是编译器在某个时刻优化了系统生成的异常情况；JVM 开始重用同一个异常对象，而不是每次需要时都创建新的异常对象。无论调用堆栈如何，该对象每次执行相关代码时都被重用，并且异常实际上不包含调用堆栈（即
    `printStackTrace()` 方法没有输出）。这种优化在完全抛出完整堆栈异常相当长时间后才会发生，因此，如果您的测试用例不包括足够的预热周期，您将看不到其效果。
- en: 'Finally, consider the case where no exception is thrown: notice that it has
    pretty much the same performance as the unchecked exception case. This case serves
    as a control in this experiment: the test does a fair amount of work to create
    the objects. The difference between the defensive case and any other case is the
    actual time spent creating, throwing, and catching the exception. So the overall
    time is quite small. Averaged out over 100,000 calls, the individual execution
    time differences will barely register (and recall that this is the worst-case
    example).'
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，考虑没有抛出异常的情况：注意到它与未检查的异常情况几乎具有相同的性能。这种情况在这个实验中起到了控制作用：测试会进行大量的工作来创建对象。防御性编程和其他情况之间的区别在于实际花费在创建、抛出和捕获异常上的时间。因此，总体时间非常短。在
    100,000 次调用中平均下来，个体执行时间的差异几乎不会被注意到（请注意，这是最坏的情况示例）。
- en: So performance penalties for using exceptions injudiciously is smaller than
    might be expected, and the penalty for having lots of the same system exception
    is almost nonexistent. Still, in some cases you will run into code that is simply
    creating too many exceptions. Since the performance penalty comes from filling
    in the stack traces, the `-XX:-StackTraceInThrowable` flag (which is `true` by
    default) can be set to disable the generation of the stack traces.
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: 所以，对于不慎使用异常而言，性能惩罚要比预期的小得多，而对于大量相同系统异常的惩罚几乎不存在。然而，在某些情况下，你可能会遇到只是简单地创建了太多异常的代码。由于性能惩罚来自于填充堆栈跟踪信息，可以设置`-XX:-StackTraceInThrowable`标志（默认为`true`）以禁用堆栈跟踪信息的生成。
- en: 'This is rarely a good idea: the stack traces are present to enable analysis
    of what unexpectedly went wrong. That capability is lost when this flag is enabled.
    And there is code that actually examines the stack traces and determines how to
    recover from the exception based on what it finds there. That’s problematic in
    itself, but the upshot is that disabling the stack trace can mysteriously break
    code.'
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: 这通常不是一个好主意：堆栈跟踪存在是为了使我们能够分析发生意外错误的原因。启用此标志后，这种能力就会丢失。实际上有代码检查堆栈跟踪并根据其中的信息决定如何从异常中恢复。这本身就是一个问题，但问题的关键是禁用堆栈跟踪可能会神秘地破坏代码。
- en: There are some APIs in the JDK itself where exception handling can lead to performance
    issues. Many collection classes will throw an exception when nonexistent items
    are retrieved from them. The `Stack` class, for example, throws an `EmptyStackException`
    if the stack is empty when the `pop()` method is called. It is usually better
    to utilize defensive programming in that case by checking the stack length first.
    (On the other hand, unlike many collection classes, the `Stack` class supports
    `null` objects, so it’s not as if the `pop()` method could return `null` to indicate
    an empty stack.)
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: JDK 本身存在一些 API，异常处理可能会导致性能问题。当从集合类中检索不存在的项时，许多集合类会抛出异常。例如，当调用`pop()`方法时，如果堆栈为空，则`Stack`类会抛出`EmptyStackException`。在这种情况下，通常最好通过首先检查堆栈长度来使用防御性编程。（另一方面，与许多集合类不同，`Stack`类支持`null`对象，因此`pop()`方法不能返回`null`来指示空堆栈。）
- en: 'The most notorious example within the JDK of questionable use of exceptions
    is in classloading: the `loadClass()` method of the `ClassLoader` class throws
    a `ClassNotFoundException` when asked to load a class that it cannot find. That’s
    not actually an exceptional condition. An individual classloader is not expected
    to know how to load every class in an application, which is why there are hierarchies
    of classloaders.'
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: 在 JDK 中最臭名昭著的一个例子是类加载中对异常使用的质疑：当`ClassLoader`类的`loadClass()`方法试图加载它无法找到的类时会抛出`ClassNotFoundException`。这实际上并不是一个异常情况。一个单独的类加载器不应该知道如何加载应用程序中的每个类，这就是为什么有类加载器层次结构的原因。
- en: In an environment with dozens of classloaders, this means a lot of exceptions
    are created as the classloader hierarchy is searched for the one classloader that
    knows how to load the given class. In very large application servers I’ve worked
    with, disabling stack trace generation can speed up start time by as much as 3%.
    Those servers load more than 30,000 classes from hundreds of JAR files; this is
    certainly a YMMV kind of thing.^([3](ch12.html#idm45775542437672))
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: 在一个存在数十个类加载器的环境中，这意味着在搜索类加载器层次结构以找到知道如何加载给定类的类加载器时会创建大量的异常。在我曾经使用过的非常大的应用服务器中，禁用堆栈跟踪生成可以加快启动时间多达
    3%。这些服务器从数百个 JAR 文件中加载超过 30,000 个类；这当然是一种因人而异的情况。^([3](ch12.html#idm45775542437672))
- en: Quick Summary
  id: totrans-252
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 快速总结
- en: Exceptions are not necessarily expensive to process, though they should be used
    only when appropriate.
  id: totrans-253
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 异常处理并不一定是处理昂贵的操作，但应该在适当的时候使用。
- en: The deeper the stack, the more expensive to process exceptions.
  id: totrans-254
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 堆栈越深，处理异常的代价就越高。
- en: The JVM will optimize away the stack penalty for frequently created system exceptions.
  id: totrans-255
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: JVM将优化频繁创建的系统异常的堆栈惩罚。
- en: Disabling stack traces in exceptions can sometimes help performance, though
    crucial information is often lost in the process.
  id: totrans-256
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 禁用异常中的堆栈跟踪有时可以提高性能，尽管在这个过程中通常会丢失关键信息。
- en: Logging
  id: totrans-257
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 日志记录
- en: Logging is one of those things that performance engineers either love or hate—or
    (usually) both. Whenever I’m asked why a program is running badly, the first thing
    I ask for are any available logs, with the hope that logs produced by the application
    will have clues as to what the application was doing. Whenever I’m asked to review
    the performance of working code, I immediately recommend that all logging statements
    be turned off.
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: 日志记录是性能工程师既爱又恨的事情之一，或者（通常）两者都是。每当我被问及为什么程序运行不佳时，我首先要求提供任何可用的日志，希望应用程序产生的日志可以提供关于应用程序正在执行的操作的线索。每当我被要求审查工作代码的性能时，我立即建议关闭所有日志记录语句。
- en: Multiple logs are in question here. The JVM produces its own logging statements,
    of which the most important is the GC log (see [Chapter 6](ch06.html#Collectors)).
    That logging can be directed into a distinct file, the size of which can be managed
    by the JVM. Even in production code, GC logging (even with detailed logging enabled)
    has such low overhead and such an expected large benefit if something goes wrong
    that it should always be turned on.
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: 这里涉及多个日志。JVM生成其自己的日志语句，其中最重要的是GC日志（参见[第6章](ch06.html#Collectors)）。该日志可以定向输出到一个独立的文件，文件的大小可以由JVM管理。即使在生产代码中，GC日志（即使启用详细日志记录）的开销非常低，并且如果出现问题，预期的好处非常大，因此应始终打开。
- en: 'HTTP servers generate an access log that is updated on every request. This
    log generally has a noticeable impact: turning off that logging will definitely
    improve the performance of whatever test is run against the application server.
    From a diagnosability standpoint, those logs are (in my experience) not terribly
    helpful when something goes wrong. However, in terms of business requirements,
    that log is often crucial, in which case it must be left enabled.'
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: HTTP服务器生成的访问日志在每个请求时都会更新。该日志通常会产生显著影响：关闭该日志记录肯定会改善针对应用服务器运行的任何测试的性能。从诊断性的角度来看，当出现问题时，这些日志（根据我的经验）通常没有太大帮助。然而，从业务需求的角度来看，该日志通常至关重要，因此必须保持启用状态。
- en: Although it is not a Java standard, many HTTP servers support the Apache `mod_log_config`
    convention, which allows you to specify exactly what information is logged for
    each request (and servers that don’t follow the `mod_log_config` syntax will typically
    support another log customization). The key is to log as little information as
    possible and still meet the business requirements. The performance of the log
    is subject to the amount of data written.
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然它不是Java的标准，但许多HTTP服务器支持Apache `mod_log_config`约定，允许您为每个请求指定要记录的信息（不遵循`mod_log_config`语法的服务器通常支持另一种日志自定义）。关键是尽量记录尽可能少的信息，同时满足业务需求。日志的性能取决于写入的数据量。
- en: 'In HTTP access logs in particular (and in general, in any kind of log), it
    is a good idea to log all information numerically: IP addresses rather than hostnames,
    timestamps (e.g., seconds since the epoch) rather than string data (e.g., “Monday,
    June 3, 2019 17:23:00 -0600”), and so on. Minimize any data conversion that will
    take time and memory to compute so that the effect on the system is also minimized.
    Logs can always be postprocessed to provide converted data.'
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: 特别是在HTTP访问日志中（以及一般来说，在任何类型的日志中），建议以数字形式记录所有信息：使用IP地址而不是主机名，时间戳（例如，自纪元以来的秒数）而不是字符串数据（例如，“2019年6月3日星期一
    17:23:00 -0600”），等等。尽量减少需要时间和内存计算的数据转换，以便系统的影响也最小化。日志始终可以进行后处理以提供转换后的数据。
- en: 'We should keep three basic principles in mind for application logs. First is
    to keep a balance between the data to be logged and level at which it is logged.
    The JDK has seven standard logging levels in the JDK, and loggers by default are
    configured to output three of those levels (`INFO` and greater). This often leads
    to confusion within projects: `INFO`-level messages sound like they should be
    fairly common and should provide a description of the flow of an application (“now
    I’m processing task A,” “now I’m doing task B,” and so on). Particularly for applications
    that are heavily threaded and scalable, that much logging will have a detrimental
    effect on performance (not to mention running the risk of being too chatty to
    be useful). Don’t be afraid to use the lower-level logging statements.'
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: 对于应用程序日志，我们应该牢记三个基本原则。首先是在记录数据和记录级别之间保持平衡。JDK中有七个标准的日志记录级别，并且默认情况下记录器配置为输出其中的三个级别（`INFO`及更高）。这经常在项目中造成混淆：`INFO`级别的消息听起来应该是相当常见的，并且应该提供应用程序流程的描述（"现在我正在处理任务A"，"现在我在执行任务B"等等）。特别是对于大量线程和可伸缩的应用程序，这样多的日志记录会对性能产生不利影响（更不用说过于啰嗦而无用了）。不要害怕使用更低级别的日志记录语句。
- en: Similarly, when code is checked into a group repository, consider the needs
    of the user of the project rather than your needs as a developer. We’d all like
    to have a lot of good feedback about how our code works after it is integrated
    into a larger system and run through a battery of tests, but if a message isn’t
    going to make sense to an end user or system administrator, it’s not helpful to
    enable it by default. It is merely going to slow down the system (and confuse
    the end user).
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
  zh: 类似地，当代码提交到组仓库时，考虑项目使用者的需求，而不是作为开发者的个人需求。我们都希望在代码集成到更大系统并通过一系列测试后能够得到很多有用的反馈，但如果一条消息对最终用户或系统管理员来说没有意义，默认启用它并不会有所帮助。这只会减慢系统速度（并使最终用户感到困惑）。
- en: The second principle is to use fine-grained loggers. Having a logger per class
    can be tedious to configure, but having greater control over the logging output
    often makes this worthwhile. Sharing a logger for a set of classes in a small
    module is a good compromise. Keep in mind that production problems—and particularly
    production problems that occur under load or are otherwise performance related—are
    tricky to reproduce if the environment changes significantly. Turning on too much
    logging often changes the environment such that the original issue no longer manifests
    itself.
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
  zh: 第二个原则是使用细粒度的记录器。每个类一个记录器可能配置起来有些繁琐，但能够更精确地控制日志输出通常是值得的。在小模块中为一组类共享一个记录器是一个不错的折衷方案。请记住，生产环境中的问题——特别是在负载较大或与性能相关的问题——如果环境发生显著变化，可能会很难复现。打开过多的日志记录通常会改变环境，使得原始问题不再显现。
- en: Hence, you must be able to turn on logging only for a small set of code (and,
    at least initially, a small set of logging statements at the `FINE` level, followed
    by more at the `FINER` and `FINEST` levels) so that the performance of the code
    is not affected.
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，您必须能够仅为一小部分代码（至少最初只是一小部分`FINE`级别的日志语句，然后是更多的`FINER`和`FINEST`级别的语句）打开日志记录，以确保不影响代码的性能。
- en: 'Between these two principles, it should be possible to enable small subsets
    of messages in a production environment without affecting the performance of the
    system. That is usually a requirement anyway: the production system administrators
    probably aren’t going to enable logging if it slows the system, and if the system
    does slow down, then the likelihood of reproducing the issue is reduced.'
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
  zh: 在这两个原则之间，应该可以在生产环境中启用小型消息子集而不影响系统性能。这通常是一个要求：生产系统管理员可能不会在降低系统性能的情况下启用日志记录，如果系统变慢，那么再现问题的可能性就会降低。
- en: 'The third principle to keep in mind when introducing logging to code is to
    remember that it is easy to write logging code that has unintended side effects,
    even if the logging is not enabled. This is another case where “prematurely” optimizing
    code is a good thing: as the example from [Chapter 1](ch01.html#Introduction)
    shows, remember to use the `isLoggable()` method anytime the information to be
    logged contains a method call, a string concatenation, or any other sort of allocation
    (for example, allocation of an `Object` array for a `MessageFormat` argument).'
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
  zh: 在向代码引入日志记录时的第三个原则是记住，编写具有意外副作用的日志记录代码是很容易的，即使未启用日志记录也是如此。这是另一种情况下，“过早”优化代码是一个好事情的例子：正如[第一章](ch01.html#Introduction)的例子所示，记得在需要记录的信息包含方法调用、字符串连接或任何其他类型的分配（例如，为
    `MessageFormat` 参数分配 `Object` 数组）时，始终使用 `isLoggable()` 方法。
- en: Quick Summary
  id: totrans-269
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 快速总结
- en: Code should contain lots of logging to enable users to figure out what it does,
    but none of that should be enabled by default.
  id: totrans-270
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 代码应包含大量日志记录，以便用户了解其功能，但默认情况下不应启用任何日志记录。
- en: Don’t forget to test for the logging level before calling the logger if the
    arguments to the logger require method calls or object allocation.
  id: totrans-271
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在调用记录器之前不要忘记测试日志记录级别，如果记录器的参数需要方法调用或对象分配。
- en: Java Collections API
  id: totrans-272
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Java 集合 API
- en: Java’s collections API is extensive; it has at least 58 collection classes.
    Using an appropriate collection class—as well as using collection classes appropriately—is
    an important performance consideration in writing an application.
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
  zh: Java 的集合 API 非常广泛；它至少拥有 58 个集合类。在编写应用程序时，选择适当的集合类以及适当使用集合类，是重要的性能考量。
- en: The first rule in using a collection class is to use one suitable for the algorithmic
    needs of an application. This advice is not specific to Java; it is essentially
    Data Structures 101\. A `LinkedList` is not suitable for searching; if access
    to a random piece of data is required, store the collection in a `HashMap`. If
    the data needs to remain sorted, use a `TreeMap` rather than attempting to sort
    the data in the application. Use an `ArrayList` if the data will be accessed by
    index, but not if data frequently needs to be inserted into the middle of the
    array. And so on…the algorithmic choice of which collection class is crucial,
    but the choice in Java isn’t different from the choice in any other programming
    language.
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
  zh: 使用集合类的第一条规则是选择适合应用程序算法需求的集合类。这些建议并不局限于 Java；它实际上是数据结构的基础知识。`LinkedList` 不适合搜索；如果需要随机访问数据，请将集合存储在
    `HashMap` 中。如果数据需要保持排序状态，请使用 `TreeMap` 而不是尝试在应用程序中对数据进行排序。如果数据将通过索引进行访问，请使用 `ArrayList`，但如果需要经常在数组中间插入数据，则不要使用
    `ArrayList`。等等……选择哪种集合类的算法选择非常关键，但在 Java 中的选择与其他编程语言中的选择并无不同。
- en: There are, however, some idiosyncrasies to consider when using Java collections.
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
  zh: 在使用 Java 集合时，需要考虑一些特殊情况。
- en: Synchronized Versus Unsynchronized
  id: totrans-276
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 同步与非同步
- en: By default, virtually all Java collections are unsynchronized (the major exceptions
    are `Hashtable`, `Vector`, and their related classes).
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
  zh: 默认情况下，几乎所有 Java 集合都是非同步的（主要的例外是 `Hashtable`、`Vector` 及其相关类）。
- en: '[Chapter 9](ch09.html#ThreadPerformance) posited a microbenchmark to compare
    CAS-based protection to traditional synchronization. That proved to be impractical
    in the threaded case, but what if the data in question will always be accessed
    by a single thread—what would be the effect of not using any synchronization at
    all? [Table 12-10](#TableUnsync) shows that comparison. Because there is no attempt
    to model the contention, the microbenchmark in this case is valid in this one
    circumstance: when there can be no contention, and the question at hand is what
    the penalty is for “oversynchronizing” access to the resource.'
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
  zh: '[第九章](ch09.html#ThreadPerformance)提出了一个微基准测试，比较基于 CAS 的保护与传统同步。这在多线程情况下是不切实际的，但如果所讨论的数据始终由单个线程访问，那么完全不使用任何同步会有什么影响呢？[表
    12-10](#TableUnsync) 显示了该比较结果。由于没有尝试模拟争用，因此在这种情况下的微基准测试在这一个特定情况下是有效的：当不存在争用时，并且所讨论的问题是“过度同步”访问资源的成本。'
- en: Table 12-10\. Performance of synchronized and unsynchronized access
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
  zh: 表 12-10\. 同步访问与非同步访问的性能
- en: '| Mode | Single access | 10,000 accesses |'
  id: totrans-280
  prefs: []
  type: TYPE_TB
  zh: '| 模式 | 单次访问 | 10,000 次访问 |'
- en: '| --- | --- | --- |'
  id: totrans-281
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| CAS operation | 22.1 ± 11 ns | 209 ± 90 μs |'
  id: totrans-282
  prefs: []
  type: TYPE_TB
  zh: '| CAS 操作 | 22.1 ± 11 ns | 209 ± 90 μs |'
- en: '| Synchronized method | 20.8 ± 9 ns | 179 ± 95 μs |'
  id: totrans-283
  prefs: []
  type: TYPE_TB
  zh: '| 同步方法 | 20.8 ± 9 ns | 179 ± 95 μs |'
- en: '| Unsynchronized method | 15.8 ± 5 ns | 104 ± 55 μs |'
  id: totrans-284
  prefs: []
  type: TYPE_TB
  zh: '| 非同步方法 | 15.8 ± 5 ns | 104 ± 55 μs |'
- en: 'There is a small penalty when using any data protection technique as opposed
    to simple unsynchronized access. As usual with a microbenchmark, the difference
    is tiny: on the order of 5–8 nanoseconds. If the operation in question is executed
    frequently enough in the target application, the performance penalty will be somewhat
    noticeable. In most cases, the difference will be outweighed by far larger inefficiencies
    in other areas of the application. Remember also that the absolute number here
    is completely determined by the target machine the test was run on (my home machine
    with an AMD processor); to get a more realistic measurement, the test would need
    to be run on hardware that is the same as the target environment.'
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
  zh: 使用任何数据保护技术相对于简单的非同步访问都会有一些小的惩罚。就像使用微基准测试一样，差异微小：大约在5-8纳秒的数量级上。如果所讨论的操作在目标应用程序中执行频率足够高，则性能惩罚会有些明显。在大多数情况下，这种差异将被应用程序其他领域的远大于此的效率低下所抵消。还要记住，这里的绝对数字完全取决于运行测试的目标机器（我的家用机器带有AMD处理器）；为了获得更真实的测量结果，需要在与目标环境相同的硬件上运行测试。
- en: So, given a choice between a synchronized list (e.g., returned from the `synchronizedList()`
    method of the `Collections` class) and an unsynchronized `ArrayList`, which should
    be used? Access to the `ArrayList` will be slightly faster, and depending on how
    often the list is accessed, a measurable performance difference can result. (As
    noted in [Chapter 9](ch09.html#ThreadPerformance), excessive calls to the synchronized
    method can be painful for performance on certain hardware platforms as well.)
  id: totrans-286
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，在同步列表（例如从`Collections`类的`synchronizedList()`方法返回的列表）和非同步`ArrayList`之间进行选择，应该使用哪一个？对`ArrayList`的访问速度稍快，而且根据列表的访问频率不同，可能会产生可测量的性能差异。（正如在[第9章](ch09.html#ThreadPerformance)中指出的，对同步方法的过度调用也可能对某些硬件平台的性能产生负面影响。）
- en: On the other hand, this assumes that the code will never be accessed by more
    than one thread. That may be true today, but what about tomorrow? If that might
    change, it is better to use the synchronized collection now and mitigate any performance
    impact that results. This is a design choice, and whether future-proofing code
    to be thread-safe is worth the time and effort will depend on the circumstances
    of the application being developed.
  id: totrans-287
  prefs: []
  type: TYPE_NORMAL
  zh: 另一方面，这假设代码永远不会被多个线程访问。今天可能是这样，但明天呢？如果可能会改变，最好现在使用同步集合，并减轻由此产生的任何性能影响。这是一个设计选择，未来是否使代码具有线程安全性值得花费时间和精力将取决于正在开发的应用程序的情况。
- en: Collection Sizing
  id: totrans-288
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 集合大小调整
- en: Collection classes are designed to hold an arbitrary number of data elements
    and to expand as necessary, as new items are added to the collection. Sizing the
    collection appropriately can be important for their overall performance.
  id: totrans-289
  prefs: []
  type: TYPE_NORMAL
  zh: 集合类设计为容纳任意数量的数据元素，并根据需要进行扩展，随着新项添加到集合中。适当调整集合的大小对其整体性能可能很重要。
- en: 'Although the data types provided by collection classes in Java are quite rich,
    at a basic level those classes must hold their data using only Java primitive
    data types: numbers (`integer`s, `double`s, and so on), object references, and
    arrays of those types. Hence, an `ArrayList` contains an actual array:'
  id: totrans-290
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管Java中集合类提供的数据类型非常丰富，但在基本水平上，这些类必须仅使用Java基本数据类型来保存其数据：数字（`integer`，`double`等），对象引用以及这些类型的数组。因此，`ArrayList`包含一个实际数组：
- en: '[PRE18]'
  id: totrans-291
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: As items are added and removed from the `ArrayList`, they are stored at the
    desired location within the `elementData` array (possibly causing other items
    in the array to shift). Similarly, a `HashMap` contains an array of an internal
    data type called `HashMap$Entry`, which maps each key-value pair to a location
    in the array specified by the hash code of the key.
  id: totrans-292
  prefs: []
  type: TYPE_NORMAL
  zh: 当在`ArrayList`中添加和删除项时，它们将存储在`elementData`数组中的所需位置（可能会导致数组中的其他项移动）。同样，`HashMap`包含一个称为`HashMap$Entry`的内部数据类型的数组，该数组将每个键值对映射到由键的哈希码指定的数组中的位置。
- en: 'Not all collections use an array to hold their elements; a `LinkedList`, for
    example, holds each data element in an internally defined `Node` class. But collection
    classes that do use an array to hold their elements are subject to special sizing
    considerations. You can tell if a particular class falls into this category by
    looking at its constructors: if it has a constructor that allows the initial size
    of the collection to be specified, it is internally using an array to store the
    items.'
  id: totrans-293
  prefs: []
  type: TYPE_NORMAL
- en: 'For those collection classes, it is important to accurately specify the initial
    size. Take the simple example of an `ArrayList`: the `elementData` array will
    (by default) start out with an initial size of 10\. When the 11th item is inserted
    into an `ArrayList`, the list must expand the `elementData` array. This means
    allocating a new array, copying the original contents into that array, and then
    adding in the new item. The data structure and algorithm used by, say, the `HashMap`
    class is much more complicated, but the principle is the same: at some point,
    those internal structures must be resized.'
  id: totrans-294
  prefs: []
  type: TYPE_NORMAL
- en: The `ArrayList` class chooses to resize the array by adding roughly half of
    the existing size, so the size of the `elementData` array will first be 10, then
    15, then 22, then 33, and so on. Whatever algorithm is used to resize the array
    (see sidebar), this results in wasted memory (which in turn will affect the time
    the application spends performing GC). Additionally, each time the array must
    be resized, an expensive array copy operation must occur to transfer the contents
    from the old array to the new array.
  id: totrans-295
  prefs: []
  type: TYPE_NORMAL
- en: To minimize those performance penalties, make sure to construct the collection
    with as accurate an estimate of its ultimate size as possible.
  id: totrans-296
  prefs: []
  type: TYPE_NORMAL
- en: Collections and Memory Efficiency
  id: totrans-297
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'You’ve just seen one example where the memory efficiency of collections can
    be suboptimal: there is often some wasted memory in the backing store used to
    hold the elements in the collection.'
  id: totrans-298
  prefs: []
  type: TYPE_NORMAL
- en: 'This can be particularly problematic for sparsely used collections: those with
    one or two elements. These sparsely used collections can waste a lot of memory
    if they are used extensively. One way to deal with that is to size the collection
    when it is created. Another way is to consider whether a collection is really
    needed in that case at all.'
  id: totrans-299
  prefs: []
  type: TYPE_NORMAL
- en: 'When most developers are asked how to quickly sort any array, they will offer
    up quicksort as the answer. Good performance engineers will want to know the size
    of the array: if the array is small enough, the fastest way to sort it will be
    to use insertion sort.^([4](ch12.html#idm45775542298712)) Size matters.'
  id: totrans-300
  prefs: []
  type: TYPE_NORMAL
- en: Similarly, `HashMap` is the fastest way to look up items based on a key value,
    but if there is only one key, `HashMap` is overkill compared to using a simple
    object reference. Even if there are a few keys, maintaining a few object references
    will consume much less memory than a full `HashMap` object, with the resulting
    (positive) effect on GC.
  id: totrans-301
  prefs: []
  type: TYPE_NORMAL
- en: Quick Summary
  id: totrans-302
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Carefully consider how collections will be accessed and choose the right type
    of synchronization for them. However, the penalty for uncontended access to a
    memory-protected collection (particularly one using CAS-based protections) is
    minimal; sometimes it is better to be safe than sorry.
  id: totrans-303
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 仔细考虑如何访问集合并选择适当的同步类型。然而，对于内存受保护的集合（特别是使用CAS-based保护的集合），无竞争访问的惩罚是最小的；有时最好保险起见。
- en: 'Sizing of collections can have a large impact on performance: either slowing
    down the garbage collector if the collection is too large or causing lots of copying
    and resizing if it is too small.'
  id: totrans-304
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 集合的大小对性能有很大影响：如果集合太大，可能会减慢垃圾收集器；如果集合太小，则可能会导致大量复制和调整大小。
- en: Lambdas and Anonymous Classes
  id: totrans-305
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Lambdas 和匿名类
- en: For many developers, the most exciting feature of Java 8 was the addition of
    lambdas. There is no denying that lambdas have a hugely positive impact on the
    productivity of Java developers, though of course that benefit is difficult to
    quantify. But we can examine the performance of code using lambda constructs.
  id: totrans-306
  prefs: []
  type: TYPE_NORMAL
  zh: 对许多开发人员来说，Java 8最令人兴奋的特性是添加了lambda。毫无疑问，lambda对Java开发人员的生产力有巨大的积极影响，尽管这种好处很难量化。但是我们可以检查使用lambda构造的代码的性能。
- en: The most basic question about the performance of lambdas is how they compare
    to their replacement, anonymous classes. There turns out to be little difference.
  id: totrans-307
  prefs: []
  type: TYPE_NORMAL
  zh: 关于lambda性能的最基本问题是它们与它们的替代品——匿名类的比较。结果显示几乎没有区别。
- en: 'The usual example of how to use a lambda class begins with code that creates
    anonymous inner classes (the usual example often uses a `Stream` rather than the
    iterator shown here; information about the `Stream` class comes later in this
    section):'
  id: totrans-308
  prefs: []
  type: TYPE_NORMAL
  zh: 使用lambda类的典型示例通常以创建匿名内部类的代码开始（通常示例使用`Stream`而不是此处显示的迭代器；有关`Stream`类的信息稍后在本节中介绍）：
- en: '[PRE19]'
  id: totrans-309
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'That is compared to the following code using lambdas:'
  id: totrans-310
  prefs: []
  type: TYPE_NORMAL
  zh: 这与使用lambda的以下代码进行比较：
- en: '[PRE20]'
  id: totrans-311
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'The body of the lambda or anonymous class is crucial: if that body performs
    any significant operations, the time spent in the operation is going to overwhelm
    any small difference in the implementations of the lambda or the anonymous class.
    However, even in this minimal case, the time to perform this operation is essentially
    the same, as [Table 12-11](#TableLambda1) shows, though as the number of expressions
    (i.e., classes/lambdas) increases, small differences do emerge.'
  id: totrans-312
  prefs: []
  type: TYPE_NORMAL
  zh: Lambda或匿名类的主体至关重要：如果主体执行任何重要操作，那么操作花费的时间将会压倒lambda或匿名类实现中的任何小差异。然而，即使在这种最小的情况下，执行此操作所需的时间基本相同，如[表12-11](#TableLambda1)所示，尽管随着表达式（即类/lambda的数量）的增加，确实会出现一些小差异。
- en: Table 12-11\. Time to execute the `calc()` method using lambdas and anonymous
    classes
  id: totrans-313
  prefs: []
  type: TYPE_NORMAL
  zh: 表12-11\. 使用lambda和匿名类执行`calc()`方法的时间
- en: '| Implementation | 1,024 expressions | 3 expressions |'
  id: totrans-314
  prefs: []
  type: TYPE_TB
  zh: '| 实现 | 1,024个表达式 | 3个表达式 |'
- en: '| --- | --- | --- |'
  id: totrans-315
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| Anonymous classes | 781 ± 50 μs | 10 ± 1 ns |'
  id: totrans-316
  prefs: []
  type: TYPE_TB
  zh: '| 匿名类 | 781 ± 50 μs | 10 ± 1 ns |'
- en: '| Lambda | 587 ± 27 μs | 10 ± 2 ns |'
  id: totrans-317
  prefs: []
  type: TYPE_TB
  zh: '| Lambda | 587 ± 27 μs | 10 ± 2 ns |'
- en: '| Static classes | 734 ± 21 μs | 10 ± 1 ns |'
  id: totrans-318
  prefs: []
  type: TYPE_TB
  zh: '| 静态类 | 734 ± 21 μs | 10 ± 1 ns |'
- en: One interesting thing about the typical usage in this example is that the code
    that uses the anonymous class creates a new object every time the method is called.
    If the method is called a lot (as it must be in a benchmark to measure its performance),
    many instances of that anonymous class are quickly created and discarded. As you
    saw in [Chapter 5](ch05.html#GC), that kind of usage often has little impact on
    performance. There is a very small cost to allocate (and, more important, to initialize)
    the objects, and because they are discarded quickly, they do not really slow down
    the garbage collector. Yet when we’re measuring in the nanosecond range, those
    small times do add up.
  id: totrans-319
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个例子中典型用法的一个有趣之处是，使用匿名类的代码每次调用方法时都会创建一个新对象。如果方法被频繁调用（如在性能测试中必须这样做），那么许多匿名类的实例会很快被创建和丢弃。正如你在[第5章](ch05.html#GC)中看到的，这种使用通常对性能影响不大。分配（更重要的是初始化）对象存在非常小的成本，并且由于它们很快被丢弃，它们实际上不会拖慢垃圾收集器。然而，在纳秒级的测量范围内，这些小时间确实会累积起来。
- en: 'The last row in the table uses preconstructed objects rather than anonymous
    classes:'
  id: totrans-320
  prefs: []
  type: TYPE_NORMAL
  zh: 表中的最后一行使用的是预构建对象，而不是匿名类：
- en: '[PRE21]'
  id: totrans-321
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: The typical usage of the lambda does not create a new object on each iteration
    of the loop—making this an area where some corner cases can favor the performance
    of the lambda usage. Even in this example, though, the differences are minimal.
  id: totrans-322
  prefs: []
  type: TYPE_NORMAL
  zh: 典型的lambda用法在循环的每次迭代中不会创建新对象，这是一些边界情况下lambda使用性能优势的地方。即使在这个例子中，差异也是微小的。
- en: Quick Summary
  id: totrans-323
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 快速总结
- en: The choice between using a lambda or an anonymous class should be dictated by
    ease of programming, since there is no difference between their performance.
  id: totrans-324
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用lambda还是匿名类的选择应该由编程的便利性决定，因为它们在性能上没有区别。
- en: Lambdas are not implemented as anonymous classes, so one exception to that rule
    is in environments where classloading behavior is important; lambdas will be slightly
    faster in that case.
  id: totrans-325
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Lambdas并非作为匿名类实现，因此在类加载行为重要的环境中有一个例外；在这种情况下，lambda会稍微更快。
- en: Stream and Filter Performance
  id: totrans-326
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 流和过滤器性能
- en: One other key feature of Java 8, and one that is frequently used in conjunction
    with lambdas, is the new `Stream` facility. One important performance feature
    of streams is that they can automatically parallelize code. Information about
    parallel streams can be found in [Chapter 9](ch09.html#ThreadPerformance); this
    section discusses general performance features of streams and filters.
  id: totrans-327
  prefs: []
  type: TYPE_NORMAL
  zh: Java 8的另一个关键特性，也是经常与lambda一起使用的特性，是新的`Stream`工具。流的一个重要性能特性是它们可以自动并行化代码。关于并行流的信息可以在[第9章](ch09.html#ThreadPerformance)找到；本节讨论流和过滤器的一般性能特性。
- en: Lazy Traversal
  id: totrans-328
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 懒遍历
- en: 'The first performance benefit from streams is that they are implemented as
    lazy data structures. Say we have a list of stock symbols, and the goal is to
    find the first symbol in the list that does not contain the letter `A`. The code
    to do that through a stream looks like this:'
  id: totrans-329
  prefs: []
  type: TYPE_NORMAL
  zh: 流的第一个性能优势是它们被实现为惰性数据结构。假设我们有一个股票符号列表，目标是找到列表中第一个不包含字母`A`的符号。通过流执行此操作的代码如下：
- en: '[PRE22]'
  id: totrans-330
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: There’s obviously a better way to implement this using a single filter, but
    we’ll save that discussion for later in this section. For now, consider what it
    means for the stream to be implemented lazily in this example. Each `filter()`
    method returns a new stream, so there are, in effect, four logical streams here.
  id: totrans-331
  prefs: []
  type: TYPE_NORMAL
  zh: 显然，有一个更好的方法可以使用单一的过滤器来实现，但我们将在本节稍后讨论这个问题。现在，考虑在这个例子中实现惰性流的含义。每个`filter()`方法返回一个新的流，因此在这里实际上有四个逻辑流。
- en: The `filter()` method, it turns out, doesn’t really do anything except set up
    a series of pointers. The effect of that is when the `findFirst()` method is invoked
    on the stream, no data processing has been performed—no comparisons of data to
    the character `A` have yet been made.
  id: totrans-332
  prefs: []
  type: TYPE_NORMAL
  zh: '`filter()`方法事实上并不执行任何操作，只是设置一系列指针。其效果是当在流上调用`findFirst()`方法时，尚未执行任何数据处理——还没有对数据与字符`A`进行比较。'
- en: Instead, `findFirst()` asks the previous stream (returned from filter 4) for
    an element. That stream has no elements yet, so it calls back to the stream produced
    by filter 3, and so on. Filter 1 will grab the first element from the array list
    (from the stream, technically) and test whether its first character is `A`. If
    so, it completes the callback and returns that element downstream; otherwise,
    it continues to iterate through the array until it finds a matching element (or
    exhausts the array). Filter 2 behaves similarly—when the callback to filter 1
    returns, it tests whether the second character is not `A`. If so, it completes
    its callback and passes the symbol downstream; if not, it makes another callback
    to filter 1 to get the next symbol.
  id: totrans-333
  prefs: []
  type: TYPE_NORMAL
  zh: 相反，`findFirst()`要求前一个流（从filter 4返回）提供一个元素。该流目前没有元素，因此它回调到由filter 3产生的流，依此类推。Filter
    1将从数组列表（从技术上讲是从流中）获取第一个元素，并测试其第一个字符是否为`A`。如果是，则完成回调并将该元素传递到下游；否则，它继续迭代数组直到找到匹配的元素（或耗尽数组）。Filter
    2的行为类似——当回调到Filter 1返回时，它测试第二个字符是否不是`A`。如果是，则完成其回调并将符号传递到下游；如果不是，则再次回调到Filter
    1获取下一个符号。
- en: 'All those callbacks may sound inefficient, but consider the alternative. An
    algorithm to process the streams eagerly would look something like this:'
  id: totrans-334
  prefs: []
  type: TYPE_NORMAL
  zh: 所有这些回调听起来可能效率低下，但考虑一下替代方案。急切处理流的算法可能如下所示：
- en: '[PRE23]'
  id: totrans-335
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: There are two reasons this alternative is less efficient than the lazy implementation
    that Java actually adopted. First, it requires the creation of a lot of temporary
    instances of the `ArrayList` class. Second, in the lazy implementation, processing
    can stop as soon as the `findFirst()` method gets an element. That means only
    a subset of the items must actually pass through the filters. The eager implementation,
    on the other hand, must process the entire list several times until the last list
    is created.
  id: totrans-336
  prefs: []
  type: TYPE_NORMAL
  zh: 这种替代方案比Java实际采用的懒惰实现效率低的原因有两点。首先，它需要创建大量的`ArrayList`类的临时实例。其次，在懒惰的实现中，一旦`findFirst()`方法获得一个元素，处理就可以停止了。这意味着只有部分项目实际上需要通过过滤器。相反，急切的实现必须多次处理整个列表，直到创建最后的列表。
- en: Hence, it should come as no surprise that the lazy implementation is far more
    performant than the alternative in this example. In this case, the test is processing
    a list of 456,976 four-letter symbols, which are sorted in alphabetical order.
    The eager implementation processes only 18,278 of those before it encounters the
    symbol `BBBB`, at which point it can stop. It takes the iterator two orders of
    magnitude longer to find that answer, as shown in [Table 12-12](#TableFilter).
  id: totrans-337
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，在这个例子中，懒惰的实现比替代方案要更高效并不奇怪。在这种情况下，测试正在处理一个按字母顺序排序的、包含456,976个四个字母符号的列表。急切的实现在遇到符号`BBBB`之前只处理了18,278个符号就停止了。而迭代器则需要更长时间才能找到答案，如[表12-12](#TableFilter)所示，需要两个数量级的时间。
- en: Table 12-12\. Time to process lazy versus eager filters
  id: totrans-338
  prefs: []
  type: TYPE_NORMAL
  zh: 表12-12\. 懒惰与急切过滤器处理时间
- en: '| Implementation | Seconds |'
  id: totrans-339
  prefs: []
  type: TYPE_TB
  zh: '| 实现 | 秒 |'
- en: '| --- | --- |'
  id: totrans-340
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| Filter/`findFirst` | 0.76 ± 0.047 ms |'
  id: totrans-341
  prefs: []
  type: TYPE_TB
  zh: '| 过滤器/`findFirst` | 0.76 ± 0.047 毫秒 |'
- en: '| Iterator/`findFirst` | 108.4 ± 4 ms |'
  id: totrans-342
  prefs: []
  type: TYPE_TB
  zh: '| 迭代器/`findFirst` | 108.4 ± 4 毫秒 |'
- en: 'One reason, then, that filters can be so much faster than iterators is simply
    that they can take advantage of algorithmic opportunities for optimizations: the
    lazy filter implementation can end processing whenever it has done what it needs
    to do, processing less data.'
  id: totrans-343
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，过滤器比迭代器快得多的一个原因是，它们可以利用算法上的优化机会：懒惰的过滤器实现只需在完成需要的工作后停止处理，处理的数据量较少。
- en: 'What if the entire set of data must be processed? What is the basic performance
    of filters versus iterators in that case? For this example, we’ll change the test
    slightly. The previous example made a good teaching point about how multiple filters
    worked, but ideally it was obvious that the code would perform better with a single
    filter:'
  id: totrans-344
  prefs: []
  type: TYPE_NORMAL
  zh: 如果整个数据集必须被处理，过滤器和迭代器在这种情况下的基本性能如何？例如，我们稍微改变了测试。之前的例子很好地说明了多个过滤器如何工作，但理想情况下，显而易见的是使用单个过滤器代码性能会更好：
- en: '[PRE24]'
  id: totrans-345
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'This example also changes the final code to count the symbols, so that the
    entire list will be processed. On the flip side, the eager implementation can
    now use an iterator directly:'
  id: totrans-346
  prefs: []
  type: TYPE_NORMAL
  zh: 这个例子还改变了最终代码以计算符号的数量，以便整个列表都能被处理。与此同时，急切的实现现在可以直接使用迭代器：
- en: '[PRE25]'
  id: totrans-347
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: Even in this case, the lazy filter implementation is faster than the iterator
    (see [Table 12-13](#TableFilterOpt)).
  id: totrans-348
  prefs: []
  type: TYPE_NORMAL
  zh: 即使在这种情况下，懒惰的过滤器实现也比迭代器更快（见[表12-13](#TableFilterOpt)）。
- en: Table 12-13\. Time to process single filter versus an iterator
  id: totrans-349
  prefs: []
  type: TYPE_NORMAL
  zh: 表12-13\. 单个过滤器与迭代器处理时间对比
- en: '| Implementation | Time required |'
  id: totrans-350
  prefs: []
  type: TYPE_TB
  zh: '| 实现 | 所需时间 |'
- en: '| --- | --- |'
  id: totrans-351
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| Filters | 7 ± 0.6 ms |'
  id: totrans-352
  prefs: []
  type: TYPE_TB
  zh: '| 过滤器 | 7 ± 0.6 毫秒 |'
- en: '| Iterator | 7.4 ± 3 ms |'
  id: totrans-353
  prefs: []
  type: TYPE_TB
  zh: '| 迭代器 | 7.4 ± 3 毫秒 |'
- en: Quick Summary
  id: totrans-354
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 快速总结
- en: Filters offer a significant performance advantage by allowing processing to
    end in the middle of iterating through the data.
  id: totrans-355
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 过滤器通过允许在迭代数据时中途结束来提供显著的性能优势。
- en: Even when the entire data set is processed, a single filter will slightly outperform
    an iterator.
  id: totrans-356
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 即使整个数据集被处理，单个过滤器的性能也略优于迭代器。
- en: Multiple filters have overhead; make sure to write good filters.
  id: totrans-357
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 多个过滤器会带来额外开销；务必编写良好的过滤器。
- en: Object Serialization
  id: totrans-358
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 对象序列化
- en: '*Object serialization* is a way to write out the binary state of an object
    such that it can be re-created later. The JDK provides a default mechanism to
    serialize objects that implement either the `Serializable` or `Externalizable`
    interface. The serialization performance of practically every object imaginable
    can be improved from the default serialization code, but this is definitely one
    of those times when it would be unwise to perform that optimization prematurely.
    The special code to serialize and deserialize the object will take a fair amount
    of time to write, and the code will be harder to maintain than code that uses
    default serialization. Serialization code can also be a little tricky to write
    correctly, so attempting to optimize it increases the risk of producing incorrect
    code.'
  id: totrans-359
  prefs: []
  type: TYPE_NORMAL
  zh: '*对象序列化* 是一种将对象的二进制状态写出的方法，以便稍后可以重新创建它。JDK提供了一个默认机制来序列化实现了 `Serializable` 或
    `Externalizable` 接口的对象。实际上几乎每种对象的序列化性能都可以从默认的序列化代码中得到改善，但这绝对是一种在没有充分理由时不应该优化的情况。编写专门的序列化和反序列化代码将花费相当多的时间，并且这样的代码比使用默认序列化更难维护。序列化代码有时候也比较棘手，因此尝试优化它会增加生成错误代码的风险。'
- en: Transient Fields
  id: totrans-360
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 临时字段
- en: In general, the way to improve object serialization cost is to serialize less
    data. This is done by marking fields as `transient`, in which case they are not
    serialized by default. Then the class can supply special `writeObject()` and `readObject()`
    methods to handle that data. If the data isn’t needed, marking it as `transient`
    is sufficient.
  id: totrans-361
  prefs: []
  type: TYPE_NORMAL
  zh: 一般来说，改进对象序列化成本的方法是序列化更少的数据。这可以通过将字段标记为 `transient` 来实现，默认情况下这些字段不会被序列化。然后类可以提供特殊的
    `writeObject()` 和 `readObject()` 方法来处理这些数据。如果数据不需要被序列化，将其标记为 `transient` 就足够了。
- en: Overriding Default Serialization
  id: totrans-362
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 覆盖默认的序列化
- en: 'The `writeObject()` and `readObject()` methods allow complete control over
    how data is serialized. With great control comes great responsibility: it’s easy
    to get this wrong.'
  id: totrans-363
  prefs: []
  type: TYPE_NORMAL
  zh: '`writeObject()` 和 `readObject()` 方法允许完全控制数据的序列化方式。伴随着极大的控制权而来的是极大的责任：很容易搞砸这个。'
- en: 'To get an idea of why serialization optimizations are tricky, take the case
    of a simple `Point` object that represents a location:'
  id: totrans-364
  prefs: []
  type: TYPE_NORMAL
  zh: 要了解为什么序列化优化很棘手，可以看看一个简单的代表位置的 `Point` 对象的情况：
- en: '[PRE26]'
  id: totrans-365
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'That code could be written to perform special serialization like this:'
  id: totrans-366
  prefs: []
  type: TYPE_NORMAL
  zh: 可以编写特殊序列化的代码如下：
- en: '[PRE27]'
  id: totrans-367
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'In a simple example like this, the more complex code isn’t going to be any
    faster, but it is still functionally correct. But beware of using this technique
    in the general case:'
  id: totrans-368
  prefs: []
  type: TYPE_NORMAL
  zh: 在像这样的简单例子中，更复杂的代码不会更快，但它仍然是功能正确的。但要注意在一般情况下使用这种技术时：
- en: '[PRE28]'
  id: totrans-369
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: Here, the `airportsVisited` field is an array of all the airports I’ve ever
    flown to or from, in the order in which I visited them. So certain airports, like
    JFK, appear frequently in the array; SYD appears only once (so far).
  id: totrans-370
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，`airportsVisited` 字段是一个数组，记录了我曾经飞过或从中飞出的所有机场，按照我访问它们的顺序排列。因此，像JFK这样的机场在数组中频繁出现；SYD目前只出现了一次。
- en: 'Because it is expensive to write object references, this code would certainly
    perform faster than the default serialization mechanism for that array: an array
    of 100,000 `Point` objects takes 15.5 ± 0.3 ms seconds to serialize on my machine
    and 10.9 ± 0.5 ms to deserialize. Using this “optimization,” it takes only 1 ±
    .600 ms seconds to serialize and 0.85 ± 0.2 μs to deserialize.'
  id: totrans-371
  prefs: []
  type: TYPE_NORMAL
  zh: 因为写入对象引用的成本很高，所以这段代码肯定比默认的序列化机制更快：在我的机器上，一个包含100,000个 `Point` 对象的数组在序列化时需要15.5
    ± 0.3毫秒，反序列化时需要10.9 ± 0.5毫秒。使用这种“优化”方法，序列化只需1 ± 0.600毫秒，反序列化只需0.85 ± 0.2微秒。
- en: This code, however, is incorrect. Before serialization, a single object represents
    JFK, and the reference to that object appears multiple times in the array. After
    the array is serialized and then deserialized, multiple objects represent JFK.
    This changes the behavior of the application.
  id: totrans-372
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，这段代码是不正确的。在序列化之前，一个单一的对象表示JFK，并且该对象的引用多次出现在数组中。在数组被序列化然后再次反序列化之后，多个对象表示JFK。这改变了应用程序的行为。
- en: When the array is deserialized in this example, those JFK references end up
    as separate, different objects. Now when one of those objects is changed, only
    that object is changed, and it ends up with different data than the remaining
    objects that refer to JFK.
  id: totrans-373
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个例子中，当数组被反序列化时，那些指向JFK的引用最终变成了单独的、不同的对象。现在，当这些对象中的一个被更改时，只有那个对象被更改了，并且它最终拥有与其他引用JFK的对象不同的数据。
- en: This is an important principle to keep in mind, because optimizing serialization
    is often about performing special handling for object references. Done correctly,
    that can greatly increase the performance of serialization code. Done incorrectly,
    it can introduce subtle bugs.
  id: totrans-374
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个重要的原则要牢记，因为优化序列化通常涉及对象引用的特殊处理。如果处理得当，这可以极大地提高序列化代码的性能。如果处理不当，可能会引入难以察觉的错误。
- en: 'With that in mind, let’s explore the serialization of the `StockPriceHistory`
    class to see how serialization optimizations can be made. The fields in that class
    include the following:'
  id: totrans-375
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑到这一点，让我们探讨`StockPriceHistory`类的序列化，看看如何进行序列化优化。该类中的字段包括以下内容：
- en: '[PRE29]'
  id: totrans-376
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: When the history for a stock is constructed for a given symbol `s`, the object
    creates and stores a sorted map of `prices` keyed by date of all the prices between
    `start` and `end`. The code also saves the `firstDate` and the `lastDate`. The
    constructor doesn’t fill in any other fields; they are initialized lazily. When
    a getter on any of those fields is called, the getter checks if `needsCalc` is
    `true`. If it is, it calculates the appropriate values for the remaining fields
    if necessary (all at once).
  id: totrans-377
  prefs: []
  type: TYPE_NORMAL
  zh: 当为给定符号`s`构建股票历史记录时，对象创建并存储了一个按日期排序的`prices`映射，其中包含`start`和`end`之间所有价格的日期。代码还保存了`firstDate`和`lastDate`。构造函数不填充任何其他字段；它们是惰性初始化的。当调用这些字段中的任何一个getter时，getter会检查`needsCalc`是否为`true`。如果是，它将必要时一次性计算剩余字段的适当值。
- en: This calculation includes creating the `histogram`, which records how many days
    the stock closed at a particular price. The histogram contains the same data (in
    terms of `BigDecimal` and `Date` objects) as is found in the `prices` map; it
    is just a different way of looking at the data.
  id: totrans-378
  prefs: []
  type: TYPE_NORMAL
  zh: 此计算包括创建`histogram`，记录股票以特定价格收盘的天数。直方图包含与`prices`映射中相同的数据（以`BigDecimal`和`Date`对象表示），只是以不同的方式查看数据。
- en: Because all of the lazily initialized fields can be calculated from the `prices`
    array, they can all be marked `transient`, and no special work is required to
    serialize or deserialize them. The example is easy in this case because the code
    was already doing lazy initialization of the fields; it can repeat that lazy initialization
    when receiving the data. Even if the code eagerly initialized these fields, it
    could still mark any calculated fields `transient` and recalculate their values
    in the `readObject()` method of the class.
  id: totrans-379
  prefs: []
  type: TYPE_NORMAL
  zh: 因为所有惰性初始化的字段都可以从`prices`数组计算得出，它们都可以标记为`transient`，因此在序列化或反序列化它们时不需要特殊处理。在这种情况下，示例很容易，因为代码已经在字段的惰性初始化上进行了处理；它可以在接收数据时重复执行这种惰性初始化。即使代码急切地初始化了这些字段，仍然可以将任何计算出的字段标记为`transient`，并在类的`readObject()`方法中重新计算它们的值。
- en: 'Note too that this preserves the object relationship between the `prices` and
    `histogram` objects: when the histogram is recalculated, it will just insert existing
    objects into the new map.'
  id: totrans-380
  prefs: []
  type: TYPE_NORMAL
  zh: 还要注意，这保留了`prices`和`histogram`对象之间的对象关系：当重新计算直方图时，它将只向新映射中插入现有对象。
- en: This kind of optimization is almost always a good thing, but in some cases it
    can hurt performance. [Table 12-14](#TableTransientHist) shows the time it takes
    to serialize and deserialize this case where the `histogram` object is transient
    versus nontransient, as well as the size of the serialized data for each case.
  id: totrans-381
  prefs: []
  type: TYPE_NORMAL
  zh: 这种优化几乎总是一件好事，但在某些情况下可能会影响性能。[表12-14](#TableTransientHist)显示了序列化和反序列化这种情况时，`histogram`对象是transient和nontransient的时间，以及每种情况下序列化数据的大小。
- en: Table 12-14\. Time to serialize and deserialize objects with transient fields
  id: totrans-382
  prefs: []
  type: TYPE_NORMAL
  zh: 表12-14。对象带有transient字段的序列化和反序列化时间
- en: '| Object | Serialization time | Deserialization time | Size of data |'
  id: totrans-383
  prefs: []
  type: TYPE_TB
  zh: '| 对象 | 序列化时间 | 反序列化时间 | 数据大小 |'
- en: '| --- | --- | --- | --- |'
  id: totrans-384
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- |'
- en: '| No transient fields | 19.1 ± 0.1 ms | 16.8 ± 0.4 ms | 785,395 bytes |'
  id: totrans-385
  prefs: []
  type: TYPE_TB
  zh: '| 没有transient字段 | 19.1 ± 0.1 毫秒 | 16.8 ± 0.4 毫秒 | 785,395 字节 |'
- en: '| Transient histogram | 16.7 ± 0.2 ms | 14.4 ± 0.2 ms | 754,227 bytes |'
  id: totrans-386
  prefs: []
  type: TYPE_TB
  zh: '| transient直方图 | 16.7 ± 0.2 毫秒 | 14.4 ± 0.2 毫秒 | 754,227 字节 |'
- en: So far, the example saves about 15% of the total time to serialize and deserialize
    the object. But this test has not actually re-created the `histogram` object on
    the receiving side. That object will be created when the receiving code first
    accesses it.
  id: totrans-387
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，这个示例节省了大约15%的总序列化和反序列化时间。但是此测试实际上还没有在接收端重新创建`histogram`对象。当接收端代码首次访问它时，该对象将被创建。
- en: 'Sometimes the `histogram` object will not be needed; the receiver may be interested
    in only the prices on particular days, and not the histogram. That is where the
    more unusual case comes in: if the `histogram` will always be needed and if it
    takes more than 2.4 milliseconds to calculate the histogram, then the case with
    the lazily initialized fields will actually have a net performance decrease.'
  id: totrans-388
  prefs: []
  type: TYPE_NORMAL
  zh: 有时`histogram`对象可能不会被需要；接收方可能只对特定日期的价格感兴趣，而不关心直方图。这就是更不寻常的情况：如果`histogram`总是需要，并且计算直方图花费超过2.4毫秒，那么使用延迟初始化字段的情况实际上会导致性能下降。
- en: In this case, calculating the histogram does not fall into that category—it
    is a very fast operation. In general, it may be hard to find a case where recalculating
    a piece of data is more expensive than serializing and deserializing that data.
    But it is something to consider as code is optimized.
  id: totrans-389
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，计算直方图并不属于那种情况——它是一个非常快速的操作。一般来说，可能很难找到重新计算数据比序列化和反序列化数据更昂贵的情况。但在优化代码时需要考虑这一点。
- en: This test is not actually transmitting data; the data is written to and read
    from preallocated byte arrays so that it measures only the time for serialization
    and deserialization. Still, notice that making the `histogram` field transient
    has also saved about 13% in the size of the data. That will be quite important
    if the data is to be transmitted via a network.
  id: totrans-390
  prefs: []
  type: TYPE_NORMAL
  zh: 这个测试实际上并不传输数据；数据写入和读取都是从预分配的字节数组进行的，因此只测量了序列化和反序列化的时间。但是，请注意，将`histogram`字段设为瞬态也节省了大约13%的数据大小。如果要通过网络传输数据，这一点将非常重要。
- en: Compressing Serialized Data
  id: totrans-391
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 压缩序列化数据
- en: 'Serialization performance of code can be improved in a third way: compress
    the serialized data so it is faster to transmit. In the stock history class, that
    is done by compressing the `prices` map during serialization:'
  id: totrans-392
  prefs: []
  type: TYPE_NORMAL
  zh: 代码的序列化性能可以通过第三种方式进行改进：压缩序列化数据以便更快地传输。在股票历史类中，通过在序列化过程中压缩`prices`映射来实现：
- en: '[PRE30]'
  id: totrans-393
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: The `zipPrices()` method serializes the map of prices to a byte array and saves
    the resulting bytes, which are then serialized normally in the `writeObject()`
    method when it calls the `defaultWriteObject()` method. (In fact, as long as the
    serialization is being customized, it will be ever-so-slightly better to make
    the `zippedPrices` array transient and write out its length and bytes directly.
    But this example code is a little clearer, and simpler is better.) On deserialization,
    the reverse operation is performed.
  id: totrans-394
  prefs: []
  type: TYPE_NORMAL
  zh: '`zipPrices()`方法将价格映射序列化为字节数组并保存生成的字节，在`writeObject()`方法中调用`defaultWriteObject()`方法时会将其正常序列化。（实际上，只要自定义了序列化，将`zippedPrices`数组设为瞬态并直接写出其长度和字节会略微更好。但这个示例代码更清晰，简单更好。）在反序列化时，执行反向操作。'
- en: If the goal is to serialize to a byte stream (as in the original sample code),
    this is a losing proposition. That isn’t surprising; the time required to compress
    the bytes is much longer than the time to write them to a local byte array. Those
    times are shown in [Table 12-15](#TableSerializeCompress).
  id: totrans-395
  prefs: []
  type: TYPE_NORMAL
  zh: 如果目标是将数据序列化为字节流（如原始示例代码中），这是一个失败的建议。这并不令人惊讶；压缩字节所需的时间远远长于将它们写入本地字节数组的时间。这些时间显示在[表格
    12-15](#TableSerializeCompress)中。
- en: Table 12-15\. Time to serialize and deserialize 10,000 objects with compression
  id: totrans-396
  prefs: []
  type: TYPE_NORMAL
  zh: 表格 12-15\. 使用压缩序列化和反序列化 10,000 个对象所需的时间
- en: '| Use case | Serialization time | Deserialization time | Size of data |'
  id: totrans-397
  prefs: []
  type: TYPE_TB
  zh: '| 使用案例 | 序列化时间 | 反序列化时间 | 数据大小 |'
- en: '| --- | --- | --- | --- |'
  id: totrans-398
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- |'
- en: '| No compression | 16.7 ± 0.2 ms | 14.4 ± 0.2 ms | 754,227 bytes |'
  id: totrans-399
  prefs: []
  type: TYPE_TB
  zh: '| 无压缩 | 16.7 ± 0.2 毫秒 | 14.4 ± 0.2 毫秒 | 754,227 字节 |'
- en: '| Compression/decompression | 43.6 ± 0.2 ms | 18.7 ± 0.5 ms | 231,844 bytes
    |'
  id: totrans-400
  prefs: []
  type: TYPE_TB
  zh: '| 压缩/解压缩 | 43.6 ± 0.2 毫秒 | 18.7 ± 0.5 毫秒 | 231,844 字节 |'
- en: '| Compression only | 43.6 ± 0.2 ms | .720 ± 0.3 ms | 231,844 bytes |'
  id: totrans-401
  prefs: []
  type: TYPE_TB
  zh: '| 仅压缩 | 43.6 ± 0.2 毫秒 | .720 ± 0.3 毫秒 | 231,844 字节 |'
- en: The most interesting point about this table is the last row. In that test, the
    data is compressed before sending, but the `unzipPrices()` method isn’t called
    in the `readObject()` method. Instead, it is called when needed, which will be
    the first time the receiver calls the `getPrice()` method. Absent that call, there
    are only a few `BigDecimal` objects to deserialize, which is quite fast.
  id: totrans-402
  prefs: []
  type: TYPE_NORMAL
  zh: 这张表格最有趣的一点在于最后一行。在这个测试中，数据在发送之前被压缩，但`readObject()`方法中并未调用`unzipPrices()`方法。相反，它在需要的时候才会被调用，这将是接收方首次调用`getPrice()`方法的时候。如果没有这个调用，反序列化时只需要处理少量的`BigDecimal`对象，速度相当快。
- en: 'In this example, the receiver might never need the actual prices: the receiver
    may need only to call the `getHighPrice()` and similar methods to retrieve aggregate
    information about the data. As long as those methods are all that is needed, a
    lot of time can be saved by lazily decompressing the `prices` information. This
    lazy decompression is also useful if the object in question is being persisted
    (e.g., if it is HTTP session state that is being stored as a backup copy in case
    the application server fails). Lazily decompressing the data saves both CPU time
    (from skipping the decompression) and memory (since the compressed data takes
    up less space).'
  id: totrans-403
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个例子中，接收者可能根本不需要实际的价格数据：接收者可能只需要调用 `getHighPrice()` 等方法来检索关于数据的聚合信息。只要这些方法是所需的全部内容，延迟解压缩
    `prices` 信息可以节省大量时间。如果正在持久化的对象是需要的（例如，如果它是 HTTP 会话状态，作为备份副本存储以防应用服务器失败），那么延迟解压缩数据既可以节省
    CPU 时间（跳过解压缩）又可以节省内存（因为压缩数据占用的空间更少）。
- en: Hence—particularly if the goal is to save memory rather than time—compressing
    data for serialization and then lazily decompressing it can be useful.
  id: totrans-404
  prefs: []
  type: TYPE_NORMAL
  zh: 因此——特别是如果目标是节省内存而不是时间——对序列化的数据进行压缩，然后延迟解压缩可能是有用的。
- en: If the point of the serialization is to transfer data over the network, we have
    the usual trade-offs based on the network speed. On a fast network, the time for
    compression can easily be longer than the time saved while transmitting less data;
    on slower networks, the opposite might be true. In this case, we are transferring
    roughly 500,000 fewer bytes, so we can calculate the penalty or savings based
    on the average time to transfer that much data. In this example, we will spend
    about 40 milliseconds to compress the data, which will mean we have to transmit
    about 500,000 fewer bytes. A network with 100 Mbit/second would break even in
    that case, meaning that slow public WiFi would benefit with the compression enabled,
    but faster networks would not.
  id: totrans-405
  prefs: []
  type: TYPE_NORMAL
  zh: 如果序列化的目的是在网络上传输数据，我们会根据网络速度做出通常的权衡。在快速网络上，压缩所花费的时间很可能比传输更少数据所节省的时间长；而在较慢的网络上，情况可能恰恰相反。在这种情况下，我们将传输大约少了
    500,000 字节的数据，因此可以根据传输这么多数据的平均时间来计算成本或节省。在这个例子中，我们将花费大约 40 毫秒来压缩数据，这意味着我们需要传输少约
    500,000 字节的数据。在 100 Mbit/秒的网络上，这种情况下是打平的，意味着慢速的公共 WiFi 将会从启用压缩中受益，但更快的网络则不会。
- en: Keeping Track of Duplicate Objects
  id: totrans-406
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 跟踪重复对象
- en: '[“Object Serialization”](#Object_Serialization) began with an example of how
    not to serialize data that contains object references, lest the object references
    be compromised when the data is deserialized. However, one of the more powerful
    optimizations possible in the `writeObject()` method is to not write out duplicate
    object references. In the case of the `StockPriceHistoryImpl` class, that means
    not writing out the duplicate references of the `prices` map. Because the example
    uses a standard JDK class for that map, we don’t have to worry about that: the
    JDK classes are already written to optimally serialize their data. Still, it is
    instructive to look at how those classes perform their optimizations in order
    to understand what is possible.'
  id: totrans-407
  prefs: []
  type: TYPE_NORMAL
  zh: '["对象序列化"](#Object_Serialization) 以一个例子开始，说明了如何不序列化包含对象引用的数据，以免在反序列化时破坏对象引用。然而，在
    `writeObject()` 方法中可能实现的更强大的优化之一是不写出重复的对象引用。对于 `StockPriceHistoryImpl` 类而言，这意味着不会写出
    `prices` 映射的重复引用。因为示例中使用了该映射的标准 JDK 类，我们不必担心这个问题：JDK 类已经被优化为最佳序列化它们的数据。尽管如此，深入了解这些类如何执行它们的优化仍然是有益的，以便理解可能的优化方式。'
- en: In the `StockPriceHistoryImpl` class, the key structure is a `TreeMap`. A simplified
    version of that map appears in [Figure 12-2](#FigureTreeMap). With default serialization,
    the JVM would write out the primitive data fields for node A; then it would recursively
    call the `writeObject()` method for node B (and then for node C). The code for
    node B would write out its primitive data fields and then recursively write out
    the data for its `parent` field.
  id: totrans-408
  prefs: []
  type: TYPE_NORMAL
  zh: 在 `StockPriceHistoryImpl` 类中，关键结构是一个 `TreeMap`。该映射的简化版本出现在[图 12-2](#FigureTreeMap)中。使用默认序列化，JVM
    将为节点 A 写出其原始数据字段；然后对节点 B（然后是节点 C）递归调用 `writeObject()` 方法。节点 B 的代码将写出其原始数据字段，然后递归写出其
    `parent` 字段的数据。
- en: '![Tree Map Structure](assets/jp2e_1202.png)'
  id: totrans-409
  prefs: []
  type: TYPE_IMG
  zh: '![树图结构](assets/jp2e_1202.png)'
- en: Figure 12-2\. Simple `TreeMap` structure
  id: totrans-410
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 12-2\. 简单的 `TreeMap` 结构
- en: 'But wait a minute—that `parent` field is node A, which has already been written.
    The object serialization code is smart enough to realize that: it doesn’t rewrite
    the data for node A. Instead, it simply adds an object reference to the previously
    written data.'
  id: totrans-411
  prefs: []
  type: TYPE_NORMAL
  zh: 但是请等一下——那个 `parent` 字段是节点 A，它已经被写入。对象序列化代码足够智能以意识到这一点：它不会重新写入节点 A 的数据。相反，它只是向先前写入的数据添加一个对象引用。
- en: 'Keeping track of that set of previously written objects, as well as all that
    recursion, adds a small performance hit to object serialization. However, as demonstrated
    in the example with an array of `Point` objects, it can’t be avoided: code must
    keep track of the previously written objects and reconstitute the correct object
    references. However, it is possible to perform smart optimizations by suppressing
    object references that can be easily re-created when the object is deserialized.'
  id: totrans-412
  prefs: []
  type: TYPE_NORMAL
  zh: 跟踪先前写入的对象集合以及所有递归操作会对对象序列化造成轻微的性能损失。然而，正如在一个 `Point` 对象数组示例中所演示的那样，这是无法避免的：代码必须跟踪先前写入的对象并恢复正确的对象引用。不过，可以通过抑制可以在反序列化时轻松重新创建的对象引用来执行智能优化。
- en: 'Different collection classes handle this differently. The `TreeMap` class,
    for example, simply iterates through the tree and writes only the keys and values;
    serialization discards all information about the relationship between the keys
    (i.e., their sort order). When the data has been deserialized, the `readObject()`
    method then re-sorts the data to produce a tree. Although sorting the objects
    again sounds like it would be expensive, it is not: that process is about 20%
    faster on a set of 10,000 stock objects than using the default object serialization,
    which chases all the object references.'
  id: totrans-413
  prefs: []
  type: TYPE_NORMAL
  zh: 不同的集合类处理方式各不相同。例如，`TreeMap` 类只需遍历树并仅写入键和值；序列化过程会丢弃关于键之间关系（即它们的排序顺序）的所有信息。当数据被反序列化后，`readObject()`
    方法会重新对数据进行排序以生成树。虽然再次对对象进行排序听起来可能会很昂贵，但实际上并非如此：在一个包含 10,000 个股票对象的集合上，这一过程比使用默认对象序列化快约
    20%。
- en: 'The `TreeMap` class also benefits from this optimization because it can write
    out fewer objects. A node (or in JDK language, an `Entry`) within a map contains
    two objects: the key and the value. Because the map cannot contain two identical
    nodes, the serialization code doesn’t need to worry about preserving object references
    to nodes. In this case, it can skip writing the node object itself and simply
    write the key and value objects directly. So the `writeObject()` method ends up
    looking something like this (syntax adapted for ease of reading):'
  id: totrans-414
  prefs: []
  type: TYPE_NORMAL
  zh: '`TreeMap` 类也从这种优化中受益，因为它可以写出更少的对象。在地图中，一个节点（或者在 JDK 语言中称为 `Entry`）包含两个对象：键和值。因为地图不能包含两个相同的节点，序列化代码不需要担心保留对节点的对象引用。在这种情况下，它可以跳过写入节点对象本身，直接写入键和值对象。因此，`writeObject()`
    方法最终看起来像这样（语法适应阅读的便利性）：'
- en: '[PRE31]'
  id: totrans-415
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: This looks very much like the code that didn’t work for the `Point` example.
    The difference in this case is that the code still writes out object when those
    objects can be the same. A `TreeMap` cannot have two nodes that are the same,
    so there is no need to write out node references. The `TreeMap` *can* have two
    values that are the same, so the values must be written out as object references.
  id: totrans-416
  prefs: []
  type: TYPE_NORMAL
  zh: 这看起来非常像对 `Point` 示例不起作用的代码。在这种情况下的不同之处在于，当这些对象可能相同时，代码仍然会写出对象。`TreeMap` 不能有两个相同的节点，因此不需要写出节点引用。然而，`TreeMap`
    *可以* 有两个相同的值，因此必须将值作为对象引用写出。
- en: 'This brings us full circle: as I stated at the beginning of this section, getting
    object serialization optimizations correct can be tricky. But when object serialization
    is a significant bottleneck in an application, optimizing it correctly can offer
    important benefits.'
  id: totrans-417
  prefs: []
  type: TYPE_NORMAL
  zh: 这将我们带回了起点：正如我在本节开头所述，正确进行对象序列化优化可能会有些棘手。但是，当对象序列化在应用程序中成为显著的瓶颈时，正确优化它确实可以带来重要的好处。
- en: Quick Summary
  id: totrans-418
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 快速总结
- en: Serialization of data can be a big performance bottleneck.
  id: totrans-419
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据的序列化可能是一个性能瓶颈。
- en: Marking instance variables `transient` will make serialization faster and reduce
    the amount of data to be transmitted. Both are usually big performance wins, unless
    re-creating the data on the receiver takes a long time.
  id: totrans-420
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将实例变量标记为 `transient` 将使序列化更快，并减少要传输的数据量。这两者通常都会带来显著的性能提升，除非在接收端重新创建数据需要很长时间。
- en: Other optimizations via the `writeObject()` and `readObject()` methods can significantly
    speed up serialization. Approach them with caution, since it is easy to make a
    mistake and introduce a subtle bug.
  id: totrans-421
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过 `writeObject()` 和 `readObject()` 方法的其他优化可以显著加快序列化的速度。在使用时要小心，因为很容易出错并引入微妙的
    bug。
- en: Compressing serialized data is often beneficial, even if the data will not travel
    across a slow network.
  id: totrans-422
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 即使数据不会通过缓慢的网络传输，压缩序列化数据通常也是有益的。
- en: Summary
  id: totrans-423
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: This look into key areas of the Java SE JDK concludes our examination of Java
    performance. One interesting theme of most of the topics of this chapter is that
    they show the evolution of the performance of the JDK itself. As Java developed
    and matured as a platform, its developers discovered that repeatedly generated
    exceptions didn’t need to spend time providing thread stacks; that using a thread-local
    variable to avoid synchronization of the random number generator was a good thing;
    that the default size of a `ConcurrentHashMap` was too large; and so on.
  id: totrans-424
  prefs: []
  type: TYPE_NORMAL
  zh: 本节对Java SE JDK的关键领域进行了介绍，这也结束了我们对Java性能的考察。本章的大多数主题之一是展示了JDK本身性能的演进。随着Java作为一个平台的发展和成熟，其开发人员发现，重复生成的异常不需要花费时间提供线程堆栈；使用线程本地变量来避免随机数生成器同步是一个好的选择；`ConcurrentHashMap`
    的默认大小太大等等。
- en: This continual process of successive improvement is what Java performance tuning
    is all about. From tuning the compiler and garbage collector, to using memory
    effectively, to understanding key performance differences in the APIs, and more,
    the tools and processes in this book will allow you to provide similar ongoing
    improvements in your own code.
  id: totrans-425
  prefs: []
  type: TYPE_NORMAL
  zh: 连续不断的改进过程正是Java性能调优的全部内容。从调优编译器和垃圾收集器，到有效使用内存，理解API中关键性能差异，等等，本书中的工具和流程将允许您在自己的代码中提供类似的持续改进。
- en: ^([1](ch12.html#idm45775544045928-marker)) *Chacun à son goût* is (with apologies
    to Johann Strauss Jr.) the opera-lover’s way of saying *YMMV* (your mileage may
    vary).
  id: totrans-426
  prefs: []
  type: TYPE_NORMAL
  zh: ^([1](ch12.html#idm45775544045928-marker)) *Chacun à son goût* 是（抱歉，约翰·施特劳斯二世）歌剧爱好者说“*YMMV*”（你的效果可能会有所不同）的方式。
- en: ^([2](ch12.html#idm45775543079160-marker)) Because of a bug in earlier versions
    of Java, it is sometimes recommended to set this flag to */dev/./urandom* or other
    variations. In Java 8 and later JVMs, you can simply use */dev/urandom*.
  id: totrans-427
  prefs: []
  type: TYPE_NORMAL
  zh: ^([2](ch12.html#idm45775543079160-marker)) 由于早期Java版本中的一个 bug，有时建议将此标志设置为 */dev/./urandom*
    或其他变体。在Java 8及更高版本的JVM中，您可以简单地使用 */dev/urandom*。
- en: '^([3](ch12.html#idm45775542437672-marker)) Or should I say: *Chacun à son goût*.'
  id: totrans-428
  prefs: []
  type: TYPE_NORMAL
  zh: ^([3](ch12.html#idm45775542437672-marker)) 或者我应该说：*Chacun à son goût*。
- en: ^([4](ch12.html#idm45775542298712-marker)) Implementations of quicksort will
    usually use insertion sort for small arrays anyway; in the case of Java, the implementation
    of the `Arrays.sort()` method assumes that any array with fewer than 47 elements
    will be sorted faster with insertion sort than with quicksort.
  id: totrans-429
  prefs: []
  type: TYPE_NORMAL
  zh: ^([4](ch12.html#idm45775542298712-marker)) 快速排序的实现通常会在小数组中使用插入排序；在Java中，`Arrays.sort()`
    方法假定任何少于47个元素的数组都可以通过插入排序比快速排序更快地排序。
