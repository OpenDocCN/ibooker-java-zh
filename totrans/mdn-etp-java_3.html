<html><head></head><body><div id="sbo-rt-content"><section data-type="chapter" epub:type="chapter" data-pdf-bookmark="Chapter 3. Travel Light on Your Pathway"><div class="chapter" id="travel_light_on_your_pathway">
<h1><span class="label">Chapter 3. </span>Travel Light on Your Pathway</h1>

<blockquote>
<p>He who would travel happily must travel light.</p>
<p data-type="attribution">Antoine de Saint-Exupéry</p>
</blockquote>

<p>In the last chapter, you built a microservices-based system, and we also showed you some migration steps from an existing application. But the challenge with all examples is that they remove complexity for the sake of easier understandability. What might seem clear for smaller examples becomes challenging with real business systems. In particular, think about complex legacy systems. As outlined in the first chapter, technologies and methodologies developed over the years have led to today’s best practices and tools to develop modern enterprise systems. Just because our industry now has a more extensive toolbox with shiny new things to work with doesn’t mean you should always use them.
If you think about this and our growing number of frameworks, methodologies, and technologies, one question becomes more pressing: What tools and architecture should you use for your next system, and how and where will you run them? Before you can decide, you need to think a bit about the most prominent architectural styles that have emerged for enterprise applications in the last couple of years (Three-tier, Enterprise Integration, service-oriented architecture, microservices, and event-driven architecture).</p>






<section data-type="sect1" data-pdf-bookmark="Three-Tier or Distributed System"><div class="sect1" id="idm45261446780272">
<h1>Three-Tier or Distributed System</h1>

<p>The Enterprise Java world is dominated by monolithic applications. They often are designed as single execution <a data-type="indexterm" data-primary="Three-tier systems" data-see="distributed systems" id="idm45261446759216"/><a data-type="indexterm" data-primary="distributed systems" id="dissys"/>units that scale with server instances and clustering functionality. They are also often referred to as “Three-tier systems” to reflect the three main parts <a data-type="indexterm" data-primary="distributed systems" data-secondary="client-side user interface" id="idm45261446757328"/><a data-type="indexterm" data-primary="distributed systems" data-secondary="server-side business logic" id="idm45261446756480"/><a data-type="indexterm" data-primary="distributed systems" data-secondary="server-side data" id="idm45261446755632"/><a data-type="indexterm" data-primary="distributed systems" data-secondary="Persistence layer" id="idm45261446754784"/><a data-type="indexterm" data-primary="distributed systems" data-secondary="Integration layer" id="idm45261446753936"/><a data-type="indexterm" data-primary="Integration layer (distributed system)" id="idm45261446753088"/><a data-type="indexterm" data-primary="Persistence layer (distributed system)" id="idm45261446752480"/>they are composed of: a client-side user interface, a server-side business logic implementation, and server-side data Persistence or Integration layer. The server-side parts <a data-type="indexterm" data-primary="monolith architectures" id="idm45261446751552"/>are called a “monolith” since they are packaged as a single large 
<span class="keep-together">executable</span>. Any changes to the system typically involve building and deploying a new version.</p>
<div data-type="tip"><h6>Tip</h6>
<p>Learn more about building microservices in <a href="https://oreil.ly/JZqsr">Sam Newman’s excellent book <em>Building Microservices</em> (O’Reilly)</a>, now in its second edition.</p>
</div>

<p>A microservices-based architecture is <a data-type="indexterm" data-primary="distributed systems" data-secondary="microservices and" id="idm45261446747920"/><a data-type="indexterm" data-primary="microservices" data-secondary="distributed systems and" id="idm45261446747072"/>an approach to developing a single application as a suite of small services, each of them running in its own process and communicating with lightweight mechanisms, often an HTTP resource API or as part of an <a data-type="indexterm" data-primary="EDA (event-driven architecture)" id="idm45261446745872"/><a data-type="indexterm" data-primary="event-driven architecture (EDA)" id="idm45261446745264"/>event-driven architecture (EDA). These services are built around business capabilities and are independently deployable by fully automated deployment machinery. There is a bare minimum of centralized management of these services, which may be written in different programming languages and use different data storage technologies.</p>

<p>The difference between the <a data-type="indexterm" data-primary="monolithic versus microservices style" id="idm45261446743792"/><a data-type="indexterm" data-primary="microservices" data-secondary="versus monolithic style" id="idm45261446743136"/>monolithic and microservice styles can’t be more fundamental. And so are the nonfunctional requirements leading to the choice of one. 
<span class="keep-together">The most</span> critical requirements result from extremely flexible scaling scenarios.  As an experienced developer and architect, you know how to evaluate functional and nonfunctional requirements to conclude your specific project. In this chapter, we will help you navigate your migration approach and target platform. Your journey starts by looking at the motivation for modernization. Let’s take a deeper look at what makes us think about modernization in general and where to start looking for 
<span class="keep-together">opportunities</span>.</p>








<section data-type="sect2" data-pdf-bookmark="Technology Updates, Modernization, and Transformation"><div class="sect2" id="idm45261446739872">
<h2>Technology Updates, Modernization, and Transformation</h2>

<p>Enterprise software is developed <a data-type="indexterm" data-primary="technology updates" id="idm45261446738080"/><a data-type="indexterm" data-primary="modernization" id="idm45261446737376"/><a data-type="indexterm" data-primary="transformation" id="idm45261446736704"/><a data-type="indexterm" data-primary="distributed systems" data-secondary="technology updates and" id="idm45261446736032"/><a data-type="indexterm" data-primary="distributed systems" data-secondary="modernization and" id="idm45261446735088"/><a data-type="indexterm" data-primary="distributed systems" data-secondary="transformation and" id="idm45261446734144"/>to put business value into code that can be executed within nonfunctional and functional requirements. Creating value depends on our ability to deliver applications quickly. Not only with better quality but also ready to be changed quickly, enabling businesses to respond to new challenges or regulatory changes in the market. And these challenges are multifaceted. First, you address scaling challenges with <a data-type="indexterm" data-primary="transaction volume" id="idm45261446732640"/><a data-type="indexterm" data-primary="cloud native computing" data-secondary="transaction volume" id="idm45261446731968"/>cloud native applications to handle bigger transaction volumes. New business cases will also require you to analyze data further and might be solved by <a data-type="indexterm" data-primary="AI (artificial intelligence)" id="idm45261446730720"/><a data-type="indexterm" data-primary="artificial intelligence (AI)" id="idm45261446730032"/><a data-type="indexterm" data-primary="ML (machine learning)" id="idm45261446729344"/><a data-type="indexterm" data-primary="machine learning (ML)" id="idm45261446728672"/>artificial intelligence (AI) and machine learning (ML). And last but not least, our interconnected world generates more data from the Internet of Things (IoT). What might read like it is a natural progression of architectures isn’t. In fact, the evolving business requirements drive modernization and architectural evolution by changing functional and nonfunctional requirements.</p>

<p>Aditionally, you will find operational concerns influencing modernization needs. For example, expiring maintenance <a data-type="indexterm" data-primary="modernization" data-secondary="operations and" id="idm45261446727088"/><a data-type="indexterm" data-primary="operational needs, modernization" id="idm45261446726112"/>contracts or outdated technologies can drive 
<span class="keep-together">technology</span> updates. The continuously evolving Java language with the <a data-type="indexterm" data-primary="modernization" data-secondary="Java release cycles" id="idm45261446724624"/><a data-type="indexterm" data-primary="Java" data-secondary="release cycles, modernization and" id="idm45261446723568"/>shortened release cycles can also influence modernization decisions. Modernization can happen at any level of your project,  ranging from the execution environment (e.g., virtual machines to container) to the Java Virtual Machine (JVM version or vendor), individual dependencies, external interfaces, and services.</p>

<p>It is essential to distinguish between three different angles to modernization here. While the <em>technology updates</em> within existing processes and boundaries are a familiar and well-established challenge for software projects, modernization refers to something else. Often paired with the word “digital,” the term <em>modernization</em> refers to adopting new technology. It involves upgrading systems, platforms, and software with new functionality. It can be as simple as taking an existing paper-based process and turning it digital using new software and hardware, or more complex, such as phasing out existing infrastructure and moving to the cloud. Sometimes you’ll also hear <em>transformation</em> when someone talks about modern systems. Digital transformation means taking advantage of modern technology to reimagine an organization’s processes, culture, people, and customer experiences. It can result in new business models, revenue streams, policies, and values. Transformation is somewhat of a holistic lens into an organization with a clear focus to fundamentally change business performance. Modernization is embedded and becomes the centerpiece that software developers and architects need to navigate.</p>

<p>Despite your project-specific reasons to take the first step in modernizing your application, it is essential to remember that modernization itself does not carry any particular mandates for specific target environments or technologies. It is an ever-changing and growing set of candidate technologies that enable companies to compete and grow in their industry. You can find some of them in technology trend reports (e.g., the <a href="https://oreil.ly/SWvEH">ThoughtWorks Technology Radar</a>) or on hype cycles (<a href="https://oreil.ly/JT4jE">Gartner Hype Cycle</a>). But as you’ve seen in the first chapter, two of the strongest motivations to constantly innovate are speed and cost pressure. Both are addressed by a modern, cloud native, microservices-based architecture.</p>
</div></section>













<section data-type="sect2" data-pdf-bookmark="The 6 Rs"><div class="sect2" id="idm45261446716688">
<h2>The 6 Rs</h2>

<p>Now that you’ve learned the motivation behind application modernization, you want to identify general approaches to modernization and define a categorization for existing applications. Doing this helps you manage a variety of different applications, especially in a platform modernization project. Rather than looking at the details of <a data-type="indexterm" data-primary="6 Rs" id="idm45261446714672"/><a data-type="indexterm" data-primary="modernization" data-secondary="6 Rs" id="idm45261446713968"/>a single application, consider the complete runtime architecture of traditional Enterprise Java applications. In that case, you’ll commonly identify on-premise hardware, which is usually virtualized and made available to projects via an individual set of instances. Given that individual projects are rarely treated as islands without any integrated systems, you get to a situation where a coordinated approach for more than just one project needs to be found.</p>

<p>Let’s first have a look at what the 6 Rs are and where the concept comes from. Essentially, you can think of each “R” as an available migration strategy for your applications. Each strategy indicates a <a data-type="indexterm" data-primary="migration" data-secondary="6 Rs" id="idm45261446711808"/>clear outcome for a transformed application, but not necessarily the actual migration steps to take. The concept was first <a href="https://oreil.ly/tk08O">mentioned by the Gartner analyst Richard Watson</a> in 2011. The five original strategies—namely Rehost, Refactor, Revise, Rebuild, and Replace—were revived and adapted in a <a href="https://oreil.ly/CAalp">popular  blog post</a> by Stephen Orban of AWS in 2016. Orban kept some of Gartner’s strategies and added a new one. Thus, the 5 Rs became the 6 Rs. Today, the 6 Rs are used as a fundamental guideline for almost any cloud transformation. Although there are still disputes about whether further strategies should be added, and you can even find 7 Rs, we stick to the 6 Rs in this book as shown in <a data-type="xref" href="#fig3-2">Figure 3-1</a>.</p>

<figure><div id="fig3-2" class="figure">
<img src="Images/moej_0301.png" alt="Six ways to classify your existing applications" width="600" height="362"/>
<h6><span class="label">Figure 3-1. </span>Six modernization approaches, an overview of the 6 Rs</h6>
</div></figure>










<section data-type="sect3" data-pdf-bookmark="Retain—Modernize later or not at all"><div class="sect3" id="idm45261446705616">
<h3>Retain—Modernize later or not at all</h3>

<p>Everyone has heard the stereotypical story of a mainframe in the basement of some very well-known company, where <a data-type="indexterm" data-primary="6 Rs" data-secondary="Retain" id="idm45261446704192"/><a data-type="indexterm" data-primary="modernization" data-secondary="6 Rs" data-tertiary="Retain" id="idm45261446703216"/>all of its business secrets are stored. Oftentimes, these mainframes are programmed <a data-type="indexterm" data-primary="CICS (Customer Information Control System)" id="idm45261446701872"/><a data-type="indexterm" data-primary="Customer Information Control System (CICS)" id="idm45261446701104"/>in CICS (Customer Information Control System, a family of mixed-language application servers that provide <a data-type="indexterm" data-primary="transactions, online management" id="idm45261446700144"/>online transaction management and connectivity for applications on IBM mainframe systems) and the data is stored in IMS (IBM Information Management System, an early database). And this isn’t necessarily a bad thing. Maybe the existing system is a perfect fit for the business and does not need to participate in a modernization project. In order to correctly scope your transformation and modernization efforts, you need to identify those systems and omit them from the modernization process. Systems with this classification need a particular integration approach that needs to be explicitly designed. Imagine a highly scalable mobile application backend that connects directly to a mainframe. In this scenario, the requests from the potentially many mobile devices would overload the costly mainframe. Retain, in this case, does not mean “untouched” but rather “not moved.”</p>
</div></section>













<section data-type="sect3" data-pdf-bookmark="Retire—Turn system off"><div class="sect3" id="idm45261446698128">
<h3>Retire—Turn system off</h3>

<p>Some candidates may clearly have <a data-type="indexterm" data-primary="6 Rs" data-secondary="Retire" id="idm45261446696816"/><a data-type="indexterm" data-primary="modernization" data-secondary="6 Rs" data-tertiary="Retire" id="idm45261446695840"/><a data-type="indexterm" data-primary="retiring a system" id="idm45261446694624"/>reached end-of-life and are already migrated and replaced or just a relic that isn’t needed going forward. Travel light and make sure to flag these systems. Subsequent housekeeping is as equally essential as building new things. Investing time to validate and decide on retiring a system is as valuable as a redesign would be.</p>
</div></section>













<section data-type="sect3" data-pdf-bookmark="Repurchase—Buy new version"><div class="sect3" id="idm45261446693216">
<h3>Repurchase—Buy new version</h3>

<p>In some cases, you can <a data-type="indexterm" data-primary="6 Rs" data-secondary="Repurchase" id="idm45261446691904"/><a data-type="indexterm" data-primary="modernization" data-secondary="6 Rs" data-tertiary="Repurchase" id="idm45261446690896"/>repurchase off-the-shelf software and get it ready made for a new execution environment. That sounds straightforward but will most likely include a migration project and reevaluation of feature lists, mostly because it is unlikely that you can update without changing the product version or its APIs. In some rare cases, you might even find missing integration documentation to be a blocker. This is why it is essential to treat this as a modernization project and not as a simple software update.</p>
</div></section>













<section data-type="sect3" data-pdf-bookmark="Rehost—Put into containers"><div class="sect3" id="idm45261446688784">
<h3>Rehost—Put into containers</h3>

<p>Often referred to as “lift and shift,” one option <a data-type="indexterm" data-primary="6 Rs" data-secondary="Rehost" id="idm45261446687472"/><a data-type="indexterm" data-primary="modernization" data-secondary="6 Rs" data-tertiary="Rehost" id="idm45261446686496"/><a data-type="indexterm" data-primary="modernization" data-secondary="containers" id="idm45261446685280"/><a data-type="indexterm" data-primary="containers" data-secondary="modernization and" id="idm45261446684336"/>for containerizing an application is to simply port the existing architecture as-is to run inside of a container. While this can be as simple as it sounds, there are some challenges on the way. In particular, there can be difficulties when it comes to optimizing the JVM for <a data-type="indexterm" data-primary="JVMs (Java Virtual Machines)" data-secondary="containers, runtimes" id="idm45261446682976"/>constrained container runtimes. Some existing middleware application servers come with their vendor-supported base images and make it convenient to switch runtimes. Particular focus should be placed on storage for stateful application runtimes. Java application servers require some data to survive container restarts and require persistent volume mappings. Transactions, load balancing, and in-memory session replication need extended configurations to ensure correct shutdown behavior and node communication. Plan for sufficient research and testing and make sure to adhere to the vendor recommendations. This step is addressing infrastructure modernization and not concerned with application code directly. Existing applications that qualify for such an approach are those that need to move to a container runtime before a refactoring can occur or as an interim step toward switching data center concepts.</p>
<div data-type="note" epub:type="note"><h6>Note</h6>
<p>Martin Fowler coined the term <a href="https://oreil.ly/0otPb">“strangler pattern”</a> as a way to extract <a data-type="indexterm" data-primary="Fowler, Martin" id="idm45261446679248"/>functionality out of a monolithic application. It is named after the Australian strangler figs that grow roots from seeds in the upper branches until they touch the ground.</p>
</div>
</div></section>













<section data-type="sect3" class="pagebreak-before" data-pdf-bookmark="Replatform—Make some slight adjustments"><div class="sect3" id="idm45261446677808">
<h3>Replatform—Make some slight adjustments</h3>

<p>As an extension to rehosting, replatforming <a data-type="indexterm" data-primary="6 Rs" data-secondary="Replatform" id="idm45261446676144"/><a data-type="indexterm" data-primary="modernization" data-secondary="6 Rs" data-tertiary="Replatform" id="idm45261446675168"/><a data-type="indexterm" data-primary="platform" data-secondary="replatforming" id="idm45261446673952"/>categorizes applications that undergo a conceptual or functional change while switching runtimes. It can also be referred to by its own “lift” name variation, “lift and adjust.” It can be related to a strangled functionality, which might be implemented on top of a new technology stack or a change in data storage or integration systems. We recommend using this approach as an initial step toward refactoring and decoupling a monolithic application. Prepending this step leads to smoother operations executing on subsequent extensions and decoupling stages. By choosing to replatform, you are allowing a gentle start to modernizing your applications and pragmatically evolving them.</p>
</div></section>













<section data-type="sect3" data-pdf-bookmark="Refactor—Build new"><div class="sect3" id="idm45261446671920">
<h3>Refactor—Build new</h3>

<p><a href="https://refactoring.com">Refactoring</a> is a <a data-type="indexterm" data-primary="6 Rs" data-secondary="Refactor" id="idm45261446670064"/><a data-type="indexterm" data-primary="modernization" data-secondary="6 Rs" data-tertiary="Refactor" id="idm45261446669056"/>disciplined technique for restructuring an existing body of code, altering its internal structure without changing its external behavior. Refactoring is the most time-consuming and costly way to move existing applications onto a new runtime or platform. It may or may not include a switch to different <a data-type="indexterm" data-primary="distributed systems" data-startref="dissys" id="idm45261446667392"/>architecture styles or on-premise or cloud hosting.</p>
</div></section>



</div></section>





</div></section>













<section data-type="sect1" data-pdf-bookmark="Divide and Containerize"><div class="sect1" id="idm45261446716096">
<h1>Divide and Containerize</h1>

<p>Now that we have looked at different modernization strategies for existing applications, and we know how and when to apply them. It is time to think about other prerequisites for our target platform.</p>








<section data-type="sect2" data-pdf-bookmark="Kubernetes as the New Application Server?"><div class="sect2" id="idm45261446664560">
<h2>Kubernetes as the New Application Server?</h2>

<p>The word “platform” in the Enterprise Java world normally refers to the application server. Application <a data-type="indexterm" data-primary="modernization" data-secondary="containers" id="moderncontain"/><a data-type="indexterm" data-primary="containers" data-secondary="modernization and" id="containmodern"/><a data-type="indexterm" data-primary="platform" data-seealso="application server" id="idm45261446660272"/><a data-type="indexterm" data-primary="Kubernetes" data-secondary="containers" data-tertiary="modernization and" id="idm45261446659328"/>servers follow a guardrailed software development approach with standardized APIs. The  vertical layers are <a data-type="indexterm" data-primary="application server" data-secondary="vertical layers" id="idm45261446657856"/>defined by what is commonly refered to as  technical layers of a three-tier system. Presentation on top of business on top of data access and/or integration. Horizontally to this we usually find business components or domains. While the vertical layers are usually well separated and decoupled, it is common to find shared classess and violated access rules between the horizontal components. If this happens frequently across the code base, we talk <a data-type="indexterm" data-primary="entangled designs" id="idm45261446656320"/>about entangled designs that turn into unmaintainable monoliths over time. But no matter how entangled the application code is, it still profits from the standard application server functionalities addressing nonfunctional and functional requirements like security, isolation, fault tolerance, transaction management, configuration management, etc.</p>

<p>If we fast-forward to distributed architectures of today, where applications consist of many small services, we observe two things: there is no longer a shortcut to a good component design, and the standard application server features are no longer available to our components.</p>

<p>The first observation leads to a mandatory requirement. Distributed services have to be well designed, loosely coupled, and strongly encapsulated components. We will talk more about design principles and approaches for modernizing monoliths in <a data-type="xref" href="ch05.xhtml#beyond_lift_and_shift">Chapter 5</a>. The second observation holds a list of missing funcionalities in cloud native runtimes. If an application server isn’t providing support for commonly used functionalities like we mentioned, there are only two places left. One can be the microservices framework of choice (e.g., Quarkus), and another one could be additional frameworks or products on top of Kubernetes.</p>

<p>Let’s take a detailed look at some of the most critical functionalities needed in the following chapters. We <a data-type="indexterm" data-primary="microservicilities" id="idm45261446652080"/>call them <em>microservicilities</em>. The term refers to a list of cross-cutting concerns that a service must implement apart from the business logic to resolve these concerns as summarized in <a data-type="xref" href="#fig3-3">Figure 3-2</a>.</p>

<figure><div id="fig3-3" class="figure">
<img src="Images/moej_0302.png" alt="Microservicilities for distributed applications" width="600" height="515"/>
<h6><span class="label">Figure 3-2. </span>Microservicilities for distributed applications</h6>
</div></figure>










<section data-type="sect3" data-pdf-bookmark="Discovery and configuration"><div class="sect3" id="idm45261446647632">
<h3>Discovery and configuration</h3>

<p>Container images are immutable. Storing <a data-type="indexterm" data-primary="containers" data-secondary="immutability" id="idm45261446646048"/><a data-type="indexterm" data-primary="service discovery" id="idm45261446645072"/><a data-type="indexterm" data-primary="modernization" data-secondary="containers" data-tertiary="images" id="idm45261446644400"/><a data-type="indexterm" data-primary="containers" data-secondary="modernization and" data-tertiary="images" id="idm45261446643184"/><a data-type="indexterm" data-primary="images, containers" id="idm45261446641968"/><a data-type="indexterm" data-primary="application server" data-secondary="container images" id="idm45261446641296"/><a data-type="indexterm" data-primary="application server" data-secondary="service discovery" id="idm45261446640352"/><a data-type="indexterm" data-primary="Kubernetes" data-secondary="service discovery and" id="idm45261446639408"/><a data-type="indexterm" data-primary="distributed systems" data-secondary="service discovery" id="idm45261446638464"/>configuration options inside them for different environments or stages is discouraged. Instead, the configuration has to be externalized and configured by instance. An externalized configuration is also one of the critical principles of cloud native applications. Service discovery is one way to get configuration information from the runtime environment instead of being hardcoded in the application. Other approaches include using ConfigMaps and Secrets. Kubernetes provides service discovery out of the box, but this might not be sufficient for your application needs. While you can manage the environment settings for each runtime environment through YAML files, additional UIs or CLIs can make it easier for DevOps teams to share responsibility.</p>
</div></section>













<section data-type="sect3" data-pdf-bookmark="Basic invocation"><div class="sect3" id="idm45261446636496">
<h3>Basic invocation</h3>

<p>Applications running inside containers are <a data-type="indexterm" data-primary="Kubernetes" data-secondary="invocation" id="idm45261446635168"/><a data-type="indexterm" data-primary="application server" data-secondary="Ingress controllers" id="idm45261446634192"/><a data-type="indexterm" data-primary="Ingress controllers" id="idm45261446633248"/><a data-type="indexterm" data-primary="distributed systems" data-secondary="invocation" id="idm45261446632576"/>accessed through Ingress controllers. Ingress exposes HTTP and HTTPS routes from outside the cluster to services within the cluster. Traffic routing is controlled by rules defined on the Ingress resource. Traditionally, this can be compared with Apache HTTP-based load balancers. Other alternatives include projects like <a href="http://www.haproxy.org">HAProxy</a> or Nginx. You can use the routing capabilities to do rolling deployments as the basis for a sophisticated CI/CD strategy. For one-time jobs, such as batch processes, Kubernetes provides job and cron-job 
<span class="keep-together">functionality</span>.</p>
</div></section>













<section data-type="sect3" data-pdf-bookmark="Elasticity"><div class="sect3" id="idm45261446629344">
<h3>Elasticity</h3>

<p>Kubernetes’s ReplicaSets control <a data-type="indexterm" data-primary="Kubernetes" data-secondary="elasticity" id="idm45261446628208"/><a data-type="indexterm" data-primary="Kubernetes" data-secondary="ReplicaSets" id="idm45261446627232"/><a data-type="indexterm" data-primary="ReplicaSets" id="idm45261446626208"/><a data-type="indexterm" data-primary="distributed systems" data-secondary="elasticity" id="idm45261446625536"/>scaling of pods. It is a way to reconcile a desired state: you tell Kubernetes what state the system should be in so it can figure out how to reach the outcome. A ReplicaSet controls the number of replicas, or exact copies, of a container that should be running at any time. What sounds like a largely static operation can be automated. The Horizontal Pod Autoscaler scales the number of pods based on observed CPU utilization. It is possible to use a custom metric or almost any other application-provided metric as input.</p>
</div></section>













<section data-type="sect3" data-pdf-bookmark="Logging"><div class="sect3" id="idm45261446623664">
<h3>Logging</h3>

<p>One of the more challenging <a data-type="indexterm" data-primary="Kubernetes" data-secondary="logging" id="idm45261446622112"/><a data-type="indexterm" data-primary="logging" data-secondary="Kubernetes" id="idm45261446621136"/><a data-type="indexterm" data-primary="application server" data-secondary="logging" id="idm45261446620192"/><a data-type="indexterm" data-primary="distributed systems" data-secondary="logging and" id="idm45261446619248"/>aspects of a distributed application is the correlation of logs from each active part. This is an area where the difference from traditional application servers becomes very visible because it used to be so simple and isn’t in the new world. Storing them individually, per container, is not recommended because you lose sight of the bigger picture and have a hard time debugging side effects and root causes for issues. There are various approaches to this, with most of them extensively using the <a href="https://oreil.ly/XflXI">ELK</a> (<a href="https://oreil.ly/FKoKx">Elasticsearch</a>, <a href="https://oreil.ly/YLtNc">Logstash</a>, <a href="https://oreil.ly/h2nIX">Kibana</a>) stack or a variant. In those stacks, Elasticsearch is the object store, where all logs are stored. Logstash gathers logs from nodes and feeds them to Elasticsearch. Kibana is the web UI for Elasticsearch, which is used to search the aggregated log files from various sources.</p>
</div></section>













<section data-type="sect3" data-pdf-bookmark="Monitoring"><div class="sect3" id="idm45261446614432">
<h3>Monitoring</h3>

<p>Monitoring in a distributed <a data-type="indexterm" data-primary="application server" data-secondary="monitoring" id="idm45261446613104"/><a data-type="indexterm" data-primary="distributed systems" data-secondary="monitoring" id="idm45261446612128"/>application is an essential ingredient to make sure all of the bits and pieces continue working. In contrast to logging, monitoring is an active observation often paired with alerting rather than simply recording events. <a href="https://prometheus.io">Prometheus</a> is the de facto standard for storing the generated information. Essentially, it is a complete open source monitoring system that includes a time-series database. Prometheus’s web UI gives you access to metric querying, alerting, and visualizations and helps you gain insights into your systems.</p>
</div></section>













<section data-type="sect3" data-pdf-bookmark="Build and deployment pipelines"><div class="sect3" id="idm45261446609584">
<h3>Build and deployment pipelines</h3>

<p>CI/CD (Continuous Integration/Continuous Delivery) isn’t <a data-type="indexterm" data-primary="CI/CD (Continuous Integration/Continuous Delivery)" id="idm45261446608064"/><a data-type="indexterm" data-primary="distributed systems" data-secondary="CI/CD (Continuous Integration/Continuous Delivery)" id="idm45261446607184"/><a data-type="indexterm" data-primary="application server" data-secondary="CI/CD (Continuous Integration/Continuous Delivery)" id="idm45261446606208"/>anything new to Enterprise Java applications or distributed applications. As a good software development practice, every production code should follow a strict and automated release cycle. With a potentially large number of services that compose an application, the automation should at least aim for 100% coverage. Traditionally a job for the open source tool <a href="https://www.jenkins.io">Jenkins</a>, modern container platforms have <a data-type="indexterm" data-primary="platform" data-secondary="distributed systems and" id="idm45261446604064"/>moved away from a centralized build system and embrace a distributed approach to CI/CD. One example is <a href="https://tekton.dev">Tekton</a>. The goal is to create reliable software releases through build, test, and deployment. We dig deeper into this in <a data-type="xref" href="ch04.xhtml#kubernetes_based_softw_dev_platform">Chapter 4</a>.</p>
</div></section>













<section data-type="sect3" data-pdf-bookmark="Resilience and fault tolerance"><div class="sect3" id="idm45261446601040">
<h3>Resilience and fault tolerance</h3>

<p>Psychologists define “resilience” as <a data-type="indexterm" data-primary="resilience" id="idm45261446599744"/><a data-type="indexterm" data-primary="fault tolerance" id="idm45261446599040"/><a data-type="indexterm" data-primary="distributed systems" data-secondary="resilience" id="idm45261446598368"/><a data-type="indexterm" data-primary="distributed systems" data-secondary="fault tolerance" id="idm45261446597424"/><a data-type="indexterm" data-primary="application server" data-secondary="resilience" id="idm45261446596480"/><a data-type="indexterm" data-primary="application server" data-secondary="fault tolerance" id="idm45261446595536"/>the process of adapting well in the face of adversity, trauma, tragedy, threats, or significant sources of stress. In distributed applications, it is the concept of recovering from failure or load scenarios without human interaction. Kubernetes provides resilience options for the cluster itself, but only sparsely supports application resiliency and fault tolerance. For example, application-level resiliency can be facilitated through PersistentVolumes that support replicated volumes or with ReplicaSets ensuring a consistent number of pod replicas across the cluster. On an application level, there is resilience and fault-tolerance support through Istio or various frameworks like <a href="https://cloudstate.io">Cloudstate</a>. You want to use features such as retry rules, circuit breaker, and pool ejection.</p>
<div data-type="note" epub:type="note"><h6>Note</h6>
<p><a href="https://istio.io">Istio</a> is an open source service mesh that layers transparently onto existing distributed applications. It is also a platform, including APIs that integrate into any logging platform, telemetry, or policy system.</p>
</div>
</div></section>













<section data-type="sect3" data-pdf-bookmark="Security"><div class="sect3" id="idm45261446590832">
<h3>Security</h3>

<p>Authentication or Authorization between <a data-type="indexterm" data-primary="authentication, microservices" id="idm45261446589216"/><a data-type="indexterm" data-primary="authorization" data-secondary="services" id="idm45261446588544"/><a data-type="indexterm" data-primary="microservices" data-secondary="authentication and" id="idm45261446587600"/><a data-type="indexterm" data-primary="microservices" data-secondary="authorization and" id="idm45261446586656"/><a data-type="indexterm" data-primary="distributed systems" data-secondary="authorization and" id="idm45261446585712"/><a data-type="indexterm" data-primary="distributed systems" data-secondary="authentication and" id="idm45261446584768"/>services is not part of Kubernetes itself. There are two ways to implement it. Using Istio, each service is provided with a strong identity that represents its role and enables interoperability across clusters and clouds. It secures service-to-service communication, as well as providing a key management to automate key and certificate generation, distribution, rotation, and 
<span class="keep-together">revocation</span>.
A more application-centric alternative can be to use a single-sign-on component like <a href="https://www.keycloak.org">Keycloak</a> or relying on <a href="https://oreil.ly/bVETR">Eclipse 
<span class="keep-together">MicroProfile</span> JSON Web Token</a> (JWT).</p>
</div></section>













<section data-type="sect3" class="pagebreak-before" data-pdf-bookmark="Tracing"><div class="sect3" id="idm45261446580368">
<h3>Tracing</h3>

<p>Tracing gives you a way to follow <a data-type="indexterm" data-primary="distributed systems" data-secondary="tracing" id="idm45261446578768"/><a data-type="indexterm" data-primary="tracing, distributed systems and" id="idm45261446577792"/>request paths and events throughout the system across individual application parts by still allowing you to trace back to an origin. You can find different approaches across the community today. Independent of languages, frameworks, or technologies you intend to use, Istio can enable distributed tracing. There are other commercial and open source projects available helping with distributed tracing across your application components. <a href="https://zipkin.io">Zipkin</a> and <a href="https://www.jaegertracing.io">Jaeger</a> are two possible solutions.</p>
</div></section>



</div></section>













<section data-type="sect2" data-pdf-bookmark="Define Your Target Platform"><div class="sect2" id="idm45261446663936">
<h2>Define Your Target Platform</h2>

<p>It’s important to note that the nine elements mentioned previously are focused on application development and do not <a data-type="indexterm" data-primary="platform" data-secondary="target" id="idm45261446573360"/><a data-type="indexterm" data-primary="target platform" id="idm45261446572384"/>capture all the necessities of a modern container platform. Just looking at this narrow focus leaves important areas unaddressed. A container platform needs to provide features and capabilities for the complete team from Dev to Ops. Depending on specific needs, there is no one-size-fits-all solution. A comprehensive way to <a data-type="indexterm" data-primary="Core layer" id="idm45261446571248"/><a data-type="indexterm" data-primary="Integration layer (distributed system)" id="idm45261446570576"/><a data-type="indexterm" data-primary="platform" data-secondary="Core layer" id="idm45261446569888"/><a data-type="indexterm" data-primary="platform" data-secondary="Customer Experience layer" id="idm45261446568944"/><a data-type="indexterm" data-primary="platform" data-secondary="Integration layer" id="idm45261446567984"/>define your target platform is to start with the three main layers: Core, Customer Experience, and Integration, then build your application landscape on an optimized technology stack. What sounds like a ready-to-use checklist is anything but. Companies are different in culture, technologies, and requirements, and the following lists are a recommended starting point without any claim to comprehensiveness. We recommend using the bullet points as evaluation categories and defining the individual functional and nonfunctional requirements underneath with a fulfillment score from zero (not available) to three (fully supported) with a middle score of two (can make it work) as a medium evaluation. Finally, add weighting logic to it to reach a complete evaluation based on a product comparison. It can be the core framework for a direct product versus do-it-yourself (DIY) comparison and also the starting point for the platform documentation.</p>










<section data-type="sect3" data-pdf-bookmark="Define the core"><div class="sect3" id="idm45261446565824">
<h3>Define the core</h3>

<p>Start with evaluating the core <a data-type="indexterm" data-primary="platform" data-secondary="core, defining" id="idm45261446564528"/>part of the platform. This category includes basic capabilities <a data-type="indexterm" data-primary="containers" data-secondary="orchestration" id="idm45261446563424"/><a data-type="indexterm" data-primary="storage mapping" id="idm45261446562400"/><a data-type="indexterm" data-primary="upgrades, rolling" id="idm45261446561728"/><a data-type="indexterm" data-primary="rolling upgrades" id="idm45261446561056"/><a data-type="indexterm" data-primary="SRE (site readability engineering)" id="idm45261446560384"/>like container orchestration, storage mapping, rolling upgrades, site reliability engineering (SRE) requirements, out-of-the-box support for the desired deployment models, and might even include further support for virtual machines. This category represents the technical foundation for your target platform:</p>

<ul>
<li>
<p>Existing core capabilities</p>
</li>
<li>
<p>Functional gap assessment</p>
</li>
<li>
<p>Hybrid-cloud support</p>
</li>
<li>
<p>Security integration</p>
</li>
<li>
<p>Managed services support</p>
</li>
<li>
<p>Operators/marketplace available (e.g., <a href="https://operatorhub.io">OperatorHub</a>, <a href="https://oreil.ly/sFuDg">Red Hat Marketplace</a>)</p>
</li>
<li>
<p>Available support levels</p>
</li>
<li>
<p>Target deployment model</p>
</li>
<li>
<p>Core modernization approach</p>
</li>
</ul>
</div></section>













<section data-type="sect3" data-pdf-bookmark="Define the customer experience layer"><div class="sect3" id="idm45261446548832">
<h3>Define the customer experience layer</h3>

<p>When thinking about platforms, <a data-type="indexterm" data-primary="platform" data-secondary="Customer Experience layer" id="idm45261446547488"/>one part gets too little attention: the customer experience layer, which contains a technical definition for the customer channels to the platform. A channel can be one of the B2X (business to something) portals or various other specific frontends. A cohesive platform that can host various applications also needs to include a clear definition for the technical composition of the individual services:</p>

<ul>
<li>
<p>Define customer-centric requirements</p>
</li>
<li>
<p>Assess existing cx framework versus build</p>
</li>
<li>
<p>Micro frontends (e.g., <a href="https://dev.entando.org">Entando</a>)</p>
</li>
<li>
<p>Integration requirements</p>
</li>
<li>
<p>Data gap analysis</p>
</li>
<li>
<p>Mobile support</p>
</li>
</ul>
</div></section>













<section data-type="sect3" data-pdf-bookmark="Define the integration"><div class="sect3" id="idm45261446539104">
<h3>Define the integration</h3>

<p>In a containerized world, integration <a data-type="indexterm" data-primary="Integration layer (distributed system)" id="idm45261446537728"/><a data-type="indexterm" data-primary="platform" data-secondary="Integration layer" id="idm45261446536960"/>becomes a new challenge. Coming from a traditional enterprise landscape, it has either been a centralized solution (Enterprise Service Bus or similar) or been part of the individual applications using some common integration framework like Apache Camel. Neither approach fits perfectly into a stateless container-oriented platform. What you are looking for in a target platform is the smooth integration between messaging components, data transformation logic, and service integration. All the relevant parts need to scale well in a stateless environment for distributed systems, and it should be easy to extend a composed application with new capabilities:</p>

<ul>
<li>
<p>Existing integration capabilities</p>
</li>
<li>
<p>Evaluate partner solution ecosystem</p>
</li>
<li>
<p>Define integration requirements (data sources, service integration, messaging, APIs)</p>
</li>
</ul>

<ul class="pagebreak-before">
<li>
<p>Define standards and frameworks (e.g., <a href="https://oreil.ly/kfXw1">Camel K</a>)</p>
</li>
<li>
<p>Evaluate serverless/knative integration (e.g., Camel K)</p>
</li>
</ul>
</div></section>













<section data-type="sect3" data-pdf-bookmark="Define the technology stack"><div class="sect3" id="idm45261446528432">
<h3>Define the technology stack</h3>

<p>The remaining category <a data-type="indexterm" data-primary="technology stack" id="idm45261446527104"/>focuses on individual technologies and frameworks. Think of it as a blueprint repository defining the relevant technologies, services, and methodologies for a productive environment. An underestimated influence on the requirements in this category is the available development skill in an organization. With a traditional Enterprise Java background, it is not easy to completely switch to a reactive development approach and a stateless application design. Also, familiarity with existing APIs and time to productivity on a new platform play a crucial role in picking the most suitable technology stack:</p>

<ul>
<li>
<p>Technology stack assessment across core, CX, and external services</p>
</li>
<li>
<p>Microservices framework (e.g, Quarkus, Spring Boot)</p>
</li>
<li>
<p>Implementation recommendation (reactive, imperative, message-driven, etc.)</p>
</li>
<li>
<p>Deployment model (IaaS, PaaS, hybrid)</p>
</li>
<li>
<p>Define target development platform</p>
</li>
<li>
<p>Development skills gap analysis</p>
</li>
</ul>

<p>After completing this assessment, you are well prepared for a journey to a containerized application platform. Next, you will <a data-type="indexterm" data-primary="modernization" data-secondary="containers" data-startref="moderncontain" id="idm45261446519152"/><a data-type="indexterm" data-primary="containers" data-secondary="modernization and" data-startref="containmodern" id="idm45261446517872"/>need to map out and plan your containerization strategy.</p>
</div></section>



</div></section>





</div></section>













<section data-type="sect1" data-pdf-bookmark="Mandatory Migration Steps and Tools"><div class="sect1" id="idm45261446516144">
<h1>Mandatory Migration Steps and Tools</h1>

<p>Following the basic assumption that you have an existing application landscape in place and cannot start everything as a green-field project, we emphasize moving existing applications into containers. Coming back to the 6 Rs from earlier, the first application you are taking a look at should fall into one of the following Rs: Rehost, Replatform, and Refactor (<a data-type="xref" href="#fig1-3">Figure 3-3</a>). While they look similar in their description, the most significant difference between the three approaches is business value versus migration time and cost.</p>

<figure><div id="fig1-3" class="figure">
<img src="Images/moej_0303.png" alt="Business value assesment" width="600" height="237"/>
<h6><span class="label">Figure 3-3. </span>Workload migration pattern</h6>
</div></figure>

<p>Which action to take and where to start modernizing depends on the application. While the concrete steps may vary, the first thing to identify is the correct candidates. Therefore, we need to analyze the existing applications, catalog them, and group them to assign them to the final migration pattern. The last step is to execute the individual migration projects.</p>








<section data-type="sect2" data-pdf-bookmark="Create an Application Portfolio"><div class="sect2" id="idm45261446510336">
<h2>Create an Application Portfolio</h2>

<p>There are many ways to create such <a data-type="indexterm" data-primary="migration" data-secondary="application portfolio" id="idm45261446508944"/><a data-type="indexterm" data-primary="application portfolio, migration" id="idm45261446507968"/>an application catalog or portfolio. And you most likely already have a way to select applications relevant for a certain business domain. If not, feel free to fast-forward to <a data-type="xref" href="ch05.xhtml#beyond_lift_and_shift">Chapter 5</a>, where we talk about the <a href="https://oreil.ly/1wPUF">Konveyor project</a>.</p>
</div></section>





</div></section>













<section data-type="sect1" data-pdf-bookmark="Prepare for Big Things"><div class="sect1" id="idm45261446505200">
<h1>Prepare for Big Things</h1>

<p>The most prestigious process in modernization is refactoring existing applications. For coverage of a proven <a data-type="indexterm" data-primary="modernization" data-secondary="refactoring" id="idm45261446503152"/>method of transitioning an existing monolithic system to a microservice architecture, we recommend <a href="https://oreil.ly/0x6oq"><em>Monolith to Microservices</em></a> by Sam Newman (O’Reilly). While <a data-type="indexterm" data-primary="Newman, Sam" id="idm45261446501088"/>he walks you through a lot of different approaches and creates a detailed process for various situations, there are also simpler approaches, such as the one outlined by Brent Frye <a data-type="indexterm" data-primary="Frye, Brent" id="idm45261446500128"/>from the Software Engineering Institute at Carnegie Mellon University. His <a href="https://oreil.ly/YKYUY">approach to modularization</a> of existing applications is a lot more generic. He recommends eight simple steps to break down the monolith. He focuses <a data-type="indexterm" data-primary="component groups" id="idm45261446498480"/><a data-type="indexterm" data-primary="macroservices" id="idm45261446497808"/><a data-type="indexterm" data-primary="monolith architectures" data-secondary="breaking down" id="idm45261446497136"/>on components and component groups. <em>Components</em> are logical sets of data objects and the actions that the system performs on those objects. Component groups become what he calls <em>macroservices</em>. A macroservice is similar to a microservice with two primary differences. First, a macroservice may share the datastore with the legacy monolithic system or other 
<span class="keep-together">macroservices</span>. Second, unlike a microservice, a 
<span class="keep-together">macroservice</span> may provide access to multiple data objects. In the last step, the macroservices are decomposed further.</p>

<p>The logical steps to breaking down your monolith according to Frye are:</p>
<ol>
<li>
<p>Identify logical components.</p>
</li>
<li>
<p>Flatten and refactor components.</p>
</li>
<li>
<p>Identify component dependencies.</p>
</li>
<li>
<p>Identify component groups.</p>
</li>
<li>
<p>Create an API for a remote user interface.</p>
</li>
<li>
<p>Migrate component groups to macroservices:</p>
<ol>
<li>
<p>Move component groups to separate projects.</p>
</li>
<li>
<p>Make separate deployments.</p>
</li>

</ol>
</li>
<li>
<p>Migrate macroservices to microservices.</p>
</li>
<li>
<p>Repeat steps 6–7 until complete.</p>
</li>

</ol>

<p>This is also the more general recommendation from <a data-type="indexterm" data-primary="Richardson, Chris" id="idm45261446482592"/>Chris Richardson. As he outlined in his <a href="https://oreil.ly/CZn61">O’Reilly SACON London keynote</a> and many times after, he is looking for an incremental approach starting with the most promising functionality.</p>

<p>Do it incrementally and repeat the extraction steps until the monolith is finally eliminated or the initial software delivery problems are solved as illustrated in <a data-type="xref" href="#fig3-4">Figure 3-4</a>.</p>

<figure><div id="fig3-4" class="figure">
<img src="Images/moej_0304.png" alt="Move functionality as long as necessary." width="600" height="382"/>
<h6><span class="label">Figure 3-4. </span>Moving monoliths to services over time by incrementally extracting them</h6>
</div></figure>

<p>The three approaches differ in depth, angle, and details. While Richardson talks about the most valuable functionality and focuses on extracting it first, Frye created a simple methodology that can be applied in all situations. Finally, Newman developed the most detailed handbook for various situations in a modernization journey. All three will be helpful on your personal journey. We are convinced, though, that the approach Richardson takes is the best starting point. What Thomas Huijskens said for data scientists is something we also strongly believe in: “The code you write is only useful if it is production code.”</p>

<p>Every modernization effort has to follow business requirements and support production functionality. Following this thought, the entire modernization project can only be successful if you identify the correct candidates.</p>
</div></section>













<section data-type="sect1" data-pdf-bookmark="Summary"><div class="sect1" id="idm45261446475504">
<h1>Summary</h1>

<p>This chapter walked you through some basic definitions for migration strategies and showed you an evaluation path for the target development platform. We’ve looked at technical recommendations, and you now know how to assess existing applications for rehosting, replatforming, and refactoring.</p>
</div></section>







</div></section></div></body></html>