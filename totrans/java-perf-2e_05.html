<html><head></head><body><section data-pdf-bookmark="Chapter 5. An Introduction to Garbage Collection" data-type="chapter" epub:type="chapter"><div class="chapter" id="GC">&#13;
<h1><span class="label">Chapter 5. </span>An Introduction to Garbage Collection</h1>&#13;
&#13;
&#13;
<p><a data-primary="garbage collection (GC)" data-type="indexterm" id="ix_ch05-asciidoc0"/><a data-primary="garbage collection (GC)" data-secondary="basics" data-type="indexterm" id="ix_ch05-asciidoc1"/>This chapter covers the basics of garbage collection&#13;
within the JVM. Short of rewriting code, tuning the garbage collector&#13;
is the most important thing that can be done to improve the performance of a&#13;
Java application.</p>&#13;
&#13;
<p>Because the performance of Java applications depends heavily on garbage&#13;
collection technology, it is not surprising that quite a few&#13;
collectors are available. The OpenJDK has three collectors suitable for production, another that is deprecated in JDK 11 but still quite popular in JDK 8, and some experimental collectors that will (ideally) be production-ready in&#13;
future releases. Other Java implementations such as Open J9 or the Azul JVM have their own collectors.</p>&#13;
&#13;
<p>The performance characteristics of all these collectors are quite different;&#13;
we will focus only on those that come with OpenJDK.&#13;
Each is covered in depth in the next chapter.&#13;
However, they share basic concepts, so&#13;
this chapter provides a basic overview of how the collectors operate.</p>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Garbage Collection Overview" data-type="sect1"><div class="sect1" id="idm45775555145320">&#13;
<h1>Garbage Collection Overview</h1>&#13;
&#13;
<p><a data-primary="garbage collection (GC)" data-secondary="overview" data-type="indexterm" id="ix_ch05-asciidoc2"/>One of the most attractive features of programming in&#13;
Java is that developers needn’t explicitly&#13;
manage the life cycle of objects: objects are created when needed, and&#13;
when the object is no longer in use, the JVM automatically frees the object.&#13;
If, like me, you spend a lot of time optimizing the memory use of&#13;
Java programs, this whole scheme might seem like a weakness instead of a&#13;
feature (and the amount of time I’ll spend covering GC might seem to lend&#13;
credence to that position). Certainly it can be considered a mixed blessing,&#13;
but I still recall the difficulties of tracking down null pointers and&#13;
dangling pointers in other languages. I’d strongly argue that tuning garbage&#13;
collectors is far easier (and less time-consuming) than tracking down pointer&#13;
bugs.</p>&#13;
&#13;
<p>At a basic level, GC consists of finding objects that are in&#13;
use and freeing the memory associated with the remaining objects (those that are not in use).&#13;
This is sometimes described as finding objects that no longer have any&#13;
references to them (implying that references are tracked via a count).&#13;
That sort of reference counting is insufficient, though. Given&#13;
a linked list of objects, each object in the list (except the head) will&#13;
be pointed to by another object in the list—but if nothing refers to the&#13;
head of the list, the entire list is not in use and can be freed. And if&#13;
the list is circular (e.g., the tail of the list points to the head),&#13;
every object in the list has a reference to it—even though no&#13;
object in the list can actually be used, since no objects reference the list&#13;
itself.</p>&#13;
&#13;
<p>So references cannot be tracked dynamically via a count; instead,&#13;
the JVM must periodically search the heap for unused objects. It does this&#13;
by starting with objects that are GC roots, which are objects that are&#13;
accessible from outside the heap. That primarily includes thread stacks and&#13;
system classes. Those objects are always reachable, so then the GC algorithm&#13;
scans all objects that are reachable via one of the root objects. Objects&#13;
that are reachable via a GC root are live objects; the remaining unreachable&#13;
objects are garbage (even if they maintain references to live objects or to&#13;
each other).</p>&#13;
&#13;
<p>When the GC algorithm finds&#13;
unused objects, the JVM can free the memory occupied by those objects and&#13;
use it to allocate additional objects. However, it is usually insufficient&#13;
simply to keep track of that free memory and use it for future allocations;&#13;
at some point, memory must be compacted to prevent memory fragmentation.</p>&#13;
&#13;
<p>Consider the case of a program that allocates an array of 1,000 bytes, then&#13;
one of 24 bytes, and repeats that process in a loop. When that process&#13;
fills up the heap, it will appear like the top row in <a data-type="xref" href="#FigureGCHeap">Figure 5-1</a>: the&#13;
heap is full, and the allocations of the array sizes are interleaved.</p>&#13;
&#13;
<p>When the heap is full, the JVM will free the unused arrays.&#13;
Say that all the 24-byte arrays are no longer in use,&#13;
and the 1,000-byte arrays&#13;
are still all in use: that yields the second row in <a data-type="xref" href="#FigureGCHeap">Figure 5-1</a>.&#13;
The heap has free areas within it,&#13;
but it can’t allocate anything larger than 24 bytes—unless the JVM moves all the 1,000-byte arrays so that they are contiguous, leaving&#13;
all the free memory in a region where it can be allocated as needed (the&#13;
third row in <a data-type="xref" href="#FigureGCHeap">Figure 5-1</a>).</p>&#13;
&#13;
<p>The implementations are a little more detailed, but the performance&#13;
of GC is dominated by these&#13;
basic operations: finding unused objects, making their memory available,&#13;
and compacting the heap. Different collectors take different approaches&#13;
to these operations, particularly compaction: some algorithms delay compaction&#13;
until absolutely necessary, some compact entire sections of the heap at a&#13;
time, and some compact the heap by relocating small amounts of memory at&#13;
a time. These different approaches are why different algorithms have different&#13;
performance <span class="keep-together">characteristics.</span></p>&#13;
&#13;
<figure><div class="figure" id="FigureGCHeap">&#13;
<img alt="jp2e 0501" src="assets/jp2e_0501.png"/>&#13;
<h6><span class="label">Figure 5-1. </span>Idealized GC heap during collection</h6>&#13;
</div></figure>&#13;
&#13;
<p>It is simpler to perform these operations if no&#13;
application threads are running while the garbage collector is running.&#13;
Java programs are typically heavily multithreaded, and the garbage&#13;
collector itself often runs multiple threads. <a data-primary="mutator threads" data-type="indexterm" id="idm45775555130344"/>This discussion&#13;
considers two logical groups of threads: those performing application logic&#13;
(often called <em>mutator threads</em>, since they are mutating objects as part of&#13;
the application logic) and those performing GC. When GC threads track object references or move&#13;
objects around in memory, they must make sure that&#13;
application threads are not using those objects. This is particularly true&#13;
when GC moves objects around: the memory location of&#13;
the object changes during that operation, and hence no application threads&#13;
can be accessing the object.</p>&#13;
&#13;
<p>The pauses when all application threads are stopped are called&#13;
<em>stop-the-world pauses</em>.&#13;
These pauses generally have the greatest impact on the performance of an&#13;
application, and minimizing those pauses is one&#13;
important consideration when tuning GC.</p>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Generational Garbage Collectors" data-type="sect2"><div class="sect2" id="idm45775555127432">&#13;
<h2>Generational Garbage Collectors</h2>&#13;
&#13;
<p><a data-primary="garbage collection (GC)" data-secondary="generational garbage collectors" data-type="indexterm" id="ix_ch05-asciidoc3"/><a data-primary="generational garbage collectors" data-type="indexterm" id="ix_ch05-asciidoc4"/>Though the details differ somewhat, most garbage collectors work&#13;
by splitting the heap into generations. <a data-primary="old generation" data-type="indexterm" id="idm45775555123176"/><a data-primary="tenured generation" data-type="indexterm" id="idm45775555122504"/><a data-primary="young generation" data-type="indexterm" id="idm45775555121832"/>These are called&#13;
the <em>old (or tenured) generation</em> and the <em>young generation</em>.<a data-primary="eden" data-type="indexterm" id="idm45775555120200"/><a data-primary="survivor spaces" data-type="indexterm" id="idm45775555119464"/>&#13;
The young generation is further&#13;
divided into sections known as <em>eden</em> and the <em>survivor spaces</em> (though&#13;
sometimes, eden is incorrectly used to refer to the entire young generation).</p>&#13;
&#13;
<p class="pagebreak-before">The rationale for having separate generations is that many objects are used&#13;
for a very short period&#13;
of time. Take, for example, the loop in the stock price calculation that&#13;
sums the square of the difference of price from the average price (part of the&#13;
calculation of standard deviation):</p>&#13;
&#13;
<pre data-code-language="java" data-type="programlisting"><code class="n">sum</code> <code class="o">=</code> <code class="k">new</code> <code class="n">BigDecimal</code><code class="o">(</code><code class="mi">0</code><code class="o">);</code>&#13;
<code class="k">for</code> <code class="o">(</code><code class="n">StockPrice</code> <code class="n">sp</code> <code class="o">:</code> <code class="n">prices</code><code class="o">.</code><code class="na">values</code><code class="o">())</code> <code class="o">{</code>&#13;
    <code class="n">BigDecimal</code> <code class="n">diff</code> <code class="o">=</code> <code class="n">sp</code><code class="o">.</code><code class="na">getClosingPrice</code><code class="o">().</code><code class="na">subtract</code><code class="o">(</code><code class="n">averagePrice</code><code class="o">);</code>&#13;
    <code class="n">diff</code> <code class="o">=</code> <code class="n">diff</code><code class="o">.</code><code class="na">multiply</code><code class="o">(</code><code class="n">diff</code><code class="o">);</code>&#13;
    <code class="n">sum</code> <code class="o">=</code> <code class="n">sum</code><code class="o">.</code><code class="na">add</code><code class="o">(</code><code class="n">diff</code><code class="o">);</code>&#13;
<code class="o">}</code></pre>&#13;
&#13;
<p>Like many Java classes, the&#13;
<code class="keep-together">BigDecimal</code>&#13;
class is&#13;
immutable: the object represents a particular number and cannot be changed.&#13;
When arithmetic is performed on the object, a new object is created (and often,&#13;
the previous object with the previous value is then discarded). When&#13;
this simple loop is executed for a year’s worth of stock prices&#13;
(roughly 250 iterations),&#13;
750&#13;
<code class="keep-together">BigDecimal</code>&#13;
objects are created to store the intermediate&#13;
values just in this loop. Those objects are discarded on the next iteration of&#13;
the loop. Within <code class="keep-together">add()</code>&#13;
and other methods, the JDK library code creates even more&#13;
intermediate <code class="keep-together">BigDecimal</code>&#13;
(and other) objects. In the end, a lot of objects&#13;
are created and discarded quickly in this small amount of code.</p>&#13;
&#13;
<p>This kind of operation is common in Java, so the garbage&#13;
collector is designed to take advantage of the fact that many&#13;
(and sometimes most) objects are only used temporarily. This is where the generational&#13;
design comes in. Objects are first allocated in the young generation, which is a subset&#13;
of the entire heap. When the young generation fills up, the garbage&#13;
collector will stop all the application threads and empty out the young&#13;
generation. Objects that are no longer in use are discarded, and objects that&#13;
are still in use are moved elsewhere.&#13;
<a data-primary="minor GC" data-type="indexterm" id="idm45775555069960"/><a data-primary="young GC" data-type="indexterm" id="idm45775555069256"/>This operation is called a <em>minor GC</em> or a <em>young GC</em>.</p>&#13;
&#13;
<p>This design has two performance advantages. First,&#13;
because the young generation is only a portion of the entire heap, processing&#13;
it is faster than processing the entire heap. The&#13;
application threads are stopped for a much shorter period of time than if&#13;
the entire heap were processed at once. You probably see a trade-off&#13;
there, since it also means that the application threads are stopped more&#13;
frequently than they would be if the JVM waited to perform GC until the entire&#13;
heap were full; that trade-off will be explored in more detail&#13;
later in this chapter. For now, though, it is almost always a big&#13;
advantage to have the&#13;
shorter pauses even though they will be more <span class="keep-together">frequent</span>.</p>&#13;
&#13;
<p>The second advantage arises from the way objects are allocated in the&#13;
young generation. Objects are allocated in eden (which encompasses the vast&#13;
majority of the young generation). When the young generation is cleared&#13;
during a collection, all objects in eden are either moved or discarded:&#13;
objects that are not in use can be discarded, and objects in use are&#13;
moved either to one of the survivor spaces or to the old&#13;
generation. Since all surviving objects&#13;
are moved, the young generation is automatically <span class="keep-together">compacted</span> when it is&#13;
collected: at the end of the collection, eden and one of the&#13;
survivor spaces are empty, and the objects that remain in the young generation&#13;
are compacted within the other survivor space.</p>&#13;
&#13;
<p>Common GC algorithms have stop-the-world pauses during collection of the&#13;
young generation.</p>&#13;
&#13;
<p>As objects are moved to the old generation, eventually it too will fill&#13;
up, and the JVM will need to find any objects within the old generation that&#13;
are no longer in use and discard them. This is where&#13;
GC algorithms have their biggest differences. The simpler algorithms&#13;
stop all application threads, find the unused objects, free their memory,&#13;
and then compact the heap. <a data-primary="full GC" data-type="indexterm" id="idm45775555062600"/>This process is called a <em>full GC</em>, and it generally&#13;
causes a relatively long pause for the application threads.</p>&#13;
&#13;
<p>On the other hand, it is possible—though&#13;
more computationally complex—to find unused objects while application&#13;
threads are running. Because the phase&#13;
where they scan for unused objects can occur without stopping&#13;
application threads, <a data-primary="concurrent garbage collector" data-type="indexterm" id="idm45775555060488"/>these algorithms are called <em>concurrent collectors</em>. <a data-primary="low-pause garbage collectors" data-type="indexterm" id="idm45775555059304"/><a data-primary="pauseless garbage collectors" data-type="indexterm" id="idm45775555058600"/>They&#13;
are also called <em>low-pause</em> (and sometimes, incorrectly, <em>pauseless</em>)&#13;
collectors since they minimize the need to stop all the application threads.&#13;
Concurrent collectors also take different approaches to compacting the&#13;
old generation.</p>&#13;
&#13;
<p>When using a concurrent collector, an application will typically experience&#13;
fewer (and much shorter) pauses.&#13;
The biggest trade-off is that the application will use more CPU overall.&#13;
Concurrent collectors can also be more difficult to tune in order to get their best&#13;
performance (though in JDK 11, tuning concurrent collectors like the G1 GC is much&#13;
easier than in previous releases, which reflects the engineering progress&#13;
that has been made since the concurrent collectors were first introduced).</p>&#13;
&#13;
<p>As you consider which garbage collector is appropriate for your situation,&#13;
think about the overall performance goals that must be met. Trade-offs exist in every situation.&#13;
In an application (such as a REST&#13;
server) measuring the response time of individual requests, consider these&#13;
points:</p>&#13;
&#13;
<ul>&#13;
<li>&#13;
<p>The individual requests will be impacted by pause times—and more importantly by long pause times for full GCs. If minimizing the effect of pauses on response times is the goal, a concurrent collector may be more appropriate.</p>&#13;
</li>&#13;
<li>&#13;
<p>If the average response time is more important than the outliers (i.e.,&#13;
the <span class="keep-together">90th%)</span> response time), a nonconcurrent collector may yield better results.</p>&#13;
</li>&#13;
<li>&#13;
<p>The benefit of avoiding long pause times with a concurrent collector comes at the expense of extra CPU usage. If your machine lacks the spare CPU cycles&#13;
needed by a concurrent collector, a nonconcurrent collector may be the better&#13;
choice.</p>&#13;
</li>&#13;
</ul>&#13;
&#13;
<p>Similarly, the choice of garbage collector in a batch application is guided&#13;
by the following trade-off:</p>&#13;
&#13;
<ul>&#13;
<li>&#13;
<p>If enough CPU is available, using the concurrent collector to avoid full GC pauses will allow the job to finish faster.</p>&#13;
</li>&#13;
<li>&#13;
<p>If CPU is limited, the extra CPU consumption of the concurrent collector will cause the batch job to take more time.</p>&#13;
</li>&#13;
</ul>&#13;
<div data-type="tip"><h1>Quick Summary</h1>&#13;
<ul>&#13;
<li>&#13;
<p>GC algorithms generally divide the heap into old and young generations.</p>&#13;
</li>&#13;
<li>&#13;
<p>GC algorithms generally employ a stop-the-world approach to clearing objects from the young generation, which is usually a quick operation.</p>&#13;
</li>&#13;
<li>&#13;
<p>Minimizing the effect of performing GC in the old generation is a trade-off between pause times and CPU usage.<a data-startref="ix_ch05-asciidoc4" data-type="indexterm" id="idm45775555044072"/><a data-startref="ix_ch05-asciidoc3" data-type="indexterm" id="idm45775555043368"/></p>&#13;
</li>&#13;
</ul>&#13;
</div>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="GC Algorithms" data-type="sect2"><div class="sect2" id="idm45775555126808">&#13;
<h2>GC Algorithms</h2>&#13;
&#13;
<p><a data-primary="garbage collection (GC)" data-secondary="algorithms for" data-type="indexterm" id="ix_ch05-asciidoc5"/><a data-primary="garbage collection algorithms" data-type="indexterm" id="ix_ch05-asciidoc6"/>OpenJDK 12 provides a variety of GC algorithms with varying degrees of support&#13;
in earlier releases. <a data-type="xref" href="#TableGCAlgorithms">Table 5-1</a> lists these algorithms&#13;
and their status in OpenJDK and <span class="keep-together">Oracle</span> Java releases.</p>&#13;
<table id="TableGCAlgorithms">&#13;
<caption><span class="label">Table 5-1. </span>Support level of various GC algorithms<sup><a data-type="noteref" href="ch05.html#idm45775555035960" id="idm45775555035960-marker">a</a></sup></caption>&#13;
<thead>&#13;
<tr>&#13;
<th>GC algorithm</th>&#13;
<th>Support in JDK 8</th>&#13;
<th>Support in JDK 11</th>&#13;
<th>Support in JDK 12</th>&#13;
</tr>&#13;
</thead>&#13;
<tbody>&#13;
<tr>&#13;
<td><p>Serial GC</p></td>&#13;
<td><p>S</p></td>&#13;
<td><p>S</p></td>&#13;
<td><p>S</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td><p>Throughput (Parallel) GC</p></td>&#13;
<td><p>S</p></td>&#13;
<td><p>S</p></td>&#13;
<td><p>S</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td><p>G1 GC</p></td>&#13;
<td><p>S</p></td>&#13;
<td><p>S</p></td>&#13;
<td><p>S</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td><p>Concurrent Mark-Sweep (CMS)</p></td>&#13;
<td><p>S</p></td>&#13;
<td><p>D</p></td>&#13;
<td><p>D</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td><p>ZGC</p></td>&#13;
<td><p>-</p></td>&#13;
<td><p>E</p></td>&#13;
<td><p>E</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td><p>Shenandoah</p></td>&#13;
<td><p>E2</p></td>&#13;
<td><p>E2</p></td>&#13;
<td><p>E2</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td><p>Epsilon GC</p></td>&#13;
<td><p>-</p></td>&#13;
<td><p>E</p></td>&#13;
<td><p>E</p></td>&#13;
</tr>&#13;
</tbody>&#13;
<tbody><tr class="footnotes"><td colspan="4"><p data-type="footnote" id="idm45775555035960"><sup><a href="ch05.html#idm45775555035960-marker">a</a></sup> (S: Fully Supported D: Deprecated E: Experimental E2: Experimental; in OpenJDK builds but not Oracle builds)</p></td></tr></tbody></table>&#13;
&#13;
<p>A brief description of each algorithm follows; <a data-type="xref" href="ch06.html#Collectors">Chapter 6</a> provides more&#13;
details on tuning them individually.</p>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="The serial garbage collector" data-type="sect3"><div class="sect3" id="SerialGC">&#13;
<h3>The serial garbage collector</h3>&#13;
&#13;
<p><a data-primary="garbage collection algorithms" data-secondary="serial garbage collector" data-type="indexterm" id="idm45775554974216"/><a data-primary="serial garbage collector" data-secondary="about" data-type="indexterm" id="idm45775554973160"/>The <em>serial garbage collector</em> is the simplest of the collectors.&#13;
This is the default collector if the application is running on a&#13;
client-class machine (32-bit JVMs on Windows) or on a single-processor&#13;
machine. At one point, the serial collector seemed like it was destined for&#13;
the trash can, but containerization has changed that: virtual machines and&#13;
<a data-primary="Docker container" data-type="indexterm" id="idm45775554971320"/>Docker containers with&#13;
one core (even a hyper-threaded core that appears as two CPUs)&#13;
have made this algorithm more relevant again.</p>&#13;
&#13;
<p>The serial collector uses a single thread to process the heap. It will&#13;
stop all application threads as the heap is processed (for either a minor&#13;
or full GC). During a full GC, it will fully compact the old generation.</p>&#13;
&#13;
<p><a data-primary="-XX:+UseSerialGC" data-type="indexterm" id="idm45775554969464"/>The serial collector is&#13;
enabled by using the&#13;
<span class="keep-together"><code>-XX:+UseSerialGC</code></span>&#13;
flag (though usually it is the default in those cases where it might be used).&#13;
Note that&#13;
unlike with most JVM flags, the serial collector is not disabled by changing the plus&#13;
sign to a minus sign (i.e., by specifying&#13;
<span class="keep-together"><code>-XX:-UseSerialGC</code>).</span>&#13;
On systems where the serial collector is the default,&#13;
it is disabled by specifying a different GC algorithm.</p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="The throughput collector" data-type="sect3"><div class="sect3" id="ThroughputGC">&#13;
<h3>The throughput collector</h3>&#13;
&#13;
<p><a data-primary="garbage collection algorithms" data-secondary="throughput collector" data-type="indexterm" id="idm45775554964696"/><a data-primary="throughput garbage collector" data-secondary="basics" data-type="indexterm" id="idm45775554963656"/>In JDK 8, the <em>throughput collector</em> is the default collector for any 64-bit machine with two or more CPUs. The throughput collector&#13;
uses multiple threads to collect the young generation, which makes&#13;
minor GCs much faster than when the serial collector is used.&#13;
This uses multiple threads to process the old&#13;
generation as well. Because it uses multiple&#13;
threads, the throughput collector is often called the <em>parallel collector</em>.</p>&#13;
&#13;
<p>The throughput collector stops all application threads during both minor&#13;
and full GCs, and it fully compacts the old generation during a full GC.&#13;
Since it is the default in most situations where it would be used, it&#13;
needn’t be explicitly enabled. <a data-primary="-XX:+UseParallelGC" data-type="indexterm" id="idm45775554960632"/>To enable it where necessary, use&#13;
the flag&#13;
<code class="keep-together">-XX:+UseParallelGC</code>.</p>&#13;
&#13;
<p>Note that old versions of the JVM enabled parallel collection in the young&#13;
and <span class="keep-together">old generations</span> separately, so you might see references to the <a data-primary="-XX:+UseParallelOldGC" data-type="indexterm" id="idm45775554957880"/>flag&#13;
<code class="keep-together">-XX:+UseParallelOldGC</code>. This flag&#13;
is obsolete (though it still functions, and you could disable this flag to&#13;
collect only the young generation in parallel if for some reason you really&#13;
wanted to).</p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="The G1 GC collector" data-type="sect3"><div class="sect3" id="G1GC">&#13;
<h3>The G1 GC collector</h3>&#13;
&#13;
<p><a data-primary="G1 GC (garbage first garbage collector)" data-type="indexterm" id="idm45775554954328"/><a data-primary="garbage collection algorithms" data-secondary="G1 GC" data-type="indexterm" id="idm45775554953656"/>The <em>G1 GC</em> (or <em>garbage first garbage collector</em>) uses a concurrent collection strategy to&#13;
collect the heap with minimal pauses. It is the default collector in JDK 11&#13;
and later for 64-bit JVMs on machines with two or more CPUs.</p>&#13;
&#13;
<p>G1 GC divides the heap into regions, but it still considers the heap to have two generations.&#13;
Some of those regions make up the young generation, and&#13;
the young generation is still collected by stopping all application threads&#13;
and moving all objects that are alive into the old generation or the&#13;
survivor spaces. (This occurs using multiple threads.</p>&#13;
&#13;
<p>In G1 GC, the old generation is processed by background&#13;
threads that don’t need to stop the application threads to perform most of&#13;
their work. Because the old generation is divided into regions, G1 GC can clean&#13;
up objects from the old generation by copying from one region into another,&#13;
which means that it (at least partially) compacts the heap during&#13;
normal processing. This helps keep G1 GC heaps from becoming fragmented,&#13;
although that is still possible.</p>&#13;
&#13;
<p>The trade-off for avoiding the full GC cycles is CPU time:&#13;
the (multiple) background threads G1 GC uses to process the old generation&#13;
must have CPU cycles available at the same time the application threads are&#13;
running.</p>&#13;
&#13;
<p><a data-primary="-XX:+UseG1GC" data-type="indexterm" id="idm45775554948920"/>G1 GC is enabled by specifying the flag&#13;
<code class="keep-together">-XX:+UseG1GC</code>. In most cases, it is the&#13;
default in JDK 11, and it is functional in JDK 8 as well—particularly in&#13;
later builds of JDK 8, which contains many important bug fixes and performance&#13;
enhancements that have been back-ported from later releases. Still, as you’ll&#13;
see when we explore G1 GC in depth, one major performance feature is missing&#13;
from G1 GC in JDK 8 that can make it unsuitable for that release.</p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="The CMS collector" data-type="sect3"><div class="sect3" id="CMSGC">&#13;
<h3>The CMS collector</h3>&#13;
&#13;
<p><a data-primary="CMS garbage collector" data-type="indexterm" id="idm45775554945240"/><a data-primary="garbage collection algorithms" data-secondary="CMS collector" data-type="indexterm" id="idm45775554944536"/>The <em>CMS collector</em> was the first concurrent collector. Like other algorithms, CMS&#13;
stops all application&#13;
threads during a minor GC, which it performs with multiple threads.</p>&#13;
&#13;
<p>CMS is officially deprecated in JDK 11 and beyond, and its use in JDK 8 is&#13;
discouraged. From a practical standpoint, the major flaw in CMS is that it has&#13;
no way to compact the heap during its background processing. If the heap&#13;
becomes fragmented (which is likely to happen at some point), CMS must&#13;
stop all application threads and compact the heap, which defeats the purpose&#13;
of a concurrent collector. Between that and the advent of G1 GC, CMS is no longer&#13;
recommended.</p>&#13;
&#13;
<p><a data-primary="-XX:+UseConcMarkSweepGC" data-type="indexterm" id="idm45775554941672"/>CMS is enabled by specifying the flag&#13;
<code class="keep-together">-XX:+UseConcMarkSweepGC</code>, which is&#13;
<code>false</code> by default. <a data-primary="-XX:+UseParNewGC" data-type="indexterm" id="idm45775554939736"/>Historically, CMS used to require setting the&#13;
<code class="keep-together">-XX:+UseParNewGC</code> flag as well (otherwise,&#13;
the young generation would be collected by a single thread), though that is&#13;
obsolete.</p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Experimental collectors" data-type="sect3"><div class="sect3" id="idm45775554937896">&#13;
<h3>Experimental collectors</h3>&#13;
&#13;
<p><a data-primary="garbage collection algorithms" data-secondary="experimental" data-type="indexterm" id="idm45775554936696"/>Garbage collection continues to be fertile ground for JVM engineers, and the&#13;
latest versions of Java come with the three experimental algorithms mentioned&#13;
earlier. I’ll have more to say about those in the next chapter; for now,&#13;
let’s continue with a look at choosing among the three collectors&#13;
supported in production environments.</p>&#13;
<aside class="less_space pagebreak-before" data-type="sidebar" epub:type="sidebar"><div class="sidebar" id="ExplicitGC">&#13;
<h5>Causing and Disabling Explicit Garbage Collection</h5>&#13;
<p><a data-primary="garbage collection (GC)" data-secondary="causing/disabling explicit GC" data-type="indexterm" id="idm45775554933160"/>GC is typically caused when the JVM decides GC is necessary: a minor GC will&#13;
be triggered when the new generation is full, a full GC will be triggered&#13;
when the old generation is full, or a concurrent GC (if applicable)&#13;
will be triggered when the heap starts to fill up.</p>&#13;
&#13;
<p><a data-primary="System.gc() method" data-type="indexterm" id="idm45775554931496"/>Java provides a mechanism for applications to force a GC to occur: the&#13;
<code class="keep-together">System.gc()</code>&#13;
method. Calling that method is almost always a bad idea. This&#13;
call always triggers a full GC (even if the JVM is running with G1 GC or CMS), so&#13;
application threads will be stopped for a relatively long period of time. And&#13;
calling this method will not make the application any more efficient; it will&#13;
cause a GC to occur sooner than might have happened otherwise, but that is&#13;
really just shifting the performance impact.</p>&#13;
&#13;
<p>There are exceptions to every rule, particularly when doing performance&#13;
monitoring or benchmarking. For small benchmarks that run a bunch&#13;
of code to properly warm up the JVM, forcing a GC before the measurement&#13;
cycle may make sense. (<code>jmh</code> optionally does this, though usually it is&#13;
not necessary.) Similarly, when doing&#13;
heap analysis, it is usually a good idea to&#13;
force a full GC before taking the heap dump. Most techniques to obtain&#13;
a heap dump will perform a full GC anyway, but you also can force a full GC in other ways:&#13;
you can execute <em><code>jcmd &lt;process id&gt; GC.run</code></em>, or you can connect&#13;
to the JVM using <code>jconsole</code> and click the Perform GC button in the Memory&#13;
panel.</p>&#13;
&#13;
<p><a data-primary="Remote Method Invocation (RMI)" data-type="indexterm" id="idm45775554926744"/><a data-primary="RMI (Remote Method Invocation)" data-type="indexterm" id="idm45775554925880"/>Another exception is Remote Method Invocation (RMI), which calls&#13;
<code class="keep-together">System.gc()</code>&#13;
every&#13;
hour as part of its distributed&#13;
garbage collector. That timing can be <span class="keep-together">changed by setting</span> a different value&#13;
for these two system properties: <span class="keep-together"><code>-Dsun.rmi.dgc.server.gcInterval=<em>N</em></code></span> and <span class="keep-together"><code>-Dsun.rmi.dgc.client.gcInterval=<em>N</em></code>.</span>&#13;
The values for <em><code>N</code></em> are in milliseconds, and the default value&#13;
is 3600000 (one hour).</p>&#13;
&#13;
<p>If you end up running third-party code that incorrectly calls the&#13;
<code class="keep-together">System.gc()</code>&#13;
method, <a data-primary="-XX:+DisableExplicitGC" data-type="indexterm" id="idm45775554919544"/>those GCs can be prevented by including&#13;
<code class="keep-together">-XX:+DisableExplicitGC</code>&#13;
in the JVM arguments; by default, that flag is <code>false</code>. Applications like&#13;
Java EE servers often&#13;
include this argument to prevent the RMI GC calls from interfering with&#13;
their <span class="keep-together">operations.</span></p>&#13;
</div></aside>&#13;
<div data-type="tip"><h1>Quick Summary</h1>&#13;
<ul>&#13;
<li>&#13;
<p>The supported GC algorithms take different approaches toward minimizing the effect of GC on an application.</p>&#13;
</li>&#13;
<li>&#13;
<p>The serial collector makes sense (and is the default) when only one CPU is available and extra GC threads would interfere with the application.</p>&#13;
</li>&#13;
<li>&#13;
<p>The throughput collector is the default in JDK 8; it maximizes the total throughput of an application but may subject individual operations to long pauses.</p>&#13;
</li>&#13;
<li>&#13;
<p>G1 GC is the default in JDK 11 and beyond; it concurrently collects the old generation while application threads are running, potentially avoiding full GCs. Its design makes it less likely to experience full GCs than CMS.</p>&#13;
</li>&#13;
<li>&#13;
<p>The CMS collector can concurrently collect the old generation while application threads are running. If enough CPU is available for its background processing, this can avoid full GC cycles for the application. It is deprecated in favor of G1 GC.<a data-startref="ix_ch05-asciidoc6" data-type="indexterm" id="idm45775554910200"/><a data-startref="ix_ch05-asciidoc5" data-type="indexterm" id="idm45775554909496"/></p>&#13;
</li>&#13;
</ul>&#13;
</div>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Choosing a GC Algorithm" data-type="sect2"><div class="sect2" id="idm45775554908312">&#13;
<h2>Choosing a GC Algorithm</h2>&#13;
&#13;
<p><a data-primary="garbage collection (GC)" data-secondary="choosing an algorithm" data-type="indexterm" id="ix_ch05-asciidoc7"/><a data-primary="garbage collection algorithms" data-secondary="choosing" data-type="indexterm" id="ix_ch05-asciidoc8"/>The choice of a GC algorithm depends in part on the hardware available, in&#13;
part on what the application looks&#13;
like, and in part on the performance goals for the application. In JDK 11, G1 GC is often the&#13;
better choice; in JDK 8, the choice will depend on your application.</p>&#13;
&#13;
<p>We will start with the rule of thumb that G1 GC is the better choice, but&#13;
there are exceptions to&#13;
every rule. In the case of garbage collection, these exceptions involve the&#13;
number of CPU cycles the application needs relative to the available hardware,&#13;
and the amount of processing the background G1 GC threads need to perform.&#13;
If you are using JDK 8, the ability of G1 GC to avoid a full GC will also&#13;
be a key consideration.&#13;
When G1 GC is not the better choice, the decision between the throughput&#13;
and serial collectors is based on the number of CPUs on the machine.</p>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="When to use (and not use) the serial collector" data-type="sect3"><div class="sect3" id="idm45775554902968">&#13;
<h3>When to use (and not use) the serial collector</h3>&#13;
&#13;
<p><a data-primary="garbage collection algorithms" data-secondary="serial garbage collector" data-type="indexterm" id="ix_ch05-asciidoc9"/><a data-primary="serial garbage collector" data-secondary="when to use" data-type="indexterm" id="ix_ch05-asciidoc10"/>On a machine with a single CPU, the JVM defaults to using the serial&#13;
collector. This includes virtual machines with one CPU, and Docker containers&#13;
that are limited to one CPU. If you limit your Docker container to&#13;
a single CPU in early versions of JDK 8, it will still use the throughput&#13;
collector by default. In that environment, you should explore using the&#13;
serial collector (even though you’ll have to set it manually).</p>&#13;
&#13;
<p>In these environments, the serial collector is usually a good choice, but&#13;
at times G1 GC&#13;
will give better results. This example is also a good starting point for&#13;
understanding the general trade-offs involved in choosing a GC algorithm.</p>&#13;
&#13;
<p>The trade-off between G1 GC and other collectors involves having available&#13;
CPU cycles for G1 GC background threads, so let’s start with a CPU-intensive&#13;
batch job.  In a batch job, the CPU will be 100% busy&#13;
for a long time, and in that case the serial collector has a marked advantage.</p>&#13;
&#13;
<p><a data-type="xref" href="#TableHardwareBatch">Table 5-2</a> lists the time required for a single thread&#13;
to compute stock histories for 100,000 stocks over a period of three years.</p>&#13;
<table id="TableHardwareBatch">&#13;
<caption><span class="label">Table 5-2. </span>Processing time on a single CPU for different GC algorithms</caption>&#13;
<thead>&#13;
<tr>&#13;
<th>GC algorithm</th>&#13;
<th>Elapsed time</th>&#13;
<th>Time paused for GC</th>&#13;
</tr>&#13;
</thead>&#13;
<tbody>&#13;
<tr>&#13;
<td><p>Serial</p></td>&#13;
<td><p>434 seconds</p></td>&#13;
<td><p>79 seconds</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td><p>Throughput</p></td>&#13;
<td><p>503 seconds</p></td>&#13;
<td><p>144 seconds</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td><p>G1 GC</p></td>&#13;
<td><p>501 seconds</p></td>&#13;
<td><p>97 seconds</p></td>&#13;
</tr>&#13;
</tbody>&#13;
</table>&#13;
&#13;
<p>The advantage of the single-threaded garbage collection is most readily&#13;
apparent when we compare the serial collector to the throughput collector.&#13;
The time spent doing the actual calculation is the elapsed time minus the&#13;
time spent paused for GC. In the serial and throughput collectors, that&#13;
time is essentially the same&#13;
(roughly 355 seconds), but the serial collector wins because it spends much&#13;
less time paused for garbage collection. In particular, the serial collector takes on&#13;
average 505 ms for a full GC, whereas the throughput collector requires&#13;
1,392 ms. The throughput collector has&#13;
a fair amount of overhead in its algorithm—that overhead is worthwhile when&#13;
two or more threads are processing the heap, but it just gets in the&#13;
way when only a single thread is available.</p>&#13;
&#13;
<p>Now compare the serial collector to G1 GC. If we eliminate&#13;
the pause time when running with G1 GC, the application takes 404 seconds&#13;
for its calculation—but we know from the other examples that&#13;
it should take only 355 seconds. What accounts for the other 49 seconds?</p>&#13;
&#13;
<p>The calculation thread can utilize all available CPU cycles. At the same time,&#13;
background G1 GC threads need CPU&#13;
cycles for their work. Because there isn’t enough CPU to satisfy both,&#13;
they end up sharing the CPU: the calculation thread will run some of the time,&#13;
and a background G1 GC thread will run some of the time. The net effect&#13;
is the calculation thread cannot run for 49 seconds because a “background”&#13;
G1 GC thread is occupying the CPU.</p>&#13;
&#13;
<p>That’s what I mean when I say that when you choose G1 GC,&#13;
sufficient CPU is needed for its background threads to run. With a long-running&#13;
application thread taking the only available CPU, G1 GC isn’t a good choice.&#13;
But what about something different, like a microservice running simple&#13;
REST requests on the constrained hardware? <a data-type="xref" href="#TableHardwareInteractive">Table 5-3</a>&#13;
shows the response time for a web server that is handling roughly 11 requests&#13;
per second on its single CPU, which takes roughly 50% of the available&#13;
CPU cycles.</p>&#13;
<table id="TableHardwareInteractive">&#13;
<caption><span class="label">Table 5-3. </span>Response times for a single CPU with different GC algorithms</caption>&#13;
<thead>&#13;
<tr>&#13;
<th>GC algorithm</th>&#13;
<th>Average response time</th>&#13;
<th>90th% response time</th>&#13;
<th>99th% response time</th>&#13;
<th>CPU utilization</th>&#13;
</tr>&#13;
</thead>&#13;
<tbody>&#13;
<tr>&#13;
<td><p>Serial</p></td>&#13;
<td><p>0.10 second</p></td>&#13;
<td><p>0.18 second</p></td>&#13;
<td><p>0.69 second</p></td>&#13;
<td><p>53%</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td><p>Throughput</p></td>&#13;
<td><p>0.16 second</p></td>&#13;
<td><p>0.18 second</p></td>&#13;
<td><p>1.40 seconds</p></td>&#13;
<td><p>49%</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td><p>G1 GC</p></td>&#13;
<td><p>0.13 second</p></td>&#13;
<td><p>0.28 second</p></td>&#13;
<td><p>0.40 second</p></td>&#13;
<td><p>48%</p></td>&#13;
</tr>&#13;
</tbody>&#13;
</table>&#13;
&#13;
<p>The default (serial) algorithm&#13;
still has the best average time, by 30%. Again, that’s because the collections&#13;
of the young generation by the serial collector are generally faster than those of&#13;
the other algorithms, so an average request is delayed less by the serial&#13;
collector.</p>&#13;
&#13;
<p>Some unlucky requests will get interrupted by a full GC of the serial collector.&#13;
In this experiment, the average time for a full GC by the serial collector took&#13;
592 milliseconds, and some took as long as 730 milliseconds. The result is that&#13;
1% of the requests took almost 700 milliseconds.</p>&#13;
&#13;
<p>That’s still better than the throughput collector can do.&#13;
The full GCs of the throughput collector averaged 1,192&#13;
milliseconds with a 1,510-millisecond maximum.&#13;
Hence the 99th% response time of the throughput collector is twice that of&#13;
the serial collector. And the average time is skewed by those outliers as well.</p>&#13;
&#13;
<p>G1 GC sits somewhere in the middle. In terms of average response time, it is&#13;
worse than the serial collector, because the simpler&#13;
serial collector algorithm is faster. In this case, that applies primarily to&#13;
the minor GCs, which took on average 86 milliseconds for the serial collector&#13;
but required 141 milliseconds for G1 GC. So an average request will get delayed&#13;
longer in the G1 GC case.</p>&#13;
&#13;
<p>Still, G1 GC has a 99th% response time that is significantly less than that&#13;
of the serial collector. In this example, G1 GC was able&#13;
to avoid full GCs, so it had none of the more than 500-millisecond delays of the serial&#13;
collector.</p>&#13;
&#13;
<p>There’s a choice of what to optimize here: if average response time is&#13;
the most important goal, the (default) serial collector is the better&#13;
choice. If you want to optimize for the 99th% response time, G1 GC&#13;
wins. It’s a judgment call, but to me, the 30 ms&#13;
difference in the average time is not as important as the 300 ms difference&#13;
in the 99th% time—so in this case G1 GC makes sense over the platform’s&#13;
default collector.</p>&#13;
&#13;
<p>This example is GC intensive; in particular, the non-concurrent&#13;
collectors each have to perform a significant amount of full GC operations.&#13;
If we tweak the test such that all objects can be collected without requiring&#13;
a full GC, the serial algorithm can match G1 GC, as&#13;
<a data-type="xref" href="#TableHardwareInteractiveNoFull">Table 5-4</a> shows.</p>&#13;
<table id="TableHardwareInteractiveNoFull">&#13;
<caption><span class="label">Table 5-4. </span>Response times for a single CPU with different GC algorithms (no full GCs)</caption>&#13;
<thead>&#13;
<tr>&#13;
<th>GC algorithm</th>&#13;
<th>Average response time</th>&#13;
<th>90th% response time</th>&#13;
<th>99th% response time</th>&#13;
<th>CPU utilization</th>&#13;
</tr>&#13;
</thead>&#13;
<tbody>&#13;
<tr>&#13;
<td><p>Serial</p></td>&#13;
<td><p>0.05 second</p></td>&#13;
<td><p>0.08 second</p></td>&#13;
<td><p>0.11 second</p></td>&#13;
<td><p>53%</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td><p>Throughput</p></td>&#13;
<td><p>0.08 second</p></td>&#13;
<td><p>0.09 second</p></td>&#13;
<td><p>0.13 second</p></td>&#13;
<td><p>49%</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td><p>G1 GC</p></td>&#13;
<td><p>0.05 second</p></td>&#13;
<td><p>0.08 second</p></td>&#13;
<td><p>0.11 second</p></td>&#13;
<td><p>52%</p></td>&#13;
</tr>&#13;
</tbody>&#13;
</table>&#13;
&#13;
<p>Because there are no full GCs, the advantage of the serial collector&#13;
to G1 GC is eliminated.&#13;
When there is little GC activity, the numbers are all in the same range,&#13;
and all the collectors perform about the same.&#13;
On the other hand, having no full GCs is pretty unlikely, and that’s the case where the serial collector will do best.&#13;
Given sufficient CPU cycles, G1 GC will generally be better even where the&#13;
serial collector is the default.</p>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Single hyper-threaded CPU hardware" data-type="sect4"><div class="sect4" id="idm45775554843096">&#13;
<h4>Single hyper-threaded CPU hardware</h4>&#13;
&#13;
<p><a data-primary="hyper-threaded CPU hardware" data-type="indexterm" id="idm45775554841688"/><a data-primary="serial garbage collector" data-secondary="single hyper-threaded CPU hardware" data-type="indexterm" id="idm45775554840920"/>What about a single-core machine or Docker container where the CPU&#13;
is hyper-threaded (and hence appears to&#13;
the JVM as a two-CPU machine)? In that case, the JVM will not use the serial&#13;
collector by default—it thinks there are two CPUs, so it will default to the&#13;
throughput collector in JDK 8 and G1 GC in JDK 11.&#13;
But it turns out that the serial collector is often&#13;
advantageous on this hardware as well. <a data-type="xref" href="#TableGC1SerialHyperThread">Table 5-5</a> shows&#13;
what happens when we run the previous batch experiment on a single&#13;
hyper-threaded CPU.</p>&#13;
<table id="TableGC1SerialHyperThread">&#13;
<caption><span class="label">Table 5-5. </span>Processing time on a single hyper-threaded CPU for different GC algorithms</caption>&#13;
<thead>&#13;
<tr>&#13;
<th>GC algorithm</th>&#13;
<th>Elapsed time</th>&#13;
<th>Time paused for GC</th>&#13;
</tr>&#13;
</thead>&#13;
<tbody>&#13;
<tr>&#13;
<td><p>Serial</p></td>&#13;
<td><p>432 seconds</p></td>&#13;
<td><p>82 seconds</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td><p>Throughput</p></td>&#13;
<td><p>478 seconds</p></td>&#13;
<td><p>117 seconds</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td><p>G1 GC</p></td>&#13;
<td><p>476 seconds</p></td>&#13;
<td><p>72 seconds</p></td>&#13;
</tr>&#13;
</tbody>&#13;
</table>&#13;
&#13;
<p>The serial collector won’t run multiple threads, so its times are essentially&#13;
unchanged from our previous test. The other algorithms have improved, but&#13;
not by as much as we might hope—the throughput collector will run two&#13;
threads, but instead of cutting the pause time in half, the pause time&#13;
has been reduced by&#13;
about 20%. Similarly, G1 GC still cannot get enough&#13;
CPU cycles for its background threads.</p>&#13;
&#13;
<p>So at least in this case—a long-running batch job with frequent&#13;
garbage collection—the default choice by the JVM will be incorrect, and&#13;
the application will be better off using the serial collector despite the&#13;
presence of “two” CPUs. If there were two actual CPUs (i.e., two cores),&#13;
things would be different. The throughput collector&#13;
would take only 72 seconds for its operations, which is less than the time required&#13;
by the serial collector. At that point, the usefulness of the serial&#13;
collector wanes, so we’ll drop it from future examples.</p>&#13;
&#13;
<p>One other point about the serial collector: an application with a very&#13;
small heap (say, 100 MB) may still perform better with the serial collector&#13;
regardless of the number of cores that are available.<a data-startref="ix_ch05-asciidoc10" data-type="indexterm" id="idm45775554825672"/><a data-startref="ix_ch05-asciidoc9" data-type="indexterm" id="idm45775554824968"/></p>&#13;
</div></section>&#13;
&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="When to use the throughput collector" data-type="sect3"><div class="sect3" id="idm45775554902088">&#13;
<h3>When to use the throughput collector</h3>&#13;
&#13;
<p><a data-primary="garbage collection algorithms" data-secondary="throughput collector" data-type="indexterm" id="ix_ch05-asciidoc11"/><a data-primary="throughput garbage collector" data-secondary="when to use" data-type="indexterm" id="ix_ch05-asciidoc12"/>When a machine has multiple CPUs available, more-complex&#13;
interactions can occur between GC algorithms, but at a basic level, the trade-offs&#13;
between G1 GC and the throughput collector are the same as we’ve just&#13;
seen.  For example,&#13;
<a data-type="xref" href="#TableGC1Batch">Table 5-6</a> shows how our sample application works when running&#13;
either two or four application threads on a machine with four cores (where&#13;
the cores are not hyper-threaded).</p>&#13;
<table id="TableGC1Batch">&#13;
<caption><span class="label">Table 5-6. </span>Batch processing time with different GC algorithms</caption>&#13;
<thead>&#13;
<tr>&#13;
<th>Application threads</th>&#13;
<th>G1 GC</th>&#13;
<th>Throughput</th>&#13;
</tr>&#13;
</thead>&#13;
<tbody>&#13;
<tr>&#13;
<td><p>Two</p></td>&#13;
<td><p>410 seconds (60.8%)</p></td>&#13;
<td><p>446 seconds (59.7%)</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td><p>Four</p></td>&#13;
<td><p>513 seconds (99.5%)</p></td>&#13;
<td><p>536 seconds (99.5%)</p></td>&#13;
</tr>&#13;
</tbody>&#13;
</table>&#13;
&#13;
<p>The times in this table are the number of seconds required to run the test,&#13;
and&#13;
the CPU utilization of the machine is shown in parentheses. When there are&#13;
two application threads, G1 GC is significantly faster than the throughput&#13;
collector. The main reason is that the throughput collector spent 35&#13;
seconds paused for full GCs. G1 GC was able to avoid those collections, at&#13;
the (relatively slight) increase in CPU time.</p>&#13;
&#13;
<p>Even when there are four application threads, G1 still wins in this example.&#13;
Here, the throughput collector paused the application threads for a total&#13;
of 176 seconds. G1 GC paused the application threads for only 88 seconds.&#13;
The G1 GC background threads did need to compete with the application&#13;
threads for CPU cycles, which took about 65 seconds away from the application&#13;
threads. That still meant G1 GC was 23 seconds faster.</p>&#13;
&#13;
<p>When the elapsed time of an application is key, the throughput collector will&#13;
be advantageous when it spends less time pausing the application threads&#13;
than G1 GC does. That happens when one or more of these things occur:</p>&#13;
&#13;
<ul>&#13;
<li>&#13;
<p>There are no (or few) full GCs. Full GC pauses can easily dominate the pause times of an application, but if they don’t occur in the first place, the throughput collector is no longer at a disadvantage.</p>&#13;
</li>&#13;
<li>&#13;
<p>The old generation is generally full, causing the background G1 GC threads to work more.</p>&#13;
</li>&#13;
<li>&#13;
<p>The G1 GC threads are starved for CPU.</p>&#13;
</li>&#13;
</ul>&#13;
&#13;
<p>In the next chapter, which details how the various algorithms&#13;
work, the reasons behind these points will be clearer (as well as ways to&#13;
tune the collectors around them). For now, we’ll look at a few examples that&#13;
prove the point.</p>&#13;
&#13;
<p>First, let’s look at the data in <a data-type="xref" href="#TableG1GCBatchFull">Table 5-7</a>. This test is the&#13;
same code we used before for batch jobs with long calculations, though it has a few&#13;
modifications: multiple application threads are doing calculations&#13;
(two, in this case), the old generation is seeded with objects to keep it 65%&#13;
full, and almost all objects can be collected directly from&#13;
the young generation. This test is run on a system with four CPUs&#13;
(not hyper-threaded) so that there is sufficient CPU for the G1 GC background&#13;
threads to run.</p>&#13;
<table id="TableG1GCBatchFull">&#13;
<caption><span class="label">Table 5-7. </span>Batch processing with long-lived objects</caption>&#13;
<thead>&#13;
<tr>&#13;
<th>Metric</th>&#13;
<th>G1 GC</th>&#13;
<th>Throughput</th>&#13;
</tr>&#13;
</thead>&#13;
<tbody>&#13;
<tr>&#13;
<td><p>Elapsed time</p></td>&#13;
<td><p>212 seconds</p></td>&#13;
<td><p>193 seconds</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td><p>CPU usage</p></td>&#13;
<td><p>67%</p></td>&#13;
<td><p>51%</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td><p>Young GC pauses</p></td>&#13;
<td><p>30 seconds</p></td>&#13;
<td><p>13.5 seconds</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td><p>Full  GC pauses</p></td>&#13;
<td><p>0 seconds</p></td>&#13;
<td><p>1.5 seconds</p></td>&#13;
</tr>&#13;
</tbody>&#13;
</table>&#13;
&#13;
<p>Because so few objects are promoted to the old generation, the&#13;
throughput collector paused the application threads&#13;
for only 15 seconds, and only 1.5 seconds of that was to collect the&#13;
old generation.</p>&#13;
&#13;
<p>Although the old generation doesn’t get many new objects promoted into it,&#13;
the test seeds the old generation such that the G1 GC threads will scan it&#13;
for garbage.&#13;
This makes more work for the background GC threads, and it causes G1 GC to&#13;
perform more work collecting the young generation in an attempt to compensate&#13;
for the fuller old generation. The end result is that G1 GC paused the&#13;
application for 30 seconds during the two-thread test—more than the&#13;
throughput collector did.</p>&#13;
&#13;
<p>Another example: when there isn’t sufficient CPU for the G1 GC background thread&#13;
to run, the throughput collector will perform better, as <a data-type="xref" href="#TableG1BatchCPU">Table 5-8</a>&#13;
shows.</p>&#13;
<table id="TableG1BatchCPU">&#13;
<caption><span class="label">Table 5-8. </span>Batch processing with busy CPUs</caption>&#13;
<thead>&#13;
<tr>&#13;
<th>Metric</th>&#13;
<th>G1 GC</th>&#13;
<th>Throughput</th>&#13;
</tr>&#13;
</thead>&#13;
<tbody>&#13;
<tr>&#13;
<td><p>Elapsed time</p></td>&#13;
<td><p>287 seconds</p></td>&#13;
<td><p>267 seconds</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td><p>CPU usage</p></td>&#13;
<td><p>99%</p></td>&#13;
<td><p>99%</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td><p>Young GC pauses</p></td>&#13;
<td><p>80 seconds</p></td>&#13;
<td><p>63 seconds</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td><p>Full  GC pauses</p></td>&#13;
<td><p>0 seconds</p></td>&#13;
<td><p>37 seconds</p></td>&#13;
</tr>&#13;
</tbody>&#13;
</table>&#13;
&#13;
<p class="pagebreak-before">This is really no&#13;
different than the case with a single CPU: the competition for CPU&#13;
cycles between the G1 GC background threads and the application threads means&#13;
that the application threads were effectively paused even when GC pauses&#13;
weren’t happening.</p>&#13;
&#13;
<p>If we’re more interested in interactive processing and response times,&#13;
the throughput collector has a harder time beating G1 GC. If your server is&#13;
short of CPU cycles such that the G1 GC and application threads compete&#13;
for CPU, then G1 GC will yield worse response times (similar to the cases we’ve&#13;
already seen). If the server is tuned such that there are no full GCs,&#13;
then G1 GC and the throughput collector will generally turn out similar results.&#13;
But the more full GCs that the throughput collector has, the better the G1 GC&#13;
average, 90th%, and 99th% response times will be.</p>&#13;
<aside data-type="sidebar" epub:type="sidebar"><div class="sidebar" id="idm45775554772936">&#13;
<h5>Average CPU Usage and GC</h5>&#13;
<p><a data-primary="CPU usage" data-secondary="GC and" data-type="indexterm" id="ix_ch05-asciidoc13"/><a data-primary="garbage collection (GC)" data-secondary="average CPU usage and" data-type="indexterm" id="ix_ch05-asciidoc14"/>Looking at only the average CPU during a test&#13;
misses the interesting picture of what happens during GC cycles. The&#13;
throughput collector will (by default) consume 100% of the CPU available on&#13;
the machine while it runs, so&#13;
a more accurate representation of the CPU usage during the test with two&#13;
application threads is shown&#13;
in <a data-type="xref" href="#ChartGCCPU1">Figure 5-2</a>.</p>&#13;
&#13;
<p>Most of the time, only the application threads are running, consuming 50% of&#13;
the total CPU. When GC kicks in, 100% of the CPU is consumed. Hence, the actual&#13;
CPU usage resembles the sawtooth pattern in the graph, even though&#13;
the average during the test is reported as the value of the straight&#13;
dashed line.</p>&#13;
&#13;
<figure><div class="figure" id="ChartGCCPU1">&#13;
<img alt="Throughput GC and CPU Usage" src="assets/jp2e_0502.png"/>&#13;
<h6><span class="label">Figure 5-2. </span>Actual versus average CPU usage (throughput)</h6>&#13;
</div></figure>&#13;
&#13;
<p>The effect is different in a concurrent collector, when&#13;
background threads are running concurrently with the application threads.&#13;
In that case, a graph of the CPU looks like <a data-type="xref" href="#ChartGCCPU2">Figure 5-3</a>.</p>&#13;
&#13;
<figure><div class="figure" id="ChartGCCPU2">&#13;
<img alt="G1 GC and CPU Usage" src="assets/jp2e_0503.png"/>&#13;
<h6><span class="label">Figure 5-3. </span>Actual versus average CPU usage (G1 GC)</h6>&#13;
</div></figure>&#13;
&#13;
<p>The application thread starts by using 50% of the total CPU. Eventually, it&#13;
has created enough garbage for a G1 GC background thread to kick in; that&#13;
thread also consumes an entire CPU, bringing the total up to 75%. When that&#13;
thread finishes, CPU usage drops to 50%, and so on. Note that there are no&#13;
100% peak-CPU periods, which is a little bit of a simplification: there will&#13;
be very short spikes to 100% CPU usage during the G1 GC young generation&#13;
collections, but those are short enough that we can ignore them for this&#13;
discussion. (Those really short spikes occur for the throughput collector&#13;
as well.)</p>&#13;
&#13;
<p>Multiple background threads can exist in a concurrent collector, but the&#13;
effect is similar: when those background threads run, they will consume CPU and drive&#13;
up the long-term CPU average.</p>&#13;
&#13;
<p>This can be important when you have a monitoring system triggered by&#13;
CPU usage rules: you want to make sure CPU alerts are not triggered by&#13;
the 100% CPU usage spikes in a full&#13;
GC or the much longer (but lower) spikes from background concurrent processing&#13;
threads. These spikes are normal occurrences for Java&#13;
programs.<a data-startref="ix_ch05-asciidoc14" data-type="indexterm" id="idm45775554759160"/><a data-startref="ix_ch05-asciidoc13" data-type="indexterm" id="idm45775554758456"/></p>&#13;
</div></aside>&#13;
<div data-type="tip"><h1>Quick Summary</h1>&#13;
<ul>&#13;
<li>&#13;
<p>G1 GC is currently the better algorithm to choose for a majority of applications.</p>&#13;
</li>&#13;
<li>&#13;
<p>The serial collector makes sense when running CPU-bound applications on a machine with a single CPU, even if that single CPU is hyper-threaded. G1 GC will still be better on such hardware for jobs that are not CPU-bound.</p>&#13;
</li>&#13;
<li>&#13;
<p>The throughput collector makes sense on multi-CPU machines running jobs that are CPU bound. Even for jobs that are not CPU bound, the throughput collector can be the better choice if it does relatively few full GCs or if the old generation is generally<a data-startref="ix_ch05-asciidoc12" data-type="indexterm" id="idm45775554753640"/><a data-startref="ix_ch05-asciidoc11" data-type="indexterm" id="idm45775554752936"/> full<a data-startref="ix_ch05-asciidoc8" data-type="indexterm" id="idm45775554752136"/><a data-startref="ix_ch05-asciidoc7" data-type="indexterm" id="idm45775554751432"/>.<a data-startref="ix_ch05-asciidoc2" data-type="indexterm" id="idm45775554750632"/></p>&#13;
</li>&#13;
</ul>&#13;
</div>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Basic GC Tuning" data-type="sect1"><div class="sect1" id="idm45775555144824">&#13;
<h1>Basic GC Tuning</h1>&#13;
&#13;
<p><a data-primary="garbage collection (GC)" data-secondary="basic tuning" data-type="indexterm" id="ix_ch05-asciidoc15"/><a data-primary="tuning (garbage collection algorithms)" data-type="indexterm" id="ix_ch05-asciidoc16"/><a data-primary="tuning (garbage collection algorithms)" data-secondary="garbage collection" data-type="indexterm" id="ix_ch05-asciidoc17"/>Although GC algorithms differ in the way they process the heap, they share&#13;
basic configuration parameters. In many cases, these basic configurations&#13;
are all that is needed to run an application.</p>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Sizing the Heap" data-type="sect2"><div class="sect2" id="GCHeapSize">&#13;
<h2>Sizing the Heap</h2>&#13;
&#13;
<p><a data-primary="heap" data-secondary="sizing for garbage collection" data-type="indexterm" id="ix_ch05-asciidoc18"/><a data-primary="sizing the heap" data-type="indexterm" id="ix_ch05-asciidoc19"/><a data-primary="tuning (garbage collection algorithms)" data-secondary="sizing the heap" data-type="indexterm" id="ix_ch05-asciidoc20"/>The first basic tuning for GC is the size of the application’s heap.&#13;
Advanced tunings affect the size of the heap’s&#13;
generations; as a first step, this section will discuss setting the&#13;
overall heap size.</p>&#13;
&#13;
<p>Like most performance issues, choosing a heap size is a matter of balance.&#13;
If the heap is too small, the program will spend too much time performing&#13;
GC and not enough time performing application logic. But simply specifying&#13;
a very large heap isn’t necessarily the answer either. The time spent in&#13;
GC pauses is dependent on the size of the heap, so as the&#13;
size of the heap increases, the duration of those pauses also increases.&#13;
The pauses will occur less frequently, but their duration will make the overall performance&#13;
lag.</p>&#13;
&#13;
<p>A second danger arises when very large heaps are used. Computer operating&#13;
systems use virtual memory to manage the physical memory of the machine.&#13;
A machine may have 8 GB of physical RAM, but the OS will make it appear&#13;
as if much more memory is available. The amount of virtual memory&#13;
is subject to the OS configuration, but&#13;
say the OS makes it look like there is 16 GB of memory. <a data-primary="paging" data-type="indexterm" id="idm45775554736760"/><a data-primary="swapping" data-type="indexterm" id="idm45775554736056"/>The OS manages that&#13;
by a process called <em>swapping</em> (or <em>paging</em>, though there is a technical difference&#13;
between those two terms that isn’t important for this discussion).&#13;
You can load programs that use up to 16 GB of memory, and the OS will copy&#13;
inactive portions of those programs to disk. When those memory areas are&#13;
needed, the OS will copy them from disk to RAM (usually, it will first need&#13;
to copy something from RAM to disk to make room).</p>&#13;
&#13;
<p>This process works well for a system running lots of applications,&#13;
because most of the applications are not active at the same time. It does not&#13;
work so well for Java applications. If a Java program with a 12 GB heap is&#13;
run on this system, the OS can handle it by keeping 8 GB of the heap in RAM and 4 GB on disk&#13;
(that simplifies the situation a little, since other programs will&#13;
use part of RAM). The JVM won’t know about this; the swapping is transparently&#13;
handled by the OS. Hence, the JVM will happily fill up all&#13;
12 GB of heap it has been told to use. This causes a severe performance penalty&#13;
as the OS swaps data from disk to RAM (which is an expensive operation&#13;
to begin with).</p>&#13;
&#13;
<p>Worse, the one time this swapping is guaranteed to occur is&#13;
during a full GC, when the JVM must access the entire heap. If the system is&#13;
swapping during a full GC, pauses will be an order of magnitude longer than&#13;
they would otherwise be. Similarly, when you use G1 GC and&#13;
the background thread sweeps through the heap, it will likely fall behind&#13;
because of the long waits for data to be copied from disk to main memory—resulting in an expensive concurrent mode failure.</p>&#13;
&#13;
<p>Hence, the first rule in sizing a heap is never to specify a heap that is&#13;
larger than the amount of physical memory on the machine—and if&#13;
multiple JVMs are running, that applies to the sum of all their heaps. You&#13;
also need to leave some room for the native memory of the JVM, as well&#13;
as some memory for other applications: typically, at least 1 GB of space for common OS profiles.</p>&#13;
&#13;
<p><a data-primary="-Xms" data-type="indexterm" id="idm45775554730904"/><a data-primary="-Xmx" data-type="indexterm" id="idm45775554730200"/>The size of the heap is controlled by two values: an initial value&#13;
(specified with&#13;
<span class="keep-together"><code>-Xms</code><em><code>N</code></em>)</span>&#13;
and a maximum value&#13;
<span class="keep-together">(<code>-Xmx</code><em><code>N</code></em>).</span>&#13;
The defaults vary depending on the operating system, the amount of system RAM,&#13;
and the JVM in use. The defaults can be affected by other flags on the&#13;
command line as well; heap sizing is one of the JVM’s core ergonomic tunings.</p>&#13;
&#13;
<p>The goal of the JVM is to find a “reasonable” default initial value&#13;
for the heap based on the system resources available to it, and to grow the&#13;
heap up to a “reasonable” maximum if (and only if) the application needs&#13;
more memory (based on how much time it spends performing GC). Absent some&#13;
of the advanced tuning flags and details discussed later in this and&#13;
the next chapters,&#13;
the default&#13;
values for the initial and maximum sizes are given in <a data-type="xref" href="#TableGCHeap">Table 5-9</a>. The JVM will round these values down slightly for alignment purposes; the GC logs that print the sizes will show that the values are not exactly equal to the numbers in this table.</p>&#13;
<table class="less_space pagebreak-before" id="TableGCHeap">&#13;
<caption><span class="label">Table 5-9. </span>Default heap sizes</caption>&#13;
<thead>&#13;
<tr>&#13;
<th>Operating system and JVM</th>&#13;
<th>Initial heap (<code>Xms</code>)</th>&#13;
<th>Maximum heap (<code>Xmx</code>)</th>&#13;
</tr>&#13;
</thead>&#13;
<tbody>&#13;
<tr>&#13;
<td><p>Linux</p></td>&#13;
<td><p>Min (512 MB, 1/64 of physical memory)</p></td>&#13;
<td><p>Min (32 GB, 1/4 of physical memory)</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td><p>macOS</p></td>&#13;
<td><p>64 MB</p></td>&#13;
<td><p>Min (1 GB, 1/4 of physical memory)</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td><p>Windows 32-bit client JVMs</p></td>&#13;
<td><p>16 MB</p></td>&#13;
<td><p>256 MB</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td><p>Windows 64-bit server JVMs</p></td>&#13;
<td><p>64 MB</p></td>&#13;
<td><p>Min (1 GB, 1/4 of physical memory)</p></td>&#13;
</tr>&#13;
</tbody>&#13;
</table>&#13;
&#13;
<p>On a machine with less than 192 MB of physical memory, the maximum heap&#13;
size will be half of the physical memory (96 MB or less).</p>&#13;
&#13;
<p><a data-primary="Docker container" data-type="indexterm" id="idm45775554709688"/>Note that the values in <a data-type="xref" href="#TableGCHeap">Table 5-9</a> are one of those tunings that will&#13;
be incorrect for Docker containers in versions of JDK 8 prior to update 192&#13;
that specify a memory limit: the&#13;
JVM will use the total amount of memory on the machine to calculate the default&#13;
sizes. In later JDK 8 versions and JDK 11, the JVM will use the memory limit&#13;
of the container.</p>&#13;
&#13;
<p>Having an initial and maximum size for the heap allows&#13;
the JVM to tune its behavior depending on the workload. If the JVM sees that&#13;
it is doing too much GC with the initial heap size, it will continually&#13;
increase the heap until the JVM is doing the “correct” amount of GC,&#13;
or until the heap hits its maximum size.</p>&#13;
&#13;
<p>For applications that don’t need a large heap, that means a heap size&#13;
doesn’t need to be set at all.&#13;
Instead, you specify the performance goals for the GC algorithm: the pause&#13;
times you are willing to tolerate, the percentage of time you want to&#13;
spend in GC, and so on. The details will depend on the GC algorithm&#13;
used and are discussed in the next chapter (though even then, the defaults&#13;
are chosen such that for a wide range of applications, those values needn’t&#13;
be tuned either).</p>&#13;
&#13;
<p>In a world where JVMs run in isolated containers, you will usually need to&#13;
specify a maximum heap. On a virtual machine running primarily a single JVM,&#13;
the default initial heap will be only one-quarter of the memory assigned to the virtual&#13;
machine. Similarly, in a JDK 11 Docker container with a memory limit, you&#13;
typically want the heap to consume most of that memory (leaving headroom&#13;
as mentioned earlier). The defaults here are better tailored to systems running&#13;
a mix of applications rather than containers dedicated to a specific JVM.</p>&#13;
&#13;
<p>No hard-and-fast rule determines the size for the maximum heap value (other&#13;
than not specifying a size larger than the machine can support). A good&#13;
rule of thumb is to size the heap so that it is 30% occupied after a full&#13;
GC. To calculate this, run the application until it has reached a&#13;
steady-state configuration: a point at which it has loaded anything it caches,&#13;
has created a maximum number of client connections, and so on. Then connect&#13;
to the application with&#13;
<span class="keep-together"><code>jconsole</code></span>,&#13;
force a full GC, and observe how much memory is used when the full GC completes. (Alternately,&#13;
for throughput GC, you can consult the GC log if it is available.) If you take&#13;
that approach, make sure to size your container (if applicable) to have&#13;
an additional 0.5–1 GB of memory for nonheap needs of the JVM.</p>&#13;
&#13;
<p>Be aware that automatic sizing of the heap occurs even if you explicitly&#13;
set the maximum size: the heap will start at its default initial size, and the JVM will grow the&#13;
heap in order to meet the performance goals of the GC algorithm.&#13;
There isn’t necessarily a memory penalty for specifying a larger heap than is&#13;
needed: it will grow only enough to meet the GC performance goals.</p>&#13;
&#13;
<p>On the other hand, if you know exactly what size heap the application needs,&#13;
you may as well set both the initial and maximum values of the heap to that&#13;
value (e.g.,&#13;
<span class="keep-together"><code>-Xms4096m</code></span>&#13;
<span class="keep-together"><code>-Xmx4096m</code>).</span>&#13;
That makes GC slightly more efficient,&#13;
because it never needs to figure out whether the heap should be resized.</p>&#13;
<div data-type="tip"><h1>Quick Summary</h1>&#13;
<ul>&#13;
<li>&#13;
<p>The JVM will attempt to find a reasonable minimum and maximum heap size based on the machine it is running on.</p>&#13;
</li>&#13;
<li>&#13;
<p>Unless the application needs a larger heap than the default, consider tuning&#13;
the performance goals of a GC algorithm (given in the next chapter) rather than fine-tuning the heap size.<a data-startref="ix_ch05-asciidoc20" data-type="indexterm" id="idm45775554696520"/><a data-startref="ix_ch05-asciidoc19" data-type="indexterm" id="idm45775554695816"/><a data-startref="ix_ch05-asciidoc18" data-type="indexterm" id="idm45775554695144"/></p>&#13;
</li>&#13;
</ul>&#13;
</div>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Sizing the Generations" data-type="sect2"><div class="sect2" id="GCGenSizing">&#13;
<h2>Sizing the Generations</h2>&#13;
&#13;
<p><a data-primary="generational garbage collectors" data-secondary="sizing the generations" data-type="indexterm" id="ix_ch05-asciidoc21"/><a data-primary="tuning (garbage collection algorithms)" data-secondary="sizing the generations" data-type="indexterm" id="ix_ch05-asciidoc22"/>Once the heap size has been determined, the JVM must decide how much of the&#13;
heap to allocate to the young generation and how much to allocate to the old&#13;
generation. The JVM usually does this automatically and usually does a good&#13;
job in determining the optimal ratio between young and old generations. In&#13;
some cases, you might hand-tune these values, though mostly this section&#13;
is here to provide an understanding of how garbage collection works.</p>&#13;
&#13;
<p>The performance implication of different generation sizes should be clear:&#13;
if there is a relatively larger young generation, young GC pause times will&#13;
increase, but the young generation will be collected less&#13;
often, and fewer objects will be promoted into the old generation. But&#13;
on the other hand, because the old generation is relatively smaller, it&#13;
will fill up more frequently and do more full GCs. Striking a balance is key.</p>&#13;
&#13;
<p>Different GC algorithms attempt to strike this balance in different ways.&#13;
However, all GC&#13;
algorithms use the same set of flags to set the sizes of the generations;&#13;
this section covers those common flags.</p>&#13;
&#13;
<p>The command-line flags to tune the generation sizes all adjust the size of&#13;
the young generation; the old generation gets everything that is left over. A variety of flags&#13;
can be used to size the young generation:</p>&#13;
<dl>&#13;
<dt><span class="keep-together"><code>-XX:NewRatio=</code><em><code>N</code></em></span></dt>&#13;
<dd>&#13;
<p><a data-primary="-XX:NewRatio" data-type="indexterm" id="idm45775554684904"/>Set the ratio of the young generation to the old generation.</p>&#13;
</dd>&#13;
<dt><span class="keep-together"><code>-XX:NewSize=</code><em><code>N</code></em></span></dt>&#13;
<dd>&#13;
<p><a data-primary="-XX:NewSize" data-type="indexterm" id="idm45775554681976"/>Set the initial size of the young generation.</p>&#13;
</dd>&#13;
<dt><span class="keep-together"><code>-XX:MaxNewSize=</code><em><code>N</code></em></span></dt>&#13;
<dd>&#13;
<p><a data-primary="-Xmn" data-type="indexterm" id="idm45775554678984"/><a data-primary="-XX:MaxNewSize" data-type="indexterm" id="idm45775554678280"/>Set the maximum size of the young generation.</p>&#13;
</dd>&#13;
<dt><span class="keep-together"><code>-Xmn</code><em><code>N</code></em></span></dt>&#13;
<dd>&#13;
<p>Shorthand for setting both&#13;
<span class="keep-together"><code>NewSize</code></span>&#13;
and&#13;
<span class="keep-together"><code>MaxNewSize</code></span>&#13;
to the same value.</p>&#13;
</dd>&#13;
</dl>&#13;
&#13;
<p>The young generation is first sized by the&#13;
<span class="keep-together"><code>NewRatio</code></span>,&#13;
which has a default&#13;
value of 2. Parameters that affect the sizing of heap spaces are generally&#13;
specified as ratios; the value is used in an equation to determine the&#13;
percentage of space affected. The&#13;
<span class="keep-together"><code>NewRatio</code></span>&#13;
value is used&#13;
in this formula:</p>&#13;
&#13;
<pre data-type="programlisting">Initial Young Gen Size = Initial Heap Size / (1 + NewRatio)</pre>&#13;
&#13;
<p>Plugging in the initial size of the heap and the&#13;
<span class="keep-together"><code>NewRatio</code></span>&#13;
yields the value that becomes the setting&#13;
for the young generation. By default, then, the young generation starts&#13;
out at 33% of the initial heap size.</p>&#13;
&#13;
<p>Alternately, the size of the young generation can be set explicitly by&#13;
specifying the&#13;
<span class="keep-together"><code>NewSize</code></span>&#13;
flag. If that option is set, it will take precedence&#13;
over the value calculated from the&#13;
<span class="keep-together"><code>NewRatio</code></span>.&#13;
There is no default for this flag since the default is to calculate it&#13;
from <span class="keep-together"><code>NewRatio</code></span>.</p>&#13;
&#13;
<p>As the heap expands, the young generation size will expand as well, up to&#13;
the maximum size specified by the&#13;
<span class="keep-together"><code>MaxNewSize</code></span>&#13;
flag. By default, that maximum is also set using the&#13;
<span class="keep-together"><code>NewRatio</code></span>&#13;
value, though it is based on the maximum (rather than initial) heap size.</p>&#13;
&#13;
<p>Tuning the young generation by specifying a range for its minimum and maximum&#13;
sizes ends up being fairly difficult. When a heap size is fixed&#13;
(by setting&#13;
<span class="keep-together"><code>-Xms</code></span>&#13;
equal to&#13;
<span class="keep-together"><code>-Xmx</code>),</span>&#13;
it is usually preferable to use&#13;
<span class="keep-together"><code>-Xmn</code></span>&#13;
to specify a fixed&#13;
size for the young generation as well. If an application needs a&#13;
dynamically sized heap&#13;
and requires a larger (or smaller) young generation, then focus on setting&#13;
the&#13;
<span class="keep-together"><code>NewRatio</code></span>&#13;
value.</p>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section class="less_space pagebreak-before" data-pdf-bookmark="Adaptive sizing" data-type="sect3"><div class="sect3" id="GCAdaptive">&#13;
<h3>Adaptive sizing</h3>&#13;
&#13;
<p><a data-primary="adaptive sizing" data-type="indexterm" id="ix_ch05-asciidoc23"/><a data-primary="generational garbage collectors" data-secondary="adaptive sizing" data-type="indexterm" id="ix_ch05-asciidoc24"/>The sizes of the heap, the generations, and the survivor spaces&#13;
can vary during execution as the JVM attempts to find the optimal performance&#13;
according to its policies and tunings. This is a best-effort solution, and it relies on past performance: the&#13;
assumption is that future GC cycles will look similar to the GC cycles&#13;
in the recent past. That turns out to be a reasonable assumption for many&#13;
workloads, and even if the allocation rate suddenly changes, the JVM will&#13;
readapt its sizes based on the new information.</p>&#13;
&#13;
<p>Adaptive sizing provides benefits in two important ways. First, it means&#13;
that small applications don’t need to worry about overspecifying the size&#13;
of their heap. Consider the administrative command-line programs used to&#13;
adjust the operations of things like a Java NoSQL server—those&#13;
programs are usually short-lived and use minimal memory resources.&#13;
These applications will use 64 (or 16) MB of heap even though&#13;
the default heap could grow to 1 GB. Because of adaptive sizing,&#13;
applications like that don’t need to be specifically tuned; the platform&#13;
defaults ensure that they will not use a large amount of memory.</p>&#13;
&#13;
<p>Second, it means that many applications don’t really need to worry about&#13;
tuning their heap size at all—or if they need a larger heap than the&#13;
platform default, they can just specify that larger heap and forget about&#13;
the other details. The JVM can autotune the heap and generation sizes to&#13;
use an optimal amount of memory, given the GC algorithm’s performance goals.&#13;
Adaptive sizing is what allows that autotuning to work.</p>&#13;
&#13;
<p>Still, adjusting the sizes takes a small amount&#13;
of time—which occurs for the most part during a GC pause. If you&#13;
have taken the time to finely tune GC parameters and the size&#13;
constraints of the application’s heap, adaptive sizing can be disabled.&#13;
Disabling&#13;
adaptive sizing is also useful for applications that go through markedly&#13;
different phases, if you want to optimally tune GC for one of those phases.</p>&#13;
&#13;
<p><a data-primary="-XX:+UseAdaptiveSizePolicy" data-type="indexterm" id="idm45775554651192"/>At a global level, adaptive sizing can be disabled by turning off the&#13;
<span class="keep-together"><code>-XX:-UseAdaptiveSizePolicy</code></span>&#13;
flag (which is <code>true</code> by default).&#13;
With the exception of the survivor spaces (which are examined in detail&#13;
in the next chapter), adaptive sizing is also effectively turned off if&#13;
the&#13;
minimum and maximum heap sizes are set to the same value,&#13;
and the initial and maximum sizes of the new generation are set to the&#13;
same value.</p>&#13;
&#13;
<p><a data-primary="-XX:+PrintAdaptiveSizePolicy" data-type="indexterm" id="idm45775554648456"/>To see how the JVM is resizing the spaces in an application,&#13;
set the&#13;
<code>-XX:+PrintAdaptiveSizePolicy</code>&#13;
flag. When a GC is performed, the&#13;
GC log will contain information detailing how the various generations&#13;
were resized during a collection.</p>&#13;
<div data-type="tip"><h1>Quick Summary</h1>&#13;
<ul>&#13;
<li>&#13;
<p>Within the overall heap size, the sizes of the generations are controlled by how much space is allocated to the young <span class="keep-together">generation.</span></p>&#13;
</li>&#13;
<li>&#13;
<p>The young generation will grow in tandem with the overall heap size, but it can also fluctuate as a percentage of the total heap (based on the initial and maximum size of the young generation).</p>&#13;
</li>&#13;
<li>&#13;
<p>Adaptive sizing controls how the JVM alters the ratio of young generation to old generation within the heap.</p>&#13;
</li>&#13;
<li>&#13;
<p>Adaptive sizing should generally be kept enabled, since adjusting those generation sizes is how GC algorithms attempt to meet their pause-time goals.<a data-startref="ix_ch05-asciidoc24" data-type="indexterm" id="idm45775554641032"/><a data-startref="ix_ch05-asciidoc23" data-type="indexterm" id="idm45775554640328"/></p>&#13;
</li>&#13;
<li>&#13;
<p>For finely tuned heaps, adaptive sizing can be disabled for a small performance boost.<a data-startref="ix_ch05-asciidoc22" data-type="indexterm" id="idm45775554638824"/><a data-startref="ix_ch05-asciidoc21" data-type="indexterm" id="idm45775554638120"/></p>&#13;
</li>&#13;
</ul>&#13;
</div>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Sizing Metaspace" data-type="sect2"><div class="sect2" id="GCMetaSpace">&#13;
<h2>Sizing Metaspace</h2>&#13;
&#13;
<p><a data-primary="metaspace" data-secondary="sizing" data-type="indexterm" id="ix_ch05-asciidoc25"/><a data-primary="tuning (garbage collection algorithms)" data-secondary="sizing metaspace" data-type="indexterm" id="ix_ch05-asciidoc26"/>When the JVM loads classes, it must keep track of certain metadata about those&#13;
classes. This occupies a separate heap space called the <em>metaspace</em>.&#13;
<a data-primary="permgen" data-type="indexterm" id="idm45775554632280"/>In older JVMs, this was handled by a different implementation called <em>permgen</em>.</p>&#13;
&#13;
<p>To end users, the metaspace is opaque: we know that it&#13;
holds a bunch of class-related data and that in&#13;
certain circumstances the size of that region needs to be tuned.</p>&#13;
&#13;
<p>Note that the metaspace does not hold the actual instance of the class (the&#13;
<span class="keep-together"><code>Class</code></span>&#13;
objects), or reflection objects (e.g.,&#13;
<span class="keep-together"><code>Method</code></span>&#13;
objects); those are held in the regular&#13;
heap. <a data-primary="class metadata" data-type="indexterm" id="idm45775554628264"/>Information in the metaspace is used only by the compiler and&#13;
JVM runtime, and the data it holds is referred to as <em>class metadata</em>.</p>&#13;
&#13;
<p>There isn’t a good way to calculate in advance the amount of space a particular&#13;
program needs for its metaspace.&#13;
The size will be proportional to the number of classes it uses, so&#13;
bigger applications will need bigger areas. This is another area where&#13;
changes in JDK technology have made life easier: tuning the permgen used&#13;
to be fairly common, but tuning the metaspace is fairly rare these days.&#13;
The main reason is that the default values for the size of the metaspace&#13;
are very generous. <a data-type="xref" href="#TablePermGen">Table 5-10</a> lists the default initial and maximum sizes.</p>&#13;
<table class="less_space pagebreak-before" id="TablePermGen">&#13;
<caption><span class="label">Table 5-10. </span>Default sizes of the metaspace</caption>&#13;
<thead>&#13;
<tr>&#13;
<th>JVM</th>&#13;
<th>Default initial size</th>&#13;
<th>Default maximum size</th>&#13;
</tr>&#13;
</thead>&#13;
<tbody>&#13;
<tr>&#13;
<td><p>32-bit client JVM</p></td>&#13;
<td><p>12 MB</p></td>&#13;
<td><p>Unlimited</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td><p>32-bit server JVM</p></td>&#13;
<td><p>16 MB</p></td>&#13;
<td><p>Unlimited</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td><p>64-bit JVM</p></td>&#13;
<td><p>20.75 MB</p></td>&#13;
<td><p>Unlimited</p></td>&#13;
</tr>&#13;
</tbody>&#13;
</table>&#13;
&#13;
<p>The metaspace behaves similarly to a separate instance of the regular heap.&#13;
It is sized dynamically based on&#13;
an initial size&#13;
<span class="keep-together">(<code>-XX:MetaspaceSize=</code><em><code>N</code></em>)</span>&#13;
and will increase as needed to&#13;
a maximum size&#13;
<span class="keep-together">(<code>-XX:MaxMetaspaceSize=</code><em><code>N</code></em>)</span>.</p>&#13;
<aside data-type="sidebar" epub:type="sidebar"><div class="sidebar" id="idm45775554610600">&#13;
<h5>Metaspace Too Big?</h5>&#13;
<p>Because the default size of metaspace is unlimited, an application&#13;
(particularly in a 32-bit JVM) could run out of&#13;
memory by filling up metaspace. The Native Memory Tracking (NMT) tools discussed&#13;
in <a data-type="xref" href="ch08.html#NativeMemory">Chapter 8</a> can help diagnose that case. If metaspace is growing&#13;
too big, you can set the value of&#13;
<span class="keep-together"><code>MaxMetaspaceSize</code></span>&#13;
lower—but then the application will eventually get an&#13;
<span class="keep-together"><code>OutOfMemoryError</code></span>&#13;
when the metaspace fills up. Figuring out why the class metadata is too large&#13;
is the real remedy in that case.</p>&#13;
</div></aside>&#13;
&#13;
<p>Resizing the metaspace requires a full GC, so it is an expensive operation. If there are a lot of&#13;
full GCs during the startup of a program (as it is loading classes), it is&#13;
often because permgen or metaspace is being resized, so increasing the&#13;
initial size is a good idea to improve startup in that case.&#13;
Servers, for example, typically specify an initial metaspace size&#13;
of 128 MB, 192 MB, or more.</p>&#13;
&#13;
<p>Java classes can be eligible for GC just like anything else. This is a&#13;
common occurrence in an application server, which creates new classloaders&#13;
every time an application is deployed (or redeployed). The old classloaders&#13;
are then unreferenced and eligible for GC, as are any classes that they&#13;
defined. Meanwhile, the new classes of the application will have new metadata,&#13;
and so there must be room in the metaspace for that. This often causes a&#13;
full GC because the metaspace needs to grow (or discard old metadata).</p>&#13;
&#13;
<p><a data-primary="classloader memory leaks" data-type="indexterm" id="idm45775554604120"/><a data-primary="memory leaks" data-secondary="classloader" data-type="indexterm" id="idm45775554603352"/>One reason to limit the size of the metaspace is to guard against a classloader&#13;
leak: when the application server (or other program like an IDE) continually&#13;
defines new classloaders and classes while maintaining references to the&#13;
old classloaders. This has the potential to fill up the metaspace and consume&#13;
a lot of memory on the machine. On the other hand, the actual classloader and&#13;
class objects in that case are also still in the main heap—and that heap is&#13;
likely to fill up and cause an <code>OutOfMemoryError</code> before the memory occupied by&#13;
the metaspace becomes a problem.</p>&#13;
&#13;
<p>Heap dumps (see <a data-type="xref" href="ch07.html#Memory">Chapter 7</a>) can be used to diagnose what classloaders exist,&#13;
which in turn can help determine if a classloader leak is filling up&#13;
metaspace. <a data-primary="jmap" data-type="indexterm" id="idm45775554599880"/>Otherwise,&#13;
<code>jmap</code> can be used with the argument&#13;
<span class="keep-together"><code>-clstats</code></span>&#13;
to print out information&#13;
about the <span class="keep-together">classloaders.</span></p>&#13;
<div data-type="tip"><h1>Quick Summary</h1>&#13;
<ul>&#13;
<li>&#13;
<p>The metaspace holds class metadata (not class objects) and behaves like a separate heap.</p>&#13;
</li>&#13;
<li>&#13;
<p>The initial size of this region can be based on its usage after all classes have been loaded. That will slightly speed up startup.</p>&#13;
</li>&#13;
<li>&#13;
<p>Applications that define and discard a lot of classes will see an occasional full GC when the metaspace fills up and old classes are removed. This is particularly common for a development environment.<a data-startref="ix_ch05-asciidoc26" data-type="indexterm" id="idm45775554593096"/><a data-startref="ix_ch05-asciidoc25" data-type="indexterm" id="idm45775554592392"/></p>&#13;
</li>&#13;
</ul>&#13;
</div>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Controlling Parallelism" data-type="sect2"><div class="sect2" id="GCParallelThreads">&#13;
<h2>Controlling Parallelism</h2>&#13;
&#13;
<p><a data-primary="-XX:ParallelGCThreads=N" data-type="indexterm" id="idm45775554589496"/><a data-primary="parallelism, controlling" data-type="indexterm" id="idm45775554588792"/><a data-primary="tuning (garbage collection algorithms)" data-secondary="controlling parallelism" data-type="indexterm" id="idm45775554588056"/>All GC algorithms except the serial collector use multiple threads.&#13;
The number of these threads is controlled by the&#13;
<span class="keep-together"><code>-XX:ParallelGCThreads=</code><em><code>N</code></em></span> flag. The value of this flag&#13;
affects the number of threads used for the following operations:</p>&#13;
&#13;
<ul>&#13;
<li>&#13;
<p><a data-primary="-XX:+UseParallelGC" data-type="indexterm" id="idm45775554584600"/>Collection of the young generation when using&#13;
<span class="keep-together"><code>-XX:+UseParallelGC</code></span></p>&#13;
</li>&#13;
<li>&#13;
<p>Collection of the old generation when using&#13;
<span class="keep-together"><code>-XX:+UseParallelGC</code></span></p>&#13;
</li>&#13;
<li>&#13;
<p><a data-primary="-XX:+UseG1GC" data-type="indexterm" id="idm45775554580760"/>Collection of the young generation when using&#13;
<span class="keep-together"><code>-XX:+UseG1GC</code></span></p>&#13;
</li>&#13;
<li>&#13;
<p>Stop-the-world phases of G1 GC (though not full GCs)</p>&#13;
</li>&#13;
</ul>&#13;
&#13;
<p>Because these GC operations stop all application threads from executing,&#13;
the JVM attempts to use as many CPU resources as it can in order to&#13;
minimize the pause time. By default, that means the JVM will run&#13;
one thread for each CPU on a machine, up to eight. Once&#13;
that threshold has been reached, the JVM adds a new thread for only every&#13;
1.6 CPUs. So the total number of threads (where <em><code>N</code></em> is the number&#13;
of CPUs) on a machine with more than eight CPUs is shown here:</p>&#13;
&#13;
<pre data-type="programlisting">ParallelGCThreads = 8 + ((N - 8) * 5 / 8)</pre>&#13;
&#13;
<p>Sometimes this number is too large. An application using a small heap&#13;
(say, 1 GB) on a machine with eight CPUs will be slightly more efficient with&#13;
four or six threads dividing up that heap.&#13;
On a 128-CPU machine, 83 GC threads is too many for all but the largest heaps.</p>&#13;
&#13;
<p>If you run the JVM inside a Docker container that has a CPU limit, that CPU limit&#13;
is used for this calculation.</p>&#13;
&#13;
<p>Additionally, if more than one JVM is running on the machine, it is a good idea&#13;
to limit the total number of GC threads among all JVMs. When they run, the&#13;
GC threads are quite efficient, and each will consume 100% of a single CPU&#13;
(this is why the average CPU usage for the throughput collector was higher than&#13;
expected in <span class="keep-together">previous</span> examples). In machines with eight or fewer CPUs,&#13;
GC will consume 100% of the CPU on the machine. On machines with more&#13;
CPUs and multiple JVMs, too many GC threads will still be running in parallel.</p>&#13;
&#13;
<p>Take the example of a 16-CPU machine running four JVMs; each JVM will have by&#13;
default 13 GC threads. If all four JVMs execute GC at the same time, the&#13;
machine will have 52 CPU-hungry threads contending for CPU time.&#13;
That results in a fair amount of contention; limiting&#13;
each JVM to four GC threads will be more efficient. Even though it may be unlikely&#13;
for all four JVMs to perform a GC operation at the same time, one JVM executing GC with 13&#13;
threads means that the application threads in the remaining JVMs now have&#13;
to compete for CPU resources on a machine where 13 of 16 CPUs are 100%&#13;
busy executing GC tasks. Giving each JVM four GC threads&#13;
provides a better balance in this case.</p>&#13;
&#13;
<p>Note that this flag does not set the number of background threads&#13;
used by G1 GC (though it does affect that). Details are given&#13;
in the next chapter.</p>&#13;
<div data-type="tip"><h1>Quick Summary</h1>&#13;
<ul>&#13;
<li>&#13;
<p>The basic number of threads used by all GC algorithms is based on the number of CPUs on a machine.</p>&#13;
</li>&#13;
<li>&#13;
<p>When multiple JVMs are run on a single machine, that number will be too high and must be reduced.<a data-startref="ix_ch05-asciidoc17" data-type="indexterm" id="idm45775554568296"/><a data-startref="ix_ch05-asciidoc16" data-type="indexterm" id="idm45775554567592"/><a data-startref="ix_ch05-asciidoc15" data-type="indexterm" id="idm45775554566920"/></p>&#13;
</li>&#13;
</ul>&#13;
</div>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="GC Tools" data-type="sect1"><div class="sect1" id="GCLogging">&#13;
<h1>GC Tools</h1>&#13;
&#13;
<p><a data-primary="garbage collection (GC)" data-secondary="tools" data-type="indexterm" id="ix_ch05-asciidoc27"/><a data-primary="performance tools" data-secondary="garbage collection" data-type="indexterm" id="ix_ch05-asciidoc28"/>Since GC is central to the performance of Java, many tools monitor its performance. The best way to see the effect that GC has on the performance of an application&#13;
is to become familiar with the GC log, which is a record of every GC operation during the program’s execution.</p>&#13;
&#13;
<p>The details in the GC log vary depending on the GC algorithm, but the basic&#13;
management of the log is the same for all algorithms. The log management is&#13;
not the same, however, between JDK 8 and subsequent releases: JDK 11 uses a&#13;
different set of command-line arguments to enable and manage the GC log.&#13;
We’ll discuss the  management of GC logs here,&#13;
and more details on the contents of the log are given in the&#13;
algorithm-specific tuning sections in the next chapter.</p>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Enabling GC Logging in JDK 8" data-type="sect2"><div class="sect2" id="idm45775554560312">&#13;
<h2>Enabling GC Logging in JDK 8</h2>&#13;
&#13;
<p><a data-primary="garbage collection (GC)" data-secondary="enabling GC logging in JDK 8" data-type="indexterm" id="idm45775554558904"/><a data-primary="logging" data-secondary="enabling GC logging in JDK 8" data-type="indexterm" id="idm45775554557736"/>JDK 8 provides multiple ways to enable the GC log. <a data-primary="-verbose:gc" data-type="indexterm" id="idm45775554556648"/><a data-primary="-XX:+PrintGC" data-type="indexterm" id="idm45775554555976"/>Specifying either of the flags&#13;
<span class="keep-together"><code>-verbose:gc</code></span>&#13;
or&#13;
<span class="keep-together"><code>-XX:+PrintGC</code></span>&#13;
will create a simple GC log (the flags are aliases for&#13;
each other, and by default the log is disabled). <a data-primary="-XX:+PrintGCDetails" data-type="indexterm" id="idm45775554553384"/>The&#13;
<span class="keep-together"><code>-XX:+PrintGCDetails</code></span>&#13;
flag will create a log with much more information. This flag is recommended (it is also <code>false</code>&#13;
by default); it is often too difficult to diagnose what is happening with GC using only the simple log.</p>&#13;
&#13;
<p><a data-primary="-XX:+PrintGCDateStamps" data-type="indexterm" id="idm45775554550952"/><a data-primary="-XX:+PrintGCTimeStamps" data-type="indexterm" id="idm45775554550248"/>In conjunction with the detailed log, it is recommended to include&#13;
<span class="keep-together"><code>-XX:+PrintGCTimeStamps</code></span> or <span class="keep-together"><code>-XX:+PrintGCDateStamps</code></span> so that the time between GC operations can be determined. The difference in&#13;
those two arguments is that the timestamps are relative to 0 (based on&#13;
when the JVM starts), while the date stamps are an actual date string.&#13;
That makes the date stamps ever-so-slightly less efficient as the dates are&#13;
formatted, though it is an infrequent enough operation that its effect is unlikely to be noticed.</p>&#13;
&#13;
<p><a data-primary="-Xloggc:&lt;path&gt;" data-type="indexterm" id="idm45775554547112"/>The GC log is written to standard output, though that location can (and&#13;
usually should) be changed with the&#13;
<code>-Xloggc:</code><em><code>filename</code></em> flag. Using <code>-Xloggc</code> automatically enables the simple GC log unless&#13;
<code>PrintGCDetails</code> has also been enabled.</p>&#13;
&#13;
<p>The amount of data that is kept in the GC log can be limited using log rotation; this is useful for a long-running server that might otherwise fill up its disk with logs over several months. <a data-primary="-XX:+UseGCLogFileRotation" data-type="indexterm" id="idm45775554543608"/><a data-primary="-XX:GCLogFileSize=N" data-type="indexterm" id="idm45775554542936"/><a data-primary="-XX:NumberOfGCLogFiles=N" data-type="indexterm" id="idm45775554542264"/>Logfile rotation is controlled with these flags:&#13;
<span class="keep-together"><code>-XX:+UseGCLogFileRotation</code> <code>-XX:NumberOfGCLogFiles=</code><em><code>N</code></em></span> <code>-XX:GCLogFileSize=<em>N</em></code>.&#13;
By default, <code>UseGCLogFileRotation</code> is disabled. When that flag is enabled, the default number&#13;
of files is 0 (meaning unlimited), and the default logfile size is 0&#13;
(meaning unlimited). Hence, values must be specified for all these options&#13;
in order for log rotation to work as expected. Note&#13;
that a logfile size will be rounded up to 8 KB for values less than that.</p>&#13;
&#13;
<p>Putting that all together, a useful set of flags for logging is as follows:</p>&#13;
&#13;
<pre data-code-language="java" data-type="programlisting"><code class="o">-</code><code class="nl">Xloggc:</code><code class="n">gc</code><code class="o">.</code><code class="na">log</code> <code class="o">-</code><code class="nl">XX:</code><code class="o">+</code><code class="n">PrintGCTimeStamps</code> <code class="o">-</code><code class="nl">XX:</code><code class="o">+</code><code class="n">UseGCLogFileRotation</code>&#13;
<code class="o">-</code><code class="nl">XX:</code><code class="n">NumberOfGCLogFile</code><code class="o">=</code><code class="mi">8</code> <code class="o">-</code><code class="nl">XX:</code><code class="n">GCLogFileSize</code><code class="o">=</code><code class="mi">8</code><code class="n">m</code></pre>&#13;
&#13;
<p>That will log GC events with timestamps to correlate to other logs and limit&#13;
the retained logs to 64 MB in eight files. This logging is&#13;
minimal enough that it can be enabled even on production systems.</p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Enabling GC Logging in JDK 11" data-type="sect2"><div class="sect2" id="idm45775554513240">&#13;
<h2>Enabling GC Logging in JDK 11</h2>&#13;
&#13;
<p><a data-primary="garbage collection (GC)" data-secondary="enabling GC logging in JDK 11" data-type="indexterm" id="ix_ch05-asciidoc29"/><a data-primary="logging" data-secondary="enabling GC logging in JDK 11" data-type="indexterm" id="ix_ch05-asciidoc31"/>JDK 11 and later versions use Java’s new unified logging feature. <a data-primary="-Xlog:gc*" data-type="indexterm" id="idm45775554509144"/>This means&#13;
that all logging—GC related or not—is enabled via the flag <code>-Xlog</code>. Then&#13;
you append various options to that flag that control how the logging should&#13;
be performed. In order to specify logging similar to the long example from&#13;
JDK 8, you would use this flag:</p>&#13;
&#13;
<pre data-code-language="java" data-type="programlisting"><code class="o">-</code><code class="nl">Xlog:</code><code class="n">gc</code><code class="o">*:</code><code class="n">file</code><code class="o">=</code><code class="n">gc</code><code class="o">.</code><code class="na">log</code><code class="o">:</code><code class="nl">time:</code><code class="n">filecount</code><code class="o">=</code><code class="mi">7</code><code class="o">,</code><code class="n">filesize</code><code class="o">=</code><code class="mi">8</code><code class="n">M</code></pre>&#13;
&#13;
<p>The colons divide the command into four sections.&#13;
You can run <code>java -Xlog:help:</code> to get more information on the available&#13;
options, but here’s how they map for this string.</p>&#13;
&#13;
<p>The first section (<code>gc*</code>) specifies which modules should enable logging;&#13;
we are enabling logging for all GC modules. There are options to log only a&#13;
particular section (e.g.,&#13;
<span class="keep-together"><code>gc+age</code></span> will log&#13;
information about the tenuring of an object, a topic covered in the next&#13;
chapter). Those specific modules often have limited output at the default&#13;
logging level, so you might use something like&#13;
<span class="keep-together"><code>gc*,gc+age=debug</code></span>&#13;
to log basic (info-level) messages from all <em>gc</em> modules and debug-level&#13;
messages from the&#13;
tenuring code. Typically, logging all modules at info level is fine.</p>&#13;
&#13;
<p>The second section sets the destination of the logfile.</p>&#13;
&#13;
<p>The third section (<code>time</code>) is a decorator: that decorator says to log messages&#13;
with a time-of-day stamp, the same as we specified for JDK 8. Multiple&#13;
decorators can be specified.</p>&#13;
&#13;
<p>Finally, the fourth section specifies output options; in this case, we’ve&#13;
said to rotate logs when they hit 8 MB, keeping eight logs altogether.</p>&#13;
&#13;
<p>One thing to note: log rotation is handled slightly differently between JDK 8&#13;
and JDK 11. Say that we have specified a log name of <em>gc.log</em> and that&#13;
three files should be retained. In JDK 8, the logs will be written this way:</p>&#13;
<ol>&#13;
<li>&#13;
<p>Start logging to <em>gc.log.0.current</em>.</p>&#13;
</li>&#13;
<li>&#13;
<p>When full, rename that to <em>gc.log.0</em> and start logging to <em>gc.log.1.current</em>.</p>&#13;
</li>&#13;
<li>&#13;
<p>When full, rename that to <em>gc.log.1</em> and start logging to <em>gc.log.2.current</em>.</p>&#13;
</li>&#13;
<li>&#13;
<p>When full, rename that to <em>gc.log.2</em>, remove <em>gc.log.0</em>, and start logging to a new <em>gc.log.0.current</em>.</p>&#13;
</li>&#13;
<li>&#13;
<p>Repeat this cycle.</p>&#13;
</li>&#13;
&#13;
</ol>&#13;
&#13;
<p>In JDK 11, the logs will be written this way:</p>&#13;
<ol>&#13;
<li>&#13;
<p>Start logging to <em>gc.log</em>.</p>&#13;
</li>&#13;
<li>&#13;
<p>When that is full, rename it to <em>gc.log.0</em> and start a new <em>gc.log</em>.</p>&#13;
</li>&#13;
<li>&#13;
<p>When that is full, rename it to <em>gc.log.1</em> and start a new <em>gc.log</em>.</p>&#13;
</li>&#13;
<li>&#13;
<p>When that is full, rename it to <em>gc.log.2</em> and start a new <em>gc.log</em>.</p>&#13;
</li>&#13;
<li>&#13;
<p>When that is full, rename it to <em>gc.log.0</em>, removing the old <em>gc.log.0</em>, and start a new <em>gc.log</em>.</p>&#13;
</li>&#13;
&#13;
</ol>&#13;
&#13;
<p>If you are wondering why we specified seven logs to retain in the previous&#13;
JDK 11 command, this is why: there will be eight active files in this case. Also note&#13;
in either case that the number appended to the file doesn’t mean anything about&#13;
the order in which the files were created. The numbers are reused in a cycle,&#13;
so there is some order, but the oldest logfile could be any one in the set.</p>&#13;
&#13;
<p>The <em>gc</em> log contains a lot of information specific to each collector, so we’ll&#13;
step through the details in the next chapter. Parsing the logs for aggregate information about your application is also useful: how many&#13;
pauses it had, how long they took on average and in total, and so on.</p>&#13;
&#13;
<p>Unfortunately, not a lot of good open source tools are available to parse logfiles.&#13;
As with profilers, commercial vendors have stepped&#13;
in to provide support, like the offerings from jClarity (Censum)&#13;
and <a href="https://www.gceasy.io">GCeasy</a>. The latter has a free service for basic log parsing.</p>&#13;
&#13;
<p><a data-primary="jconsole" data-type="indexterm" id="idm45775554413064"/><a data-primary="jvisualvm" data-type="indexterm" id="idm45775554412136"/>For real-time monitoring of the heap, use <code>jvisualvm</code> or <code>jconsole</code>. The Memory&#13;
panel of <code>jconsole</code> displays a real-time graph of the heap, as shown in&#13;
<a data-type="xref" href="#FigureJConsoleMemory">Figure 5-4</a>.</p>&#13;
&#13;
<figure><div class="figure" id="FigureJConsoleMemory">&#13;
<img alt="A graph of heap occupancy over GC cycles" src="assets/jp2e_0504.png"/>&#13;
<h6><span class="label">Figure 5-4. </span>Real-time heap display</h6>&#13;
</div></figure>&#13;
&#13;
<p>This particular view shows the entire heap, which is periodically&#13;
cycling between using about 100 MB and 160 MB. <code>jconsole</code> can instead&#13;
display only eden, the survivor spaces, the old generation, or the permanent generation. If I’d selected eden as the region to chart, it would have shown a similar pattern, as eden fluctuated between 0 MB and 60 MB (and, as you can guess, that means if I’d charted the old generation, it would have been essentially a flat line at 100 MB).</p>&#13;
&#13;
<p><a data-primary="jstat" data-type="indexterm" id="idm45775554405512"/>For a scriptable solution,&#13;
<span class="keep-together"><code>jstat</code></span>&#13;
is the tool of choice.&#13;
<span class="keep-together"><code>jstat</code></span>&#13;
provides nine options to print different information about the heap;&#13;
<span class="keep-together"><code>jstat -options</code></span>&#13;
will provide the full list. One useful option&#13;
is&#13;
<span class="keep-together"><code>-gcutil</code></span>,&#13;
which displays the time spent in GC as well as the <span class="keep-together">percentage</span>&#13;
of each GC area that is currently filled. Other options to&#13;
<span class="keep-together"><code>jstat</code></span>&#13;
will display&#13;
the GC sizes in terms of KB.</p>&#13;
&#13;
<p>Remember that&#13;
<span class="keep-together"><code>jstat</code></span>&#13;
takes an optional&#13;
argument—the number of milliseconds to repeat the command—so it can&#13;
monitor over time the effect of GC in an application. Here is some sample&#13;
output repeated every second:</p>&#13;
<pre data-type="programlisting">&#13;
% <strong>jstat -gcutil 23461 1000</strong>&#13;
  S0     S1     E      O      P     YGC     YGCT    FGC    FGCT     GCT&#13;
 51.71   0.00  99.12  60.00  99.93     98    1.985     8    2.397    4.382&#13;
  0.00  42.08   5.55  60.98  99.93     99    2.016     8    2.397    4.413&#13;
  0.00  42.08   6.32  60.98  99.93     99    2.016     8    2.397    4.413&#13;
  0.00  42.08  68.06  60.98  99.93     99    2.016     8    2.397    4.413&#13;
  0.00  42.08  82.27  60.98  99.93     99    2.016     8    2.397    4.413&#13;
  0.00  42.08  96.67  60.98  99.93     99    2.016     8    2.397    4.413&#13;
  0.00  42.08  99.30  60.98  99.93     99    2.016     8    2.397    4.413&#13;
 44.54   0.00   1.38  60.98  99.93    100    2.042     8    2.397    4.439&#13;
 44.54   0.00   1.91  60.98  99.93    100    2.042     8    2.397    4.439&#13;
</pre>&#13;
&#13;
<p>When monitoring of process ID 23461 started, the program had already&#13;
performed 98 collections&#13;
of the young generation (<code>YGC</code>), which took a total of 1.985 seconds (<code>YGCT</code>).&#13;
It had also performed eight full GCs (<code>FGC</code>) requiring 2.397 seconds (<code>FGCT</code>); hence&#13;
the total time in GC (<code>GCT</code>) was 4.382 seconds.</p>&#13;
&#13;
<p>All three sections of the young generation are displayed here: the two&#13;
survivor spaces (<code>S0</code> and <code>S1</code>) and eden (<code>E</code>). The monitoring started just as&#13;
eden was filling up (99.12% full), so in the next second there was a young&#13;
collection: eden reduced to 5.55% full, the survivor spaces switched places,&#13;
and a small amount of memory was promoted to the old generation (<code>O</code>), which&#13;
increased to using 60.98% of its space. As is typical, little or&#13;
no change occurred in the permanent generation (<code>P</code>) because all necessary classes&#13;
have already been loaded by the application.</p>&#13;
&#13;
<p>If you’ve forgotten to enable GC logging, this is a good substitute to watch&#13;
how GC operates over time.<a data-startref="ix_ch05-asciidoc31" data-type="indexterm" id="idm45775554389768"/><a data-startref="ix_ch05-asciidoc29" data-type="indexterm" id="idm45775554389064"/></p>&#13;
<div data-type="tip"><h1>Quick Summary</h1>&#13;
<ul>&#13;
<li>&#13;
<p>GC logs are the key piece of data required to diagnose GC issues; they should be collected routinely (even on production servers).</p>&#13;
</li>&#13;
<li>&#13;
<p>A better GC logfile is obtained with the&#13;
<span class="keep-together"><code>PrintGCDetails</code></span>&#13;
flag.</p>&#13;
</li>&#13;
<li>&#13;
<p>Programs to parse and understand GC logs are readily available; they are helpful in summarizing the data in the GC log.</p>&#13;
</li>&#13;
<li>&#13;
<p><code>jstat</code> can provide good visibility into GC for a live program.<a data-startref="ix_ch05-asciidoc28" data-type="indexterm" id="idm45775554382424"/><a data-startref="ix_ch05-asciidoc27" data-type="indexterm" id="idm45775554381720"/></p>&#13;
</li>&#13;
</ul>&#13;
</div>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Summary" data-type="sect1"><div class="sect1" id="idm45775554512328">&#13;
<h1>Summary</h1>&#13;
&#13;
<p>Performance of the garbage collector is one key feature of the overall&#13;
performance of any Java application. For many applications, though, the&#13;
only tuning required is to select the appropriate GC algorithm and,&#13;
if needed, to increase the heap size of the application. Adaptive sizing&#13;
will then allow the JVM to autotune its behavior to provide good&#13;
performance using the given heap.</p>&#13;
&#13;
<p>More-complex applications will require additional tuning, particularly&#13;
for specific GC algorithms. If the simple GC settings in this chapter do&#13;
not provide the performance an application requires, consult the tunings.<a data-startref="ix_ch05-asciidoc1" data-type="indexterm" id="idm45775554378712"/><a data-startref="ix_ch05-asciidoc0" data-type="indexterm" id="idm45775554378008"/></p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
</div></section></body></html>