- en: Chapter 6\. Building Kubernetes-Native Applications
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In the previous chapter, we outlined how to migrate from the traditional Java
    enterprise pattern to a container-centric approach. In this chapter, we will walk
    through the components needed to migrate to microservices-based architectures
    and how Kubernetes can connect the dots.
  prefs: []
  type: TYPE_NORMAL
- en: We also learned in previous chapters how much a microservices-based approach
    helps to make our software reliable, portable, and ready to scale upon demand.
    Modern architectures are planned with scalability already in the scope since the
    beginning, and this offers both opportunities and challenges. Enterprise Java
    developers know their code is usually part of the business logic, relying on frameworks
    to make it robust and consistent with well-recognized software design patterns.
    It is more common today that the same application could serve millions of requests
    running on a public cloud, even distributed geographically. To do that, it has
    to be architected to fit this model, decoupling functions, avoiding a single point
    of failure, and distributing the load to several parts of the architecture to
    avoid service interruptions.
  prefs: []
  type: TYPE_NORMAL
- en: Find the Right Balance Between Scalability and Complexity
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In an ideal world, all applications would be stateless, and they could scale
    up independently. They wouldn’t crash, and the network links would always be reliable.
    The reality looks different. The migration from monoliths to microservices-based
    architectures enables cloud native deployments, and we’ve covered some of the
    benefits that brings. However, that also brings some challenges: managing multiple
    points of ingress for your app, keeping the relationships between multiple microservices
    consistent, and managing distributed databases and schemas.'
  prefs: []
  type: TYPE_NORMAL
- en: In [Figure 6-1](#fig6-2), you can see how the transition from monolithic to
    microservices-based apps brings a new approach, having multiple interconnections
    or even multiple databases to work with.
  prefs: []
  type: TYPE_NORMAL
- en: '![From Monolith to Microservices Architectures](Images/moej_0601.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 6-1\. From monolith to microservices architectures
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Similar to the [CAP theorem](https://oreil.ly/nruM5), it is very hard to simultaneously
    provide scalability without increasing the complexity of a system. That’s why
    Kubernetes is so helpful because it’s ubiquitous, it runs in any cloud, and you
    can delegate most of this complexity to this platform. This lets you focus “just”
    on app development. On the other hand, we need to find a solution also for *stateful*
    apps in the cloud native world, and we will see that Kubernetes also provides
    help on this side.
  prefs: []
  type: TYPE_NORMAL
- en: Functional Requirements for Modern Architectures
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Kubernetes is very helpful with defining distributed applications as shown in
    [Figure 3-1](ch03.xhtml#fig3-2). Any Java developer should be well aware of [Design
    Patterns](https://oreil.ly/V4aqC) from Gang of Four, a masterpiece of software
    engineering where authors define the most-used software design patterns. Kubernetes
    extends this set of patterns, creating a new set of cloud native specific requirements
    to make applications resilient to various loads as shown in [Figure 6-2](#fig6-3).
    Let’s dig into some of those in the next sections.
  prefs: []
  type: TYPE_NORMAL
- en: '![Functional requirements for Modern Architectures](Images/moej_0602.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 6-2\. Functional requirements for modern architectures
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: API-Driven
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The microservices mantra is “API first.” If you take a look again at [Figure 6-1](#fig6-2),
    you’ll notice that splitting a monolithic app into a bunch of microservices leads
    to the first challenge: how to let these pieces of software communicate with each
    other? In monoliths, you rely on the app scope of modules, packages. Microservices
    usually communicate with each other via REST calls, where each one can be either
    producer or consumer of services. This is not the only way to connect your microservices;
    it’s also a common use case to use queues, messages, or caches. But in general,
    each microservice exposes its primitives or functions through a set of APIs, and
    this can also be intermediated by an API gateway as we discussed in the Coolstore
    example in [Chapter 2](ch02.xhtml#changing_technologies).'
  prefs: []
  type: TYPE_NORMAL
- en: Kubernetes itself is API-driven software. All core components of the platform
    such as Pods, Services, and Deployments are manipulated through REST APIs. All
    operations and communications between components and external user commands are
    [REST API calls that the API server handles](https://oreil.ly/PauGF). When we
    interact with Kubernetes through `kubectl` or JKube, we are just invoking an API
    via HTTPS sending and receiving JSON content. This ecosystem of APIs is the perfect
    environment for an API-driven architecture, such as one that uses microservices.
    Now that we know how our microservices communicate, how do we discover new services?
  prefs: []
  type: TYPE_NORMAL
- en: Discovery
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: It’s pretty straightforward to let microservices communicate with each other
    using REST calls. In addition, it would be nice to have the invocation of other
    components and functions at ease, such as when importing a module or a package
    into our app. In modern architectures, the number of microservices to invoke and
    connect could potentially be pretty high, thus it may not be enough to simply
    store the network endpoints such as IP address or hostnames. As we discussed in
    [Chapter 4](ch04.xhtml#kubernetes_based_softw_dev_platform), Kubernetes simplifies
    networking with the `Service` object, allowing two or more Pods to talk to each
    other within the platform’s internal networking. Kubernetes also provides the
    capability to list objects inside the cluster from an application, thanks to its
    API. Java developers can use frameworks such as JKube to have a Java Kubernetes
    client for this purpose.
  prefs: []
  type: TYPE_NORMAL
- en: Listing Kubernetes Services and Pods, which represent some microservices, is
    the first step to a real-time inventory of components of our software stack, which
    additionally helps to maintain and extend at runtime applications. Furthermore,
    Kubernetes enables integration with external tools or frameworks for that, such
    as Service Mesh, which provides service discovery protocol to detect services
    as they come up.
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: '[Service mesh](https://oreil.ly/jGh80) is an increasingly popular choice for
    microservices-based architectures. It provides a control panel that also interacts
    with Kubernetes to manage service discovery, mutual authentication, A/B testing,
    routing, and circuit breaker pattern out of the box. [Further details can be found
    online](https://oreil.ly/ECIF4).'
  prefs: []
  type: TYPE_NORMAL
- en: Security and Authorization
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Another challenge that modern app developers need to take into account is security
    for the entire stack. From the app to the platform, best practices also apply
    to modern architectures, and the complexity and the required effort may rise significantly
    when there are many services to connect, many databases to query, and many endpoints
    to serve. Again, Kubernetes comes in to help.
  prefs: []
  type: TYPE_NORMAL
- en: Kubernetes provides security for the entire ecosystem. Role-based access control
    (RBAC) and fine-grained permission rules are possible. Furthermore, Pods are run
    by a special user called *Service Account* that has access to the Kubernetes API
    Server, usually having limited scope to the user’s namespace. Besides that, Kubernetes
    provides a special API to manage passwords and certificates called *Secrets*.
    A Secret is a volume mounted into the Pod by the platform at runtime, with its
    value stored into Kubernetes’s database etcd, along with cluster state and configurations.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: '[etcd](https://etcd.io) is a distributed key-value database used by Kubernetes
    to store the cluster state. The content of the database can be also encrypted,
    and only the cluster administrator can access its content.'
  prefs: []
  type: TYPE_NORMAL
- en: As we discussed, the communication between microservices is usually done via
    HTTPS REST calls, whose certificates are managed via Secrets. Containers and Kubernetes
    provide a good starting point for ensuring security in applications, from which
    Java developers can start to implement app security best practices.
  prefs: []
  type: TYPE_NORMAL
- en: Monitoring
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Measuring resource consumption is essential in modern architectures, and ever
    more so in cloud environments with a pay-per-use consumption model. It isn’t easy
    to estimate how many computational resources your app will need under stress,
    and overestimation may increase costs. Kubernetes enables monitoring at the operating
    system level to application level, with its ecosystem of API and tools.
  prefs: []
  type: TYPE_NORMAL
- en: A popular cloud native tool to gather metrics from the platform and the app
    is [Prometheus](https://prometheus.io), a time-series database that can export
    metrics from the Kubernetes cluster and apps using [a query language called PromQL](https://oreil.ly/tYn9Q).
  prefs: []
  type: TYPE_NORMAL
- en: Metrics are also used to help Kubernetes decide when to scale your application
    up or down according to the monitored load on the app. You can drive this scale
    with custom metrics, such as JVM threads or queue size, and make monitoring a
    proactive tool to empower your services. Prometheus also provides alerts and alarms,
    which are useful to schedule automated actions for your applications when they
    need to react faster.
  prefs: []
  type: TYPE_NORMAL
- en: Java developers can also interact with Prometheus and metrics inside Kubernetes
    with [Micrometer](https://micrometer.io), an open source tool that provides a
    registration mechanism for metrics and core metric types. It is available for
    any JVM-based workloads, and it is the popular choice for both Spring Boot and
    Quarkus projects to interact with Prometheus and Kubernetes. “Think SLF4J, but
    for metrics.”
  prefs: []
  type: TYPE_NORMAL
- en: Tracing
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Observability is another key aspect in modern architectures, and measuring latency
    between REST API calls is an important facet of managing microservices-based apps.
    It is crucial to ensure that the communication is always clear and the latency
    is minimal. When the number of microservices increases, a small delay in some
    part of the architecture can result in an acceptable service interruption for
    the user. In these situations, Kubernetes is helpful for debugging the majority
    of operational problems that arise when moving to a distributed architecture.
  prefs: []
  type: TYPE_NORMAL
- en: '[Jaeger](https://www.jaegertracing.io) is a popular open source tool that connects
    to Kubernetes to provide observability. It uses distributed tracing to follow
    the path of a request through different microservices. It provides a visual representation
    of the call flows through a dashboard, and it is often also integrated with Service
    mesh. Jaeger is very helpful to developers for monitoring distributed transactions,
    optimizing performance and latency, and performing root cause analysis.'
  prefs: []
  type: TYPE_NORMAL
- en: Logging
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: As we discussed, a single call in your microservices-based app, such as the
    Coolstore example, can invoke different services that interact with each other.
    It’s important to monitor and observe the app, but also to store relevant pieces
    of information in logs. Your application’s logging approach changes with modern
    apps. While in monoliths we usually rely on multiple log files stored in different
    paths on the disk, usually managed by the application server, distributed apps
    *stream* logs. As your app can scale up rapidly and move to different nodes or
    even clouds, it makes no sense to access the single instance to retrieve logs;
    therefore, a distributed log system is needed.
  prefs: []
  type: TYPE_NORMAL
- en: Kubernetes makes logging easy as well. By default, it provides the capability
    to access a Pod’s logs by reading the application’s standard streams such as STDOUT
    (Standard Output) and STDERR (Standard Error). Thus, the app should not write
    logs into a certain path, but send logs to standard streams.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: It is still possible to store logs in specific paths that can also be persistent
    in Kubernetes, but this is considered an antipattern.
  prefs: []
  type: TYPE_NORMAL
- en: Kubernetes also interacts with distributed logging systems such as [Elasticsearch](https://elastic.co),
    an open source document-oriented NoSQL database based on [Apache Lucene](https://lucene.apache.org)
    to store logs and events. Elasticsearch usually comes with a forwarder, such as
    [Fluentd](https://fluentd.org), and a dashboard to visualize logs such as [Kibana](https://elastic.co/kibana).
    Together, this creates the EFK stack (Elasticsearch, Fluentd, Kibana). With this
    logging stack, developers consult logs from multiple microservices in an aggregated
    view through the Kibana dashboard, and they are also able to make queries in a
    query language called Kibana Query Language (KQL).
  prefs: []
  type: TYPE_NORMAL
- en: Distributed logging is the de facto standard with cloud native apps, and Kubernetes
    connects and interacts with many offerings such as EFK to provide centralized
    logging for the whole cluster.
  prefs: []
  type: TYPE_NORMAL
- en: CI/CD
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Continuous Integration (CI) is a phase in the software development cycle where
    code from different team members or different features is integrated. This usually
    involves merging code (integration), building the application (container), and
    carrying out basic tests, all within an ephemeral environment.
  prefs: []
  type: TYPE_NORMAL
- en: Continuous Delivery (CD) refers to a set of practices to automate various aspects
    of delivery software. One of these practices is called delivery pipeline, which
    is an automated process to define the steps a change in code or configuration
    has to go through to reach upper environments and eventually production.
  prefs: []
  type: TYPE_NORMAL
- en: Together, they are often referred to as CI/CD, and it is one of the key technology
    enablers for DevOps methodology.
  prefs: []
  type: TYPE_NORMAL
- en: Modern services need to react fast to changes or issues. As we can monitor,
    trace, and log distributed architectures, we should also be able to update our
    microservices-based app faster. Pipelines are the best way to deploy apps in production
    following the phases as shown in [Figure 6-3](#fig6-4).
  prefs: []
  type: TYPE_NORMAL
- en: '![Continuous Integration and Continuous Delivery](Images/moej_0603.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 6-3\. Continuous Integration and Continuous Delivery
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: A *pipeline* is a series of steps, sequential or parallel, that build and test
    the app in all preproduction environments before finally releasing it to production.
    It can be fully automated or can interact with external tools for manual step
    approval (e.g., Service Now, JIRA, etc.). Kubernetes interacts and connects with
    many external CI/CD tools such as [Jenkins](https://jenkins.io), and also provides
    a native CI/CD subsystem called [Tekton](https://tekton.dev).
  prefs: []
  type: TYPE_NORMAL
- en: Tekton is a Kubernetes-native CI/CD system, which means it extends the Kubernetes
    API and provides its custom resources that you can use to create your pipelines.
    It relies [on a catalog of Tasks](https://oreil.ly/Oxx5P) that comes already bundled
    with Tekton to compose your pipelines, such as Maven or Java Source-to-Image Tasks.
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Tekton can be installed in Kubernetes with an Operator from [OperatorHub.io](https://operatorhub.io).
  prefs: []
  type: TYPE_NORMAL
- en: 'To create Kubernetes-native pipelines, the following custom resources are provided
    by Tekton:'
  prefs: []
  type: TYPE_NORMAL
- en: Task
  prefs: []
  type: TYPE_NORMAL
- en: A reusable, loosely coupled number of steps that perform a specific function
    (e.g., building a container image). Tasks get executed as Kubernetes Pods while
    steps in a Task map onto containers.
  prefs: []
  type: TYPE_NORMAL
- en: Pipeline
  prefs: []
  type: TYPE_NORMAL
- en: A list of Tasks needed to build and/or deploy your apps.
  prefs: []
  type: TYPE_NORMAL
- en: TaskRun
  prefs: []
  type: TYPE_NORMAL
- en: The execution and result of running an instance of Task.
  prefs: []
  type: TYPE_NORMAL
- en: PipelineRun
  prefs: []
  type: TYPE_NORMAL
- en: The execution and result of running an instance of Pipeline, which includes
    a number of TaskRuns.
  prefs: []
  type: TYPE_NORMAL
- en: 'An example of a Tekton Pipeline for the Inventory Quarkus microservice that
    we created in [Chapter 2](ch02.xhtml#changing_technologies) is listed next, you
    can also find it in this [book’s GitHub repository](https://oreil.ly/2UUCL):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: Java developers may also find it convenient to create and control Tekton Pipelines
    and Tasks direcly from the code, using Fabric8 Tekton Java client. This option
    gives the full control from a single point, and you don’t need to maintain external
    manifests such as YAML files.
  prefs: []
  type: TYPE_NORMAL
- en: 'First, import Maven dependency in POM file:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'Then you can use Tekton Java API to create Tasks or Pipeline:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: Debugging Microservices
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: While distributed architectures have plenty of benefits, they also pose some
    challenges. Even if you eventually run your code inside a Kubernetes cluster,
    you still develop (in general) locally where you have your IDE, compilers, etc.
    There are several ways to explain the development cycle. There are two loops,
    as illustrated in [Figure 6-4](#fig4-10). The one closer to the developer, called
    the inner loop, is where you code, test, and debug iteratively. The other loop,
    further away from the developer, called the outer loop, is where your code runs
    inside a container image you have to build, push, and deploy, and that takes a
    lot longer.
  prefs: []
  type: TYPE_NORMAL
- en: '![Inner Loop and Outer Loop](Images/moej_0604.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 6-4\. Inner loop and outer loop
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: While the outer loop is part of the CI/CD world, the inner loop is where you
    start coding and testing your software before launching a Tekton Pipeline to deploy
    your application into Kubernetes. Debugging microservices is also part of the
    inner loop.
  prefs: []
  type: TYPE_NORMAL
- en: 'Developers can follow different approaches to start debugging microservices:'
  prefs: []
  type: TYPE_NORMAL
- en: Using [Docker Compose](https://oreil.ly/ULV5g) and deploying all the services
    locally
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Using [minikube](https://oreil.ly/1ogSc), or any local Kubernetes clusters,
    and deploying all the services there
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Mocking up all the services you interact with
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Docker Compose helps create containers that run in any Docker hosts, without
    Kubernetes. It is used for managing multiple containers in local development,
    but it is not mapped to any target Kubernetes clusters; thus, maintaining the
    local development setup separate from the target one may be difficult.
  prefs: []
  type: TYPE_NORMAL
- en: They are all valid approaches, but there are times where services are external
    and reachable only from the remote Kubernetes cluster, or mocking up that part
    of code is difficult or not possible.
  prefs: []
  type: TYPE_NORMAL
- en: '[Microcks](https://microcks.io) is an open source Kubernetes-native debugging
    tool for API mocking and testing. It helps turn API contract, collection, or SoapUI
    projects into live mocks. It can be a convenient way to develop faster on Kubernetes
    without dependencies.'
  prefs: []
  type: TYPE_NORMAL
- en: Let’s look at some additional options for in-Kubernetes microservices debugging.
  prefs: []
  type: TYPE_NORMAL
- en: Port Forwarding
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Kubernetes offers remote shelling into Pods for quick debugging tasks such as
    filesystem check. Additionally, [you can set up port forwarding](https://oreil.ly/IAu5H)
    between your local machine connected to a Kubernetes cluster and your app running
    in a Pod. This option is useful when you want to connect to a database running
    in a Pod, attach an administrative web interface you don’t want to expose to the
    public, or, in this case, attach a debugger to the JVM running our application
    server.
  prefs: []
  type: TYPE_NORMAL
- en: By port forwarding the debugging port for the application server, you can attach
    the debugger from your IDE and actually step through the code in the Pod as it
    is running in real time. Remember, if your app is not in debug mode, you first
    need to turn on the debug ports.
  prefs: []
  type: TYPE_NORMAL
- en: 'To start debugging, you need to expose the port for debugging. For example,
    for debugging the Inventory microservice, you need to access the debugging port
    5005:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: Now when we connect on *localhost:5005*, it will get forwarded to the Inventory
    instance running in the Pod.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Port forwarding is only active as long as the `kubectl port-forward` command
    is allowed to run. Since we run it in the foreground, we are able to stop port
    forwarding by hitting Ctrl+C (or Cmd+C on a Mac).
  prefs: []
  type: TYPE_NORMAL
- en: 'In order to debug the source code, you can either use your IDE of choice or
    you can debug from the console as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: Quarkus Remote Development Mode
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Quarkus provides a [Remote Development Mode](https://oreil.ly/rLflo) that allows
    you to run Quarkus in a container environment such as Kubernetes and have changes
    made to your local files immediately.
  prefs: []
  type: TYPE_NORMAL
- en: 'To enable it, add this section in your `application.properties`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: '[![1](Images/1.png)](#co_building_kubernetes_native_applications_CO1-1)'
  prefs: []
  type: TYPE_NORMAL
- en: Mutable applications are used in development mode to apply and test changes
    live in a Quarkus Java application, without reloading the artifact.
  prefs: []
  type: TYPE_NORMAL
- en: '[![2](Images/2.png)](#co_building_kubernetes_native_applications_CO1-2)'
  prefs: []
  type: TYPE_NORMAL
- en: A password that is used to secure communication between the remote side and
    the local side.
  prefs: []
  type: TYPE_NORMAL
- en: '[![3](Images/3.png)](#co_building_kubernetes_native_applications_CO1-3)'
  prefs: []
  type: TYPE_NORMAL
- en: The URL at which your app is going to be running in dev mode.
  prefs: []
  type: TYPE_NORMAL
- en: 'You can generate the mutable JAR with Maven. You can let Quarkus deploy the
    app to Kubernetes as follows if you are connected with the Kubernetes Registry:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: Note
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'You can add the Quarkus Kubernetes extension with this command: `./mvnw quarkus:add-extension
    -Dextensions="kubernetes"`'
  prefs: []
  type: TYPE_NORMAL
- en: 'Deploy the app to Kubernetes:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'Finally, you connect in remote dev mode to the app:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: This allows you to use Quarkus to connect the live coding features from your
    local machine to a remote container environment such as Kubernetes.
  prefs: []
  type: TYPE_NORMAL
- en: Telepresence
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[Telepresence](https://www.telepresence.io) is an open source tool that helps
    debug microservices in Kubernetes. It runs a single service locally, while connecting
    that service to a remote Kubernetes cluster. Telepresence is programming language-agnostic,
    providing a convenient way to connect your local enviroment to any workload running
    on Kubernetes to debug.'
  prefs: []
  type: TYPE_NORMAL
- en: Debugging apps on Kubernetes with Telepresence is very easy. First, download
    and install [Telepresence CLI](https://oreil.ly/wkwOC) and have an active session
    to your cluster, as Telepresence will read the *~/.kube/config* file to connect
    to Kubernetes.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Telepresence will modify the network in Kubernetes so that Services are reachable
    from your laptop and vice versa.
  prefs: []
  type: TYPE_NORMAL
- en: 'Once the CLI is installed and configured in your workstation, you can run this
    command to initialize and test the connection to your cluster with Telepresence:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'You should get an output similar to the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'We can start debugging the Inventory microservice that you deployed in the
    previous steps. Before doing that, let’s list available apps to debug:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'You should get an output similar to the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: To start debugging this microservice, you need to let Telepresence intercept
    the internal Kubernetes traffic represented by the Service.
  prefs: []
  type: TYPE_NORMAL
- en: 'The Inventory’s Kubernetes Service is using port 8080, as you can see with
    the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'You should get an output similar to the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'Now you can start intercepting the traffic connecting to your Deployment with
    the port used by the Service. You can also specify the path to a file on which
    Telepresence should write the environment variables that your service is currently
    running with:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'You should get an output similar to the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 'Look at the content of the environment file `inventory.env` just created:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: 'Now you can access the Inventory microservice as if you were connected to the
    internal Kubernetes network, and working with the environment variables just retrieved:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: 'You should get an output similar to the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we discussed how Kubernetes patterns can help Java developers
    with modernizing their apps, offering a platform that provides many components
    to extend app capabilities. The API-driven, pluggable architecture of Kubernetes
    easily enables external tools to provide an ecosystem of software and utilities
    that reminds, but also extends the application server model for Java enterprise.
    Essential tasks such as logging, monitoring, or debugging apps are provided in
    a way that fits the cloud native model, where apps are ubiquituous and can run
    in multiple places and multiple clouds at the same time.
  prefs: []
  type: TYPE_NORMAL
- en: 'In the next chapter, we will discuss a new concept of serving and delivering
    the enterprise application, resource-saving and cloud-ready: the serverless way.'
  prefs: []
  type: TYPE_NORMAL
