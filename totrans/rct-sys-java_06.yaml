- en: Chapter 4\. Design Principles of Reactive Systems
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第四章 设计响应式系统的原则
- en: 'In [Chapter 3](ch03.html#distributed-system), we looked at the challenges behind
    distributed systems. It’s now time to see what Reactive has to offer. Reactive
    can be seen as a set of principles for building distributed systems, a kind of
    checklist to verify that no major known concern was overlooked while architecting
    and building a system. These principles focus on the following:'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在[第三章](ch03.html#distributed-system)中，我们探讨了分布式系统面临的挑战。现在是时候看看响应式系统能为我们提供什么了。响应式可以被看作是构建分布式系统的一套原则，一种检查清单，以确保在架构和构建系统时没有忽略任何主要已知的关注点。这些原则专注于以下内容：
- en: Responsiveness
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 响应性
- en: The ability to handle requests when facing failures or peaks of load
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 在面对故障或负载高峰时处理请求的能力
- en: Efficiency
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 效率
- en: The ability to do more with fewer resources
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 能够在资源较少的情况下完成更多任务
- en: In this chapter, we cover the principles promoted by reactive systems.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 本章我们将讨论响应式系统推广的原则。
- en: Reactive Systems 101
  id: totrans-7
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 响应式系统 101
- en: In 2013, a group of distributed systems experts gathered and wrote the first
    version of “The Reactive Manifesto.” They assembled in this whitepaper their experience
    building distributed systems and cloud applications. While in 2013 the cloud was
    not precisely what it is today, the dynamic creation of ephemeral resources was
    already a well-known mechanism.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 2013年，一群分布式系统专家聚集在一起，撰写了第一版“响应式宣言”。在这份白皮书中，他们汇集了构建分布式系统和云应用的经验。虽然在2013年，云并不像今天这样具体，但短暂资源的动态创建已经是一个众所周知的机制。
- en: '“The Reactive Manifesto” defines *reactive systems* as distributed systems
    having four characteristics:'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: “响应式宣言”将*响应式系统*定义为具有四个特性的分布式系统：
- en: Responsive
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 响应性
- en: Able to handle requests in a timely fashion
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 能够及时处理请求
- en: Resilient
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 韧性
- en: Able to manage failures gracefully
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 能够优雅地处理故障
- en: Elastic
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 弹性
- en: Able to scale up and down according to the load and resources
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 能够根据负载和资源进行动态扩展和收缩
- en: Message driven
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 消息驱动
- en: Using asynchronous message-based communication among the components forming
    the system
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 在系统中组件之间使用异步基于消息的通信
- en: These four characteristics are represented in [Figure 4-1](#image:reactive-systems).
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 这四个特性在[图4-1](#image:reactive-systems)中有所体现。
- en: '![Reactive systems characteristics](assets/rsij_0401.png)'
  id: totrans-19
  prefs: []
  type: TYPE_IMG
  zh: '![响应式系统特性](assets/rsij_0401.png)'
- en: Figure 4-1\. Reactive systems characteristics
  id: totrans-20
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图4-1 响应式系统特性
- en: If you’re seeing this picture for the first time, you may be confused by all
    the arrows. It can look like a well-tailored marketing campaign. It’s not, and
    let’s explain why these pillars make a lot of sense when building cloud native
    and Kubernetes-native applications. Let’s start with the bottom of the figure.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你第一次看到这幅图片，可能会被所有箭头弄得一头雾水。它看起来像是一个精心策划的营销活动。但事实并非如此，让我们解释一下为什么在构建云原生和Kubernetes原生应用程序时，这些支柱理念非常合理。让我们从图的底部开始。
- en: Instead of trying to make distributed systems simpler than they are, reactive
    systems embrace their asynchronous nature. They use *asynchronous message passing*
    to establish the connective tissue among the components. Asynchronous message
    passing ensures loose coupling, isolation, and location transparency. In a reactive
    system, interactions rely on messages sent to abstract destinations. These messages
    carry everything—data as well as failures. Asynchronous message passing also improves
    resource utilization. Employing nonblocking communication (we cover that part
    later in this chapter) allows idle components to consume almost no CPU and memory.
    Asynchronous message passing enables elasticity and resilience, as depicted by
    the two bottom arrows in [Figure 4-1](#image:reactive-systems).
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 响应式系统并不试图简化分布式系统，而是接受其异步性质。它们使用*异步消息传递*来建立组件之间的连接。异步消息传递确保松耦合、隔离和位置透明性。在响应式系统中，交互依赖于发送到抽象目的地的消息。这些消息不仅携带数据，还携带失败信息。异步消息传递还提高了资源利用率。采用非阻塞通信（我们稍后在本章中详细讨论）允许空闲组件几乎不消耗CPU和内存。异步消息传递实现了弹性和韧性，如在[图4-1](#image:reactive-systems)中所示的两个底部箭头。
- en: '*Elasticity* means that the system can adapt itself, or parts of itself, to
    handle the fluctuating load. By looking at the messages flowing among the components,
    a system can determine which parts reach their limits and create more instances
    or route the messages elsewhere. Cloud infrastructure enables creating these instances
    quickly at runtime. But elasticity is not only about scaling up; it’s also about
    scaling down. The system can decide to scale down underused parts to save resources.
    At runtime, the system adjusts itself, always meeting the current demand, avoiding
    bottlenecks, overflows, and overcommitted resources. As you can imagine, elasticity
    requires observability, replication, and routing features. Observability is covered
    in [Chapter 13](ch13.html#observability). In general, the last two are provided
    by the infrastructure such as Kubernetes or cloud providers.'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: '*弹性* 意味着系统可以自适应或其部分可以自适应以处理波动的负载。通过观察组件之间流动的消息，系统可以确定哪些部分达到了其极限，并创建更多实例或将消息路由到其他地方。云基础设施可以在运行时快速创建这些实例。但弹性不仅仅是扩展；它还涉及缩减。系统可以决定缩减未充分使用的部分以节省资源。在运行时，系统会自我调整，始终满足当前的需求，避免瓶颈、溢出和过度分配资源。正如你所想象的，弹性需要可观察性、复制和路由功能。可观察性在
    [第十三章](ch13.html#observability) 中有所涵盖。总的来说，最后两者由基础设施如 Kubernetes 或云提供者提供。'
- en: '*Resilience* means handling failure gracefully. As explained in [Chapter 3](ch03.html#distributed-system),
    failures are inevitable in distributed systems. Instead of hiding them, reactive
    systems consider failures first-class citizens. The system should be able to handle
    them and react to them. Failures are contained within each component, isolating
    components from one another. This isolation ensures that parts of the system can
    fail and recover without jeopardizing the whole system. For instance, by replicating
    components (elasticity), the system can continue to handle incoming messages even
    if some elements are failing. The implementation of resilience is shared between
    the application (which needs to be aware of failures, contain them, and, if possible,
    handle them gracefully) and the infrastructure (which monitors the systems and
    restarts fallen components).'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: '*韧性* 意味着优雅地处理故障。正如 [第三章](ch03.html#distributed-system) 所解释的，分布式系统中的故障是不可避免的。与其隐藏故障，响应式系统将故障视为一等公民。系统应能够处理和响应这些故障。故障被隔离在每个组件内部，使各组件相互隔离。这种隔离确保系统的各部分可以失败和恢复，而不会危及整个系统。例如，通过复制组件（弹性），即使某些元素失败，系统也可以继续处理传入的消息。韧性的实现由应用程序（需要意识到故障、隔离它们并在可能时优雅地处理它们）和基础设施（监控系统并重新启动失败的组件）共同分享。'
- en: 'The last characteristic is the whole purpose of reactive systems: being *responsive*.
    Your system needs to stay responsive—to respond in a timely fashion—even under
    fluctuating load (elasticity) and when facing failure (resilience). Relying on
    message passing enables these characteristics and much more, such as flow control
    by monitoring the messages in the system and applying backpressure when necessary.'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 最后一个特性是响应式系统的整体目的：*响应性*。你的系统需要保持响应能力——即使在波动的负载（弹性）和面对故障（韧性）时也要能够及时响应。依赖消息传递可以实现这些特性，以及更多，例如通过监控系统中的消息并在必要时施加反压力来实现流量控制。
- en: 'In a nutshell, reactive systems are exactly what we want to build: distributed
    systems able to handle the uncertainty, failures, and load efficiently. Their
    characteristics meet the requirement for cloud native and Kubernetes-native applications
    perfectly. But don’t be mistaken; building a reactive system is still making a
    distributed system. It’s challenging. However, by following these principles,
    the resulting system will be more responsive, more robust, and more efficient.
    The rest of this book details how we can easily implement such systems with Quarkus
    and messaging technologies.'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 简而言之，响应式系统正是我们想要构建的东西：能够有效处理不确定性、故障和负载的分布式系统。它们的特性完美符合云原生和 Kubernetes 原生应用程序的要求。但不要误解；构建响应式系统仍然是在构建分布式系统。这是具有挑战性的。然而，通过遵循这些原则，得到的系统将更加响应、更加健壮和更加高效。本书的其余部分详细说明了如何使用
    Quarkus 和消息传递技术轻松实现这样的系统。
- en: Commands and Events
  id: totrans-27
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 命令与事件
- en: Now that we’ve covered many of the foundational principles, you might be confused.
    In [Chapter 1](ch01.html#introduction), we said that being reactive is related
    to being event driven, but in the previous section, we explicitly mentioned asynchronous
    message passing. Does that mean the same thing? Not completely.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经涵盖了许多基础原则，您可能会感到困惑。在[第一章](ch01.html#introduction)中，我们说反应性与事件驱动有关，但在前一节中，我们明确提到了异步消息传递。这意味着相同的吗？并非完全如此。
- en: But first, we need to discuss the differences between commands and events. As
    complicated as a distributed system design can be, the concepts of commands and
    events are fundamental. Nearly all interactions between individual components
    involve one or the other.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 但首先，我们需要讨论命令和事件之间的区别。分布式系统设计虽然复杂，但命令和事件的概念是基础的。几乎所有个体组件之间的互动都涉及其中之一。
- en: Commands
  id: totrans-30
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 命令
- en: 'Every system issues commands. *Commands* are actions that a user wishes to
    perform. Most HTTP-based APIs pass commands: the client asks for an action to
    happen. It’s important to understand that the action has not yet happened. It
    may happen in the future, or not; it may complete successfully or fail. In general,
    commands are sent to a specific recipient, and a result is sent back to the client.'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 每个系统都会发布命令。*命令* 是用户希望执行的操作。大多数基于 HTTP 的 API 传递命令：客户端要求执行某项操作。重要的是要理解该操作尚未发生。它可能会在未来发生，也可能不会；它可能成功完成，也可能失败。通常，命令被发送到特定的接收者，并将结果发送回客户端。
- en: Take the simple HTTP application we used in [Chapter 3](ch03.html#distributed-system).
    You emitted a simple HTTP request. As we’ve said, that was a command. The application
    receives that command, handles it, and produces a result.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 以我们在[第三章](ch03.html#distributed-system)使用的简单 HTTP 应用为例。您发出了一个简单的 HTTP 请求。正如我们所说，那是一个命令。应用程序接收到该命令，处理它，并产生一个结果。
- en: Events
  id: totrans-33
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 事件
- en: '*Events* are actions that have successfully completed. An event represents
    a *fact*, something that happened: a keystroke, a failure, an order, anything
    important to the organization or system at hand. An event can be the result of
    work done by a command.'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: '*事件* 是成功完成的操作。事件代表了一个*事实*，即发生的事情：一个按键、一个失败、一个订单，或者对组织或系统至关重要的任何事情。事件可能是由命令执行产生的结果。'
- en: Let’s go back to the preceding HTTP request example. Once the response has been
    written, it becomes an event. We have seen an HTTP request and its response. That
    event can be written in a log or broadcast to interested parties so they can be
    aware of what happened.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们回到之前的 HTTP 请求示例。一旦响应被写入，它就成为一个事件。我们已经看到了一个 HTTP 请求及其响应。该事件可以被写入日志或广播给感兴趣的各方，以便他们了解发生了什么。
- en: Events are immutable. You cannot delete an event. Admittedly, you can’t change
    the past. If you want to refute a previously sent fact, you need to fire another
    event invalidating the fact. The carried facts are made irrelevant only by another
    fact establishing the current knowledge.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 事件是不可变的。您无法删除事件。诚然，您无法改变过去。如果要反驳先前发送的事实，您需要触发另一个事件，使该事实失效。只有通过另一个确立当前知识的事实，才能使携带的事实变得无关紧要。
- en: Messages
  id: totrans-37
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 消息
- en: But, how to publish these events? There are many ways. These days, solutions
    like Apache Kafka or Apache ActiveMQ (we cover both in [Chapter 11](ch11.html#event-bus))
    are popular. They act as brokers between the producers and consumers. Essentially,
    our events are written into *topics* or *queues*. To write these events, the application
    sends a message to the broker, targeting a specific destination (the queue or
    the topic).
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 但是，如何发布这些事件呢？有许多方法。像 Apache Kafka 或 Apache ActiveMQ 这样的解决方案现在很流行（我们在[第十一章](ch11.html#event-bus)中涵盖了两者）。它们充当生产者和消费者之间的代理。本质上，我们的事件被写入*主题*或*队列*中。要写入这些事件，应用程序向代理发送消息，指定特定的目标（队列或主题）。
- en: A *message* is a self-contained data structure describing the event and any
    relevant details about the event, such as who emitted it, at what time it was
    emitted, and potentially its unique ID. It’s generally better to keep the event
    itself business-centric and use additional metadata for the technical aspects.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: '*消息* 是描述事件及其相关细节的独立数据结构，比如谁发出的、发出时间以及可能的唯一标识符。通常最好将事件本身保持业务中心化，使用额外的元数据处理技术细节。'
- en: On the other side, to consume events, you subscribe to the queue or topic containing
    the events you are interested in and receive the messages. You unwrap the event
    and can also get the associated metadata (for example, when the event happened,
    where it happened, and so forth). The processing of an event can lead to the publication
    of other events (again, packaged in messages and sent to a known destination)
    or to the execution of commands.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 另一方面，为了消费事件，您可以订阅包含您感兴趣的事件的队列或主题，并接收消息。您可以解封事件，并获取相关的元数据（例如事件发生的时间、地点等）。事件的处理可能会导致发布其他事件（再次封装为消息并发送到已知目的地）或执行命令。
- en: Brokers and messages can also convey commands. In this case, the message contains
    the description of the action to execute, and another message (potentially multiple
    messages) would carry the outcome if needed.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 代理和消息也可以传递命令。在这种情况下，消息包含要执行的动作描述，另一个消息（可能是多个消息）将携带必要的结果。
- en: 'Commands Versus Events: An Example'
  id: totrans-42
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 命令与事件：一个例子
- en: Let’s take a look at an example to highlight the differences between commands
    and events. Imagine an ecommerce shop, like the one depicted in [Figure 4-2](#image:shop-order-services).
    The user picks a set of products and finalizes the order (process to payment,
    get the delivery date, etc.).
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们来看一个例子，突出命令和事件之间的区别。想象一个电子商务店铺，就像[图 4-2](#image:shop-order-services)所示的那样。用户选择一组产品并完成订单（处理支付、获取送货日期等）。
- en: '![Simplified architecture of an ecommerce shop](assets/rsij_0402.png)'
  id: totrans-44
  prefs: []
  type: TYPE_IMG
  zh: '![电子商务店铺简化架构](assets/rsij_0402.png)'
- en: Figure 4-2\. Simplified architecture of an ecommerce shop
  id: totrans-45
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 4-2\. 电子商务店铺简化架构
- en: 'The user sends a command (using an HTTP request, for example) to the shop service
    with the items the user wishes to receive. In a traditional application, once
    `ShopService` receives the command, it would call `OrderService` and invoke an
    `order` method with the username, the list of items (basket), and so on. Calling
    the `order` method is a command. That makes `ShopService` dependent on `OrderService`
    and reduces the component autonomy: `ShopService` cannot operate without `OrderService`.
    We are creating a distributed monolith, a distributed application that would collapse
    as soon as one of its parts fails.^([1](ch04.html#idm45358831669616))'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 用户通过命令（例如使用HTTP请求）向商店服务发送希望接收的商品。在传统应用程序中，一旦`ShopService`接收到命令，它将调用`OrderService`并调用一个`order`方法，传递用户名、商品列表（购物篮）等信息。调用`order`方法属于命令。这使得`ShopService`依赖于`OrderService`，并降低了组件的自主性：`ShopService`无法在没有`OrderService`的情况下运行。我们正在创建一个分布式单体，一个分布式应用程序，一旦其中一个部分失败就会崩溃。^([1](ch04.html#idm45358831669616))
- en: 'Let’s see the difference if, instead of using a command between `ShopService`
    and `OrderService`, we publish an event. Once the user finalizes the order, the
    application still sends a command to `ShopService`. However, this time, `ShopService`
    *transforms* that command into an event: *a new order has been placed*. The event
    contains the user, the basket, and so on. The event is a fact written in a log,
    or wrapped into a message and sent to a broker.'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们不使用命令而是发布一个事件，让我们看看其中的区别。一旦用户完成订单，应用程序仍然会向`ShopService`发送一个命令。但是，这次，`ShopService`会将该命令*转换*成一个事件：*已下订单*。该事件包含用户、购物篮等信息。事件是写入日志中的事实，或者被包装成消息发送到代理。
- en: On the other side, `OrderService` observes the *a new order has been placed*
    event, by reading where these events are stored. When `ShopService` emits the
    event, it receives it and can process it.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 在另一方面，`OrderService`通过读取存储事件的位置来观察*已下订单*事件。当`ShopService`发出该事件时，它接收并可以处理它。
- en: With this architecture, `ShopService` does not depend on `OrderService`. In
    addition, `OrderService` does not depend on `ShopService`, and it would process
    any observed event, regardless of the emitter. For example, a mobile application
    can emit the same event when the user validates an order from a mobile phone.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 使用这种架构，`ShopService`不依赖于`OrderService`。此外，`OrderService`也不依赖于`ShopService`，并且它会处理任何观察到的事件，无论是谁发出的。例如，移动应用程序在用户从手机验证订单时可以发出相同的事件。
- en: Multiple components can consume events ([Figure 4-3](#image:shop-messages)).
    For example, in addition to `OrderService`, `StatisticsService` keeps track of
    the most ordered items. It consumes the same event, without having to modify `ShopService`
    to receive them.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 多个组件可以消费事件（[图 4-3](#image:shop-messages)）。例如，除了`OrderService`，`StatisticsService`也跟踪最常订购的商品。它消费相同的事件，而无需修改`ShopService`以接收它们。
- en: A component observing events can derive new ones from them. For instance, `StatisticsService`
    could analyze the order and compute recommendations. These recommendations could
    be seen as another fact, and so communicate as an event. `ShopService` could observe
    these events and process them to influence item selection. However, `StatisticsService`
    and `ShopService` are independent of each other. The knowledge is cumulative and
    occurs by receiving new events and deriving, as done by `StatisticsService`, new
    facts from the received events.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 一个观察事件的组件可以从中派生新的事件。例如，`StatisticsService`可以分析订单并计算推荐。这些推荐可以被视为另一个事实，并作为事件进行通信。`ShopService`可以观察这些事件并处理它们以影响商品选择。然而，`StatisticsService`和`ShopService`是彼此独立的。知识是累积的，并且通过接收新事件并从中派生新事实（就像`StatisticsService`所做的那样）来实现。
- en: As depicted in [Figure 4-3](#image:shop-messages), we can use *message queues*
    to transport our events. These events are wrapped into messages, sent to known
    destinations (`orders` and `recommendations`). `OrderService` and `StatisticsService`
    consume and process the messages independently.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 如 [图 4-3](#image:shop-messages) 所示，我们可以使用*消息队列*来传输我们的事件。这些事件被包装成消息，发送到已知的目的地（`orders`
    和 `recommendations`）。`OrderService` 和 `StatisticsService` 独立地消费和处理这些消息。
- en: '![Architecture of the ecommerce shop using events and message brokers](assets/rsij_0403.png)'
  id: totrans-53
  prefs: []
  type: TYPE_IMG
  zh: '![基于事件和消息代理的电子商务店铺架构](assets/rsij_0403.png)'
- en: Figure 4-3\. Architecture of the ecommerce shop with events and message queues
  id: totrans-54
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 4-3\. 带有事件和消息队列的电子商务店铺架构
- en: It’s important for these destinations to persist the events as an ordered sequence.
    By keeping that sequence, the system can go back in time and reprocess the events.
    Such a *replay* mechanism, popular in the Kafka world, has multiple benefits.
    You can restart with a clean state after a disaster by reprocessing all the stored
    events. Then, if we change the recommendation algorithm from the statistic services,
    for example, it would be able to re-accumulate all the knowledge and derive new
    recommendations.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 对于这些目的地来说，持久化事件作为一个有序序列是很重要的。通过保持这个顺序，系统可以回溯并重新处理事件。这样的*重放*机制，在 Kafka 世界中很受欢迎，有多种好处。例如，在灾难后通过重新处理所有存储的事件可以重新启动一个干净的状态。然后，如果我们从统计服务改变推荐算法，它将能够重新累积所有知识并派生新的推荐。
- en: While the event emission sounds explicit in this example, that’s not always
    the case. For instance, events can be created from database writes.^([2](ch04.html#idm45358831644992))
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然在这个例子中事件的发射听起来很明确，但情况并非总是如此。例如，事件可以从数据库写入中创建。^([2](ch04.html#idm45358831644992))
- en: Commands and events are the basis of most of the interactions. While we use
    mostly commands, events come with significant benefits. Events are facts. Events
    tell a story, the story of your system, a narrative that describes your system’s
    evolution. In reactive systems, events are wrapped into messages, and these messages
    are sent to destinations, transported by message brokers such as AMQP or Kafka
    ([Figure 4-4](#image:reactive-architecture)). Such an approach solves two important
    architectural issues arising from the distributed systems. First, it naturally
    handles real-world asynchronicity. Second, it binds together services without
    relying on strong coupling. At the edge of the system, this approach uses commands
    most of the time, often relying on HTTP.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 命令和事件是大多数交互的基础。虽然我们主要使用命令，但事件带来了显著的好处。事件是事实。事件讲述一个故事，你系统的故事，描述你系统演变的叙述。在反应系统中，事件被包装成消息，并且这些消息被发送到目的地，通过消息代理如
    AMQP 或 Kafka（[图 4-4](#image:reactive-architecture)）。这种方法解决了分布式系统中出现的两个重要的架构问题。首先，它自然地处理现实世界的异步性。其次，它在不依赖强耦合的情况下将服务绑定在一起。在系统的边缘，这种方法大多数时候使用命令，通常依赖于
    HTTP。
- en: '![Overview of a reactive system](assets/rsij_0404.png)'
  id: totrans-58
  prefs: []
  type: TYPE_IMG
  zh: '![反应系统概述](assets/rsij_0404.png)'
- en: Figure 4-4\. Overview of a reactive system
  id: totrans-59
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 4-4\. 反应系统概述
- en: This asynchronous message-passing aspect of reactive systems forms the connective
    tissue. It not only grants the applications forming the system more autonomy and
    independence, but also enables resilience and elasticity. You may wonder how,
    and you will get the beginning of our response in the next section.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 反应系统中这种异步消息传递的特性形成了连接组织。它不仅赋予了构成系统的应用更多的自治和独立性，还能实现弹性和弹性。你可能会想知道如何做到这一点，在下一节中你将找到我们的开头回应。
- en: Destinations and Space Decoupling
  id: totrans-61
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 目的地和空间解耦
- en: The reactive applications, forming a reactive system, communicate using messages.
    They subscribe to destinations and receive the messages sent by other components
    to these destinations. These messages can carry commands or events, though as
    described in the previous section, events provide interesting benefits. These
    destinations are not bound to specific components or instances. They are virtual.
    Components must know only the name (generally business related, such as `orders`)
    of the destination, not who’s producing or consuming. It enables location transparency.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 响应式应用程序形成响应式系统，它们使用消息进行通信。它们订阅目的地并接收其他组件发送到这些目的地的消息。这些消息可以携带命令或事件，正如前一节所述，事件提供了一些有趣的好处。这些目的地不绑定到特定的组件或实例。它们是虚拟的。组件只需知道目的地的名称（通常是业务相关的，如
    `orders`），而不需要知道是谁在生产或消费。这使得位置透明性成为可能。
- en: If you are using Kubernetes, you may consider location transparency as already
    managed for you. Indeed, you can use Kubernetes *services* to implement location
    transparency. You have a single endpoint delegating to a group of selected *pods*.
    But this location transparency is somewhat limited and often tied to HTTP or request/reply
    protocols. Other environments can use service discovery infrastructure such as
    [HashiCorp Consul](https://consul.io) or [Netflix Eureka](https://oreil.ly/H9Ygn).
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您正在使用 Kubernetes，您可能已经考虑到位置透明性由系统自动管理。实际上，您可以使用 Kubernetes *服务* 来实现位置透明性。您只需使用一个端点来委派给一组选定的
    *pod*。但这种位置透明性在某种程度上是有限的，并且通常与 HTTP 或请求/回复协议相关联。其他环境可以使用诸如 [HashiCorp Consul](https://consul.io)
    或 [Netflix Eureka](https://oreil.ly/H9Ygn) 等服务发现基础设施。
- en: Using messages sent to a destination allows you, as the sender, to ignore who
    precisely is going to receive the message. You don’t know if someone is currently
    available or if multiple components or instances are waiting for your message.
    This number of consumers can evolve at runtime; more instances can be created,
    moved, or destroyed, and new components deployed. But for you, as a sender, you
    don’t need to know. You just use a specified destination. Let’s illustrate the
    advantages of this *addressability* by using the example from the previous section.
    `ShopService` emits `order placed` events carried inside messages sent to the
    `orders` destination ([Figure 4-3](#image:shop-messages)). It is likely possible
    that during a quiet period, only a single instance of `OrderService` runs. If
    there are not many orders, why bother having more? We could even imagine having
    no instance, and instantiating one when we receive an order. Serverless platforms
    are offering this *scale-from-zero* ability. However, over time, your shop gets
    more customers, and a single instance may not be enough. Thanks to location transparency,
    we can start other instances of `OrderService` to share the load ([Figure 4-5](#image:shop-elasticity)).
    `ShopService` is not modified and ignores this new topology.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 作为发送者，通过发送消息到目的地，您可以忽略具体是谁会接收该消息。您不知道当前是否有人可用，或者多个组件或实例是否在等待您的消息。这些消费者的数量可以在运行时发生变化；可以创建、移动或销毁更多实例，并部署新的组件。但作为发送者，您不需要知道这些。您只需使用指定的目的地。让我们通过前一节的示例来说明这种
    *可寻址性* 的优势。`ShopService` 发出 `order placed` 事件，这些事件被包含在发送到 `orders` 目的地的消息中（参见
    [Figure 4-3](#image:shop-messages)）。在安静期间，可能只有一个 `OrderService` 实例正在运行。如果订单不多，为什么要费心多部署呢？我们甚至可以想象没有任何实例，在收到订单时实例化一个。无服务器平台提供了这种
    *从零扩展* 的能力。然而，随着时间的推移，您的商店会吸引更多客户，单个实例可能不够用。由于位置透明性，我们可以启动其他 `OrderService` 实例来分担负载（参见
    [Figure 4-5](#image:shop-elasticity)）。`ShopService` 不会修改，也不会关心这种新的拓扑结构。
- en: '![Elasticity provided by the use of message passing](assets/rsij_0405.png)'
  id: totrans-65
  prefs: []
  type: TYPE_IMG
  zh: '![通过消息传递提供的弹性](assets/rsij_0405.png)'
- en: Figure 4-5\. Elasticity provided by the use of message passing
  id: totrans-66
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 4-5\. 通过消息传递提供的弹性
- en: The way the load is shared among the consumers is also irrelevant for the sender.
    It can be a round-robin, a load-based selection, or something more clever. When
    the load returns to normal, the system can reduce the number of instances and
    save resources. Note that this kind of elasticity works perfectly for stateless
    services. For stateful services, it may be harder, as the instances may have to
    share the state. However, solutions exist (though not without caveats), like the
    [Kubernetes `StatefulSet`](https://oreil.ly/kVRID) or an [in-memory data grid](https://oreil.ly/wNUIQ),
    to coordinate state among instances of the same service. Message passing also
    enables replication. Following the same principle, we can shadow the active `OrderService`
    instance and take over if the primary instance fails ([Figure 4-6](#image:shop-fail-over)).
    This approach avoids service disruption. That kind of failover may also require
    state sharing.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 消费者之间的负载共享方式对于发送者来说也是无关紧要的。可以是循环轮询、基于负载的选择，或者更聪明的方式。当负载恢复正常时，系统可以减少实例数量并节省资源。请注意，这种弹性对于无状态服务非常有效。对于有状态服务，可能更为困难，因为实例可能需要共享状态。不过，已存在解决方案（尽管存在一些注意事项），如[Kubernetes
    `StatefulSet`](https://oreil.ly/kVRID)或者[in-memory data grid](https://oreil.ly/wNUIQ)，用于协调同一服务实例之间的状态。消息传递还能实现复制。遵循相同原则，我们可以影子化活跃的`OrderService`实例，并在主实例失败时接管（参见[图 4-6](#image:shop-fail-over)）。这种方法避免了服务中断。此类故障转移可能还需要共享状态。
- en: '![Resilience provided by the use of message passing](assets/rsij_0406.png)'
  id: totrans-68
  prefs: []
  type: TYPE_IMG
  zh: '![使用消息传递提供的弹性](assets/rsij_0406.png)'
- en: Figure 4-6\. Resilience provided by the use of message passing
  id: totrans-69
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 4-6\. 使用消息传递提供的弹性
- en: By using message passing, our system becomes not only asynchronous, but also
    elastic and resilient. When you architect your system, you list the destinations
    that implement the communication pattern you want. In general, you would use one
    destination per type of event, but that’s not necessarily the case. However, avoid
    at all costs having a destination per component instance. It introduces coupling
    between the sender and the receiver, discarding the benefits. It also reduces
    the extensibility. Finally, it’s important to keep the set of destinations stable.
    Changing a destination would break the components using it or would force you
    to handle redirections.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 使用消息传递，我们的系统不仅变得异步，还变得具有弹性和弹性。在架构设计系统时，您会列出实现所需通信模式的目标。通常情况下，每种事件类型使用一个目标，但并非一定如此。但是，务必尽量避免每个组件实例使用一个目标。这会增加发送方和接收方之间的耦合，丧失优势。它还会降低可扩展性。最后，保持目标集合稳定非常重要。更改目标会打破使用它的组件或迫使您处理重定向问题。
- en: Time Decoupling
  id: totrans-71
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 时间解耦
- en: Location transparency is not the only benefit. Asynchronous message passing
    also enables time decoupling.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 透明定位并非唯一的好处。异步消息传递还能实现时间解耦。
- en: Modern message backbones, such as [AMQP 1.0](https://amqp.org), [Apache Kafka](https://kafka.apache.org/),
    and even Java Message Service (JMS), enable time decoupling. With these event
    brokers, events are not lost if there are no consumers. The events are stored
    and delivered later. Each broker has its own way. For instance, AMQP 1.0 uses
    persistent messages and durable subscribers to ensure message delivery. Kafka
    stores records in a durable, fault-tolerant, ordered log. The records can be retrieved
    so long as they remain stored within the topic.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 现代消息骨干，例如[AMQP 1.0](https://amqp.org)，[Apache Kafka](https://kafka.apache.org/)，甚至Java消息服务（JMS），都能实现时间解耦。使用这些事件代理，如果没有消费者，事件不会丢失。事件将被存储并稍后传递。每个代理都有自己的方式。例如，AMQP
    1.0使用持久消息和持久订阅者来确保消息传递。Kafka将记录存储在持久、容错、有序的日志中。只要它们保持存储在主题中，就可以检索记录。
- en: If our `ShopService` emits the finalized orders as events, it does not need
    to know whether `OrderService` is available. It knows that it’s going to be processed
    eventually. If, for example, no instances of `OrderService` are available when
    `ShopService` emits the event, it’s not lost. When an instance gets ready, it
    receives the pending orders and processes them. The user is then notified asynchronously
    with an email.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们的`ShopService`作为事件发出最终订单，它不需要知道`OrderService`是否可用。它知道订单最终会被处理。例如，当`ShopService`发出事件时，如果没有`OrderService`实例可用，订单不会丢失。当实例准备好时，它会接收待处理订单并进行处理。然后通过电子邮件异步通知用户。
- en: Of course, the message broker must be available and reachable. Most message
    brokers have replication abilities preventing unavailability issues and message
    loss.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，消息代理必须是可用和可达的。大多数消息代理都具备复制能力，以防止不可用问题和消息丢失。
- en: Note
  id: totrans-76
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: It is becoming common to store events in an event log. Such ordered and append-only
    structure represents the full history of your system. Every time the state changes,
    the system appends the new state to the log.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 将事件存储在事件日志中正变得越来越常见。这样有序且追加式的结构代表了系统的完整历史。每当状态变化时，系统都将新状态追加到日志中。
- en: Time decoupling increases the independence of our components. Time decoupling,
    combined with other features enabled by asynchronous message passing, achieves
    a high level of independence among our components and keeps coupling to a minimum.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 时间解耦增加了我们组件的独立性。时间解耦，结合异步消息传递启用的其他特性，实现了我们组件之间的高度独立性，并将耦合降至最低。
- en: The Role of Nonblocking Input/Output
  id: totrans-79
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 非阻塞输入/输出的作用
- en: At this point, you may wonder what the difference is between an application
    using Kafka or AMQP and a reactive system. Message passing is the essence of reactive
    systems, and most of them rely on some sort of message broker. Message passing
    enables resilience and elasticity, which lead to responsiveness. It promotes space
    and time decoupling, making our system much more robust.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 此时，你可能会想知道使用Kafka或AMQP的应用与响应式系统之间的区别是什么。消息传递是响应式系统的核心，大多数系统依赖某种消息代理。消息传递使得系统具备了弹性和响应能力。它促进了空间和时间的解耦，使我们的系统更加健壮。
- en: But reactive systems are not only exchanging messages. Sending and receiving
    messages must be done efficiently. To achieve this, Reactive promotes the use
    of nonblocking I/Os.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 但是响应式系统不仅仅是在交换消息。发送和接收消息必须高效完成。为了实现这一点，响应式系统推广使用非阻塞I/O。
- en: Blocking Network I/O, Threads, and Concurrency
  id: totrans-82
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 阻塞网络I/O、线程和并发
- en: To understand the benefits of nonblocking I/O, we need to know how blocking
    I/Os work. Let’s use a client/server interaction to illustrate. When a client
    sends a request to a server, the server processes it and sends back a response.
    HTTP, for instance, follows this principle. For this to happen, both the client
    and the server need to establish a connection before the interaction starts. We
    will not go into the depths of the [seven-layer model](https://oreil.ly/kcTBH)
    and the protocol stack involved in this interaction; you can find plenty of articles
    online about that topic.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 要理解非阻塞I/O的好处，我们需要了解阻塞I/O的工作原理。让我们使用客户端/服务器交互来说明。当客户端向服务器发送请求时，服务器处理它并发送回响应。例如，HTTP遵循这一原则。为了实现这一点，客户端和服务器在交互开始之前都需要建立连接。我们不会深入讨论[七层模型](https://oreil.ly/kcTBH)及其涉及的协议栈；你可以在网上找到许多关于这个主题的文章。
- en: Note
  id: totrans-84
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: Examples from this section can be run directly from your IDE. Use *chapter-4/non-blocking-io/src/main/java/org/acme/client/EchoClient.java*
    to invoke the started server. Be sure to avoid running multiple servers concurrently
    as they all use the same port (9999).
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 本节的示例可以直接从你的IDE中运行。使用*chapter-4/non-blocking-io/src/main/java/org/acme/client/EchoClient.java*来调用已启动的服务器。请确保避免并发运行多个服务器，因为它们都使用相同的端口（9999）。
- en: To establish that connection between the client and the server, we use `sockets`,
    as shown in [Example 4-1](#reactive-system::blocking-server).
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 为了建立客户端和服务器之间的连接，我们使用`sockets`，如示例[4-1](#reactive-system::blocking-server)所示。
- en: Example 4-1\. A single-threaded echo server using blocking I/O (*chapter-4/non-blocking-io/src/main/java/org/acme/blocking/BlockingEchoServer.java*)
  id: totrans-87
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例4-1。使用阻塞I/O的单线程回显服务器(*chapter-4/non-blocking-io/src/main/java/org/acme/blocking/BlockingEchoServer.java*)
- en: '[PRE0]'
  id: totrans-88
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: The client and server have to bind themselves to a socket forming the connection.
    The server listens to its socket for the client to connect. Once established,
    the client and server can both write and read data from the socket bound to that
    connection.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 客户端和服务器必须将自己绑定到一个套接字来建立连接。服务器监听它的套接字，等待客户端连接。一旦建立，客户端和服务器都可以在与该连接绑定的套接字上写入和读取数据。
- en: Traditionally, because it’s simpler, applications are developed using a synchronous
    development model. Such a development model executes instructions sequentially,
    one after the other. So when such applications interact across the network, they
    expect to continue using a synchronous development model even for I/O. This model
    uses synchronous communication and blocks the execution until the operation completes.
    In [Example 4-1](#reactive-system::blocking-server), we wait for a connection
    and handle it synchronously. We read and write using synchronous APIs. It’s simpler,
    but it leads to the use of blocking I/O.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 传统上，因为它更简单，应用程序是使用同步开发模式开发的。这种开发模式依次执行指令，一个接一个。因此，当这些应用程序通过网络进行交互时，它们期望继续使用同步开发模式进行I/O。这种模型使用同步通信并阻塞执行，直到操作完成。在[示例 4-1](#reactive-system::blocking-server)中，我们等待连接并同步处理它。我们使用同步API进行读写。这样做更简单，但会导致使用阻塞I/O。
- en: With blocking I/O, when the client sends a request to the server, the socket
    processing that connection and the corresponding thread that reads from it is
    blocked until some read data appears. The bytes are accumulated in the network
    buffer until everything is read and ready for processing. Until the operation
    is complete, the server can do nothing more but wait.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 使用阻塞I/O时，当客户端向服务器发送请求时，处理该连接的套接字以及从中读取数据的相应线程将被阻塞，直到出现一些可读数据。字节会在网络缓冲区中累积，直到所有数据都被读取并准备好进行处理。在操作完成之前，服务器除了等待之外什么也做不了。
- en: The consequence of this model is that we cannot serve more than one connection
    within a single thread. When the server receives a connection, it uses that thread
    to read the request, process it, and write the response. That thread is blocked
    until the last byte of the response is written on the wire. A single client connection
    blocks the server! Not very efficient, right?
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 这种模型的结果是我们无法在单个线程中服务多个连接。当服务器接收到连接时，它会使用该线程读取请求、处理请求并写入响应。该线程会被阻塞，直到响应的最后一个字节被写入线路。单个客户端连接会阻塞服务器！效率不高，对吧？
- en: To execute concurrent requests with this approach, the only way is to have multiple
    threads. We need to allocate a new thread for each client connection. To handle
    more clients, you need to use more threads and process each request on a different
    *worker* thread; see [Example 4-2](#multi-threaded-server).
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 使用这种方法执行并发请求的唯一方法是使用多个线程。我们需要为每个客户端连接分配一个新线程。为了处理更多客户端，您需要使用更多线程并在不同的*工作*线程上处理每个请求；参见[示例 4-2](#multi-threaded-server)。
- en: Example 4-2\. Principles behind multithreaded server using blocking I/O
  id: totrans-94
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 4-2\. 使用阻塞I/O的多线程服务器背后的原理
- en: '[PRE1]'
  id: totrans-95
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: To implement this principle, we need a thread pool (*worker pool*). When the
    client connects, we accept the connection and offload the processing to a separate
    thread. Thus, the server thread can still accept other connections, as shown in
    [Example 4-3](#reactive-system::blocking-server-workers).
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 要实现这一原则，我们需要一个线程池（*工作池*）。当客户端连接时，我们接受连接并将处理分派到单独的线程中。因此，服务器线程仍然可以接受其他连接，如[示例 4-3](#reactive-system::blocking-server-workers)所示。
- en: Example 4-3\. A multithreaded echo server using blocking I/O (*chapter-4/non-blocking-io/src/main/java/org/acme/blocking/BlockingWithWorkerEchoServer.java*)
  id: totrans-97
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 4-3\. 使用阻塞I/O的多线程回显服务器（*chapter-4/non-blocking-io/src/main/java/org/acme/blocking/BlockingWithWorkerEchoServer.java*）
- en: '[PRE2]'
  id: totrans-98
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: '[![1](assets/1.png)](#co_design_principles_of_reactive_systems_CO1-1)'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: '[![1](assets/1.png)](#co_design_principles_of_reactive_systems_CO1-1)'
- en: Create a worker thread pool to handle the request.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 创建一个工作线程池来处理请求。
- en: '[![2](assets/2.png)](#co_design_principles_of_reactive_systems_CO1-2)'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: '[![2](assets/2.png)](#co_design_principles_of_reactive_systems_CO1-2)'
- en: Offload the processing of the request to a thread from the thread pool. The
    rest of the code is unchanged.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 将请求的处理分派到线程池中的一个线程。其余代码保持不变。
- en: 'That’s the model used, by default, in traditional Java frameworks such as Jakarta
    EE or Spring.^([3](ch04.html#idm45358831203712)) Even if these frameworks may
    use nonblocking I/O under the hood, they use *worker* threads to handle the requests.
    But this approach has many drawbacks, including:'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 这是传统Java框架（如Jakarta EE或Spring）默认使用的模型。即使这些框架可能在内部使用非阻塞I/O，它们仍然使用*工作*线程来处理请求。但这种方法有许多缺点，包括：
- en: Each thread requires a stack of memory allocated to it. With the increasing
    number of connections, spawning multiple threads and switching between them will
    consume not only memory but also CPU cycles.
  id: totrans-104
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 每个线程都需要分配给它的内存栈。随着连接数量的增加，产生多个线程并在它们之间进行切换将消耗内存和CPU周期。
- en: At any given point in time, multiple threads could be waiting for the client
    requests. That’s a massive waste of resources.
  id: totrans-105
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在任何给定时间点，可能有多个线程在等待客户端请求。这是资源的巨大浪费。
- en: Your concurrency (the number of requests you can handle at a given time—10 in
    the previous example) is limited by the number of threads you can create.
  id: totrans-106
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你的并发性（在给定时间内能处理的请求数量——如前面示例中的 10）受到可以创建的线程数的限制。
- en: On public clouds, the blocking I/O approach inflates your monthly bill; on private
    clouds, it reduces the deployment density. Therefore, this approach is not ideal
    if you have to handle many connections or implement applications dealing with
    a lot of I/O. In the realm of distributed systems, that’s often the case. Luckily,
    there’s an alternative.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 在公共云上，阻塞 I/O 方法会增加你的月度账单；在私有云上，它会减少部署密度。因此，如果需要处理多个连接或实现涉及大量 I/O 的应用程序，则此方法并不理想。在分布式系统领域，这种情况经常发生。幸运的是，有一个替代方案。
- en: How Does Nonblocking I/O Work?
  id: totrans-108
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 非阻塞 I/O 是如何工作的？
- en: The alternative is *nonblocking I/O*. The difference is evident from its name.
    Instead of waiting for the completion of the transmission, the caller is not blocked
    and can continue its processing. The magic happens in the operating system. With
    nonblocking I/O, the operating system queues the requests. The system processes
    the actual I/O in the future. When the I/O completes, and the response is ready,
    a *continuation*, often implemented as a callback, happens and the caller receives
    the result.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 替代方案是 *非阻塞 I/O*。其差异从名称中就能看出来。与等待传输完成不同，调用者不会被阻塞，可以继续其处理过程。这种魔法发生在操作系统中。使用非阻塞
    I/O，操作系统将请求排队。系统在未来处理实际的 I/O。当 I/O 完成并且响应准备好时，会发生一个 *continuation*，通常实现为回调函数，调用者接收结果。
- en: 'To better understand the benefits and see how these continuations work, we
    need to look under the hood: how is nonblocking I/O implemented? We already mentioned
    a queue. The system enqueues I/O operations and returns immediately, so the caller
    is not blocked while waiting for the I/O operations to complete. When a response
    comes back, the system stores the result in a structure. When the caller needs
    the result, it interrogates the system to see whether the operation completed
    ([Example 4-4](#reactive-system::non-blocking-server-loop)).'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 要更好地理解其优势并看看这些 continuation 是如何工作的，我们需要深入了解一下：非阻塞 I/O 是如何实现的？我们已经提到了一个队列。系统将
    I/O 操作入队并立即返回，因此调用者在等待 I/O 操作完成时不会被阻塞。当响应返回时，系统将结果存储在一个结构中。当调用者需要结果时，它询问系统是否完成操作（[示例 4-4](#reactive-system::non-blocking-server-loop)）。
- en: Example 4-4\. An echo server using nonblocking I/O (*chapter-4/non-blocking-io/src/main/java/org/acme/nio/NonBlockingServer.java*)
  id: totrans-111
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 4-4\. 使用非阻塞 I/O 的回显服务器（*chapter-4/non-blocking-io/src/main/java/org/acme/nio/NonBlockingServer.java*）
- en: '[PRE3]'
  id: totrans-112
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Nonblocking I/O introduces a few new concepts:'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 非阻塞 I/O 引入了一些新概念：
- en: We don’t use `InputStream` or `OutputStream` (which are blocking by nature),
    but `Buffer`, which is a temporary storage.
  id: totrans-114
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们不使用 `InputStream` 或 `OutputStream`（它们天生是阻塞的），而是使用 `Buffer`，这是一个临时存储。
- en: '`Channel` can be viewed as an endpoint for an open connection.'
  id: totrans-115
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Channel` 可以被视为开放连接的端点。'
- en: '`Selector` is the cornerstone of nonblocking I/O in Java.'
  id: totrans-116
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Selector` 是 Java 中非阻塞 I/O 的基石。'
- en: '`Selector` manages multiple channels, either server or client channels. When
    you use nonblocking I/O, you create `Selector`. Each time you deal with a new
    channel, you register this channel on the selector with the events you are interested
    in (accept, ready to read, ready to write).'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: '`Selector` 管理多个通道，可以是服务器通道或客户端通道。当您使用非阻塞 I/O 时，您会创建 `Selector`。每当处理新通道时，您都会将此通道注册到选择器中，并指定您感兴趣的事件（接受、准备读取、准备写入）。'
- en: Then your code polls `Selector` with only one thread to see if the channel is
    ready. When the channel is ready to read or write, you can start to read and write.
    We don’t need to have a thread for every channel at all, and a single thread can
    handle many channels.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，你的代码使用单个线程轮询 `Selector`，查看通道是否准备就绪。当通道准备好读取或写入时，可以开始读取和写入。我们根本不需要为每个通道都创建一个线程，一个单独的线程可以处理多个通道。
- en: The selector is an abstraction of the nonblocking I/O implementation provided
    by the underlying operating system. Various approaches, depending on the operating
    systems, are available.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 选择器是底层操作系统提供的非阻塞 I/O 实现的抽象。根据操作系统的不同，有多种方法可供选择。
- en: First, `select` was implemented in the 1980s. It supports the registration of
    1,024 sockets. That was certainly enough in the ’80s, but not anymore.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，`select`是在上世纪80年代实现的。它支持注册1,024个套接字。在80年代这当然足够了，但现在不再是这样了。
- en: '`poll` is a replacement for `select` introduced in 1997. The most significant
    difference is that `poll` no longer limits the number of sockets. However, as
    with `select`, the system tells you only how many channels are ready, not which
    ones. You need to iterate over the set of channels to check which ones are ready.
    When there are few channels, it is not a big problem. Once the number of channels
    is more than hundreds of thousands, the iteration time is considerable.'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: '`poll`是1997年引入的`select`的替代品。最大的区别是，`poll`不再限制套接字的数量。但是，与`select`一样，系统仅告诉您有多少通道准备就绪，而不是哪些通道准备就绪。您需要迭代通道集合以检查哪些通道已准备就绪。当通道较少时，这不是一个大问题。一旦通道数量超过数十万，迭代时间就会相当可观。'
- en: Then, `epoll` appeared in 2002 in the Linux Kernel 2.5.44. `Kqueue` appeared
    in FreeBSD in 2000 and `/dev/poll` in Solaris around the same time. These mechanisms
    return the set of channels that are ready to be processed—no more iteration over
    every channel! Finally, Windows systems provide IOCP, an optimized implementation
    of `select`.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，`epoll`在2002年出现在Linux内核2.5.44中。`Kqueue`在2000年出现在FreeBSD中，而`/dev/poll`在同一时间左右出现在Solaris中。这些机制返回准备处理的通道集合——不再需要迭代处理每个通道！最后，Windows系统提供了IOCP，这是`select`的优化实现。
- en: What’s important to remember is that regardless of how the operating systems
    implement it, with nonblocking I/O, you need only a single thread to handle multiple
    requests. This model is much more efficient than blocking I/O, as you don’t need
    to create threads to handle concurrent requests. Eliminating these extra threads
    makes your application much more efficient in terms of memory consumption (about
    1 MB per thread) and avoids wasting CPU cycles because of context switches (1–2
    microseconds per switch).^([4](ch04.html#idm45358830663584))
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 重要的是要记住，无论操作系统如何实现，使用非阻塞I/O，您只需要一个线程来处理多个请求。这个模型比阻塞I/O更高效，因为您不需要创建线程来处理并发请求。消除这些额外的线程使您的应用程序在内存消耗（每个线程约为1
    MB）方面更高效，并避免因上下文切换而浪费CPU周期（每次切换1-2微秒）^([4](ch04.html#idm45358830663584))
- en: Reactive systems recommend the use of nonblocking I/O to receive and send messages.
    Thus, your application can handle more messages with fewer resources. Another
    advantage is that an idle application would consume almost no memory or CPUs.
    You don’t have to reserve resources up front.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 响应式系统建议使用非阻塞I/O来接收和发送消息。因此，您的应用程序可以使用更少的资源处理更多的消息。另一个优点是，空闲应用程序几乎不会消耗内存或CPU。您不必预先保留资源。
- en: Reactor Pattern and Event Loop
  id: totrans-125
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 反应器模式和事件循环
- en: 'Nonblocking I/O gives us the possibility to handle multiple concurrent requests
    or messages with a single thread. How could we handle these concurrent requests?
    How do we structure our code when using nonblocking I/O? The examples given in
    the previous section are not scaling well; we can quickly see that implementing
    a REST API with such a model will be a nightmare. Besides, we would like to avoid
    using worker threads, as it would discard the advantages of nonblocking I/O. We
    need something different: the reactor pattern.'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 非阻塞I/O使我们有可能使用单个线程处理多个并发请求或消息。我们如何处理这些并发请求？在使用非阻塞I/O时如何构建我们的代码结构？前一节中给出的示例的性能不佳；我们很快就会看到，使用这种模型实现REST
    API将是一场噩梦。此外，我们希望避免使用工作线程，因为这将抛弃非阻塞I/O的优势。我们需要不同的东西：反应器模式。
- en: The *reactor pattern*, illustrated in [Figure 4-7](#image:event-loop), allows
    associating I/O events with *event handlers*. The *reactor*, the cornerstone of
    this mechanism, invokes the event handlers when the expected event is received.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: '*反应器模式*，如[图 4-7](#image:event-loop)所示，允许将I/O事件与*事件处理程序*关联起来。*反应器*，这个机制的基石，当接收到预期的事件时调用事件处理程序。'
- en: The purpose of the reactor pattern is to avoid creating a thread for each message,
    request, and connection. This pattern receives events from multiple channels and
    sequentially distributes them to the corresponding event handlers.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 反应器模式的目的是避免为每个消息、请求和连接创建线程。该模式从多个通道接收事件，并将它们顺序地分配给相应的事件处理程序。
- en: '![The reactor pattern](assets/rsij_0407.png)'
  id: totrans-129
  prefs: []
  type: TYPE_IMG
  zh: '![反应器模式](assets/rsij_0407.png)'
- en: Figure 4-7\. The reactor pattern
  id: totrans-130
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图4-7。反应器模式
- en: Implementation of the reactor pattern uses an *event loop* ([Figure 4-7](#image:event-loop)).
    It’s a thread iterating over the set of channels, and when data is ready to be
    consumed, the event loop invokes the associated event handler sequentially, in
    a single-threaded manner.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 反应器模式的实现使用了一个 *事件循环*（[图 4-7](#image:event-loop)）。它是一个线程，迭代遍历通道集，并在数据准备就绪时按顺序、以单线程方式调用相关的事件处理程序。
- en: When you combine nonblocking I/O and the reactor pattern, you organize your
    code as a set of event handlers. That approach works wonderfully with reactive
    code as it exposes the notion of events, the essence of Reactive.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 当您将非阻塞 I/O 与反应器模式相结合时，您会将代码组织为一组事件处理程序。这种方法与反应式代码非常契合，因为它暴露了事件的概念，这是反应式的本质。
- en: 'The reactor pattern has two variants:'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 反应器模式有两个变种：
- en: The *multireactor* pattern uses multiple event loops (generally one or two per
    CPU core), which increase the concurrency of the application. Multireactor pattern
    implementations, such as Eclipse Vert.x, call the event handlers in a single-threaded
    manner to avoid deadlock or state visibility issues.
  id: totrans-134
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*multireactor* 模式使用多个事件循环（通常每个 CPU 内核一个或两个），这增加了应用程序的并发性。多反应器模式的实现，如 Eclipse
    Vert.x，以单线程方式调用事件处理程序，以避免死锁或状态可见性问题。'
- en: The *proactor* pattern can be seen as an asynchronous version of the reactor
    pattern. Long-running event handlers invoke a continuation when they complete.
    Such mechanisms allow mixing nonblocking and blocking I/O ([Figure 4-8](#image:proactor)).
  id: totrans-135
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*proactor* 模式可以看作是反应器模式的异步版本。长时间运行的事件处理程序在完成时调用续集。这种机制允许混合非阻塞和阻塞 I/O（[图 4-8](#image:proactor)）。'
- en: '![the proactor pattern](assets/rsij_0408.png)'
  id: totrans-136
  prefs: []
  type: TYPE_IMG
  zh: '![proactor 模式](assets/rsij_0408.png)'
- en: Figure 4-8\. The proactor pattern
  id: totrans-137
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 4-8\. proactor 模式
- en: You can integrate nonblocking event handlers, as well as blocking ones, by offloading
    their execution to separate threads when it’s inevitable. When their execution
    completes, the proactor pattern invokes the continuation. As you will see in [Chapter 6](ch06.html#quarkus-reactive),
    this is the pattern used by Quarkus.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以通过将其执行分派到单独的线程来集成非阻塞事件处理程序以及阻塞事件处理程序，当不可避免地需要时。当它们的执行完成时，proactor 模式将调用续集。正如您将在[第
    6 章](ch06.html#quarkus-reactive)中看到的，这是 Quarkus 使用的模式。
- en: Anatomy of Reactive Applications
  id: totrans-139
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 反应式应用程序的解剖
- en: In the last few years, many frameworks have popped up, offering reactive application
    support. Their goal is to simplify the implementation of reactive applications.
    They achieve this by providing higher-level primitives and APIs to handle events
    and abstract nonblocking I/O.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 在过去几年中，许多框架已经涌现，提供反应式应用程序支持。它们的目标是简化反应式应用程序的实现。它们通过提供更高级的原语和 API 来处理事件和抽象非阻塞
    I/O 来实现这一目标。
- en: Indeed, and you may have recognized this already, using nonblocking I/O is not
    that simple. Combining this with a reactor pattern (or a variant) can be convoluted.
    Fortunately, alongside frameworks, libraries and toolkits are doing the heavy
    lifting. Netty is an asynchronous event-driven network application framework leveraging
    nonblocking I/O to build highly concurrent applications. It’s the most used library
    to handle nonblocking I/O in the Java world. But Netty can be challenging. [Example 4-5](#reactive-system::netty-echo)
    implements the *echo* TCP server using Netty.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 实际上，您可能已经意识到了，使用非阻塞 I/O 并不是那么简单。将其与反应器模式（或变体）结合使用可能会很复杂。幸运的是，随着框架的出现，库和工具包正在承担繁重的工作。Netty
    是一个异步事件驱动的网络应用程序框架，利用非阻塞 I/O 构建高并发应用程序。它是处理 Java 世界中非阻塞 I/O 的最常用库。但是 Netty 可能会很具有挑战性。[示例 4-5](#reactive-system::netty-echo)
    使用 Netty 实现了 *echo* TCP 服务器。
- en: Example 4-5\. An echo server using Netty (*chapter-4/non-blocking-io/src/main/java/org/acme/netty/NettyEchoServer.java*)
  id: totrans-142
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 4-5\. 使用 Netty 的回显服务器（*第 4 章 / 非阻塞 I/O / src / main / java / org / acme /
    netty / NettyEchoServer.java*）
- en: '[PRE4]'
  id: totrans-143
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: The Vert.x toolkit, based on top of Netty, provides higher-level features to
    build reactive applications such as HTTP clients and servers, messaging clients,
    etc. Typically, the same *echo* TCP server using Vert.x looks like [Example 4-6](#reactive-system::vertx-echo).
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 基于 Netty 的 Vert.x 工具包提供了构建反应式应用程序所需的更高级功能，例如 HTTP 客户端和服务器、消息客户端等。通常，使用 Vert.x
    的相同 *echo* TCP 服务器看起来像[示例 4-6](#reactive-system::vertx-echo)。
- en: Example 4-6\. An echo server using Vert.x (*chapter-4/non-blocking-io/src/main/java/org/acme/vertx/VertxEchoServer.java*)
  id: totrans-145
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 4-6\. 使用 Vert.x 的回显服务器（*第 4 章 / 非阻塞 I/O / src / main / java / org / acme
    / vertx / VertxEchoServer.java*）
- en: '[PRE5]'
  id: totrans-146
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Most Java frameworks offering Reactive capabilities are based on Netty or Vert.x.
    As shown in [Figure 4-9](#image:reactive-framework), they all follow the same
    type of blueprint.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数提供响应能力的 Java 框架基于 Netty 或 Vert.x。如[图 4-9](#image:reactive-framework)所示，它们都遵循相同类型的蓝图。
- en: '![The common architecture of reactive frameworks](assets/rsij_0409.png)'
  id: totrans-148
  prefs: []
  type: TYPE_IMG
  zh: '![响应式框架的常见架构](assets/rsij_0409.png)'
- en: Figure 4-9\. The common architecture of reactive frameworks
  id: totrans-149
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 4-9\. 响应式框架的常见架构
- en: At the bottom, you have the nonblocking I/O. Generally, frameworks use Netty
    or Vert.x. This layer handles client connections, outbound requests, and response
    writing. In other words, it manages the I/O part. Most of the time, this layer
    implements the reactor pattern (or a variant), and so provides an event-loop-based
    model.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 底层是非阻塞 I/O。通常，框架使用 Netty 或 Vert.x。这一层处理客户端连接、出站请求和响应写入。换句话说，它管理 I/O 部分。大多数情况下，这一层实现反应器模式（或其变体），因此提供基于事件循环的模型。
- en: Then, in the second layer, you have the *reactive framework* per se. The role
    of this layer is to provide high-level APIs that are easy to use. You use these
    APIs to write your application code. Instead of having to handle nonblocking I/O
    channels, this layer provides high-level objects such as HTTP requests, responses,
    Kafka messages, and so on. Much easier!
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，在第二层，你有本身的*响应式框架*。这一层的作用是提供易于使用的高级 API。你可以使用这些 API 编写应用程序代码。与处理非阻塞 I/O 通道不同，这一层提供高级对象，如
    HTTP 请求、响应、Kafka 消息等。要简单得多！
- en: Finally, in the top layer, you have your application. Your code does not need
    to touch nonblocking I/O concepts, thanks to the reactive framework. It can focus
    on incoming events and handle them. Your code is *just* a collection of event
    handlers. It can use the features provided by the reactive framework to interact
    with other services or middleware.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，在顶层，你有你的应用程序。由于响应式框架的帮助，你的代码不需要涉及非阻塞 I/O 概念。它可以专注于接收事件并处理它们。你的代码只是一组事件处理器。它可以使用响应式框架提供的功能与其他服务或中间件交互。
- en: 'But there is a catch. The event handler from your code is invoked using the
    *event loop* thread (an I/O thread). If your code blocks this thread, no other
    concurrent events can be processed. It would be a disaster in terms of responsiveness
    and concurrency. The consequence of such an architecture is clear: your code must
    be nonblocking. It must never block the I/O threads, as they are rare and are
    used to handle multiple concurrent requests. To achieve this, you could offload
    the processing of some events to a worker thread (using the proactor pattern).
    While it can discard some of the benefits of nonblocking I/O, it is sometimes
    the most rational choice ([Figure 4-10](#image:event-loop-worker)). Nevertheless,
    we should not abuse this as it would discard the reactive benefits and make the
    application slow. The multiple context switches required to handle an event on
    a worker thread penalizes the response time.'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 但是有一个问题。来自你代码中的事件处理器是使用*事件循环*线程（即 I/O 线程）调用的。如果你的代码阻塞了这个线程，那么没有其他并发事件可以被处理。这在响应性和并发性方面将是一场灾难。这种架构的后果显而易见：你的代码必须是非阻塞的。它绝不能阻塞
    I/O 线程，因为它们是稀有的，并且用于处理多个并发请求。为了实现这一点，你可以将某些事件的处理卸载到工作线程中（使用 proactor 模式）。虽然这可能会丢弃非阻塞
    I/O 的一些好处，但有时这是最明智的选择（[图 4-10](#image:event-loop-worker)）。然而，我们不应滥用这一点，因为这将丢弃响应式的优势并使应用程序变慢。在工作线程上处理事件所需的多次上下文切换会影响响应时间。
- en: '![Running some event handlers on worker threads](assets/rsij_0410.png)'
  id: totrans-154
  prefs: []
  type: TYPE_IMG
  zh: '![在工作线程上运行一些事件处理器](assets/rsij_0410.png)'
- en: Figure 4-10\. Running some event handlers on worker threads
  id: totrans-155
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 4-10\. 在工作线程上运行一些事件处理器
- en: Typically, our applications from [Chapter 2](ch02.html#quarkus) and [Chapter 3](ch03.html#distributed-system)
    rely on such a mechanism.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 典型地，我们在[第二章](ch02.html#quarkus)和[第三章](ch03.html#distributed-system)中的应用程序依赖于这样的机制。
- en: Another possibility is to rely only on nonblocking code, relying on asynchronous
    APIs provided by the reactive framework. These APIs would be nonblocking, and
    if the business logic involved I/O, it uses nonblocking I/O. Every time an *event
    handler* executes an asynchronous operation, another handler (the continuation)
    is registered, and when the expected event arrives, the event loop invokes it.
    Thus, the processing is divided into smaller handlers running asynchronously.
    That model is the most efficient and embraces the concepts entirely behind Reactive.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 另一种可能性是仅依赖非阻塞代码，依赖响应式框架提供的异步 API。这些 API 将是非阻塞的，如果业务逻辑涉及 I/O，则使用非阻塞 I/O。每当一个*事件处理程序*执行异步操作时，将注册另一个处理程序（继续执行），并且当预期的事件到达时，事件循环将调用它。因此，处理被分成更小的异步运行处理程序。这种模式是最高效的，并完全接纳了反应式背后的概念。
- en: Summary
  id: totrans-158
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: Reactive systems are about building better distributed systems. They don’t aim
    to hide the nature of distributed systems but, on the contrary, embrace it.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 反应式系统是关于构建更好的分布式系统。它们的目标不是隐藏分布式系统的本质，而是相反地接受它。
- en: 'In this chapter, you learned the following:'
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，您学到了以下内容：
- en: The four pillars of reactive systems (asynchronous message passing, elasticity,
    resilience, and responsiveness)
  id: totrans-161
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 反应式系统的四大支柱（异步消息传递、弹性、弹性和响应能力）
- en: How asynchronous message passing enables elasticity and resilience, and increases
    the autonomy of each individual component
  id: totrans-162
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 异步消息传递如何实现弹性和弹性，并增加每个单独组件的自治性
- en: The role of commands and events in a distributed system
  id: totrans-163
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在分布式系统中命令和事件的角色
- en: How nonblocking I/O improves resource utilization in reactive applications
  id: totrans-164
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 非阻塞 I/O 如何提升反应式应用程序中的资源利用率
- en: But this last point has a significant drawback, as we need to write nonblocking
    code. What a coincidence! The next chapter is precisely about that!
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 但是这最后一点有一个显著的缺点，因为我们需要编写非阻塞代码。多么巧合！下一章正好讲述这个！
- en: ^([1](ch04.html#idm45358831669616-marker)) [“Don’t Build a Distributed Monolith”](https://oreil.ly/CtY3x)
    by Ben Christensen is an interesting talk about distributed monoliths and why
    you should avoid them.
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: ^([1](ch04.html#idm45358831669616-marker)) [“不要构建分布式单体”](https://oreil.ly/CtY3x)
    由 Ben Christensen 是一个关于分布式单体的有趣演讲，讲述了为什么应该避免它们。
- en: ^([2](ch04.html#idm45358831644992-marker)) This pattern is called [Change Data
    Capture](https://oreil.ly/Umhs9). Frameworks such as [Debezium](https://debezium.io)
    are a key element of reactive systems when using databases, as the events are
    emitted without any impact on the application code.
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: ^([2](ch04.html#idm45358831644992-marker)) 这种模式称为[变更数据捕获](https://oreil.ly/Umhs9)。像[Debezium](https://debezium.io)这样的框架在使用数据库时是反应式系统的关键组成部分，因为这些事件会在不影响应用程序代码的情况下发出。
- en: ^([3](ch04.html#idm45358831203712-marker)) We are referring to the traditional
    Spring Framework. Reactive Spring is based on nonblocking I/O.
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: ^([3](ch04.html#idm45358831203712-marker)) 我们正在指的是传统的 Spring Framework。响应式 Spring
    基于非阻塞 I/O。
- en: ^([4](ch04.html#idm45358830663584-marker)) [“Measuring Context Switching and
    Memory Overheads for Linux Threads”](https://oreil.ly/hv2Uy) by Eli Bendersky
    provides interesting data about the cost of threads on Linux.
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: ^([4](ch04.html#idm45358830663584-marker)) [“测量 Linux 线程上的上下文切换和内存开销”](https://oreil.ly/hv2Uy)
    由 Eli Bendersky 提供了有关 Linux 线程成本的有趣数据。
