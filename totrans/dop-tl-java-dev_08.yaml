- en: Chapter 8\. Deploying for Developers
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Ana-Maria Mihalceanu
  prefs: []
  type: TYPE_NORMAL
- en: However beautiful the strategy, you should occasionally look at the results.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Sir Winston Churchill
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: When computers were extremely large and expensive, manufacturers often bundled
    together the software with the hardware. With the development of mass-market software,
    this type of operation was time-consuming, and new forms of software distribution
    emerged. Today’s development processes focus on decoupling build and deployment
    activities to facilitate fast software distribution and parallel activities in
    teams.
  prefs: []
  type: TYPE_NORMAL
- en: The deployment of an application represents the transformation of that software
    from a packaged artifact to an operational working state. Modern development days
    require this transformation to happen as fast as possible in order to get rapid
    feedback about the running state of our system.
  prefs: []
  type: TYPE_NORMAL
- en: 'As a developer, your focus is mainly on writing performant application code.
    Yet DevOps is collaboration centric, and your work should flawlessly blend within
    the infrastructure. While looking at your deployment process, you should continuously
    ask yourself, “What instructions would a machine need to execute this deployment
    as I envisioned it?” and share those with the colleagues or experts in charge
    of the infrastructure and automation. When planning a deployment process, you
    can make a wish list that you can later scale to more components of the distributed
    system:'
  prefs: []
  type: TYPE_NORMAL
- en: To gradually extend the functionalities of your system, conduct small deployments
    often. Using this approach, you can easily roll back to a previously working state
    in case of failures.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Isolate deployment of each microservice, as you should be able to scale or replace
    it individually.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: You should be able to reuse in another environment an already deployed microservice.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Automate infrastructure deployment and evolve it with your application features.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Regardless of the container orchestration platform where you will deploy any
    of your microservices, you likely will start by packaging the application and
    continue with the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Building and pushing a container image
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Choosing and implementing a deployment strategy
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'As the application deployment progresses throughout various stages or environments,
    is likely for you to get involved in the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Workload management
  prefs: []
  type: TYPE_NORMAL
- en: Refine health checks and the amount of CPU and memory used to avoid slow or
    nonresponsive functionalities.
  prefs: []
  type: TYPE_NORMAL
- en: Observability aspects
  prefs: []
  type: TYPE_NORMAL
- en: Use metrics, logs, and traces to provide visibility into internals of your distributed
    systems and measure its outputs.
  prefs: []
  type: TYPE_NORMAL
- en: This chapter walks you through these activities and explores their impact at
    scale.
  prefs: []
  type: TYPE_NORMAL
- en: Building and Pushing Container Images
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Deploying applications to containers requires creating the Java application
    artifacts and building container images. By leveraging the recommended artifact
    formats and practices shared in [Chapter 6](ch06.xhtml#package_management), we
    can focus on producing container images.
  prefs: []
  type: TYPE_NORMAL
- en: Starting with Docker’s appearance in 2013, building container images using Dockerfiles
    became popular. A *Dockerfile* is a standardized image format consisting of the
    base operating system, application artifacts to be added, and required runtime
    configurations. Essentially, this file is the blueprint for how your future container
    will behave. As explained in [Chapter 3](ch03.xhtml#thinking_in_containers), besides
    Docker, you can build container images with tools like [Podman](https://podman.io),
    [Buildah](https://buildah.io), and [kaniko](https://oreil.ly/X1A8A).
  prefs: []
  type: TYPE_NORMAL
- en: As DevOps methodology relies on good communication among application developers
    and infrastructure engineers, some teams find it best to keep the Dockerfiles
    at the repository root. Moreover, scripts or pipelines can further use that location
    when instrumenting a container image build. In addition to writing your Dockerfile,
    Java-specific options can help you make container images part of your standard
    build processes, such as Eclipse JKube or Jib.
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Using Java-specific tools to generate and push container images might tempt
    you to control the entire runtime from application code. To avoid tight coupling
    between infrastructure and application code, you should configure those tools
    with parameters that can be overwritten at build or runtime. Modern Java frameworks
    provide customization of configuration files under *src/main/resources*. The examples
    from this chapter use parameters in project configuration files to showcase this
    approach.
  prefs: []
  type: TYPE_NORMAL
- en: Managing Container Images by Using Jib
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Google’s [Jib](https://oreil.ly/nWoWY) is one of the tools that you can use
    to containerize Java applications without writing a Dockerfile. It provides a
    Java library, and Maven and Gradle plug-ins for creating OCI-compatible container
    images. Additionally, the tool does not require running the Docker daemon locally
    in order to produce a container image.
  prefs: []
  type: TYPE_NORMAL
- en: Jib takes advantage of image layering and registry caching to achieve fast,
    incremental builds. The tool can create reproducible build images as long as the
    inputs remain the same.
  prefs: []
  type: TYPE_NORMAL
- en: 'To begin using Jib within your Maven project, set up the authentication method
    for the target container registry by using any of the following:'
  prefs: []
  type: TYPE_NORMAL
- en: System properties `jib.to.auth.username` and `jib.to.auth.password`
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`<to>` section in the plug-in configuration with `username` and `password`
    elements'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A `<server>` configuration in *~/.m2/settings.xml*
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Previous login into a registry with Docker login (credentials in a credential
    helper or in *~/.docker/config.json*)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Caution
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: If you are using a specific base image registry, you can set up its credentials
    by using the `<from>` section in the plug-in configuration or `jib.from.auth.username`
    and `jib.from.auth.password` system properties.
  prefs: []
  type: TYPE_NORMAL
- en: 'Next, let’s configure the Maven plug-in in your *pom.xml*:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'The image tag configuration is mandatory and is the target path in the container
    registry. Now you can build the image to a container registry with a single command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'If you would like to build and push the container image by using Gradle, you
    can configure the authentication in one of these ways:'
  prefs: []
  type: TYPE_NORMAL
- en: Use the `to` and `from` section in the plug-in configuration in *build.gradle*.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Connect into a registry with a Docker login command (store credentials in a
    credential helper or in *~/.docker/config.json*).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Next, add the plug-in to your *build.gradle*:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'And invoke the following command in a terminal window:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'To simplify container image customization when using Jib, some frameworks have
    integrated the plug-in as a dependency library. For example, Quarkus provides
    the *quarkus-container-image-jib* extension for personalizing the container image
    build process. Using this extension, we can revisit the Quarkus example from [Chapter 4](ch04.xhtml#dissecting_the_monolith)
    and add it using the following Maven command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'Furthermore, you can customize the image details in *src/main/resources/application.properties*:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: '[![1](Images/1.png)](#co_deploying_for_developers_CO1-1)'
  prefs: []
  type: TYPE_NORMAL
- en: The extension used for building (and pushing) container images.
  prefs: []
  type: TYPE_NORMAL
- en: '[![2](Images/2.png)](#co_deploying_for_developers_CO1-2)'
  prefs: []
  type: TYPE_NORMAL
- en: The container registry to use.
  prefs: []
  type: TYPE_NORMAL
- en: '[![3](Images/3.png)](#co_deploying_for_developers_CO1-3)'
  prefs: []
  type: TYPE_NORMAL
- en: The container image will be part of this group.
  prefs: []
  type: TYPE_NORMAL
- en: '[![4](Images/4.png)](#co_deploying_for_developers_CO1-4)'
  prefs: []
  type: TYPE_NORMAL
- en: The name of the container image is optional; if not set, it defaults to the
    application name.
  prefs: []
  type: TYPE_NORMAL
- en: '[![5](Images/5.png)](#co_deploying_for_developers_CO1-5)'
  prefs: []
  type: TYPE_NORMAL
- en: The tag of the container image is also optional; if not set, it defaults to
    the application version.
  prefs: []
  type: TYPE_NORMAL
- en: 'Finally, you can build and push the container image:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: In [Chapter 3](ch03.xhtml#thinking_in_containers), you read about keeping the
    container images small. The size of a container image influences the time spent
    by the orchestrating platform to pull that image from the registry. Often, the
    size of the base image used by the `FROM` instruction influences the size of your
    container image, and Jib allows you to control it by changing the `baseImage`
    configuration. Moreover, when using Jib, you can also control the ports you expose
    or the entry point of your container image.
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Changing the JVM base image is also helpful when performing JDK upgrades. In
    addition, the Quarkus extension supports customization of the JVM base image (`quarkus.jib.base-jvm-image`)
    and the native base image (`quarkus.jib.base-native-image`) used for the native
    binary build.
  prefs: []
  type: TYPE_NORMAL
- en: The code sample referenced in this section is available on [GitHub](https://oreil.ly/AshKo).
  prefs: []
  type: TYPE_NORMAL
- en: Building Container Images with Eclipse JKube
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: An alternative tool that a Java developer can use to containerize Java applications
    without writing Dockerfiles is [Eclipse JKube](https://oreil.ly/Fp5xx). This community
    project, supported by the Eclipse Foundation and Red Hat, can help you build container
    images and cooperate with Kubernetes. The project contains a Maven plug-in that
    is the refactored and rebranded version of the [Fabric8 Maven plug-in](https://oreil.ly/dHtw8).
    At the time of writing this chapter, Gradle plug-ins are available for technical
    preview, and support is planned for the future.
  prefs: []
  type: TYPE_NORMAL
- en: 'To start using the Eclipse JKube Maven plug-in within your project, please
    add the Kubernetes Maven plug-in to your *pom.xml*:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: Let’s add the snippet to the sample Spring Boot application from [Chapter 4](ch04.xhtml#dissecting_the_monolith).
  prefs: []
  type: TYPE_NORMAL
- en: Example 8-1\. pom.xml configuration file for sample Spring Boot project
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: '[![1](Images/1.png)](#co_deploying_for_developers_CO2-1)'
  prefs: []
  type: TYPE_NORMAL
- en: You can provide a default value for the container registry property and override
    it at build time.
  prefs: []
  type: TYPE_NORMAL
- en: '[![2](Images/2.png)](#co_deploying_for_developers_CO2-2)'
  prefs: []
  type: TYPE_NORMAL
- en: You can provide a default value for the repository property and override it
    at build time.
  prefs: []
  type: TYPE_NORMAL
- en: '[![3](Images/3.png)](#co_deploying_for_developers_CO2-3)'
  prefs: []
  type: TYPE_NORMAL
- en: You can provide a default value for the tag property and override it at build
    time. The default image name will be the project name.
  prefs: []
  type: TYPE_NORMAL
- en: 'To produce a container image for that application, run the following at the
    command line:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: JKube selects opinionated defaults like base images and handcrafted startup
    scripts, depending on the type of technology stack you are using. For this case,
    JKube uses the current local Docker build context for pulling and pushing the
    container images.
  prefs: []
  type: TYPE_NORMAL
- en: 'In addition, the image name results from concatenating the values of the Maven
    properties `${jkube.docker.registry}`, `${repository}`, `${project.name}`, and
    ​`$⁠{tag}` : `registry.hub.docker.com/myuser/demo:0.0.1-SNAPSHOT`.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Yet, in order to separate the development part from the operational side, we
    will customize these details and override them at build time. By customizing the
    property, `jkube.generator.name`, you can include a remote registry, repository,
    image name, and tag of choice:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, we can build an image for a remote container registry by using the following
    command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'If you would like to build and push the image to the remote container registry,
    you can use this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: This command builds the image *quay.io/repo/demo:0.0.1* and pushes it to the
    respective remote registry.
  prefs: []
  type: TYPE_NORMAL
- en: Caution
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'When using remote registries, you need to provide credentials. Eclipse JKube
    will search for these locations to obtain credentials:'
  prefs: []
  type: TYPE_NORMAL
- en: The system properties `jkube.docker.username` and `jkube​.docker.password`
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The `<authConfig>` section in the plug-in configuration with the `<username>`
    and `<password>` elements
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A `<server>` configuration in *~/.m2/settings.xml*
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Previous login into a registry with Docker login (credentials in a credential
    helper or in *~/.docker/config.json*)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: OpenShift configuration in *~/.config/kube*
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'You can use the same steps to build and push container images using the [Eclipse
    JKube Kubernetes Gradle plug-in](https://oreil.ly/CeYVl). In that case, you should
    configure the plug-in in *build.gradle*:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: At the command line, you can build the container image by using `gradle k8sBuild`
    and push the result with `gradle k8sPush`.
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: You can add `k8s:watch` goal to the plug-in configuration in order to automatically
    re-create images or copy new artifacts into running containers when your code
    changes.
  prefs: []
  type: TYPE_NORMAL
- en: Deploying to Kubernetes
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: With a good understanding of building and pushing container images, you can
    focus on running containers. When working with distributed systems, containers
    help you achieve deployment independency and can isolate application code from
    failures.
  prefs: []
  type: TYPE_NORMAL
- en: 'Because a distributed system will likely have more than one microservice, you
    will need to figure out how to manage those using containers. Orchestration tools
    can help you manage a large number of containers as they typically provide the
    following:'
  prefs: []
  type: TYPE_NORMAL
- en: A declarative system configuration
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Container provisioning and discovery
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: System monitoring and crash recovery
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Instruments for defining rules and constraints on container placement and performance.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Kubernetes* is an open source platform automating deployment, scaling, and
    management of containerized workloads. With Kubernetes, you can organize your
    deployments in such a way that the platform can spin up or remove instances to
    match the load demand. Furthermore, Kubernetes can replace and reschedule containers
    when nodes die.'
  prefs: []
  type: TYPE_NORMAL
- en: Features like portability and extensibility increased the popularity of Kubernetes,
    stimulating community contributions and vendors’ support. The proven success of
    Kubernetes to support increasingly complex categories of applications continues
    to enable enterprise transition to both hybrid cloud and microservices.
  prefs: []
  type: TYPE_NORMAL
- en: With Kubernetes, you can deploy your application(s) in such a way to have Kubernetes
    run more instances of your service if load increases, stop instances if load decreases,
    or spin up new instances should existing ones fail. As a developer, when you want
    to deploy to Kubernetes, you need access to a Kubernetes cluster. A *Kubernetes
    cluster* consists of a set of nodes that run containerized applications, as shown
    in [Figure 8-1](#components-of-kubernetes).
  prefs: []
  type: TYPE_NORMAL
- en: '![The components of a Kubernetes cluster](Images/dtjd_0801.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 8-1\. Kubernetes components (image adapted from [Kubernetes documentation](https://oreil.ly/nyzh7))
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Every cluster has at least one worker node, and each worker hosts Pods. Within
    a cluster, namespaces are used to isolate groups of resources (Pods included).
    Pods are the components in direct contact with your running containers, instantiated
    from container images previously built and pushed to a container registry.
  prefs: []
  type: TYPE_NORMAL
- en: When you work with Kubernetes, you are using a set of objects that are validated
    and accepted by the system. To work with Kubernetes objects, you need to use the
    Kubernetes API. Nowadays it’s possible to instrument Kubernetes deployments by
    using visual helpers, command-line interfaces, or Java add-ons like Dekorate and
    JKube to generate and deploy Kubernetes manifests.
  prefs: []
  type: TYPE_NORMAL
- en: Local Setup for Deployment
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'As a developer, you are used to configuring a local setup to implement application
    features. Typically, this local setup involves having access to a version control
    system, and installing and configuring the following:'
  prefs: []
  type: TYPE_NORMAL
- en: A JDK
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Maven or Gradle
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: An IDE like IntelliJ IDEA, Eclipse, or Visual Studio Code
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Optionally, a database or middleware that integrates with your code
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'One or more tools for building, running, and pushing container images: Docker,
    Podman, Buildah, Jib, JKube, etc.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'A Kubernetes development cluster: [minikube](https://oreil.ly/SfNR3), [kind](https://oreil.ly/BcYHp),
    or [Red Hat CodeReady Containers](https://oreil.ly/iIkzu). For development purposes,
    [Docker Desktop](https://oreil.ly/gmh6B) also offers a single-node Kubernetes
    cluster that runs locally within your Docker instance. [Rancher Desktop](https://oreil.ly/09wOS)
    is another great tool that can help you locally with container management and
    running Kubernetes. If running a local development cluster consumes too many resources,
    you may prefer to have development namespaces in remote Kubernetes cluster(s)
    or use an already provisioned one like [Developer Sandbox for Red Hat OpenShift](https://oreil.ly/14VUx).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Before creating any Kubernetes resources, let’s summarize some Kubernetes concepts:'
  prefs: []
  type: TYPE_NORMAL
- en: Cluster
  prefs: []
  type: TYPE_NORMAL
- en: A set of nodes where you can instruct Kubernetes on deploying containers.
  prefs: []
  type: TYPE_NORMAL
- en: Namespace
  prefs: []
  type: TYPE_NORMAL
- en: A Kubernetes object responsible for isolating groups’ resources based on different
    permissions.
  prefs: []
  type: TYPE_NORMAL
- en: User
  prefs: []
  type: TYPE_NORMAL
- en: Interaction with the Kubernetes API requires a form of authentication managed
    through users.
  prefs: []
  type: TYPE_NORMAL
- en: Context
  prefs: []
  type: TYPE_NORMAL
- en: A specific combination that contains a Kubernetes cluster, a user, and a namespace.
  prefs: []
  type: TYPE_NORMAL
- en: Kubelet
  prefs: []
  type: TYPE_NORMAL
- en: The main agent that runs on each cluster node and ensures that containers are
    running and healthy, according to pod specifications.
  prefs: []
  type: TYPE_NORMAL
- en: Deployment
  prefs: []
  type: TYPE_NORMAL
- en: A resource that instructs Kubernetes on creating or modifying instances of pods
    with a containerized application.
  prefs: []
  type: TYPE_NORMAL
- en: ReplicaSet
  prefs: []
  type: TYPE_NORMAL
- en: Every time Kubernetes creates a deployment, this resource instantiates a ReplicaSet
    and delegates to it counting pods.
  prefs: []
  type: TYPE_NORMAL
- en: Service
  prefs: []
  type: TYPE_NORMAL
- en: A way to expose an application having multiple instances in different pods as
    a network service.
  prefs: []
  type: TYPE_NORMAL
- en: Keeping in mind these concepts, let’s investigate how you can generate Kubernetes
    objects and deploy them.
  prefs: []
  type: TYPE_NORMAL
- en: Generate Kubernetes Manifests by Using Dekorate
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[Dekorate](http://dekorate.io) can generate Kubernetes manifests at compile
    time, using Java annotations and standard Java framework configuration mechanisms.
    [Table 8-1](#dekorate_dependencies) shows Dekorate Maven dependencies available
    for Quarkus, Spring Boot, or a generic Java project.'
  prefs: []
  type: TYPE_NORMAL
- en: Table 8-1\. Dekorate Maven dependencies
  prefs: []
  type: TYPE_NORMAL
- en: '| Framework | Dependency |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| Quarkus |'
  prefs: []
  type: TYPE_TB
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '| Spring Boot |'
  prefs: []
  type: TYPE_TB
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '| Generic Java Application |'
  prefs: []
  type: TYPE_TB
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s create some Kubernetes resources by adding Dekorate to [Example 8-1](#example_0801):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: If no configuration is provided, Dekorate will produce a Deployment and Service
    resource in the manifest created under *target/classes/META-INF/dekorate*. This
    generated Service type is `ClusterIP` and makes the application available only
    within the Kubernetes cluster. If you want to expose the service externally, using
    the load balancer of a cloud provider, you can do that by using a Service resource
    of type `LoadBalancer`, as explained in the [Kubernetes documentation](https://oreil.ly/uPUm6).
  prefs: []
  type: TYPE_NORMAL
- en: 'When working with Dekorate, you can customize the generation of Kubernetes
    resources by using the following approaches:'
  prefs: []
  type: TYPE_NORMAL
- en: Specifying configurations in `application.properies`
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Adding the `@KubernetesApplication` annotation to the `DemoApplication` class
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'To avoid tight coupling between infrastructure and application code, we customize
    the Service resource *src/main/resources/application.properties* by using the
    following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: 'To generate the Kubernetes objects, you can package the application like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: 'After packaging the application, you will notice among the other files that
    are created, two files named *kubernetes.json* and *kubernetes.yml* in the *target/classes/META-INF/dekorate*
    directory. Either of these manifests can be used to deploy to Kubernetes:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: '[![1](Images/1.png)](#co_deploying_for_developers_CO3-1)'
  prefs: []
  type: TYPE_NORMAL
- en: A Deployment provides declarative updates for Pods and ReplicaSets.
  prefs: []
  type: TYPE_NORMAL
- en: '[![2](Images/2.png)](#co_deploying_for_developers_CO3-2)'
  prefs: []
  type: TYPE_NORMAL
- en: Labels are used by selectors to connect the Service to the Pods, but also to
    align the specifications of `Deployment` to ReplicaSets and Pods.
  prefs: []
  type: TYPE_NORMAL
- en: '[![3](Images/3.png)](#co_deploying_for_developers_CO3-4)'
  prefs: []
  type: TYPE_NORMAL
- en: Name of the Deployment object.
  prefs: []
  type: TYPE_NORMAL
- en: '[![4](Images/4.png)](#co_deploying_for_developers_CO3-9)'
  prefs: []
  type: TYPE_NORMAL
- en: Container image used by the Deployment.
  prefs: []
  type: TYPE_NORMAL
- en: '[![5](Images/5.png)](#co_deploying_for_developers_CO3-10)'
  prefs: []
  type: TYPE_NORMAL
- en: Port exposed by the container and targeted by the Service.
  prefs: []
  type: TYPE_NORMAL
- en: '[![6](Images/6.png)](#co_deploying_for_developers_CO3-11)'
  prefs: []
  type: TYPE_NORMAL
- en: A Service exposes the application running on a set of Pods as a network service.
  prefs: []
  type: TYPE_NORMAL
- en: '[![7](Images/7.png)](#co_deploying_for_developers_CO3-14)'
  prefs: []
  type: TYPE_NORMAL
- en: Port used to serve incoming traffic.
  prefs: []
  type: TYPE_NORMAL
- en: '[![8](Images/8.png)](#co_deploying_for_developers_CO3-16)'
  prefs: []
  type: TYPE_NORMAL
- en: Expose the service externally using the load balancer of a cloud provider.
  prefs: []
  type: TYPE_NORMAL
- en: 'Assuming you have previously logged in a Kubernetes cluster, you can deploy
    to it using the command-line interface:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: As a result, you can access the application by using the external IP (`LoadBalancer
    Ingress`) and port by Kubernetes after applying the manifests.
  prefs: []
  type: TYPE_NORMAL
- en: Generate and Deploy Kubernetes Manifests with Eclipse JKube
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Eclipse JKube can also generate and deploy Kubernetes/OpenShift manifests at
    compile time. In addition to creating Kubernetes descriptors (YAML files), you
    can adjust the output by using the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Inline configuration within the XML plug-in configuration
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: External configuration templates of deployment descriptors
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[“Building Container Images with Eclipse JKube”](Images/#building-container-images-with-eclipse-jkube)
    explored building container images with JKube and with Docker daemon integration.
    We will reuse the Quarkus sample code from [“Managing Container Images by Using
    Jib”](Images/#managing-container-images-using-jib) to generate and deploy Kubernetes
    resources with Eclipse JKube and Jib.'
  prefs: []
  type: TYPE_NORMAL
- en: Example 8-2\. *pom.xml* configuration file for sampled Quarkus project
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: '[![1](Images/1.png)](#co_deploying_for_developers_CO4-1)'
  prefs: []
  type: TYPE_NORMAL
- en: For consistency, you can reuse the Quarkus extension properties within the JKube
    image name.
  prefs: []
  type: TYPE_NORMAL
- en: '[![2](Images/2.png)](#co_deploying_for_developers_CO4-2)'
  prefs: []
  type: TYPE_NORMAL
- en: Expose the service on each node’s IP at a static port (the `NodePort`).
  prefs: []
  type: TYPE_NORMAL
- en: '[![3](Images/3.png)](#co_deploying_for_developers_CO4-3)'
  prefs: []
  type: TYPE_NORMAL
- en: Specify that the build strategy is Jib.
  prefs: []
  type: TYPE_NORMAL
- en: 'We can now invoke the container image build (`k8s:build`) and create a Kubernetes
    resource (`k8s:resource`) in a single command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: 'The following structure will appear under *target/classes/META-INF/jkube*:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: '*kubernetes.yml* contains both the Deployment and the Service resource definition,
    while in the *kubernetes* folder you have them separated in two distinct files.'
  prefs: []
  type: TYPE_NORMAL
- en: 'As we did for the Dekorate manifest, we can deploy *kubernetes.yml* by using
    the command-line interface:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: 'Or you can use the `k8s:apply` Maven goal of the JKube plug-in to achieve the
    same result:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: This goal will search for the previously generated files and apply them to the
    connected Kubernetes cluster. The application will be reachable using the cluster
    IP and the assigned node port.
  prefs: []
  type: TYPE_NORMAL
- en: Furthermore, you can model the interaction between the generated resources and
    the Kubernetes cluster with more plug-in goals. [Table 8-2](#additional_jkube_goals)
    lists other goals available with the Kubernetes Maven plug-in.
  prefs: []
  type: TYPE_NORMAL
- en: Table 8-2\. Eclipse JKube additional goals
  prefs: []
  type: TYPE_NORMAL
- en: '| Goal | Description |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '`k8s:log`'
  prefs: []
  type: TYPE_NORMAL
- en: '| Gets the logs from your running container in Kubernetes |'
  prefs: []
  type: TYPE_TB
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '`k8s:debug`'
  prefs: []
  type: TYPE_NORMAL
- en: '| Opens the debug port so that you can debug the application deployed in Kubernetes
    from your IDE |'
  prefs: []
  type: TYPE_TB
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '`k8s:watch`'
  prefs: []
  type: TYPE_NORMAL
- en: '| Does an automatic deployment of your application by watching your application
    context |'
  prefs: []
  type: TYPE_TB
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '`k8s:deploy`'
  prefs: []
  type: TYPE_NORMAL
- en: '| Forks the Install goal and applies your generated manifests onto a Kubernetes
    cluster |'
  prefs: []
  type: TYPE_TB
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '`k8s:undeploy`'
  prefs: []
  type: TYPE_NORMAL
- en: '| Deletes all of the resources applied with `k8s:apply` |'
  prefs: []
  type: TYPE_TB
- en: Now that you have seen how to deploy to Kubernetes, let’s see how we can refine
    this by choosing and implementing a deployment strategy.
  prefs: []
  type: TYPE_NORMAL
- en: Choose and Implement a Deployment Strategy
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Deploying a single application to Kubernetes can be an easy task when using
    the right tools. As developers, we should also think ahead and decide how we might
    replace an old version of a microservice with a newer one without downtime.
  prefs: []
  type: TYPE_NORMAL
- en: 'When you choose a deployment strategy to Kubernetes, you need to look into
    establishing these quotas:'
  prefs: []
  type: TYPE_NORMAL
- en: Number of desired instances for your application
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Minimum healthy running instances
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Maximum instances
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The ideal situation is to have the number of desired running instances in the
    shortest time possible while using minimal resources (CPU, memory). But let’s
    try the already established methodologies and compare their performance.
  prefs: []
  type: TYPE_NORMAL
- en: 'All-in-one deployment using the `Recreate` strategy is the simplest available
    when using Kubernetes Deployment objects:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: '[![1](Images/1.png)](#co_deploying_for_developers_CO5-1)'
  prefs: []
  type: TYPE_NORMAL
- en: The deployment strategy is `Recreate`.
  prefs: []
  type: TYPE_NORMAL
- en: '[![2](Images/2.png)](#co_deploying_for_developers_CO5-2)'
  prefs: []
  type: TYPE_NORMAL
- en: You can set `revisionHistoryLimit` to specify the number of old ReplicaSets
    for this deployment that you want to retain. By default, Kubernetes stores the
    last 10 ReplicaSets.
  prefs: []
  type: TYPE_NORMAL
- en: Whenever the preceding specification is applied in a cluster, Kubernetes will
    take down all the current running pod instances, and once they are terminated,
    will bring up new ones. We do not need to set up a minimum and maximum number
    of instances, only the number of desired instances (4).
  prefs: []
  type: TYPE_NORMAL
- en: In this example, Kubernetes does not delete the previous ReplicaSet immediately
    after performing an update. Instead, it keeps the ReplicaSet around with a replicas
    count of 0. If the deployment introduced a change that breaks the stability of
    the system, we can roll back to a previous working version by choosing from the
    old ReplicaSets.
  prefs: []
  type: TYPE_NORMAL
- en: 'You can find out the previous revisions by running the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: 'And roll back to a previous version by using the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: Although this strategy is efficient in terms of memory and amount of CPU consumption,
    it introduces a gap in time when the microservice is unavailable.
  prefs: []
  type: TYPE_NORMAL
- en: 'Another Kubernetes built-in strategy is `RollingUpdate`, where the current
    running instances are slowly replaced by the new ones:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: '[![1](Images/1.png)](#co_deploying_for_developers_CO6-1)'
  prefs: []
  type: TYPE_NORMAL
- en: Maximum number of Pods that can be unavailable when performing the deployment
  prefs: []
  type: TYPE_NORMAL
- en: '[![2](Images/2.png)](#co_deploying_for_developers_CO6-2)'
  prefs: []
  type: TYPE_NORMAL
- en: Maximum number of Pods that can be created over the desired number of Pods
  prefs: []
  type: TYPE_NORMAL
- en: '[![3](Images/3.png)](#co_deploying_for_developers_CO6-3)'
  prefs: []
  type: TYPE_NORMAL
- en: Desired number of Pods
  prefs: []
  type: TYPE_NORMAL
- en: By focusing on the maximum number of the unavailable Pods, this strategy safely
    upgrades your deployment, without experiencing any downtime. But, depending on
    your microservice startup time, the entire transition to the newer version of
    the deployment can take longer to complete. If the deployment introduces a change
    that breaks the stability of the system, Kubernetes will update the Deployment
    template but will keep the previous running Pods.
  prefs: []
  type: TYPE_NORMAL
- en: Caution
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: The rolling deployment is the standard default deployment to Kubernetes if you
    do not fill in a strategy in the object `spec`.
  prefs: []
  type: TYPE_NORMAL
- en: If your application is using a database, you should consider the impact of having
    two application versions running simultaneously. Another disadvantage with this
    strategy is that during the upgrade, there will be a mix of old and new versions
    of the application. If you want to keep the zero downtime and avoid mixing application
    versions in production, take a look at the blue/green deployment technique.
  prefs: []
  type: TYPE_NORMAL
- en: '*Blue/green deployment* is a strategy that reduces downtime and risk of failure
    by running two identical (production) environments named Blue and Green; see [Figure 8-2](#blue-green-setup).
    When using this deployment strategy, no new instances will serve user requests
    until all become available; at that moment, all old instances become instantly
    unavailable. You can achieve this by orchestrating services and routing requests.'
  prefs: []
  type: TYPE_NORMAL
- en: '![Blue/Green deployment strategy](Images/dtjd_0802.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 8-2\. Blue/green strategy
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'Let’s observe how we can implement blue/green deployments by using standard
    Kubernetes objects:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Apply the blue version of the microservice having the label `version: blue`.
    We will associate the convention of *blue deployment* by using the value of the
    label `version`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE32]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Expose this deployment by using a Kubernetes Service. After this, traffic is
    served from the blue version:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Apply the *green deployment* of a microservice having the label `version: green`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE35]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Switch the traffic from blue deployment to green by patching the Service object:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: If the blue deployment is no longer needed, you can remove it by using `kubectl
    delete`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Although this deployment strategy is more complex and requires more resources,
    you can shorten the time between software development and user feedback. This
    approach is less disruptive for experimenting with features; if any issues appear
    after a deployment, you can quickly route to a previous stable version.
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: You can explore a blue/green deployment strategy with more cloud native tools
    that are compatible with Kubernetes, such as [Istio](https://istio.io) and [Knative](https://knative.dev).
  prefs: []
  type: TYPE_NORMAL
- en: The last strategy that we will look at is a *canary deployment*. This is a way
    to reduce risk and validate new system features by releasing software to a small
    percentage of users. Performing a canary deployment allows you to try out the
    new version of a microservice with a small user audience without replacing any
    of the existing instances of the application. To evaluate the behavior of the
    deployments (canary and existing), you should implement a load balancer configuration
    on top of the service instances and add weighted routing to choose how much traffic
    is routed to each resource.
  prefs: []
  type: TYPE_NORMAL
- en: Currently, the canary strategy can be achieved by adding an extra layer of tools
    ([Figure 8-3](#istio-canary-setup)). API gateways with weighted routing support
    let you manage your API endpoints and decide the amount of traffic routed toward
    them. Service mesh control planes like Istio are a solution compatible with Kubernetes
    that can help you to control service-to-service communication over a network and
    the percentage of user traffic to each service version.
  prefs: []
  type: TYPE_NORMAL
- en: '![Weighted traffic routing in Istio](Images/dtjd_0803.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 8-3\. Canary strategy using weighted traffic routing in Istio
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: If you still struggle to choose a deployment mechanism, check out [Table 8-3](#deployment_strategies),
    which summarizes characteristics of the previously discussed strategies.
  prefs: []
  type: TYPE_NORMAL
- en: Table 8-3\. Characteristics of the deployment strategies
  prefs: []
  type: TYPE_NORMAL
- en: '|  | Re-create | Rolling update | Blue/green | Canary |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| Out of the box in Kubernetes | Yes | Yes | No | No |'
  prefs: []
  type: TYPE_TB
- en: '| Downtime occurrence | Yes | No | No | No |'
  prefs: []
  type: TYPE_TB
- en: '| Rollback process | Manually roll out a previous version | Stop rollout and
    keep the previous version | Switch traffic to previous version | Delete canary
    instance |'
  prefs: []
  type: TYPE_TB
- en: '| Traffic control | No | No | Yes | Yes |'
  prefs: []
  type: TYPE_TB
- en: '| Traffic sent simultaneously to old and new version | No | Yes | No | Yes
    |'
  prefs: []
  type: TYPE_TB
- en: Managing Workloads in Kubernetes
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'An application running on Kubernetes is a *workload*. In the cluster, your
    workload will run on one or several Pods having a defined lifecycle. To simplify
    Pod lifecycle management, Kubernetes provides several built-in workload resources:'
  prefs: []
  type: TYPE_NORMAL
- en: Deployment and ReplicaSet
  prefs: []
  type: TYPE_NORMAL
- en: Help manage a stateless application workload.
  prefs: []
  type: TYPE_NORMAL
- en: StatefulSet
  prefs: []
  type: TYPE_NORMAL
- en: Enables you to run a stateful application either as a single instance or as
    a replicated set.
  prefs: []
  type: TYPE_NORMAL
- en: Job and CronJob
  prefs: []
  type: TYPE_NORMAL
- en: Define tasks that run to completion and then stop. These types of resources
    are useful when implementing batch-processing activities. Jobs are one-off tasks,
    while CronJobs run according to a schedule.
  prefs: []
  type: TYPE_NORMAL
- en: DaemonSet
  prefs: []
  type: TYPE_NORMAL
- en: Can help you to define Pods with functionalities impacting the entire node.
    Scheduling the workload using this type of resource is rare.
  prefs: []
  type: TYPE_NORMAL
- en: Earlier, we generated and deployed Kubernetes manifests containing a Deployment
    specification, as typically microservices are stateless applications. But how
    can we prevent failure for those microservices that depend on an external service
    or persist their data in a database? Moreover, as a microservice codebase evolves,
    how can it use a fair share of memory and CPU?
  prefs: []
  type: TYPE_NORMAL
- en: Setting Up Health Checks
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Another benefit of working with distributed systems and in the cloud is that
    microservices independence often stimulates automated deployments. As automated
    deployments can occur several times per day, on multiple instances, you need a
    way to validate that your application is available and running as expected. Each
    increase in the number of components in the system brings with it an increase
    in the probability of failure: a deadlock, a host becoming unavailable, a hardware
    failure, etc. To detect issues before they propagate as outages, we can validate
    the status of a microservice by using health checks.'
  prefs: []
  type: TYPE_NORMAL
- en: Health checks should span across the entire system, from application code to
    infrastructure. Infrastructure can use application health checks to determine
    when to serve traffic using readiness probes or to restart the container via liveness
    probes. You should know that a liveness probe does not always execute after the
    readiness probe succeeds. When your application needs additional time to initialize,
    you can define the amount of time in seconds to wait before executing the probe
    or use a startup probe to check if the container has started.
  prefs: []
  type: TYPE_NORMAL
- en: 'At the Kubernetes level, the *kubelet* is the component that uses liveness,
    readiness, and startup probes to assess the state of your containers. The kubelet
    uses readiness probes to check when a container is ready to start accepting traffic,
    and liveness probes to know when to restart it. You can use any of these three
    mechanisms to implement liveness, readiness, or startup probes:'
  prefs: []
  type: TYPE_NORMAL
- en: Opening a TCP socket against a container
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Making an HTTP request against a containerized application that exposes API
    endpoints
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Running a command inside a container in case your application uses a protocol
    different from HTTP or TCP
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: With Kubernetes v1.23, a gRPC health probe mechanism is available as an alpha
    feature. Please keep an eye on the evolution of the [Kubernetes health probe documentation](https://oreil.ly/IDsqC).
  prefs: []
  type: TYPE_NORMAL
- en: 'The simplest way of implementing a health check is to periodically evaluate
    the running application by sending requests to some of its API endpoints. You
    can determine the health of the system based on the response payload. Typically,
    these health endpoints are HTTP GET or HEAD requests that do not change the state
    of the system and perform a lightweight task. You can define a */health* endpoint
    in a RESTful API to check the internal status of your microservice or you can
    use framework-compatible dependencies:'
  prefs: []
  type: TYPE_NORMAL
- en: The [Actuator](https://oreil.ly/rNxMx) module provides useful insight into a
    Spring environment running applications. Actuator has functions for health checking
    and gathers metrics by exposing multiple endpoints over HTTP and Java Management
    Extensions (JMX).
  prefs: []
  type: TYPE_NORMAL
- en: You can add the Actuator module to your Spring Boot project as a Maven or Gradle
    dependency (see [Table 8-4](#actuator_dependency)) and can access the default
    health endpoints at */actuator/health*.
  prefs: []
  type: TYPE_NORMAL
- en: Table 8-4\. Actuator as Maven or Gradle dependency
  prefs: []
  type: TYPE_NORMAL
- en: '| Build tool | Definition |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| Maven |'
  prefs: []
  type: TYPE_TB
- en: '[PRE37]'
  prefs: []
  type: TYPE_PRE
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '| Gradle |'
  prefs: []
  type: TYPE_TB
- en: '[PRE38]'
  prefs: []
  type: TYPE_PRE
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: With Actuator, you can check the health of individual components with health
    indicators or have a composite health check with composite health contributors.
    You can work with several predefined health indicators, including `DataSourceHealth​Indi⁠cator`,
    `MongoHealthIndicator`, `RedisHealthIndicator`, and `CassandraHealthIndicator`.
    These implement the `HealthIndicator` interface, which enables you to check the
    health of that component. For example, if your application is using a database
    to persist data, the database health indicator will be automatically added by
    Spring Boot if it detects a datasource. The health check consists of creating
    a connection to a database to perform a simple query.
  prefs: []
  type: TYPE_NORMAL
- en: Although using the built-in health indicators saves you development time, sometimes
    you should investigate the health of dependent systems aggregated together. Spring
    Boot will aggregate all health indicators it finds in the application context
    under the `/actuator/health` endpoint. Yet, if a health check on one of the dependent
    systems is unsuccessful, the composite probe will fail. For such cases, you should
    consider implementing the `CompositeHealthContributor` interface in a Spring bean
    or treating the potential failure by offering a fallback response.
  prefs: []
  type: TYPE_NORMAL
- en: The MicroProfile Health module allows services to report their health, and it
    publishes the overall health status to a defined endpoint. Quarkus applications
    can use the [SmallRye Health extension](https://oreil.ly/r9QuE), which is an implementation
    of the Eclipse MicroProfile Health Check specification. You can add the extension
    to your Maven or Gradle configuration by using snippets from [Table 8-5](#smallrye_health_dependency).
  prefs: []
  type: TYPE_NORMAL
- en: Table 8-5\. SmallRye Health as Maven or Gradle dependency
  prefs: []
  type: TYPE_NORMAL
- en: '| Build tool | Definition |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| Maven |'
  prefs: []
  type: TYPE_TB
- en: '[PRE39]'
  prefs: []
  type: TYPE_PRE
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '| Gradle |'
  prefs: []
  type: TYPE_TB
- en: '[PRE40]'
  prefs: []
  type: TYPE_PRE
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: All health-check procedures in the application are accumulated in the `/q/health`
    REST endpoint. Some Quarkus extensions provide default health checks. This means
    that the extension can automatically register its health checks.
  prefs: []
  type: TYPE_NORMAL
- en: For example, when using a Quarkus datasource, the `quarkus-agroal` extension
    automatically registers a readiness health check that will validate that datasource.
    You can disable automatic registration of the extension health check via the property
    `quarkus.health.extensions.enabled`.
  prefs: []
  type: TYPE_NORMAL
- en: When you investigate the health of dependent systems, you can define your own
    health checks by implementing `org.eclipse.microprofile.health.HealthCheck` and
    use `@Liveness`, `@Readiness`, and `@Startup` to distinguish the role of each
    check. A composite health check inspects the condition of the dependent systems
    aggregated together. Yet this approach is counterproductive if one of the dependent
    systems fails. A more proactive strategy involves offering a fallback response
    and monitoring a set of metrics showing the application’s health. These are more
    useful as they offer early notifications about a system’s deteriorating health,
    giving us time to take mitigating measures.
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'Besides the automatic readiness probes when adding specific extensions, Quarkus
    comes with some health-check implementations for you to check the status of various
    components:'
  prefs: []
  type: TYPE_NORMAL
- en: '`SocketHealthCheck` checks if the host is reachable using a socket.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`UrlHealthCheck` checks if the host is reachable using an HTTP URL connection.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`InetAddressHealthCheck` checks if the host is reachable using the `InetAddress.isReachable`
    method.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'When you implement health checks using REST endpoints at the application level,
    you will likely invoke those using an HTTP request from a probe. Kubernetes probes
    consult these endpoints to determine the health of your container. A probe has
    configuration parameters to control its behavior, including the following:'
  prefs: []
  type: TYPE_NORMAL
- en: How often to execute the probe (`periodSeconds`)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How long to wait after starting the container to initiate the probe (`initialDelaySeconds`)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Number of seconds after which the probe is considered failed (`timeoutSeconds`)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Number of times the probe can fail before giving up (`failureThreshold`)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Minimum consecutive successes for the probe to be considered successful after
    having failed (`successThreshold`)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The tools we have previously used to generate Kubernetes manifests (Dekorate
    and Eclipse JKube) can help you start working with health probes. For example,
    let’s add the Actuator dependency to the Spring Boot project and package the application
    by using the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE41]'
  prefs: []
  type: TYPE_PRE
- en: 'The Kubernetes manifest file from *target/classes/dekorate/* will contain specifications
    for health probes:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE42]'
  prefs: []
  type: TYPE_PRE
- en: '[![1](Images/1.png)](#co_deploying_for_developers_CO7-1)'
  prefs: []
  type: TYPE_NORMAL
- en: Declaration of readiness and liveness probe is within the container specification.
  prefs: []
  type: TYPE_NORMAL
- en: '[![2](Images/2.png)](#co_deploying_for_developers_CO7-2)'
  prefs: []
  type: TYPE_NORMAL
- en: The probe can fail three times before giving up.
  prefs: []
  type: TYPE_NORMAL
- en: '[![3](Images/3.png)](#co_deploying_for_developers_CO7-3)'
  prefs: []
  type: TYPE_NORMAL
- en: The probe should make an HTTP GET request against the container.
  prefs: []
  type: TYPE_NORMAL
- en: '[![4](Images/4.png)](#co_deploying_for_developers_CO7-4)'
  prefs: []
  type: TYPE_NORMAL
- en: Wait 0 seconds after starting the container to initiate the probe.
  prefs: []
  type: TYPE_NORMAL
- en: '[![5](Images/5.png)](#co_deploying_for_developers_CO7-5)'
  prefs: []
  type: TYPE_NORMAL
- en: Execute the probe every 30 seconds.
  prefs: []
  type: TYPE_NORMAL
- en: '[![6](Images/6.png)](#co_deploying_for_developers_CO7-6)'
  prefs: []
  type: TYPE_NORMAL
- en: Minimum one consecutive success for the probe to be considered successful after
    having failed.
  prefs: []
  type: TYPE_NORMAL
- en: '[![7](Images/7.png)](#co_deploying_for_developers_CO7-7)'
  prefs: []
  type: TYPE_NORMAL
- en: After 10 seconds, the probe is considered failed.
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Depending on the tech stack that you use, [Eclipse JKube](https://oreil.ly/guUR9)
    has a list of enrichers that can help you adjust health checks.
  prefs: []
  type: TYPE_NORMAL
- en: Now that you have used application health checks to ensure that the system is
    performing as expected, we can look into fine-tuning resource quotas for containerized
    applications.
  prefs: []
  type: TYPE_NORMAL
- en: Adjusting Resource Quotas
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: A common practice is to have several users or teams share a cluster with a fixed
    number of nodes. To facilitate a fair share of resources for each deployed application,
    cluster administrators establish a `ResourceQuota` object. This object provides
    constraints that limit resource consumption for a namespace.
  prefs: []
  type: TYPE_NORMAL
- en: When you define specifications for a Pod, you can specify the amount of resources
    each container will need. Requests define the minimum amount of resources that
    containers need, while limits define the maximum amount of resources that the
    container can consume. The kubelet enforces those limits for the running container.
  prefs: []
  type: TYPE_NORMAL
- en: 'For a container, the common resources to specify are CPU and memory. For each
    container of a Pod, you can define them as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '`spec.containers[].resources.limits.cpu`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`spec.containers[].resources.limits.memory`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`spec.containers[].resources.requests.cpu`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`spec.containers[].resources.requests.memory`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In Kubernetes, the CPU is assigned with values in millicores or millicpu, and
    memory is measured in bytes. The kubelet collects metrics such as CPU and memory
    from your Pods and can check them using [Metrics Server](https://oreil.ly/31lKM).
  prefs: []
  type: TYPE_NORMAL
- en: 'As your containers start to compete for resources, you should carefully divide
    the CPU and memory based on limits and requests. To achieve that, you need the
    following:'
  prefs: []
  type: TYPE_NORMAL
- en: A tool or practice to programmatically generate traffic for your application.
    For local development purposes, you can start with tools like [hey](https://oreil.ly/rJK0q)
    or [Apache JMeter](https://oreil.ly/pvNfd).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A tool or practice to collect metrics and decide how to set requests and limits
    for CPU and memory. For example, on local minikube installations, you can enable
    the [`metrics-server` add-on](https://oreil.ly/9Ix3p).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Next, you can add the resource limits and requests to your existing container
    specification. You can also have them generated if you are using Dekorate and
    have them defined at the application configuration level. For example, in the
    case of Quarkus, you can add the Kubernetes extension that includes Dekorate:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE43]'
  prefs: []
  type: TYPE_PRE
- en: 'and configure them in *src/main/resources/application.properties*:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE44]'
  prefs: []
  type: TYPE_PRE
- en: 'These configurations can be customized when packaging the application. After
    running `mvn clean package`, note that the newly generated Deployment object includes
    resource specifications:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE45]'
  prefs: []
  type: TYPE_PRE
- en: '[![1](Images/1.png)](#co_deploying_for_developers_CO8-1)'
  prefs: []
  type: TYPE_NORMAL
- en: The container is limited to use maximum 200 millicores (m) and 230 mebibytes
    (MiB).
  prefs: []
  type: TYPE_NORMAL
- en: '[![2](Images/2.png)](#co_deploying_for_developers_CO8-3)'
  prefs: []
  type: TYPE_NORMAL
- en: The container can request a minimum 100 m and 115 MiB.
  prefs: []
  type: TYPE_NORMAL
- en: Caution
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: If a container specifies a memory limit but does not specify a memory request,
    Kubernetes automatically assigns a memory request that matches the limit. If a
    container specifies a CPU limit but does not specify a CPU request, Kubernetes
    automatically assigns a CPU request that matches the limit.
  prefs: []
  type: TYPE_NORMAL
- en: Working with Persistent Data Collections
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: A basic principle of microservices is that each service manages its own data.
    If services share the same underlying data schemas, unintentional coupling between
    services can occur, thus endangering independent deployments.
  prefs: []
  type: TYPE_NORMAL
- en: If you are working with NoSQL databases, like CouchDB or MongoDB, don’t worry
    about database changes, as altering the data structure can be performed from application
    code.
  prefs: []
  type: TYPE_NORMAL
- en: On the other hand, if you are using a standard SQL database, you can use tools
    like [Flyway](https://flywaydb.org) or [Liquibase](https://liquibase.org) to handle
    schema changes. These tools can help you generate migration scripts and keep track
    of which of those were run in the database and which were not yet applied. When
    any of these migration tools is invoked, it will scan the available migration
    scripts, identify ones that have not been run on a particular database, and then
    execute those.
  prefs: []
  type: TYPE_NORMAL
- en: 'When investigating the options from [“Choose and Implement a Deployment Strategy”](#choosing-and-implementing-a-deployment-strategy),
    you should consider the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Both database schema versions must work well with the application versions used
    during the deployment phase.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Ensure that you have a schema compatibility with the previous working version
    of your containerized application.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Changing a column’s data type requires converting all values stored according
    to the old column definition.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Renaming a column, a table, or a view are backward-incompatible operations unless
    you use triggers or a programmatic migration script.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: By separating application deployments from applying migration scripts, you can
    independently manage your microservices. Most of the time, cloud providers offer
    several datasources as part of their cloud service. These types of offerings might
    be the right option for your workloads if you are looking for database solutions
    without having to manage and maintain the underlying layers. Nevertheless, also
    consider how to protect, manage, and secure sensitive data when using a managed
    database service.
  prefs: []
  type: TYPE_NORMAL
- en: Should databases run in Kubernetes? The answer to this question depends on how
    the Kubernetes way to manage workload and traffic aligns with operational steps
    to maintain the database. Because maintaining databases requires more complex
    sequences of actions, the Kubernetes community resolved these challenges by implementing
    operators that incorporate logical domain and operational runbooks needed to run
    databases in Kubernetes. [OperatorHub.io](https://operatorhub.io) has an extensive
    list of operators.
  prefs: []
  type: TYPE_NORMAL
- en: Best Practices for Monitoring, Logging, and Tracing
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: So far, we’ve been focusing on making containerized applications operational.
    On your local machine, you are the only end user of your work, but your application
    will face the rest of the world in production. To have your application aligned
    to the expectations of all your end users, you should observe its evolution in
    time under different conditions and environment instances.
  prefs: []
  type: TYPE_NORMAL
- en: In recent years, the term *observability* has become popular in the IT industry,
    but chances are that you have already been working on *observable* Java applications.
    Observability is the ability to measure a system’s current state based on the
    telemetry data it generates, such as logs, metrics, and traces. If you have implemented
    auditing, exception handling, or event logging, you have already started to observe
    your application behavior. Furthermore, to build observability for your distributed
    system, you will likely use different tools to implement monitoring, logging,
    and tracing practices.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: You should observe applications, networks, and infrastructures that you and
    your team(s) are responsible for, regardless of the tools used to implement them.
  prefs: []
  type: TYPE_NORMAL
- en: Applications and the underlying infrastructure can produce useful metrics, logs,
    and traces to correctly observe a system. As shown in [Figure 8-4](#observability-overview),
    collecting this telemetry data contributes to visualizing the state of the system
    and to triggering notifications when a part of your system is underperforming.
  prefs: []
  type: TYPE_NORMAL
- en: '![Observability overview](Images/dtjd_0804.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 8-4\. Gathering metrics, logs, and traces from applications and infrastructure
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Alerts help you acknowledge an unforeseen scenario and implement a recovery
    mechanism if the unexpected conditions reoccur. You can use distribution of notifications
    to identify a pattern in the normal workflow of the system. This pattern can further
    help you automate the recovery mechanism and use it whenever the alert is received.
  prefs: []
  type: TYPE_NORMAL
- en: As observability measures the state of a distributed system, you can have it
    as input to repair the faulty states of your microservices; see [Figure 8-5](Images/#observation-to-automatic-recovery).
    Kubernetes has a built-in self-healing mechanism that includes restarting failed
    containers, disposing of unhealthy containers, or not routing traffic to Pods
    that are not ready to serve traffic. At the node level, the control plane watches
    over the state of the worker nodes. Some practices for automating the recovery
    mechanism involve extending the Kubernetes self-healing mechanism by utilizing
    Job and DaemonSet resources. For example, you can use a DaemonSet to run a node-monitoring
    daemon on every worker, while a Job creates one or more Pods and retries execution
    of those until a specified number successfully terminate.
  prefs: []
  type: TYPE_NORMAL
- en: '![Observation to automatic recovery](Images/dtjd_0805.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 8-5\. Improving from observation to automating recovery
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Observability also helps you measure the state of the system when traffic spikes
    occur. Applications that respond with delay induce frustrations in end users.
    In such cases, you should investigate how you can scale your containerized applications.
    Moreover, autoscaling eliminates the need to respond manually to traffic spikes
    that need new resources and instances by automatically changing their active number.
  prefs: []
  type: TYPE_NORMAL
- en: In Kubernetes, a HorizontalPodAutoscaler (HPA) resource automatically updates
    a workload resource like Deployment, aiming to scale the workload to match demand
    automatically. A HorizontalPodAutoscaler resource responds to increased load by
    deploying more Pods. If the load diminishes and the number of Pods is above the
    minimum configured, the HorizontalPodAutoscaler requires the Deployment resource
    to scale down.
  prefs: []
  type: TYPE_NORMAL
- en: 'As explained in the [Kubernetes documentation](https://oreil.ly/UWebg), the
    algorithm HorizontalPodAutoscaler uses the ratio of the desired metric value to
    the current metric value:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE46]'
  prefs: []
  type: TYPE_PRE
- en: 'To demonstrate how the preceding algorithm works when you set up a HorizontalPodAutoscaler
    resource, let’s reuse the example from [“Adjusting Resource Quotas”](#adjusting-resource-quotas),
    where we adjusted resource quotas:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE47]'
  prefs: []
  type: TYPE_PRE
- en: 'Each Pod using the previous configuration can request a minimum 100 m for CPU.
    You can set up the HorizontalPodAutoscaler to maintain an average CPU utilization
    across all Pods of 80% for this deployment by using the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE48]'
  prefs: []
  type: TYPE_PRE
- en: Assuming that the current metric value for CPU is 320 m and the desired value
    is 160 m, the number of replicas needed is 320 / 160 = 2.0. Based on the HorizontalPodAutoscaler
    configuration, the Deployment updates the ReplicaSet and then the ReplicaSet adds
    Pods to match the workload need. If the current metric value for CPU decreases
    at 120 m, the number of replicas needed will be 120 / 160 = 0.75, and the scale-down
    to one replica will occur gradually.
  prefs: []
  type: TYPE_NORMAL
- en: Another option to scale with Kubernetes is to use *vertical scaling*, which
    means to match the workload by assigning more resources to the Pods that are already
    running. [VerticalPodAutoscaler](https://oreil.ly/vTegk) (VPA) needs to be installed
    and enabled in order to further use its policies. To avoid undefined behavior
    over your Pods, do not use VerticalPodAutoscaler and HorizontalPodAutoscaler simultaneously
    to adjust CPU or memory of resources.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s look into some monitoring, logging, and tracing recommendations to understand
    observability better when deploying, scaling, and maintaining containerized applications.
  prefs: []
  type: TYPE_NORMAL
- en: Monitoring
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: You can use monitoring to observe a system in near real-time. Typically, this
    practice involves setting up a technical solution that can gather logs and predefined
    sets of metrics, as shown in [Figure 8-6](#pull-and-query-metrics).
  prefs: []
  type: TYPE_NORMAL
- en: '![Pulling and querying metrics](Images/dtjd_0806.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 8-6\. Pulling and querying metrics
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: '*Metrics* are numeric values of system properties over time, like maximum Java
    heap memory available or the total number of garbage collections that occurred.
    [Table 8-6](#metrics_types) shows which metrics can help you when monitoring a
    system.'
  prefs: []
  type: TYPE_NORMAL
- en: Table 8-6\. General types of metrics
  prefs: []
  type: TYPE_NORMAL
- en: '| Name | Description |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| *Counter* | A cumulative value based on incrementing an integer |'
  prefs: []
  type: TYPE_TB
- en: '| *Timer* | Measures both the count of timed events and the total time of all
    timed events |'
  prefs: []
  type: TYPE_TB
- en: '| *Gauge* | A single numerical value that can go up and down arbitrarily |'
  prefs: []
  type: TYPE_TB
- en: '| *Histogram* | Measures distribution of values in a stream of data |'
  prefs: []
  type: TYPE_TB
- en: '| *Meter* | Indicates the rate at which a set of events occur |'
  prefs: []
  type: TYPE_TB
- en: A few popular Java libraries for working with metrics include MicroProfile Metrics,
    Spring Boot Actuator, and Micrometer. For a better overview of your system behavior,
    you can collect and query these metrics with tools such as [Prometheus](https://prometheus.io).
  prefs: []
  type: TYPE_NORMAL
- en: To provide you with an example, we will reuse [Example 8-1](#example_0801),
    expose its metrics under */actuator/prometheus*, and send those to Prometheus
    by generating the container image and Kubernetes resources using Eclipse JKube.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s start by adding the Micrometer registry dependency, which specifically
    enables Prometheus support:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE49]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, you need to instruct Spring Boot’s Actuator which endpoints it should
    expose by adding this line to *src/main/resources/application.properties*:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE50]'
  prefs: []
  type: TYPE_PRE
- en: 'The Spring Boot application exposes the metrics under */actuator/prometheus*.
    Metrics related to JVM are also available at */actuator/prometheus*, such as `jvm.gc.pause`
    that measures garbage collection pause times. To further expose these metrics
    at the container and Kubernetes resource level, we can customize the Eclipse JKube
    setup with the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE51]'
  prefs: []
  type: TYPE_PRE
- en: '[![1](Images/1.png)](#co_deploying_for_developers_CO9-1)'
  prefs: []
  type: TYPE_NORMAL
- en: Execute this configuration with the `k8s:resource` goal.
  prefs: []
  type: TYPE_NORMAL
- en: '[![2](Images/2.png)](#co_deploying_for_developers_CO9-2)'
  prefs: []
  type: TYPE_NORMAL
- en: Adjust the generated Docker image to expose the Prometheus port.
  prefs: []
  type: TYPE_NORMAL
- en: '[![3](Images/3.png)](#co_deploying_for_developers_CO9-3)'
  prefs: []
  type: TYPE_NORMAL
- en: Expose the 9779 port at the container-image level and have it in Kubernetes
    resources annotations.
  prefs: []
  type: TYPE_NORMAL
- en: '[![4](Images/4.png)](#co_deploying_for_developers_CO9-4)'
  prefs: []
  type: TYPE_NORMAL
- en: Generate Kubernetes resources helpful for Spring Boot applications.
  prefs: []
  type: TYPE_NORMAL
- en: 'To build the container image and generate the Kubernetes resources, run the
    following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE52]'
  prefs: []
  type: TYPE_PRE
- en: 'The Kubernetes resources generated at *target/classes/META-INF/jkube/kubernetes.yml*
    will contain the Prometheus annotations controlling the metrics collection process:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE53]'
  prefs: []
  type: TYPE_PRE
- en: 'Once you deploy the generated resources, you can use a custom Prometheus query
    (PromQL) to query different metrics. For example, you can pick the `jvm.gc.pause`
    metric and run the following PromQL query to check the average time spent in garbage
    collection by cause:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE54]'
  prefs: []
  type: TYPE_PRE
- en: 'When generating and capturing metrics, several best practices should be followed:'
  prefs: []
  type: TYPE_NORMAL
- en: As metrics can be defined at both the application and infrastructure level,
    have team members collaborate on defining those.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Always expose internal JVM metrics, such as number of threads, CPU usage, how
    often the garbage collector ran, heap, and nonheap memory usage.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Make an effort to create metrics for application-specific implementations that
    impact nonfunctional requirements. For example, cache statistics like size, hits,
    and entry time-to-live can offer you insights when assessing the performance of
    a functionality.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Tailor metrics that can support key performance indicators (KPIs) used by business
    people. For example, the number of end users who used a new functionality is a
    KPI that can be proven with software metrics.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Measure and expose details about errors and exceptions that occur within your
    system. You can use these details later to establish error patterns and thus perform
    an enhancement.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Logging
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'At the Java application level, developers use logging to record exceptional
    cases. Logs are useful to obtain insights with additional context information
    and can complement existing metrics. When it comes to logging, three formats are
    available: plain text, JSON or XML, and binary.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Besides the Java language built-in log, several logging frameworks can help
    you achieve this task: [Simple Logging Facade for Java (SLF4J)](http://www.slf4j.org)
    and [Apache Log4j 2](https://oreil.ly/foEtO). Some logging best practices include
    the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Be conservative; log only details that are relevant to a particular functionality
    of your system.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Write meaningful information in the log message in order to help you and your
    colleagues troubleshoot future issues.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Use the correct log level: `TRACE` for capturing fine-grained insights, `DEBUG`
    for statements helpful when troubleshooting, `INFO` for general information, `WARN`
    and `ERROR` to signal events that might require action.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Make sure you use guard clauses or lambda expressions to log messages if the
    corresponding log level is enabled.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Have the log level customizable via variables that can be set at container runtime.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Set appropriate permissions to locations where your log files will live.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Customize layout of your logs to have region-specific formats.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Protect sensitive data when logging. For example, logging personally identifiable
    information (PII) can lead not only to compliance violations, but also to security
    vulnerabilities.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Periodically rotate logs to prevent log files from growing too large or have
    them automatically discarded. Container and Pod logs are transient by default.
    This means that the container logs are gone when Pods are deleted, crashed, or
    scheduled on a different node. But you can stream your logs asynchronously to
    a centralized storage or service and keep locally a fixed number of rotated log
    files.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Tracing
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Within a distributed system, a request traverses multiple components. Tracing
    helps you capture metadata and timing details concerning the flow of a request
    to identify slow transactions or where failures occur.
  prefs: []
  type: TYPE_NORMAL
- en: 'Finding the right instrumentation to capture traces can be challenging for
    a developer. Proprietary agents can help you with that, but you should look into
    solutions aligned to vendor-neutral, open standards like [OpenCensus](https://opencensus.io)
    or [OpenTracing](https://opentracing.io). Many developers found it difficult to
    choose the best option for an application and have it work across vendors and
    projects, so OpenTracing and OpenCensus projects merged and formed another [CNCF](https://www.cncf.io)
    incubating project called [OpenTelemetry](https://oreil.ly/QyOhu). This collection
    of tools, APIs, and SDKs standardizes the way you collect and transmit metrics,
    logs, and traces. The OpenTelemetry tracing specification defines the following
    terms:'
  prefs: []
  type: TYPE_NORMAL
- en: Trace
  prefs: []
  type: TYPE_NORMAL
- en: A single transaction request that uses other services and resources as it moves
    through a distributed system.
  prefs: []
  type: TYPE_NORMAL
- en: Span
  prefs: []
  type: TYPE_NORMAL
- en: A named, timed operation representing a workflow piece. A trace contains multiple
    spans.
  prefs: []
  type: TYPE_NORMAL
- en: Attributes
  prefs: []
  type: TYPE_NORMAL
- en: Key/value pairs that you can use to query, filter, and comprehend trace data.
  prefs: []
  type: TYPE_NORMAL
- en: Baggage items
  prefs: []
  type: TYPE_NORMAL
- en: Key/value pairs that cross process boundaries.
  prefs: []
  type: TYPE_NORMAL
- en: Context propagation
  prefs: []
  type: TYPE_NORMAL
- en: A common subsystem shared by traces, metrics, and baggage. A developer can pass
    additional context information to a span by using attributes, logs, and baggage
    items.
  prefs: []
  type: TYPE_NORMAL
- en: '[Figure 8-7](#distributed-tracing) illustrates the trace for a transaction
    that begins with microservice Blue and traverses microservices Violet and Green.
    The trace has three spans, and attributes are set on the Violet and Green spans.'
  prefs: []
  type: TYPE_NORMAL
- en: '![Distributed tracing example](Images/dtjd_0807.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 8-7\. Distributed tracing example
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: To give an example that incorporates both metrics and traces, we will enhance
    [Example 8-2](#generate-kubernetes-resources-with-jkube) by tracing the request
    to the */greeting* endpoint and detecting the time spent to return a response
    with a Timer metric.
  prefs: []
  type: TYPE_NORMAL
- en: 'Next, let’s export the metrics to Prometheus and for further processing include
    OpenTelemetry support by adding the following Quarkus extensions:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE55]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, let’s customize the endpoint for sending spans by adding the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE56]'
  prefs: []
  type: TYPE_PRE
- en: '[![1](Images/1.png)](#co_deploying_for_developers_CO10-1)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Define the host as a configuration that you can parametrize. The default value
    for the host of the endpoint is `localhost`, but you can override it with `-Dexporter.host`:
    `mvn package -Dexporter.host=myhost`.'
  prefs: []
  type: TYPE_NORMAL
- en: '[![2](Images/2.png)](#co_deploying_for_developers_CO10-2)'
  prefs: []
  type: TYPE_NORMAL
- en: At compile time, the `quarkus-kubernetes` extension that is already in the project
    will take into account this environment variable and autogenerate the configuration
    of the Kubernetes resources. The configuration reuses the value of `custom.host`.
  prefs: []
  type: TYPE_NORMAL
- en: '[![3](Images/3.png)](#co_deploying_for_developers_CO10-3)'
  prefs: []
  type: TYPE_NORMAL
- en: The gRPC endpoint for sending spans that reuses the previous host definition.
    The configuration reuses the value of `custom.host`.
  prefs: []
  type: TYPE_NORMAL
- en: 'To measure the duration of a request sent to the */greeting* endpoint, we will
    annotate it with `@Timed` and instrument its traces by customizing a `Span` with
    two attributes:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE57]'
  prefs: []
  type: TYPE_PRE
- en: '[![1](Images/1.png)](#co_deploying_for_developers_CO11-1)'
  prefs: []
  type: TYPE_NORMAL
- en: Attribute set to trace when the logic started.
  prefs: []
  type: TYPE_NORMAL
- en: '[![2](Images/2.png)](#co_deploying_for_developers_CO11-2)'
  prefs: []
  type: TYPE_NORMAL
- en: After recording the exception, set the attribute to trace the exception case.
  prefs: []
  type: TYPE_NORMAL
- en: 'Given the changes introduced, you can rebuild and push the container image,
    and deploy the Kubernetes resources generated at compile time by using the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE58]'
  prefs: []
  type: TYPE_PRE
- en: To instrument end-to-end distributed tracing, you can use a tool like [Jaeger](https://oreil.ly/Kp09K)
    ([Figure 8-8](#jaeger-filtered-trace)). This top-level [CNCF project](https://oreil.ly/vZRTZ)
    can easily integrate with Kubernetes. You can set up the value for `quarkus​.opentele⁠metry.tracer.exporter.otlp.endpoint`
    by using the Jaeger endpoint. Within the Jaeger UI, you can search traces by using
    the `pause` tag.
  prefs: []
  type: TYPE_NORMAL
- en: '![Filtering traces by tag with Jaeger](Images/dtjd_0808.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 8-8\. Filtering traces by tag with Jaeger
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'Furthermore, you can observe the requests that generated an exception as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Search in the Jaeger UI for traces having `error=true` and `unexpec⁠ted​.pause=exception`
    tags.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Utilize the `Timer` named `custom` in a Prometheus query like the following
    one:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE59]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Inspect logs for the message `Thread interrupted`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Here are some recommended practices for tracing:'
  prefs: []
  type: TYPE_NORMAL
- en: Instrument a trace end-to-end, meaning forward the tracing headers to all the
    downstream services, data stores, or middleware part of your system.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Report metrics related to request rate, errors, and their duration. The rate,
    errors, duration (RED) method is popular in the SRE world and focuses on instrumenting:
    request throughput, request error rate, latency, or response time.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If you instrument your custom tracing spans, avoid using a lot of metadata.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: When searching for Java-compatible tracing solutions, look at the language-specific
    implementation of [OpenTelemetry in Java](https://oreil.ly/Df5RD).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: When designing systems for observability, remember that your metrics and logs
    should be available for a later analysis. As a consequence, regardless of where
    you deploy, always have tools and practices that can reliably capture and store
    metrics and logging data.
  prefs: []
  type: TYPE_NORMAL
- en: High Availability and Geographic Distribution
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: When working on a software system, you have probably received a nonfunctional
    requirement indicating that your application(s) should be available 24/7. In the
    industry literature, *availability* refers to the probability that a system is
    operational at a given time; this is expressed as a percentage of uptime in a
    given year.
  prefs: []
  type: TYPE_NORMAL
- en: '*High availability* (HA) is the ability of a system to work continuously without
    failure for an established time. As developers, we create software with the intent
    to be always available for end users, but external factors like power outages,
    network failures, and underprovisioned environments can impact the quality of
    service received by consumers.'
  prefs: []
  type: TYPE_NORMAL
- en: Small-size container images and successful deployments to Kubernetes are the
    first steps toward having an application available on Kubernetes. For example,
    let’s assume you have to upgrade your worker nodes to a newer Kubernetes version.
    This operation includes that your nodes have to pull all the containers before
    working with the latest Kubernetes version. The longer it takes for each node
    to pull the containers, the lengthier it will be for the cluster to work as expected.
  prefs: []
  type: TYPE_NORMAL
- en: Different deployment strategies were explained in [“Choose and Implement a Deployment
    Strategy”](#choosing-and-implementing-a-deployment-strategy) because downtime,
    traffic routing between deployment versions, and the rollback process influence
    availability. In a failed deployment, a fast rollback process can save you from
    user discomfort, time, and compute resources. Moreover, you want your system to
    have a highly available state, and the way you define health checks and adjust
    resources for your containerized applications impacts its performance to work
    continuously without failure for an established time. Eventually, you can fine-tune
    your health checks, resource consumption, and deployments by observing your system’s
    behavior through logs, metrics, and traces.
  prefs: []
  type: TYPE_NORMAL
- en: Availability is commonly defined as a percentage of uptime in a given year.
    [Table 8-7](#connecting-availability-and-downtime) shows the connection between
    a given availability percentage to the corresponding amount of downtime per year.
    The table uses a year with 365 days, and for consistency, all times are rounded
    to two decimal digits.
  prefs: []
  type: TYPE_NORMAL
- en: Table 8-7\. Connecting a certain availability percentage to downtime per year
  prefs: []
  type: TYPE_NORMAL
- en: '| Availability % | Downtime in a year |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| 90% | 36.5 days |'
  prefs: []
  type: TYPE_TB
- en: '| 95% | 18.25 days |'
  prefs: []
  type: TYPE_TB
- en: '| 99% | 3.65 days |'
  prefs: []
  type: TYPE_TB
- en: '| 99.9% | 8.76 hours |'
  prefs: []
  type: TYPE_TB
- en: '| 99.95% | 4.38 hours |'
  prefs: []
  type: TYPE_TB
- en: '| 99.99% | 52.56 minutes |'
  prefs: []
  type: TYPE_TB
- en: '| 99.999% | 5.25 minutes |'
  prefs: []
  type: TYPE_TB
- en: '| 99.9999% | 31.53 seconds |'
  prefs: []
  type: TYPE_TB
- en: Nowadays, service providers use service-level indicators (SLIs) to measure the
    goal set by a service-level objective (SLO). SLOs are the individual commitments
    made by the service provider to a customer. You can incorporate the percentages
    from [Table 8-7](#connecting-availability-and-downtime) by setting a value for
    availability as part of the SLO. Tools like [Prometheus](https://prometheus.io)
    and [Grafana](https://grafana.com) can help you calculate the performance of your
    applications by incorporating the SLOs, querying metrics, and alerting when goals
    are endangered.
  prefs: []
  type: TYPE_NORMAL
- en: 'To create highly available systems, reliability engineering offers three principles
    of systems design:'
  prefs: []
  type: TYPE_NORMAL
- en: Eliminate single points of failure at the application, network, and infrastructure
    level. Because even the way you internally code your application can sometimes
    generate failures, you should properly test every software component. Observability
    and great deployment strategies help you eliminate the possible failures in your
    system.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Detect failures as they occur. Monitoring and alerting help discover when a
    system reaches critical conditions.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Have a reliable transition to a running component when a failure occurs to another
    one. An efficient rollback process in case of deployment issues, the Kubernetes
    self-healing mechanism, and smooth traffic routing between Kubernetes resources
    help in this matter.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'A good plan for failure involves following the preceding principles and implementing
    them using several best practices:'
  prefs: []
  type: TYPE_NORMAL
- en: Perform data backups, recovery, and replications.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Set up network load balancing to distribute the traffic efficiently when increased
    workloads are received by the critical features of your applications. Load balancing
    helps you eliminate single points of failure at the application level while using
    the network and infrastructure available.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: When it comes to natural disasters that could affect your system, having it
    deployed in multiple geographical locations can prevent service failure. It is
    critical to run independent application stacks in each location so the others
    can continue running if a failure occurs in one place. Ideally, these locations
    should spread globally and not be localized in a specific area.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If you are worried about a Kubernetes cluster performance when a component or
    its control-plane node goes down, you should choose to have highly available Kubernetes
    [clusters](https://oreil.ly/9iTgz). Kubernetes high availability is about having
    a multiple control-plane setup behaving like a unified data center. A setup consisting
    of multiple control planes protects your system from losing a worker node to the
    failure of the control plane node’s etcd. Managing Kubernetes clusters is not
    an easy task, but you should know that a wide range of cloud providers will share
    this type of configuration up-front when setting the clusters for you.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Depending on your requirements, maintaining multiregion Kubernetes clusters
    can be unjustified. But you can still set up multiple namespaces to ensure availability
    across the same cluster.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Since one of the previous practices involved multiregional deployments, you
    should know that by using this technique, you can improve end-user experiences
    by keeping latencies low for a distributed user base. Your application architecture
    can achieve low latency because it would keep data close to end users distributed
    worldwide.
  prefs: []
  type: TYPE_NORMAL
- en: Another aspect to consider when having geographically distributed applications
    is the ability to comply with data privacy laws and regulations. As more and more
    social and economic activities occur online, the importance of privacy and data
    protection is increasingly recognized. In some countries, collection, usage, and
    sharing of personal information to different parties without notice or consent
    of consumers are considered illegal. According to [United Nations Conference on
    Trade and Development (UNCTAD)](https://oreil.ly/p0KH2), 128 out of 194 countries
    have put in place legislation to secure the protection of data and privacy.
  prefs: []
  type: TYPE_NORMAL
- en: As you start to understand the requirements on your end to ensure the high availability
    of a distributed system, let’s explore the cloud models that can help you achieve
    it.
  prefs: []
  type: TYPE_NORMAL
- en: Hybrid and MultiCloud Architectures
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The *cloud* is a collection of technologies to approach challenges like availability,
    scaling, security, and resilience. It can exist on premises, on a Kubernetes distribution,
    or in a public infrastructure. Often, you will see the terms *hybrid cloud* and
    *multicloud* used synonymously. The most intuitive definition for a multicloud
    architecture is that this type of architecture requires at least one public cloud.
  prefs: []
  type: TYPE_NORMAL
- en: Hybrid cloud architecture differs from multicloud by including a private cloud
    infrastructure component and at least one public cloud ([Figure 8-9](#multi-cloud-hybrid-cloud)).
    As a result, when a hybrid cloud architecture has more than one public offering,
    that architecture can be simultaneously a multicloud one.
  prefs: []
  type: TYPE_NORMAL
- en: '![Multi-cloud and Hybrid Cloud](Images/dtjd_0809.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 8-9\. Multicloud and hybrid cloud
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'When deploying on hybrid or multicloud infrastructures, you should take into
    consideration these cross-team aspects:'
  prefs: []
  type: TYPE_NORMAL
- en: Having a unified view over what and where you deployed.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Replacing provider-specific SaaS and IaaS services.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Following a unified approach for mitigating security vulnerabilities across
    clouds.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Scaling out and provisioning new resources seamlessly.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: When you port applications across clouds, you need to avoid disconnection of
    services. There is a time to recovery when moving workloads between infrastructures,
    but you can provide an end-user flawless transition using appropriate network
    configurations and deployment strategies.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: At such a large scale, automation helps when orchestrating processes. Besides,
    the orchestrations platform for containerized applications, you and your team
    will likely add an extra layer of tools and processes to manage workloads.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'From a developer point of view, you can contribute to a hybrid or multicloud
    strategy by taking care of these elements:'
  prefs: []
  type: TYPE_NORMAL
- en: Your application’s codebase should be the same regardless of the environment
    (namespace).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Your local building and deployment practice should be reproducible when other
    colleagues attempt to work with your code.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Avoid referencing local dependencies in your code or container image build.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: When possible, parameterize the container image through build-time variables
    or environment variables.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If you need to support environment customizations, propagate them with environment
    variables from the orchestration platform toward container/application code parameters.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Use dependencies and images from repositories and registries that your organization
    has previously validated as trusted sources.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Prefer volumes to share information among containers.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: When working toward a hybrid or multicloud architecture, always ask yourself
    how you and your colleagues will evolve the software piece you are currently building.
    A progressive software architecture starts with a forward-thinking developer mindset.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'This chapter covered aspects of deployments that can concern a Java developer.
    Although the typical Java developer role does not involve infrastructure administration,
    you can influence the operational stages and processes of your application by
    doing the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Building and pushing container images to container image registries by using
    Java-based tools like Jib and Eclipse JKube
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Generating and deploying Kubernetes manifests by using Dekorate and Eclipse
    JKube
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Implementing health checks and coordinating their execution at the infrastructure
    level
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Observing the behavior of the distributed system in order to know when to introduce
    changes and which resources to adjust
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Associating deployment aspects with high availability, hybrid, and multicloud
    architectures
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Since you have a good understanding of deploying applications, the next chapter
    investigates DevOps workflows for mobile software.
  prefs: []
  type: TYPE_NORMAL
