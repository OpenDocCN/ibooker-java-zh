- en: Chapter 11\. Data Science and R
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Data science is a relatively new discipline that first came to the attention
    of many with this [article by O’Reilly’s Mike Loukides](https://www.oreilly.com/ideas/what-is-data-science).
    While there are many definitions in the field, Loukides distills his detailed
    observation of and participation in the field into this definition:'
  prefs: []
  type: TYPE_NORMAL
- en: A data application acquires its value from the data itself, and creates more
    data as a result. It’s not just an application with data; it’s a data product.
    Data science enables the creation of data products.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: One of the main open source ecosystems for data science software is at Apache
    and includes [Hadoop](https://hadoop.apache.org) (which includes the HDFS distributed
    filesystem, Hadoop Map/Reduce,^([1](ch11.html#idm45290648185096)) Ozone object
    store, and Yarn scheduler), the [Cassandra distributed database](https://cassandra.apache.org),
    and the [Spark compute engine](https://spark.apache.org). Read the “Modules and
    Related Tools” section of the Hadoop page for a current list.
  prefs: []
  type: TYPE_NORMAL
- en: What’s interesting here is that a great deal of this infrastructure, which is
    taken for granted by data scientists, is written in Java and Scala (a JVM language).
    Much of the rest is written in Python, a language that complements Java.
  prefs: []
  type: TYPE_NORMAL
- en: Data science problems may involve a lot of setup, so we’ll only give one example
    from traditional DS, using the Spark framework. Spark is written in Scala so it
    can be used directly by Java code.
  prefs: []
  type: TYPE_NORMAL
- en: In the rest of the chapter I’ll focus on a language called R, which is widely
    used both in statistics and in data science (well, also in many other sciences;
    many of the graphs you see in refereed journal articles are prepared with R).
    R is widely used and is useful to know. Its primary implementation was not written
    in Java, but in a mixture of C, Fortran, and R itself. But R can be used within
    Java, and Java can be used within R. I’ll talk about several implementations of
    R and how to select one, and then I’ll show techniques for using Java from R and
    R from Java, as well as using R in a web application.
  prefs: []
  type: TYPE_NORMAL
- en: 11.1 Machine Learning with Java
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Problem
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: You want to use Java for machine learning and data science, but everyone tells
    you to use Python.
  prefs: []
  type: TYPE_NORMAL
- en: Solution
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Use one of the many powerful Java toolkits available for free download.
  prefs: []
  type: TYPE_NORMAL
- en: Discussion
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: It’s sometimes said that machine learning (ML) and deep learning have to be
    done in C++ for efficiency or in Python for the wide availability of software.
    While these languages have their advantages and their advocates, it is certainly
    possible to use Java for these purposes. However, setting up these packages and
    presenting a short demo tends to be longer than would fit in this book’s typical
    recipe format.
  prefs: []
  type: TYPE_NORMAL
- en: With industry giant Amazon having released its Java-based Deep Java Learning
    (DJL) library as this book was going to press, and many other good libraries available
    (with quite a few supporting [CUDA](https://developer.nvidia.com/cuda-zone) for
    faster GPU-based processing) (see [Table 11-1](#javacook-ds-java-ml)), there is
    no reason to avoid using Java for ML. With the exception of DJL, I’ve tried to
    list packages that are still being maintained and have a decent reputation among
    users.
  prefs: []
  type: TYPE_NORMAL
- en: Table 11-1\. Some Java machine learning packages
  prefs: []
  type: TYPE_NORMAL
- en: '| Library name | Description | Info URL | Source URL |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| ADAMS | Workflow engine for building/maintaining data-driven, reactive workflows;
    integration with business processes | [*https://adams.cms.waikato.ac.nz/*](https://adams.cms.waikato.ac.nz/)
    | [*https://github.com/waikato-datamining/adams-base*](https://github.com/waikato-datamining/adams-base)
    |'
  prefs: []
  type: TYPE_TB
- en: '| Deep Java Library | Amazon’s ML library | [*https://djl.ai*](https://djl.ai)
    | [*https://github.com/awslabs/djl*](https://github.com/awslabs/djl) |'
  prefs: []
  type: TYPE_TB
- en: '| Deeplearning4j | DL4J, Eclipse’s distributed deep-learning library; integrates
    w/ Hadoop and Apache Spark | [*https://deeplearning4j.org/*](https://deeplearning4j.org/)
    | [*https://github.com/eclipse/deeplearning4j*](https://github.com/eclipse/deeplearning4j)
    |'
  prefs: []
  type: TYPE_TB
- en: '| ELKI | Data mining toolkit | [*https://elki-project.github.io/*](https://elki-project.github.io/)
    | [*https://github.com/elki-project/elki*](https://github.com/elki-project/elki)
    |'
  prefs: []
  type: TYPE_TB
- en: '| Mallet | ML for text processing | mallet.cs.umass.edu | [*https://github.com/mimno/Mallet.git*](https://github.com/mimno/Mallet.git)
    |'
  prefs: []
  type: TYPE_TB
- en: '| Weka | ML algorithms for data mining; tools for data preparation, classification,
    regression, clustering, association rules mining, and visualization | [*https://www.cs.waikato.ac.nz/ml/weka/index.html*](https://www.cs.waikato.ac.nz/ml/weka/index.html)
    | [*https://svn.cms.waikato.ac.nz/svn/weka/trunk/weka*](https://svn.cms.waikato.ac.nz/svn/weka/trunk/weka)
    |'
  prefs: []
  type: TYPE_TB
- en: See Also
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The book *Data Mining: Practical Machine Learning and Techniques* by Ian Witten
    et al. (Morgan Kaufmann) was written by the team behind Weka.'
  prefs: []
  type: TYPE_NORMAL
- en: See also Eugen Parschiv’s [list of Java AI software packages](https://www.baeldung.com/java-ai).
  prefs: []
  type: TYPE_NORMAL
- en: 11.2 Using Data In Apache Spark
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Problem
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: You want to process data using Spark.
  prefs: []
  type: TYPE_NORMAL
- en: Solution
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Create a `SparkSession`, use its `read()` function to read a `DataSet`, apply
    operations, and summarize results.
  prefs: []
  type: TYPE_NORMAL
- en: Discussion
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Spark is a massive subject! Entire books have been written on using it. Quoting
    [Databricks](https://databricks.com), home of much of the original Spark team:^([2](ch11.html#idm45290648114600))
  prefs: []
  type: TYPE_NORMAL
- en: Apache Spark™ has seen immense growth over the past several years, becoming
    the de-facto data processing and AI engine in enterprises today due to its speed,
    ease of use, and sophisticated analytics. Spark unifies data and AI by simplifying
    data preparation at massive scale across various sources, providing a consistent
    set of APIs for both data engineering and data science workloads, as well as seamless
    integration with popular AI frameworks and libraries such as TensorFlow, PyTorch,
    R and SciKit-Learn.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: I cannot convey the whole subject matter in this book. However, one thing Spark
    is good for is dealing with lots of data. In [Example 11-1](#javacook-ds-EX-spark1),
    we read an Apache-format logfile and find (and count) the lines with 200, 404,
    and 500 responses.
  prefs: []
  type: TYPE_NORMAL
- en: Example 11-1\. spark/src/main/java/sparkdemo/LogReader.java
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: '[![1](assets/1.png)](#co_data_science_and_r_CO1-1)'
  prefs: []
  type: TYPE_NORMAL
- en: Set up the filename for the logfile. It probably should come from `args`.
  prefs: []
  type: TYPE_NORMAL
- en: '[![2](assets/2.png)](#co_data_science_and_r_CO1-2)'
  prefs: []
  type: TYPE_NORMAL
- en: Start up the Spark `SparkSession` object—the runtime.
  prefs: []
  type: TYPE_NORMAL
- en: '[![3](assets/3.png)](#co_data_science_and_r_CO1-3)'
  prefs: []
  type: TYPE_NORMAL
- en: Tell Spark to read the logfile and keep it in memory (cache).
  prefs: []
  type: TYPE_NORMAL
- en: '[![4](assets/4.png)](#co_data_science_and_r_CO1-4)'
  prefs: []
  type: TYPE_NORMAL
- en: Define the filters for 200, 404, and 500 errors. They should be able to use
    lambdas to make the code shorter, but there’s an ambiguity between the Java and
    Scala versions of `FilterFunction`.
  prefs: []
  type: TYPE_NORMAL
- en: '[![5](assets/5.png)](#co_data_science_and_r_CO1-5)'
  prefs: []
  type: TYPE_NORMAL
- en: Print the results.
  prefs: []
  type: TYPE_NORMAL
- en: 'To make this *compile*, you need to add the following to a Maven POM file:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: Then you should be able to do `mvn package` to get a JAR file packaged.
  prefs: []
  type: TYPE_NORMAL
- en: 'The use of the `provided` scope is because we will also download the Apache
    Spark runtime package from [the Spark Download page](https://spark.apache.org/downloads.html)
    in order to *run* the application. Unpack the distribution and set the `SPARK_HOME`
    environment to the root of it:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: Then you can use the `run` script that I’ve provided in the source download
    (*javasrc/spark*).
  prefs: []
  type: TYPE_NORMAL
- en: 'Spark is designed for larger-scale computing than what’s in this simple example,
    so its voluminous output simply dwarfs the output from my simple sample program.
    Nonetheless, for an approximately 42,000-line file, I did get this result, buried
    among the logging:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: As mentioned, Spark is a massive subject but a necessary tool for most data
    scientists. You can program Spark in Java (obviously), or in Scala. Scala is a
    JVM language that promotes functional programming (see [this Scala tutorial for
    Java devs](https://www.dhgarrette.com/nlpclass/scala/basics.html)) in Python and
    probably other languages. You can learn more at [*https://spark.apache.org*](https://spark.apache.org)
    or from the many books, videos, and tutorials online.
  prefs: []
  type: TYPE_NORMAL
- en: 11.3 Using R Interactively
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Problem
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: You don’t know the first thing about R, and you want to.
  prefs: []
  type: TYPE_NORMAL
- en: Solution
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: R has been around for ages, and its predecessor S for a decade before that.
    There are many books and online resources devoted to this language. The official
    home page is at [*https://www.r-project.org*](https://www.r-project.org). There
    are many online tutorials; the [R Project hosts one](https://cran.r-project.org/doc/contrib/Paradis-rdebuts_en.pdf).
    R itself is available in most systems’ package managers, and it can be downloaded
    from the official [download site](https://cran.r-project.org/mirrors.html). The
    name *CRAN* in these URLs stands for Comprehensive R Archive Network, named in
    a similar fashion to TeX’s CTAN and the Perl language’s CPAN.
  prefs: []
  type: TYPE_NORMAL
- en: In this example we’ll write some data from a Java program and then analyze and
    graph it using R interactively.
  prefs: []
  type: TYPE_NORMAL
- en: Discussion
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'This is merely a brief intro to using R interactively. Suffice to say that
    R is a valuable interactive environment for exploring data. Here are some simple
    calculations to show the flavor of the language: a chatty startup (so long I had
    to cut part of it), simple arithmetic, automatic printing of results if not saved,
    half-decent errors when you make a mistake, and arithmetic on vectors. You may
    see some similarities to Java’s JShell (see [Recipe 1.4](ch01.html#javacook-getstarted-JSHELL));
    both are REPL (Read-Evaluate-Print Loop) interfaces. R adds the ability to save
    your interactive session (*workspace*) when exiting the program, so all your data
    and function definitions are restored next time you start R. A simple interactive
    session showing a bit of the syntax of R might look like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: R purists will usually use the *assignment arrow* ← in lieu of the *=* sign
    when assigning. If you like that, go for it.
  prefs: []
  type: TYPE_NORMAL
- en: 'This short session barely scratches the surface: R offers hundreds of built-in
    functions, sample datasets, over a thousand add-on packages, built-in help, and
    much more. For interactive exploration of data, R is really the one to beat.'
  prefs: []
  type: TYPE_NORMAL
- en: Some people prefer a GUI frontend to R. [RStudio](https://rstudio.com) is the
    most widely used GUI frontend.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now we want to write some data from Java and process it in R (we’ll use Java
    and R together in later recipes in this chapter). In [Recipe 5.9](ch05.html#javacook-numbers-SECT-13)
    we discussed the `java.util.Random` class and its `nextDouble()` and `nextGaussian()`
    methods. The `nextDouble()` and related methods try to give a flat distribution
    between 0 and 1.0, in which each value has an equal chance of being selected.
    A Gaussian or normal distribution is a bell curve of values from negative infinity
    to positive infinity, with the majority of the values clustered around zero (0.0).
    We’ll use R’s histogramming and graphics functions to examine visually how well
    they do so:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: To illustrate the different distributions, I generated 10,000 numbers each using
    `nextRandom()` and `nextGaussian()`. The code for this is in *Random4.java* (not
    shown here) and is a combination of the preceding sample code with code to print
    just the numbers into two files. I then plotted histograms using R; the R script
    used to generate the graph is in *javasrc* under *src/main/resources*, but its
    core is shown in [Example 11-2](#javacook-ds-histograms). The results are shown
    in [Figure 11-1](#javacook-ds-FIG-1).
  prefs: []
  type: TYPE_NORMAL
- en: Example 11-2\. R commands to generate histograms
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: The `png()` call tells R which graphics device to use. Others include `X11()`
    and `Postscript()`. `read.table()` reads data from a text file into a table; the
    `[1]` gives us just the data column, ignoring some metadata. The `layout()` call
    says we want two graphics objects displayed side by side. Each `hist()` call draws
    one of the two histograms. And `dev.off()` closes the output and flushes any writing
    buffers to the PNG file. The result is shown in [Figure 11-1](#javacook-ds-FIG-1).
  prefs: []
  type: TYPE_NORMAL
- en: '![jcb4 1101](assets/jcb4_1101.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 11-1\. Flat (left) and Gaussian (right) distributions
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 11.4 Comparing/Choosing an R Implementation
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Problem
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: You’re not sure which implementation of R to use.
  prefs: []
  type: TYPE_NORMAL
- en: Solution
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Look at original R, Renjin, and FastR.
  prefs: []
  type: TYPE_NORMAL
- en: Discussion
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The original for R was S, an environment for interactive programming developed
    by John Chambers and others at AT&T Bell Labs starting in 1976. I ran into S when
    supporting the University of Toronto Statistics Department, and again when reviewing
    a commercial implementation of it, SPlus, for a long-ago glossy magazine called
    *Sun Expert*. AT&T was only making S source available to universities and to commercial
    licensees who could not further distribute the source. Two developers at the University
    of Auckland, Ross Ihaka and Robert Gentleman, developed a clone of S, starting
    in 1995. They named it R after their own first initials and as a play on the name
    S. (There is precedent for this: the *awk* language popular on Unix/Linux was
    named for the initials of its designers Aho, Weinberger, and Kernighan). R grew
    quickly because it was very largely compatible with S and was more readily available.
    This implementation of original R is actively managed by the [R Foundation for
    Statistical Computing](https://r-project.org), which also manages the [Comprehensive
    R Archive Network](https://cran.r-project.org).'
  prefs: []
  type: TYPE_NORMAL
- en: '[Renjin](http://renjin.org) is a fairly complete implementation of R in Java.
    This project provides built JAR files via their own Maven repository.'
  prefs: []
  type: TYPE_NORMAL
- en: '[FastR](https://jaxenter.com/fastr-r-virtual-machine-java-140667.html) is another
    implementation in Java, designed to run in the faster GraalVM and supporting direct
    invocation of JVM code from almost any other programming language. The technical
    lead of the FastR descibes the implementation in [this blog post](https://medium.com/graalvm/faster-r-with-fastr-4b8db0e0dceb).'
  prefs: []
  type: TYPE_NORMAL
- en: Besides these implementations, R’s popularity has led to development of many
    access libraries for invoking R from many popular programming languages. [Rserve](https://www.rforge.net/Rserve)
    is a TCP/IP networked access mode for R, for which Java wrappers exist.
  prefs: []
  type: TYPE_NORMAL
- en: '11.5 Using R from Within a Java App: Renjin'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Problem
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: You want to access R from within a Java application using Renjin.
  prefs: []
  type: TYPE_NORMAL
- en: Solution
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Add Renjin to your Maven or Gradle build, and call it via the Script Engines
    mechanism described in [Recipe 18.3](ch18.html#javacook-otherlang-scripting).
  prefs: []
  type: TYPE_NORMAL
- en: Discussion
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Renjin is a pure-Java, open source reimplementation of R and provides a script
    engines interface. Add the following dependency to your build tool:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: Of course there is probably a later version of Renjin than the one shown above
    by the time you read this; use the latest unless there’s a reason not to.
  prefs: []
  type: TYPE_NORMAL
- en: 'Note that you will also need a `<repository>` entry since the maintainers put
    their artifacts in the repo at `nexus.betadriven.com` instead of the usual Maven
    Central. Here’s what I used (obtained from [*https://www.renjin.org/downloads.html*](https://www.renjin.org/downloads.html)):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: Once that’s done, you should be able to access Renjin via the Script Engines
    framework, as in [Example 11-3](#otherlang-renjinscriptingjava).
  prefs: []
  type: TYPE_NORMAL
- en: Example 11-3\. main/src/main/java/otherlang/RenjinScripting.java
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: Because R treats all numbers as floating point, like many interpreters, the
    value printed is `84.0`.
  prefs: []
  type: TYPE_NORMAL
- en: One can also get Renjin to invoke a script file; [Example 11-4](#otherlang-renjinscriptinglonger)
    invokes the same script used in [Recipe 11.3](#javacook-ds-r-interact) to generate
    and plot a batch of pseudorandom numbers.
  prefs: []
  type: TYPE_NORMAL
- en: Example 11-4\. Renjin with a script file
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: Renjin can also be used as a standalone R implementation if you download an
    all-dependencies JAR file from [*https://renjin.org/downloads.html*](https://renjin.org/downloads.html).
  prefs: []
  type: TYPE_NORMAL
- en: 11.6 Using Java from Within an R Session
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Problem
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: You are partway through a computation in R and realize that there’s a Java library
    to do the next step. Or for any other reason, you need to call Java code from
    within an R session.
  prefs: []
  type: TYPE_NORMAL
- en: Solution
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Install rJava, call `.jinit()`, and use `J()` to load classes or invoke methods.
  prefs: []
  type: TYPE_NORMAL
- en: Discussion
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Here is the part of an interactive R session in which we install rJava, initialize
    it by calling `.jinit()`, and invoke `java.time.LocalDate.now()` to get the current
    date:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: '[![1](assets/1.png)](#co_data_science_and_r_CO2-1)'
  prefs: []
  type: TYPE_NORMAL
- en: Install the `rJava` package; only needs to be done once.
  prefs: []
  type: TYPE_NORMAL
- en: '[![2](assets/2.png)](#co_data_science_and_r_CO2-2)'
  prefs: []
  type: TYPE_NORMAL
- en: load `rJava`, and initialize it with `.jinit()`; both needed in every R session.
  prefs: []
  type: TYPE_NORMAL
- en: '[![3](assets/3.png)](#co_data_science_and_r_CO2-3)'
  prefs: []
  type: TYPE_NORMAL
- en: The `J` function takes one argument of a full class name. If only that argument
    is given, a class descriptor (like a `java.lang.Class` object) is returned. If
    more than one argument is given, the second is a static method name, and any subsequent
    arguments are passed to that method.
  prefs: []
  type: TYPE_NORMAL
- en: '[![4](assets/4.png)](#co_data_science_and_r_CO2-4)'
  prefs: []
  type: TYPE_NORMAL
- en: Returned objects can have Java methods invoked with the standard R *\$* notation;
    here the `toString()` method is invoked to return just a character string instead
    of a `LocalDate` object.
  prefs: []
  type: TYPE_NORMAL
- en: 'The `.jcall` function gives you more control over calling method and return
    types:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: '[![1](assets/1.png)](#co_data_science_and_r_CO3-1)'
  prefs: []
  type: TYPE_NORMAL
- en: Invoke Java `LocalDate.now()` method and save result in R variable *d*.
  prefs: []
  type: TYPE_NORMAL
- en: '[![2](assets/2.png)](#co_data_science_and_r_CO3-2)'
  prefs: []
  type: TYPE_NORMAL
- en: Invoke Java `getYear()` method on the `LocalDate` object; the “I” tells `jcall`
    to expect an integer result.
  prefs: []
  type: TYPE_NORMAL
- en: '[![3](assets/3.png)](#co_data_science_and_r_CO3-3)'
  prefs: []
  type: TYPE_NORMAL
- en: Call `System.getProperty("user.dir")` and print the result; the “S” tells `.jcall`
    to expect a string return.
  prefs: []
  type: TYPE_NORMAL
- en: '[![4](assets/4.png)](#co_data_science_and_r_CO3-4)'
  prefs: []
  type: TYPE_NORMAL
- en: If you will be using a class several times, save the `Class` object, and pass
    it as the first argument of `.jcall()`.
  prefs: []
  type: TYPE_NORMAL
- en: There are more capabilities here; consult [the documentation](https://cran.r-project.org/web/packages/rJava)
    and [a developer.com article](https://www.developer.com/java/ent/getting-started-with-r-using-java.html).
  prefs: []
  type: TYPE_NORMAL
- en: 11.7 Using FastR, the GraalVM Implementation of R
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Problem
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: You use the R language but feel a need for speed.
  prefs: []
  type: TYPE_NORMAL
- en: Solution
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Use FastR, Oracle’s GraalVM reimplementation of the R language.
  prefs: []
  type: TYPE_NORMAL
- en: Discussion
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Assuming you have installed GraalVM as described in [Recipe 1.2](ch01.html#jcb-getstarted-graal),
    you can just type the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'If you have set your `PATH` to have GraalVM before other directories, the command
    *R* will now give you the GraalVM version of R. To access the standard R, you
    will have to either set your `PATH` or give a full path to the R installation.
    On all Unix and Unix-like systems, the command *which R* will reveal all R commands
    on your `PATH`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'Let’s just run it:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: From that point on, you should be able to do practically anything that you would
    do in standard R, since this R’s source code is largely derived from the R Foundation’s
    source.
  prefs: []
  type: TYPE_NORMAL
- en: 11.8 Using R in a Web App
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Problem
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: You want to display R’s data and graphics in a web page on a web server.
  prefs: []
  type: TYPE_NORMAL
- en: Solution
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'There are several approaches that would achieve this effect:'
  prefs: []
  type: TYPE_NORMAL
- en: Prepare the data, generate graphics as we did in [Recipe 11.3](#javacook-ds-r-interact),
    and then incorporate both into a static web page.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Use one of [several R add-on web frameworks](https://cran.r-project.org/web/views/WebTechnologies.html#web-and-server-frameworks),
    such as [shiny](https://cran.r-project.org/web/packages/shiny/index.html) or [Rook](https://cran.r-project.org/web/packages/Rook/index.html).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Invoke a JVM implementation of R from within a Servlet, JSF, Spring Bean, or
    other web-tier component.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Discussion
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The first approach is trivial, and doesn’t need discussion here.
  prefs: []
  type: TYPE_NORMAL
- en: 'For the second, I’ll actually use `timevis`, which in turn uses `shiny`. This
    isn’t built in to the R library, so we first have to install it, using R’s `install.packages()`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: This may take a while as it downloads and builds multiple dependencies.
  prefs: []
  type: TYPE_NORMAL
- en: 'For this demo I have a small dataset with some basic information on medieval
    literature, which I load and display using `shiny`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: When run, this creates a temporary file containing HTML and JavaScript to allow
    interactive exploration of the data. The library also opens this in a browser,
    shown in [Figure 11-2](#javacook-ds-FIG-timevis). One can explore the data by
    expanding or contracting the timeline and scrolling sideways.
  prefs: []
  type: TYPE_NORMAL
- en: '![jcb4 1102](assets/jcb4_1102.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 11-2\. TimeVis (shiny) in action
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Where there are two boxes (Cid, Sagas), the first is when the life or stories
    took place, and the second is when they were written down.
  prefs: []
  type: TYPE_NORMAL
- en: To expose this on the public web, copy the file (whose full path is revealed
    in the browser titlebar) and the *lib* folder in that same directory into a directory
    served by the web server. Or just use File→Save As→Complete Web Page within the
    browser. Either way, you must do this while the R session is running, as the temporary
    files are deleted when the session ends. Or, if you are familiar with the `shiny`
    framework, you can insert the `timevis` visualization into a `shiny` application.
  prefs: []
  type: TYPE_NORMAL
- en: ^([1](ch11.html#idm45290648185096-marker)) *Map/Reduce* is a famous algorithm
    pioneered by Google to handle large data problems. An unspecified number of generators
    process *map* data—such as words on a web page or the page’s URL—and a single
    (usually) reduce process reduces the maps to a manageable form, such as a list
    of all the pages that contain the given words. Early on, data science went overboard
    on trying to do everything with Map/Reduce; now the pendulum has swung back to
    using compute engines like Spark.
  prefs: []
  type: TYPE_NORMAL
- en: ^([2](ch11.html#idm45290648114600-marker)) DataBricks offers several free ebooks
    on Spark from their website; it also offers commercial Spark add-ons.
  prefs: []
  type: TYPE_NORMAL
