- en: Chapter 8\. Advanced AWS Lambda
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第8章。高级 AWS Lambda
- en: As we start getting towards the end of the book, it’s time to learn some of
    the aspects of Lambda that are important as you start to build production-ready
    applications—error handling, scaling, plus a few capabilities of Lambda that we
    don’t use all the time, but are there—and important—when you need them.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 随着我们接近本书的结尾，是时候学习一些 Lambda 的方面了，这些方面对于构建可用于生产的应用程序至关重要——例如错误处理、扩展以及 Lambda 的一些能力，我们并非总是使用，但在需要时很重要。
- en: Error Handling
  id: totrans-2
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 错误处理
- en: All of our examples so far have lived in the wonderful world of rainbows and
    unicorns where no systems fail and no one makes a mistake in writing code. Of
    course, back in the real world, Things Go Wrong, and any useful production application
    and architecture needs to handle the times when errors occur, whether those be
    errors in our code or in the systems we rely on.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们所有的示例都生活在没有系统故障和没有人在编写代码时犯错误的美好世界中。当然，在现实世界中，事情会出错，任何有用的生产应用程序和架构都需要处理错误发生的时间，无论是在我们的代码中还是在我们依赖的系统中。
- en: Since AWS Lambda is a “platform,” it has certain constraints and behavior when
    it comes to errors, and in this section we’ll dig into what kind of errors can
    happen, for which contexts, and how we can handle them. As a language note, we
    use the words *error* and *exception* interchangeably, without the nuance that
    comes between the two terms in the Java world.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 由于 AWS Lambda 是一个“平台”，在处理错误时有一定的限制和行为，本节我们将深入探讨可以发生哪些类型的错误，在哪些情境中发生以及我们如何处理它们。作为语言说明，我们将“错误”和“异常”这两个词互换使用，没有
    Java 世界中两个术语之间的微妙差别。
- en: Classes of Error
  id: totrans-5
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 错误类别
- en: 'When using Lambda, there are several different classes of error that can occur.
    The primary ones are as follows, in order roughly of the time in which they can
    occur through the processing of an event:'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 在使用 Lambda 时，可能会出现几种不同类别的错误。主要错误如下，按照事件处理过程中可能发生的时间顺序大致排列如下：
- en: Error initializing the Lambda function (a problem loading our code, locating
    the handler, or with the function signature)
  id: totrans-7
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 初始化 Lambda 函数时出现的错误（加载我们的代码、定位处理程序或函数签名时的问题）
- en: Error parsing input into specified function parameters
  id: totrans-8
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将输入解析为指定函数参数时出现的错误
- en: Error communicating with an external downstream service (database, etc).
  id: totrans-9
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 与外部下游服务（数据库等）通信时出现的错误。
- en: Error generated within the Lambda function (either within its code or within
    the immediate environment, like an out-of-memory problem)
  id: totrans-10
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在 Lambda 函数内部生成的错误（无论是在其代码中还是在其直接环境中，例如内存不足的问题）
- en: Error caused by function timeout
  id: totrans-11
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 函数超时引起的错误
- en: Another way we can break up errors is into *handled* errors and *unhandled*
    errors.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以将错误分为已处理错误和未处理错误两类另一种方法。
- en: For example, let’s consider the case where we communicate with a downstream
    microservice over HTTP, and it throws an error. In this case, we may choose to
    catch the error within the Lambda function and process it there (a handled error),
    or we may let the error propagate out to the environment (an unhandled error).
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，让我们考虑与下游微服务通过 HTTP 进行通信并且它抛出错误的情况。在这种情况下，我们可以选择在 Lambda 函数内部捕获错误并在那里处理（已处理错误），或者让错误传播到环境中（未处理错误）。
- en: Alternatively, say we specified an incorrect method name in our Lambda configuration.
    In this case, we are unable to catch the error in the Lambda function code, so
    this is always an unhandled error.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 或者，假设我们在 Lambda 配置中指定了一个不正确的方法名。在这种情况下，我们无法在 Lambda 函数代码中捕获错误，因此这始终是一个未处理错误。
- en: If we handle an error ourselves, within code, then Lambda really has nothing
    to do with our particular error handling strategy. We can log to standard error
    if like, but as we saw in [Chapter 7](ch07.html#ch07), standard error is treated
    identically to standard output as far as Lambda as concerned, and no alarms are
    raised if content is sent to it.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们在代码中自行处理错误，那么 Lambda 实际上与我们的特定错误处理策略无关。我们可以选择像日志记录到标准错误一样，但正如我们在[第7章](ch07.html#ch07)中所看到的，Lambda
    将标准错误与标准输出视为相同，如果内容发送到其中，不会引发任何警报。
- en: Therefore, the nuances that come with handling errors in Lambda are all about
    unhandled errors—those that bubble out of our code to the Lambda runtime via an
    uncaught exception or that happen externally to our code. What happens to these
    errors? Interestingly, this depends significantly on the type of event source
    that triggers our Lambda function in the first place, as we will now examine.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，在 Lambda 处理错误时，所有的微妙之处都在于未处理的错误——即通过未捕获的异常将错误传递给 Lambda 运行时或外部发生的错误。这些错误会发生什么？有趣的是，这显著取决于触发
    Lambda 函数的事件源类型，现在我们将详细探讨这一点。
- en: The Various Behaviors of Lambda Error Processing
  id: totrans-17
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Lambda 错误处理的各种行为
- en: 'Lambda divides what it does with errors according to the event source that
    triggers invocation. Every event source is placed into one of the event source
    types we listed in [Chapter 5](ch05.html#ch05) ([Table 5-1](ch05.html#lambda-event-source-types)):'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: Lambda 根据触发调用的事件源来处理错误。我们在第 5 章中列出了每一种事件源类型（[表 5-1](ch05.html#lambda-event-source-types)）：
- en: Synchronous event sources (e.g., API Gateway)
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 同步事件源（例如，API 网关）
- en: Asynchronous event sources (e.g., S3 and SNS)
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 异步事件源（例如，S3 和 SNS）
- en: Stream/queue event sources (e.g., Kinesis Data Streams and SQS)
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 流/队列事件源（例如，Kinesis 数据流和 SQS）
- en: Each of these categories has a different model for processing errors thrown
    by a Lambda function, as follows.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 这些类别中的每一个都有一个不同的模型来处理 Lambda 函数抛出的错误，如下所示。
- en: Synchronous event sources
  id: totrans-23
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 同步事件源
- en: This is the simplest model. For Lambda functions invoked in this way, the error
    is propagated back up to the caller, and no automatic retry is performed. How
    the error is exposed to the upstream client depends on the precise nature of how
    the Lambda function was called, so you should try forcing errors within your code
    to see how such problems are exposed.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 这是最简单的模型。对于以这种方式调用的 Lambda 函数，错误将向上传播到调用者，并且不会执行自动重试。错误如何暴露给上游客户端取决于调用 Lambda
    函数的具体方式，因此您应该在代码中尝试强制错误，以查看此类问题如何暴露。
- en: For example, if API Gateway is the event source, then errors thrown by a Lambda
    function will result in an error being sent back to API Gateway. API Gateway in
    turn returns a 500 HTTP response to the original requestor.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，如果 API 网关是事件源，那么 Lambda 函数抛出的错误将导致错误被发送回 API 网关。API 网关随后向原始请求者返回一个 500 的
    HTTP 响应。
- en: Asynchronous event sources
  id: totrans-26
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 异步事件源
- en: Since this model of invocation is asynchronous, or event oriented, there is
    no upstream caller that can do anything useful with an error, so Lambda has a
    more sophisticated error handling model.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 由于此调用模型是异步的或事件导向的，没有上游调用者可以对错误执行任何有用的操作，因此 Lambda 具有更复杂的错误处理模型。
- en: First, if an error is detected in this model of invocation, then Lambda will
    (by default) retry processing the event up to twice further (for a total of three
    attempts), with a delay between such retries (the precise delay is not documented,
    but we’ll see an example a little later).
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，如果在这种调用模型中检测到错误，则 Lambda 将（默认情况下）重试处理事件多达两次（总共三次尝试），并在重试之间设置延迟（具体延迟未记录，但稍后我们将看到一个示例）。
- en: If the Lambda function fails for all retry attempts, then the event will be
    posted to the function’s error destination and/or dead letter queue if either
    is configured (more on this later); otherwise, the event is discarded and lost.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 如果 Lambda 函数在所有重试尝试失败时，事件将被发布到函数的错误目标和/或死信队列（如果已配置）；否则，事件将被丢弃和丢失。
- en: Stream/queue event sources
  id: totrans-30
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 流/队列事件源
- en: In the absence of a configured error-handling strategy (see [“Handling Kinesis
    and DynamoDB Stream Errors”](#failure-handling-features)), if an error bubbles
    up to the Lambda runtime when processing an event from a stream/queue event source,
    then Lambda will keep retrying the event until either (a) the failing event expires
    in the upstream source or (b) the problem is resolved. This means that the processing
    of the stream or queue is effectively blocked until the error is resolved. Note
    that there are particular nuances here when using streams that are scaled to multiple
    shards, which we recommend you research if this applies to you.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 在没有配置错误处理策略的情况下（参见[“处理 Kinesis 和 DynamoDB 流错误”](#failure-handling-features)），如果在处理来自流/队列事件源的事件时，错误向上冒泡到
    Lambda 运行时，则 Lambda 将持续重试该事件，直到（a）上游源中的失败事件过期或（b）问题解决。这意味着流或队列的处理实际上被阻塞，直到错误解决。请注意，在使用扩展到多个分片的流时，存在特定的细微差别，如果适用，请建议进行研究。
- en: 'The following documentation pages are useful when you are considering error
    handling with Lambda:'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 在考虑Lambda错误处理时，以下文档页面非常有用：
- en: '[Error Handling and Automatic Retries in AWS Lambda](https://oreil.ly/4wxMf)'
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[AWS Lambda中的错误处理和自动重试](https://oreil.ly/4wxMf)'
- en: '[AWS Lambda Function Errors in Java](https://oreil.ly/ag0cu)'
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[AWS Lambda中的Java函数错误](https://oreil.ly/ag0cu)'
- en: Deep Dive into Asynchronous Event Source Errors
  id: totrans-35
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 深入了解异步事件源错误
- en: Asynchronous event sources are a popular use of Lambda and have a complicated
    error processing model, so let’s look at this topic a little deeper by way of
    an example.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 异步事件源是Lambda的一种常见使用方式，并且具有复杂的错误处理模型，因此让我们通过一个例子更深入地了解这个主题。
- en: Retries
  id: totrans-37
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 重试
- en: 'We start with the following code:'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 我们从以下代码开始：
- en: '[PRE0]'
  id: totrans-39
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: We wire this up to an S3 bucket in the same way that we did for the `BatchEvents
    Lambda` function in [Chapter 5](ch05.html#ch05), and we’ll see the SAM template
    for that a little later.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 我们以与第5章中“BatchEvents Lambda”函数相同的方式将其与S3存储桶连接，稍后我们将看到该SAM模板。
- en: If we upload a file to the S3 bucket attached to this function, we see [Figure 8-1](#s3-error-logs)
    in our logs.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们将文件上传到与此函数关联的S3存储桶中，我们在日志中看到[图8-1](#s3-error-logs)。
- en: Notice that Lambda tries to process the S3 event three times—once at 20:44:00,
    then about a minute later, and then about two minutes after that. These are the
    three total attempts to process an event that Lambda promises for an asynchronous
    event source.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，Lambda尝试处理S3事件共三次——首次在20:44:00，然后约一分钟后，再约两分钟后。这是Lambda为异步事件源承诺的三次事件处理尝试。
- en: 'We are able configure the number of retries that Lambda will perform—0, 1,
    or 2—using a separate CloudFormation resource. For example, let’s configure Lambda
    not to attempt any retries for the `SingleEventLambda` function from [“Example:
    Building a Serverless Data Pipeline”](ch05.html#serverless-data-pipeline-example).
    We can add the following resource to the application template:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 我们能够使用单独的CloudFormation资源配置Lambda将执行的重试次数——0、1或2次。例如，让我们配置Lambda不对“SingleEventLambda”函数进行任何重试，该函数来自于[“示例：构建无服务器数据管道”](ch05.html#serverless-data-pipeline-example)。我们可以向应用程序模板添加以下资源：
- en: '[PRE1]'
  id: totrans-44
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: '![images/ch08_image01.png](assets/awsl_0801.png)'
  id: totrans-45
  prefs: []
  type: TYPE_IMG
  zh: '![images/ch08_image01.png](assets/awsl_0801.png)'
- en: Figure 8-1\. Lambda logs during S3 error
  id: totrans-46
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图8-1\. S3错误期间的Lambda日志
- en: If we don’t make any further changes, Lambda won’t do anything more after all
    the retries (if any) are complete—brief data about the original event will be
    logged, but eventually it will be discarded. For something like S3 this isn’t
    too bad—we can always list all of the objects in S3 later. But for other event
    sources, this might be a problem if we can’t go and regenerate the events once
    the cause of the error is fixed. There are two solutions to this problem—DLQs
    and destinations. DLQs have been around longer, so we’ll describe them first,
    but destinations have more capabilities.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们不做进一步的更改，Lambda在所有重试（如果有）完成后将不会再执行任何操作——将会记录关于原始事件的简要数据，但最终将被丢弃。对于像S3这样的情况，这并不太糟糕——我们随时可以稍后列出S3中的所有对象。但对于其他事件源来说，如果在修复错误原因后无法重新生成事件，则可能会成为问题。这个问题有两种解决方案——DLQ和目标。DLQ已存在较长时间，因此我们将首先描述它们，但目标具有更多功能。
- en: Dead letter queues
  id: totrans-48
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 死信队列
- en: Lambda provides the capability of automatically forwarding events (for asynchronous
    sources) that fail all of their retries to a dead letter queue (DLQ). This DLQ
    can be either an SNS topic or an SQS queue. Once the event is in SNS or SQS, you
    can do whatever you want with it either immediately, or manually later, in the
    case of SQS. For example, you may register a separate Lambda function as an SNS
    topic listener that posts a copy of the failing event to an operations Slack channel
    for manual processing.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: Lambda提供了自动转发事件的功能（对于失败所有重试的异步源）到死信队列（DLQ）。此DLQ可以是SNS主题或SQS队列。一旦事件进入SNS或SQS，您可以立即处理，或稍后手动处理（对于SQS而言）。例如，您可以注册一个单独的Lambda函数作为SNS主题的监听器，将失败的事件副本发布到操作Slack频道进行手动处理。
- en: DLQs can be configured along with all the other properties of a Lambda function.
    For example, we can add a DLQ to our example app, and also add a DLQ processing
    function, with the SAM template.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: DLQ可以与Lambda函数的所有其他属性一起配置。例如，我们可以向我们的示例应用程序添加一个DLQ，并且还可以添加一个DLQ处理函数，使用SAM模板。
- en: Example 8-1\. SAM template with DLQ and DLQ listener
  id: totrans-51
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 8-1\. 带有DLQ和DLQ监听器的SAM模板
- en: '[PRE2]'
  id: totrans-52
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'The important elements to observe here are as follows:'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 这里需要注意的重要元素如下：
- en: We define our own SNS topic to act as a DLQ.
  id: totrans-54
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们定义自己的SNS主题以充当DLQ。
- en: Within the application function (`S3ErroringLambda`), we tell Lambda that we
    want a DLQ for the function, that it’s of type SNS, and that DLQ messages should
    be sent to the topic we created in this template.
  id: totrans-55
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在应用程序函数（`S3ErroringLambda`）内部，我们告诉Lambda我们希望为该函数设置DLQ，其类型为SNS，并且DLQ消息应发送到我们在此模板中创建的主题。
- en: We also define a separate function (`DLQProcessingLambda`) that is triggered
    by events sent to the DLQ.
  id: totrans-56
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们还定义了一个单独的函数（`DLQProcessingLambda`），该函数由发送到DLQ的事件触发。
- en: 'Our code for `DLQProcessingLambda` is as follows:'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的`DLQProcessingLambda`代码如下：
- en: '[PRE3]'
  id: totrans-58
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Now if we upload a file to S3, we see the following in the logs for `DLQProcessing
    Lambda` after the final delivery attempt to `S3ErroringLambda`:'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，如果我们向S3上传文件，我们会在`DLQProcessing Lambda`的日志中看到以下内容，显示了对`S3ErroringLambda`的最终交付尝试后的处理：
- en: '[PRE4]'
  id: totrans-60
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: The event sent to the DLQ processing function includes the full original event
    that failed, allowing you to save this off and process later. It also includes
    the `RequestID` of the original event, which allows you to search within the application
    Lambda function’s log for clues as to what went wrong.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 发送到DLQ处理函数的事件包括失败的完整原始事件，允许您稍后保存并处理。它还包括原始事件的`RequestID`，允许您在应用程序Lambda函数的日志中搜索有关出错原因的线索。
- en: While in this example we included all of the DLQ resources within the same template
    as the application itself, you may choose to use resources outside of the application
    and therefore share those DLQ elements across applications.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然在这个示例中，我们将所有DLQ资源包含在应用程序模板中，但您可以选择在应用程序外使用资源，因此跨应用程序共享这些DLQ元素。
- en: Destinations
  id: totrans-63
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 目标
- en: 'At the end of 2019 AWS introduced an alternative to DLQs for capturing failed
    events: [*destinations*](https://oreil.ly/XT6Ds). Destinations are actually a
    more powerful feature than DLQ since you can capture both errors *and* successfully
    processed asynchronous events.'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 在2019年底，AWS推出了一个用于捕获失败事件的DLQ替代方案：[*destinations*](https://oreil.ly/XT6Ds)。目标实际上比DLQ更强大，因为您可以捕获错误和成功处理的异步事件。
- en: Further, destinations support more types of target than DLQs. SNS and SQS are
    supported, just as they are with DLQs, but you can also route directly to another
    Lambda function (skipping the message bus part) or EventBridge.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，目标支持比DLQ更多类型的目标。支持SNS和SQS，就像它们与DLQ一样，但您还可以直接路由到另一个Lambda函数（跳过消息总线部分）或EventBridge。
- en: 'To configure a Destination, we use the same type of `AWS::Lambda::EventInvokeConfig`
    resource we created earlier when configuring retry counts (see [“Retries”](#asynchronous-retries)).
    For example, let’s replace the DLQ in the previous example with a Destination:'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 要配置目标，我们使用与之前配置重试计数时创建的`AWS::Lambda::EventInvokeConfig`资源相同类型的资源（参见[“重试”](#asynchronous-retries)）。例如，让我们用目标替换前面示例中的DLQ：
- en: '[PRE5]'
  id: totrans-67
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'There are a few aspects to notice from this example:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 从这个示例中可以注意到几个方面：
- en: There are no explicit queues or topics.
  id: totrans-69
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 没有显式的队列或主题。
- en: The Destination at the end defines that when `S3ErroringLambda` fails, we want
    events to be sent to `ErrorProcessingLambda`.
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 最后，目标定义了当`S3ErroringLambda`失败时，我们希望将事件发送到`ErrorProcessingLambda`。
- en: The application function needs to be given permission to invoke the error handling
    function, which we enable via the `Policies` property on the `S3Erroring Lambda`
    resource.
  id: totrans-71
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 应用程序函数需要被授予调用错误处理函数的权限，我们通过`S3Erroring Lambda`资源的`Policies`属性启用此权限。
- en: The event that is sent to `ErrorProcessingLambda` is *not* the same type as
    that sent to a DLQ. At time of writing, the `aws-lambda-java-events` library has
    not been updated to include the Destination types, and deserializing these types
    is tricky due to some unfortunate naming of fields within the sent objects. Ideally
    by the time you read this book, this will have been fixed!
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 发送到`ErrorProcessingLambda`的事件与发送到DLQ的事件类型不同。在撰写本文时，`aws-lambda-java-events`库尚未更新以包含目标类型，并且由于发送对象中字段的不幸命名，反序列化这些类型非常棘手。希望到您阅读本书时，这些问题已得到解决！
- en: Destinations will likely replace most usages of DLQ, and we’re also interested
    to see how people use the `OnSuccess` version of destinations to build interesting
    solutions.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 目标可能会取代大多数DLQ的使用方式，我们还对看到如何使用目标的`OnSuccess`版本来构建有趣的解决方案感兴趣。
- en: Handling Kinesis and DynamoDB Stream Errors
  id: totrans-74
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 处理Kinesis和DynamoDB流错误
- en: In late 2019, AWS added a number of [failure-handling features](https://oreil.ly/gWKX-)
    to the Kinesis and DynamoDB stream event sources. These new features make it possible
    to avoid “poison pill” scenarios, where a single bad record could block stream
    (or shard) processing for up to a week (depending on how long the stream retains
    records).
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 2019 年末，AWS 向 Kinesis 和 DynamoDB 流事件源添加了许多[故障处理功能](https://oreil.ly/gWKX-)。这些新功能使得可以避免“毒丸”场景，其中单个不良记录可能会阻塞流（或分片）处理长达一周（取决于流保留记录的时间）。
- en: 'The failure-handling features can be configured via SAM (or CloudFormation),
    and are applied when a Lambda function fails to process a batch of records from
    either a Kinesis or DynamoDB stream. The new features are as follows:'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 故障处理功能可以通过 SAM（或 CloudFormation）进行配置，并且在 Lambda 函数无法处理来自 Kinesis 或 DynamoDB
    流的记录批次时应用。新功能如下所示：
- en: Bisect on Function Error
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 函数错误的二分法
- en: Instead of simply retrying the entire batch of records for a failed Lambda invocation,
    this feature splits the batch into two. These smaller batches are retried separately.
    This approach can automatically narrow failures down to whichever individual records
    are causing a problem, and those records can be dealt with via the other error-handling
    features.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 这个功能不是简单地重试整个记录批次以用于失败的 Lambda 调用，而是将批次分成两部分。这些较小的批次将分别重试。这种方法可以自动将故障缩小到导致问题的任何个别记录，并且可以通过其他错误处理功能处理这些记录。
- en: Maximum Record Age
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 最大记录年龄
- en: This instructs the Lambda function to skip records older than a specified Maximum
    Record Age (which can be from 60 seconds to 7 days).
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 这指示 Lambda 函数跳过早于指定的最大记录年龄的记录（可以从 60 秒到 7 天）。
- en: Maximum Retry Attempts
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 最大重试尝试次数
- en: This feature retries failed batches for a configurable number of times and then
    sends information about the batch of records to the configured *on-failure destination*
    (the next feature in this list).
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 此功能将失败的批次重试可配置的次数，然后将有关批次记录的信息发送到配置的*失败目标*（列表中的下一个特性）。
- en: Destination on Failure
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 失败时的目标
- en: This is an SNS topic or SQS queue that will receive information about failed
    batches. Note that it doesn’t receive the actual failed records—those have to
    be extracted from the stream before they expire.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个将接收有关失败批次信息的 SNS 主题或 SQS 队列。请注意，它不接收实际失败的记录——这些记录必须在它们过期之前从流中提取。
- en: A comprehensive error-handling approach can (and should) combine all of these
    features. For example, a failed batch of records can be split (perhaps several
    times) until there is a single-record batch causing a failure. That single-record
    batch might be retried 10 times or until the record is 15 minutes old, at which
    point the details of the batch (with its single failed record) will be sent to
    an SNS topic. A separate Lambda could be subscribed to that SNS topic, automatically
    retrieve the failed record from the stream, and store it in S3 for later investigation.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 一个全面的错误处理方法可以（并且应该）结合所有这些特性。例如，一组失败的记录可以被分割（可能多次），直到有一个导致失败的单一记录批次。这个单一记录批次可能会重试
    10 次，或者直到记录达到 15 分钟之后，此时批次的详细信息（包含其单个失败记录）将被发送到一个 SNS 主题。一个独立的 Lambda 可以订阅该 SNS
    主题，自动从流中检索失败的记录，并将其存储在 S3 中以供后续调查。
- en: Tracing Errors with X-Ray
  id: totrans-86
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用 X-Ray 跟踪错误
- en: If you are using AWS X-Ray (discussed in [“Distributed Tracing”](ch07.html#distributed-tracing)),
    then it will be able to show where errors are occurring in your graph of components.
    For more details, see [“Finding Errors”](ch07.html#finding-errors), and the X-Ray
    documentation.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您使用 AWS X-Ray（讨论见[“分布式跟踪”](ch07.html#distributed-tracing)），它将能够显示组件图中发生错误的位置。有关更多详细信息，请参阅[“查找错误”](ch07.html#finding-errors)和
    X-Ray 文档。
- en: Error Handling Strategies
  id: totrans-88
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 错误处理策略
- en: So given everything we now know about errors, and Lambda’s capabilities and
    behaviors regarding them, how should we choose to deal with errors?
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，考虑到我们现在对错误的所有了解，以及 Lambda 在处理它们时的能力和行为，我们应该如何选择处理错误？
- en: For unhandled errors, we should set up monitoring (see [“Alarms”](ch07.html#cloudwatch-alarms)),
    and when errors occur, we will likely need some kind of manual intervention. The
    urgency of this will depend on the context, and also the type of the event source—remember
    in the case of stream/queue event sources that processing is blocked until the
    error is cleared.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 对于未处理的错误，我们应该设置监控（参见[“警报”](ch07.html#cloudwatch-alarms)），当错误发生时，我们可能需要某种形式的手动干预。这种紧急性取决于上下文，也取决于事件源的类型——请记住，在流/队列事件源的情况下，直到错误被清除之前，处理都会被阻塞。
- en: For handled errors, though, we have an interesting choice. Should we process
    the error and rethrow, or should we capture the error and exit the function cleanly?
    Again, this will depend on the context and invocation type, but here are some
    thoughts.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 对于处理过的错误，我们有一个有趣的选择。我们应该处理错误并重新抛出，还是捕获错误并清晰地退出函数？再次强调，这将取决于上下文和调用类型，但以下是一些思考。
- en: For synchronous event sources, you will likely want to return some kind of error
    to the original caller. Typically you’ll want to do that explicitly within the
    Lambda code and return a well-formatted error. A problem here, though, is that
    Lambda won’t know if this is an error, so you’ll need to track this metric manually.
    The problem with letting unhandled errors bubble out from synchronously called
    Lambdas is that you have no control over the error returned to the upstream client.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 对于同步事件源，您可能希望向原始调用者返回某种错误。通常情况下，您会希望在 Lambda 代码中明确地执行此操作，并返回格式良好的错误。然而，这里的一个问题是
    Lambda 不知道这是否是一个错误，因此您需要手动跟踪此度量。让同步调用的 Lambda 中未处理的错误冒出的问题在于，您无法控制返回给上游客户端的错误。
- en: For asynchronous event sources, what you do will largely depend on whether you
    want to use a DLQ or Destination. If you do, then there’s often no harm in either
    letting an error bubble out or throwing a custom error and then handling the error
    in whatever is processing messages from the DLQ/Destination. If you don’t use
    a DLQ/Destination then you may want to at least log the failing input event if
    the error occurs within your code.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 对于异步事件源，您要做的事情很大程度上取决于您是否想要使用 DLQ 或目的地。如果是这样，那么让错误冒出或抛出自定义错误，然后在处理来自 DLQ/目的地的消息的过程中处理错误通常不会有什么坏处。如果不使用
    DLQ/目的地，则在代码内发生错误时，您可能至少希望记录失败的输入事件。
- en: For Kinesis and DynamoDB stream event sources, using one of the failure-handling
    features described earlier allows processing to continue even if some records
    cause errors. With a properly configured *Destination on Failure*, this is an
    effective error-handling strategy, although it assumes that it is safe for your
    application to potentially process records out of order. If that isn’t the case,
    then consider omitting the failure-handling features and relying on the platform’s
    automatic retry behavior (which in this case would block processing until the
    error is resolved or the records expire).
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 对于 Kinesis 和 DynamoDB 流事件源，使用之前描述的某种故障处理功能允许在某些记录导致错误时继续处理。通过正确配置的*失败时目的地*，这是一种有效的错误处理策略，尽管这假定您的应用程序可以安全地处理可能无序的记录。如果不是这种情况，请考虑省略故障处理功能，并依赖平台的自动重试行为（在这种情况下，将阻塞处理直到错误解决或记录过期）。
- en: For SQS you’ll typically want to handle errors within your code, since otherwise
    further processing is blocked. An effective way to do this is to put a top-level
    `try-catch` block in your handler function. Within this block, you can set up
    your own retry strategy or log the failing event and exit the function cleanly.
    In certain situations, you really will want to block further event processing
    until the problem causing the error is resolved, in which case you can throw a
    new error from the top-level try-catch block and use the platform’s automatic
    retry behavior.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 对于 SQS，通常希望在代码内部处理错误，否则会阻塞后续处理。一个有效的方法是在处理函数中放置一个顶层的`try-catch`块。在这个块中，您可以设置自己的重试策略或记录失败事件并清晰地退出函数。在某些情况下，您确实希望阻止进一步的事件处理，直到导致错误的问题解决，此时您可以从顶层的try-catch块中抛出一个新错误，并使用平台的自动重试行为。
- en: Scaling
  id: totrans-96
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 扩展
- en: In [Chapter 5](ch05.html#ch05) we touched on one of the most valuable aspects
    of Lambda—its ability to auto-scale without any effort (see [Figure 5-10](ch05.html#data-pipeline-fanout)).
    In the data pipeline example we used this auto-scaling ability to implement a
    “fan-out” pattern—processing many small events in parallel.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 在[第5章](ch05.html#ch05)中，我们提到了 Lambda 最宝贵的一个方面之一——其能够在没有任何努力的情况下自动扩展（参见[图5-10](ch05.html#data-pipeline-fanout)）。在数据管道示例中，我们利用这种自动扩展能力实现了“扇出”模式——并行处理许多小事件。
- en: This is the key to Lambda’s scaling model—if all current instances of a function
    are currently in use when a new event occurs, then Lambda will automatically create
    a new instance, *scaling out* the function, to handle the new event.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 这是 Lambda 扩展模型的关键——如果当前所有函数实例在收到新事件时都在使用中，则 Lambda 将自动创建一个新实例，*扩展*该函数，以处理新事件。
- en: Eventually, after a period of inactivity, function instances will be *reaped*,
    *scaling in* the function.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 最终，在一段不活动时间之后，函数实例将被*收回*，*扩缩容*函数。
- en: From a cost perspective, Lambda guarantees that we are only charged while our
    function is processing an event, so it costs the same to process one hundred Lambda
    events serially in one function instance as it does to process them in parallel
    in one hundred instances (subject to any extra time costs involved in cold start,
    which we describe later in this chapter).
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 从成本的角度来看，Lambda 保证我们仅在处理事件时收费，因此以串行方式处理一百个 Lambda 事件在一个函数实例中与在一百个实例中并行处理它们的成本相同（在冷启动中可能存在额外的时间成本，我们稍后在本章中描述）。
- en: Lambda scaling has limits, of course, which we’ll examine in a moment, but first
    let’s take a look at Lambda’s magical auto-scaling.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，Lambda 的扩展是有限制的，我们稍后会详细讨论，但首先让我们来看一下 Lambda 的神奇自动扩展。
- en: Observing Lambda Scaling
  id: totrans-102
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 观察 Lambda 的扩展
- en: 'Let’s start with the following code:'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们从以下代码开始：
- en: '[PRE6]'
  id: totrans-104
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Static and instance members of a function handler’s class are instantiated once
    per instance of a function. We discuss this further later, in the section about
    cold starts. Therefore, if we invoke the previous code five times in succession,
    it will always return the same value for the `instanceID` member.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 函数处理程序类的静态和实例成员会每个函数实例实例化一次。我们稍后在冷启动部分进一步讨论这一点。因此，如果我们连续五次调用前面的代码，它将始终为 `instanceID`
    成员返回相同的值。
- en: 'Now let’s change the code a little, adding a `sleep` statement:'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们稍微修改一下代码，加入一个 `sleep` 语句：
- en: '[PRE7]'
  id: totrans-107
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Make sure if you’re deploying this code to include a `Timeout` configuration
    of at least six seconds; otherwise, you’ll see a good example of a timeout error!
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 确保如果您部署此代码，请包括至少六秒的 `Timeout` 配置；否则，您将看到超时错误的一个很好的例子！
- en: Now invoke the function several times in parallel. One way to do this is by
    running the same `aws lambda invoke` command from multiple terminal tabs. Depending
    on how quick on the draw you are for navigating terminal sessions, you’ll now
    see that different container IDs are returned for different invocations.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 现在并行多次调用该函数。一种方法是在多个终端标签页中运行相同的 `aws lambda invoke` 命令。根据您在导航终端会话时的快速程度，您将看到不同的容器
    ID 用于不同的调用。
- en: This behavior is visible because when Lambda receives the second request to
    invoke your function, the previous container that was used for the first request
    is still processing that request, so Lambda creates a new instance, automatically
    scaling out, to handle the second request. This creation of a new instance happens
    for the third and fourth requests too, if you’re fast enough.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 之所以能够观察到这种行为，是因为当 Lambda 收到第二个请求来调用您的函数时，之前用于第一个请求的容器仍在处理该请求，因此 Lambda 会创建一个新实例来处理第二个请求，自动扩展容量。如果您的速度足够快，这种新实例的创建也会发生在第三和第四个请求上。
- en: This is an example of invoking the Lambda function directly, but this is the
    same scaling behavior we see when Lambda is invoked by most event sources, including
    API Gateway, S3, or SNS, whenever one instance of a Lambda function is not sufficient
    to keep up with the event load. Magical auto-scaling, without any effort!
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 这是直接调用 Lambda 函数的一个示例，但当 Lambda 被大多数事件源（包括 API Gateway、S3 或 SNS）调用时，我们看到相同的扩展行为，即当一个
    Lambda 函数实例不足以跟上事件负载时，神奇的自动扩展，毫不费力！
- en: Scaling Limits and Throttling
  id: totrans-112
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 缩放限制和限速
- en: AWS is not an infinite computer, and there are limits to Lambda’s scaling. Amazon
    limits the number of concurrent executions across all functions per AWS account,
    per region. By default, at the time of writing, this limit is one thousand, but
    you can make a support request to have this increased. Partly this limit exists
    because of the physical constraints of living in a material universe and partly
    so that your AWS bill doesn’t explode to astronomical proportions!
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: AWS 并不是一个无限的计算机，Lambda 的扩展是有限制的。亚马逊限制每个 AWS 帐户、每个区域的所有函数的并发执行次数。在撰写本文时，默认情况下，此限制为一千次，但您可以提出支持请求以增加此限制。部分原因是因为生活在物质宇宙的物理限制，部分原因是为了避免您的
    AWS 账单激增到天文数字！
- en: If you reach this limit, you’ll start to experience *throttling*, and you’ll
    know this because the account-wide `Throttles` CloudWatch metric for your Lambda
    functions will suddenly have an amount greater than zero. This makes it a great
    metric to set a Cloudwatch alarm for (we talked about built-in metrics and alarms
    in [“Metrics”](ch07.html#metrics)).
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 如果达到此限制，您将开始经历*限流*，您将因账户级别的 `Throttles` CloudWatch 指标为 Lambda 函数突然显示大于零的数量而知道这一点。这使其成为设置
    CloudWatch 警报的优秀指标（我们在 [“指标”](ch07.html#metrics) 中讨论了内置指标和警报）。
- en: 'When your function is throttled, the behavior exhibited by AWS is similar to
    the behavior that occurs when your function throws an error (which we talked about
    earlier in this chapter—[“The Various Behaviors of Lambda Error Processing”](#lambda-error-behaviors))—in
    other words, it depends on the type of event source. In summary:'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 当您的函数被限流时，AWS 表现出的行为类似于函数抛出错误时的行为（我们在本章前面讨论过的“Lambda 错误处理的各种行为”——[“Lambda 错误行为”](#lambda-error-behaviors)）——换句话说，这取决于事件源的类型。总结：
- en: For synchronous event sources (e.g., API Gateway), throttling is treated as
    an error and passed back up to the caller as an HTTP status code 500 error.
  id: totrans-116
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于同步事件源（例如 API Gateway），Lambda 将将限流视为错误，并作为 HTTP 状态码 500 错误返回给调用者。
- en: For asynchronous event sources (e.g., S3), Lambda will retry calling your Lambda
    function for up to six hours, by default. This is configurable, for example, by
    using the `MaximumEventAgeInSeconds` property of the [`AWS::Lambda::EventInvokeConfig`
    CloudFormation resource](https://oreil.ly/by8cO) that we introduced in [“Retries”](#asynchronous-retries).
  id: totrans-117
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于异步事件源（例如 S3），Lambda 默认会在最多六个小时内重试调用您的 Lambda 函数。可以通过例如使用 [`AWS::Lambda::EventInvokeConfig`
    CloudFormation 资源](https://oreil.ly/by8cO) 的 `MaximumEventAgeInSeconds` 属性进行配置，如我们在
    [“重试”](#asynchronous-retries) 中介绍的那样。
- en: For stream/queue event sources (e.g., Kinesis), Lambda will block and retry
    until successful or the data expires.
  id: totrans-118
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于流/队列事件源（例如 Kinesis），Lambda 将阻塞并重试，直到成功或数据过期。
- en: Stream-based sources may also have other scaling restrictions, for example,
    based on the number of shards of your stream and the configured [`ParallelizationFactor`](https://oreil.ly/4RSoj).
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 基于流的源还可能有其他缩放限制，例如基于流的分片数量和配置的 [`ParallelizationFactor`](https://oreil.ly/4RSoj)。
- en: Since the Lambda concurrency limit is account-wide, one particularly important
    aspect to be aware of is that one Lambda function that has scaled particularly
    wide can impact every other Lambda function in the same AWS account + region pair.
    Because of this, it is strongly recommended that, at the very least, you use separate
    AWS accounts for production and testing—deliberately DoS’ing (denial-of-servicing)
    your production application because of a load test against a staging environment
    is a particularly embarrassing situation to explain!
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 由于 Lambda 并发限制是账户级别的，特别需要注意的一个方面是，一个扩展特别广的 Lambda 函数可能会影响同一 AWS 账户+地区中的每个其他
    Lambda 函数。因此，强烈建议至少在生产和测试中使用单独的 AWS 账户——由于负载测试针对分级环境而故意造成 DoS（拒绝服务）攻击您的生产应用程序是一种特别尴尬的情况，需要解释清楚！
- en: But beyond the production versus test account separation, we also recommend
    using different AWS “subaccounts” within one AWS “organization” for different
    “services” within your ecosystem to further isolate yourself from the problems
    of account-wide limits.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 但是除了生产与测试账户分离之外，我们还建议在 AWS “组织” 内使用不同的 AWS “子账户” 为生态系统中的不同 “服务” 进行隔离，以进一步避免账户范围限制的问题。
- en: Burst limits
  id: totrans-122
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 突发限制
- en: The limits and throttling mentioned refer to the total capacity available to
    your Lambda functions. However, there’s another limit to be occasionally aware
    of—the *burst limit*. This refers to *how quickly* (as opposed to *how wide*)
    your Lambda function can scale. By default Lambda can scale out a function by
    up to 500 instances every minute, with perhaps a small boost at the beginning.
    If your workload can burst faster than this (and we’ve seen some that can), then
    you’ll need to be aware of burst limits and may want to consider asking AWS to
    increase your burst limit.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 提及的限制和限流是指您的 Lambda 函数可用的总容量。然而，偶尔还需注意另一个限制——*突发限制*。这指的是您的 Lambda 函数可以扩展的速度（而不是范围）。默认情况下，Lambda
    可以每分钟最多扩展一个函数到 500 个实例，可能在开始时有一个小的增加。如果您的工作负载比这更快地爆发（我们见过一些能做到的），那么您需要注意突发限制，并可能考虑请求
    AWS 增加您的突发限制。
- en: Reserved concurrency
  id: totrans-124
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 保留并发限制
- en: We just mentioned earlier that one Lambda function that has scaled particularly
    wide can impact the rest of the account by using all of the available concurrency.
    Lambda has a tool to help with this—the optional *reserved concurrency* configuration
    that can be applied to a function’s configuration.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 我们刚才提到过一个 Lambda 函数，它的扩展特别广，可能会通过使用所有可用的并发量来影响账户中的其他函数。Lambda 有一个工具可以帮助解决这个问题——可选的
    *保留并发量* 配置，可以应用于函数的配置中。
- en: 'Setting a reserved concurrency value does two things:'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 设置一个保留的并发值会做两件事：
- en: It guarantees that the particular function will always have up to that available
    amount of concurrency, no matter what any other functions are doing in the account.
  id: totrans-127
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它保证该特定函数将始终具有该可用并发量，而不管账户中的其他函数在做什么。
- en: It limits that function to scale *no wider* than that amount of concurrency.
  id: totrans-128
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它将该函数限制在*不超过*该并发量的范围内。
- en: 'This second feature has some useful benefits that we discuss in [“Solution:
    Manage scaling with reserved concurrency”](ch09.html#manage-scaling-with-reserved-concurrency).'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 这个第二个特性有一些有用的好处，我们在 [“解决方案：使用保留的并发管理扩展”](ch09.html#manage-scaling-with-reserved-concurrency)
    中讨论过。
- en: If you are using SAM to define your application’s infrastructure, you can use
    the `ReservedConcurrentExecutions` property of the `AWS::Serverless::Function`
    resource type to declare a reserved concurrency setting.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你正在使用 SAM 来定义应用程序的基础设施，你可以使用 `AWS::Serverless::Function` 资源类型的 `ReservedConcurrentExecutions`
    属性来声明一个保留的并发设置。
- en: Thread Safety
  id: totrans-131
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 线程安全
- en: Because of Lambda’s scaling model, we are guaranteed that at most one event
    will be processed per function instance at any one time. In other words, you never
    need to be concerned about multiple events being processed at the same time within
    a function’s runtime, let alone within a function object instance. Therefore,
    unless you create any of your own threads, Lambda programming is entirely thread
    safe.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 由于 Lambda 的扩展模型，我们可以保证每个函数实例在任何时候最多只处理一个事件。换句话说，在函数的运行时，你永远不需要担心多个事件同时被处理，更不用说在函数对象实例内部了。因此，除非你自己创建了任何线程，Lambda
    编程是完全线程安全的。
- en: Vertical Scaling
  id: totrans-133
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 垂直扩展
- en: Almost all of Lambda’s scaling capability is “horizontal”—that is, its ability
    to scale wider to handle multiple events in parallel. This is in contrast to “vertical”
    scaling—the ability to handle more load by increasing the computational capability
    of an individual node.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: Lambda 几乎所有的扩展能力都是“水平”的——即，它能够扩展以处理多个事件并行处理。这与“垂直”扩展相对应——即通过增加单个节点的计算能力来处理更多的负载。
- en: Lambda also has a rudimentary vertical scaling option, however, in its memory
    configuration. We discussed this in [“Memory and CPU”](ch03.html#memory-and-cpu).
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: Lambda 还有一个基本的垂直扩展选项，但是它是通过内存配置来实现的。我们在 [“内存和 CPU”](ch03.html#memory-and-cpu)
    中讨论过这个问题。
- en: Versions and Aliases, Traffic Shifting
  id: totrans-136
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 版本和别名，流量转移
- en: In your experiments with Lambda so far, you may have occasionally seen the string
    "`$LATEST`" appear. This is a reference to a Lambda function’s *version*. There’s
    more to versions than just `$LATEST` though, so let’s take a look.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 在你迄今为止对 Lambda 进行的实验中，你可能偶尔会看到字符串“`$LATEST`”出现。这是对 Lambda 函数的 *版本* 的引用。不过，版本远不止于
    `$LATEST`，所以让我们来看看吧。
- en: Lambda Versions
  id: totrans-138
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Lambda 版本
- en: Whenever we’ve deployed a new configuration, or new code, for our Lambda functions,
    we’ve always overridden what came before. The old function was dead, long live
    the new function.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 每当我们部署了新的配置或新代码到我们的 Lambda 函数中，我们总是覆盖之前的内容。旧的函数已经过时，新函数永存。
- en: However, Lambda supports keeping those old functions around if you want it to,
    by way of a capability named Lambda Function Versioning.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，Lambda 支持保留这些旧函数，如果你愿意的话，这是通过 Lambda 函数版本控制这个功能来实现的。
- en: Without using versioning explicitly, Lambda has exactly one version of your
    function at any one time. Its name is `$LATEST`, which you can reference explicitly;
    alternatively, if you don’t specify a version (or alias, which we’ll see in a
    moment), you are also referring implicitly to `$LATEST`.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 如果不显式使用版本控制，Lambda 在任何时候都只有一个版本的函数。它的名称是“`$LATEST`”，你可以明确引用它；或者，如果你不指定版本（或别名，我们马上就会看到的），你也隐含地引用了“`$LATEST`”。
- en: When you create or update a function, however, you are able at the time, or
    some time later, to snapshot that function to a version. The identifier of the
    version is a linear counter, starting at 1. You can’t edit a version, which means
    that it only ever makes sense to create a versioned snapshot from the current
    `$LATEST` version.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 当你创建或更新一个函数时，可以在当时或之后某个时间点对该函数进行版本快照。版本的标识符是一个线性计数器，从1开始。你无法编辑一个版本，这意味着只有从当前的`$LATEST`版本创建版本化快照才有意义。
- en: You invoke a version of a function when calling it explicitly by adding a `:VERSION-IDENTIFIER`
    to its ARN, or if using the AWS CLI, you can add a `--qualifier` *`VERSION-IDENTIFIER`*
    parameter to the `aws lambda invoke` command.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 调用函数的一个版本时，可以通过将`：VERSION-IDENTIFIER`添加到其ARN中显式调用它，或者如果使用AWS CLI，则可以在`aws lambda
    invoke`命令的`--qualifier` *`VERSION-IDENTIFIER`*参数中添加它。
- en: You can create a version using various AWS CLI commands or the web console.
    You can’t create a version explicitly using SAM, but you can do so implicitly
    when you use *aliases*, which we’ll explain next.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 可以使用各种AWS CLI命令或Web控制台创建版本。不能直接使用SAM显式创建版本，但在使用*别名*时可以隐式创建版本，我们接下来会解释这一点。
- en: Lambda Aliases
  id: totrans-145
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Lambda别名
- en: While you are able to explicitly reference a numbered version of a Lambda function,
    when using versions, it’s more typical to use an *alias*. An alias is a named
    pointer to a Lambda version—either `$LATEST`, or a numeric, snapshotted version.
    An alias can be updated at any time to point to a different version. For example,
    you may start off pointing to `$LATEST`, but then point to a specific version
    when you want to add stability to the alias.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管可以显式引用Lambda函数的编号版本，但在使用版本时，更典型的是使用*别名*。别名是指向Lambda版本的命名指针——可以是`$LATEST`，也可以是一个数字化的快照版本。可以随时更新别名以指向不同的版本。例如，您可以从`$LATEST`开始，但随后指向特定版本以增加别名的稳定性。
- en: You invoke an alias of a function in precisely the same way as you do with a
    function version—by specifying it in an ARN or in the `--qualifier` argument of
    the CLI. An event source can be configured to point to a specific alias, and if
    the underlying alias is updated to point to a new version, then events from the
    source will flow to that new version.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 您以与函数版本完全相同的方式调用函数的别名——通过在ARN中指定它或在CLI的`--qualifier`参数中指定它。可以配置事件源以指向特定的别名，并且如果基础别名更新以指向新版本，则来自源的事件将流向该新版本。
- en: When you deploy a Lambda function with SAM, you can define an alias that is
    automatically updated to point to the latest, published version. You do this by
    adding the `AutoPublishAlias` property, and giving an alias name as a value.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 在使用SAM部署Lambda函数时，可以定义一个别名，该别名会自动更新以指向最新发布的版本。您可以通过添加`AutoPublishAlias`属性并提供别名名称作为值来实现这一点。
- en: However, there’s a much more powerful way of using aliases with SAM.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，使用SAM时有一种更强大的使用别名的方式。
- en: Traffic Shifting
  id: totrans-150
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 流量转移
- en: If you use the `AutoPublishAlias` property of a Lambda function with SAM, all
    events from an event source immediately get routed to the new version of the function.
    If something goes wrong, you can manually update the alias to point to the previous
    version.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 如果在SAM中使用Lambda函数的`AutoPublishAlias`属性，则来自事件源的所有事件将立即路由到函数的新版本。如果出现问题，您可以手动更新别名以指向前一个版本。
- en: Lambda and SAM also have functionality to improve this process first by giving
    the opportunity to split traffic, sending some to the new version and some to
    the old version. This means that if a problem occurs, and a rollback is required,
    not all traffic has been impacted by the problem.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: Lambda和SAM还具有通过首先给予分流流量的机能来改善此流程的功能，将一些流量发送到新版本，一些流量发送到旧版本。这意味着如果发生问题，并且需要回滚，则并非所有流量都受到问题的影响。
- en: The second improvement is that a rollback can automatically be performed if
    an error is detected, where you have the opportunity to define how the error is
    calculated in a couple of different ways.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 第二个改进是，如果检测到错误，可以自动执行回滚，您可以定义如何以几种不同的方式计算错误。
- en: There are a number of moving pieces involved in getting this working—Lambda
    aliases, Lambda alias update policies, and use of the [AWS CodeDeploy](https://oreil.ly/t2gIB)
    service. Fortunately, SAM does a good job of wrapping all of this up for you so
    that you don’t need to worry about all of the gory details. The main thing you
    need to do is add a `DeploymentPreference` property to your Lambda function in
    your SAM template, which is [thoroughly documented](https://oreil.ly/EhJaS).
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 有许多移动部件涉及使其工作—Lambda别名、Lambda别名更新策略以及使用[AWS CodeDeploy](https://oreil.ly/t2gIB)服务。幸运的是，SAM能很好地将所有这些包装起来，以便你不需要担心所有这些繁琐的细节。你主要需要做的是在SAM模板中的Lambda函数中添加一个`DeploymentPreference`属性，这在[详细文档](https://oreil.ly/EhJaS)中有说明。
- en: 'A choice you need to make when using traffic shifting is how you want your
    traffic to be shifted to the new alias. This breaks down into four options:'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 使用流量转移时需要做出的选择是如何将你的流量转移到新别名上。这可以分为四个选项：
- en: All at once
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 一次性全部
- en: While this may sound the same at first glance as `AutoPublishAlias` it’s actually
    a lot more powerful, since you have the opportunity to automatically roll back
    deployment through “hooks,” as we’ll describe in a moment. This is a fully automated
    implementation of [*Blue Green Deployment*](https://oreil.ly/qowK1) for Lambda.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然这乍一看可能与`AutoPublishAlias`相同，但实际上它更加强大，因为你有机会通过“钩子”自动回滚部署，我们稍后将描述。这是Lambda的[*蓝绿部署*](https://oreil.ly/qowK1)的完全自动化实现。
- en: Canary
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 金丝雀
- en: Send a small percentage of traffic to the new version, and if it works, then
    send the remaining traffic; otherwise, roll back.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 向新版本发送少量流量，如果有效，则发送剩余流量；否则，回滚。
- en: Linear
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 线性
- en: Similar to Canary, but send increasing percentages of traffic to the new version,
    still allowing for rollback.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 与金丝雀类似，但向新版本发送逐渐增加的流量百分比，仍允许回滚。
- en: Custom
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 自定义
- en: Decide for yourself how you want traffic to split across the old and new aliases.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 决定如何在旧别名和新别名之间分配流量由你自己决定。
- en: As we mentioned already, a powerful element to this feature is that automatic
    rollback can be implemented via two different mechanisms—*hooks* and *alarms*.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们之前提到的，此功能的一个强大元素是可以通过两种不同的机制实现自动回滚—*钩子*和*警报*。
- en: '*Hook*-triggered rollback is available to any of the previous schemes. You
    can define *pretraffic hooks* and/or *posttraffic hooks*. These hooks are simply
    other Lambda functions that will run whatever logic they need to decide whether
    deployment has been successful—either before any traffic is routed to the new
    alias or after all traffic has been shifted.'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: '*钩子*触发的回滚适用于任何之前的方案。你可以定义*预流量钩子*和/或*后流量钩子*。这些钩子只是其他Lambda函数，它们将运行它们需要的任何逻辑来决定部署是否成功—无论是在任何流量路由到新别名之前还是在所有流量转移后。'
- en: '*Alarms* are available with schemes that offer gradual traffic shifting. You
    can define any number of *CloudWatch Alarms* (which we discussed in [“Alarms”](ch07.html#cloudwatch-alarms)),
    and if any of those alarms transition to their *alarm* state, then a rollback
    to the original alias will be performed.'
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: '*警报*适用于提供逐渐流量转移的方案。你可以定义任意数量的*CloudWatch警报*（我们在[“警报”](ch07.html#cloudwatch-alarms)中讨论过），如果其中任何警报转换为*警报*状态，则将执行回滚到原始别名。'
- en: For more details on Lambda traffic shifting, see the [SAM documentation](https://oreil.ly/SXGLS).
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 欲了解有关Lambda流量转移的更多详细信息，请参阅[SAM文档](https://oreil.ly/SXGLS)。
- en: When (Not) to Use Versions and Aliases
  id: totrans-168
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 何时（不）使用版本和别名
- en: Lambda’s traffic shifting capability is very powerful, and if you don’t already
    have a canary release scheme upstream of your Lambda code, then it may well be
    useful for you.
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: Lambda的流量转移能力非常强大，如果你在Lambda代码的上游尚未使用金丝雀发布方案，那么它可能对你有所帮助。
- en: However, apart from traffic shifting, we try to steer away from versions and
    aliases. We find that they typically add unnecessary complexity, and instead we
    prefer to use alternative techniques. For example, for separating development
    and production versions of code, we prefer to use different deployed stacks. For
    “rolling back” code, our preference is to use a fast-running deployment pipeline,
    and roll back at the source repository, triggering a new commit through the pipeline.
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，除了流量转移之外，我们尽量避免使用版本和别名。我们发现它们通常增加了不必要的复杂性，而我们更倾向于使用其他技术。例如，对于代码的开发和生产版本的分离，我们更喜欢使用不同的部署堆栈。对于“回滚”代码，我们更倾向于使用快速运行的部署管道，并在源代码库中进行回滚，通过管道触发新的提交。
- en: Note
  id: totrans-171
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: Very occasionally you’ll see that some event sources use, and recommend, using
    Lambda aliases. One example of this is when integrating Lambda with [AWS Application
    Load Balancer (ALB)](https://oreil.ly/4U1ZD).
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 偶尔您会看到一些事件源使用并推荐使用 Lambda 别名。其中一个例子是将 Lambda 与[AWS 应用负载均衡器（ALB）](https://oreil.ly/4U1ZD)集成时。
- en: 'If you do use versions and aliases, be aware of a couple of “gotchas,” beyond
    the function instance warning earlier:'
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您使用版本和别名，请注意除了之前提到的函数实例警告之外的一些“陷阱”：
- en: Versions do not automatically clean up after themselves, so periodically you’ll
    want to delete old versions. Otherwise, you may find you hit your account-level
    “function and layer storage” limit of 75GB.
  id: totrans-174
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 版本不会自动清理，因此定期删除旧版本很重要。否则，您可能会发现自己达到账户级别的“函数和层存储”限制，即 75GB。
- en: The default CloudWatch metrics views in the AWS Web Console for Lambda are a
    little odd when you’re using aliases and versions. Make sure you’re being explicit
    about which version(s) or alias(es) you want to view data for when you’re using
    CloudWatch metrics in this way.
  id: totrans-175
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当您在使用 CloudWatch 指标时，请确保您明确指定要查看数据的版本或别名，因为 AWS Web 控制台中默认的 CloudWatch 指标视图在使用版本和别名时有点奇怪。
- en: Cold Starts
  id: totrans-176
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 冷启动
- en: Now we move on to the thorny subject of *cold starts*. Depending on who you
    talk to, cold starts may be a minor footnote in the life of a Lambda developer,
    or it may be a complete blocker to Lambda even being considered a valid computation
    platform. We find how best to approach cold starts is somewhere between these
    two points—worth understanding and treating with rigor, but not a deal-breaker
    in most situations.
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们来讨论*冷启动*这个棘手的问题。根据您与谁交流的不同，冷启动可能是 Lambda 开发者生活中的一个小注脚，也可能是阻止 Lambda 被视为有效计算平台的一个完全阻碍因素。我们发现如何最好地处理冷启动在这两个极端之间——值得深入理解和严谨对待，但在大多数情况下并非不可抗拒的因素。
- en: But what are cold starts, when do they happen, what impact do they have, and
    how can we mitigate them? There’s a lot of fear, uncertainty, and doubt (FUD)
    surrounding cold starts, and we hope to remove some of that FUD for you here.
    Let’s dive in.
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 但是冷启动是什么，何时发生，它们会产生什么影响，以及我们如何减轻它们的影响？关于冷启动有很多恐惧、不确定性和怀疑（FUD），我们希望在这里消除其中一些
    FUD。让我们深入探讨。
- en: What Is a Cold Start?
  id: totrans-179
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 什么是冷启动？
- en: Back in [Chapter 3](ch03.html#ch03), we explored the chain of activity ([Figure 3-1](ch03.html#lambda-execution-environment))
    that occurs when a Lambda function is invoked for the first time—from starting
    a host Linux environment through to calling our handler function. In between those
    two activities the JVM will be started, the Lambda Java Runtime will be started,
    our code will be loaded, and depending on the precise nature of our Lambda function,
    more may happen besides. We collectively group this chain into something we call
    a *cold start*, and it results in a new *instance* (an execution environment,
    a runtime, and our code) of our Lambda function being available to process events.
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 回顾[第 3 章](ch03.html#ch03)，我们探讨了当第一次调用 Lambda 函数时发生的活动链（[图 3-1](ch03.html#lambda-execution-environment)）——从启动主机
    Linux 环境到调用我们的处理函数。在这两个活动之间，JVM 将被启动，Lambda Java 运行时将被启动，我们的代码将被加载，根据我们 Lambda
    函数的具体特性，可能会发生更多其他活动。我们将这个链条总称为*冷启动*，它导致我们的 Lambda 函数的新*实例*（执行环境、运行时和我们的代码）可以处理事件。
- en: An important point here is that all of this activity occurs *when our Lambda
    function is invoked*, not before. In other words, Lambda doesn’t create function
    instances solely when Lambda code is deployed—it creates them *on demand*.
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 这里一个重要的观点是，所有这些活动都发生在我们的 Lambda 函数被调用时，而不是之前。换句话说，Lambda 不仅在部署 Lambda 代码时创建函数实例，而是根据需要创建它们。
- en: However, cold starts are special occurrences, rather than something that happens
    on every invocation, because typically Lambda won’t perform a cold start for every
    event that triggers our function. This is because once our function has finished
    executing, Lambda can [*freeze*](https://oreil.ly/YrC-W) the instance and keep
    it around for a little while in case another event happens soon. If an event does
    happen soon, then Lambda will *thaw* the instance and call it with the event.
    For many Lambda functions, cold starts in fact occur less than 1% of the time,
    but it’s still useful to know when they do occur.
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，冷启动是特殊事件，而不是每次调用都会发生的事情，因为通常Lambda不会为每个触发函数的事件执行冷启动。这是因为一旦我们的函数执行完毕，Lambda可以[*冻结*](https://oreil.ly/YrC-W)实例并保留一段时间，以防接下来会有另一个事件发生。如果很快又发生了一个事件，Lambda将*解冻*实例并用事件调用它。对于许多Lambda函数来说，冷启动实际上不到1%的时间发生，但了解它们发生的时机仍然很有用。
- en: When Does a Cold Start Occur?
  id: totrans-183
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 冷启动何时发生？
- en: 'A cold start is necessary whenever there is no existing function instance available
    to process an event. This situation happens at the following times:'
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 当没有现有的函数实例可用来处理事件时，冷启动是必要的。这种情况发生在以下时候：
- en: When a Lambda function’s code or configuration changes (including when the first
    version of a function is deployed)
  id: totrans-185
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 当Lambda函数的代码或配置更改时（包括首次部署函数的第一个版本时）
- en: When all previous instances have been expired due to inactivity
  id: totrans-186
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 当所有之前的实例因为不活跃而被销毁
- en: When all previous instances have been “reaped” due to age
  id: totrans-187
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 当所有之前的实例因“老化”而被“清理”时
- en: When Lambda needs to scale out because all current instances for the required
    function are already processing events
  id: totrans-188
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 当Lambda需要扩展，因为所有当前函数的实例都在处理事件
- en: Let’s look at these four types of occurrence in a little more detail.
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们更详细地看看这四种发生情况。
- en: When we deploy our function for the first time, Lambda will create an instance
    of our function, as we’ve already seen. However, Lambda will also create a new
    instance whenever a function is invoked after we deploy a new version of the function
    code, or when we change the Lambda configuration of our functions. Such configuration
    doesn’t just cover environment variables—it also covers runtime aspects like timeouts,
    memory settings, DLQ, etc.
  id: totrans-190
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 当我们首次部署我们的函数时，Lambda会创建一个我们函数的实例，正如我们已经见过的那样。然而，每当我们部署函数代码的新版本，或者更改函数的Lambda配置后，Lambda也会创建一个新的实例当函数被调用。这样的配置不仅涵盖环境变量，还包括运行时方面，如超时设置，内存设置，DLQ等。
- en: A corollary of this is that one instance of a Lambda function is guaranteed
    to have the same code and configuration no matter how many times it is called.
  id: totrans-191
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这个推论是Lambda函数的一个实例无论被调用多少次，保证都有相同的代码和配置。
- en: Lambda will keep function instances around for a little while in case another
    event happens “soon.” The precise definition of *soon* is not documented, but
    it can be anywhere between a few minutes and a few hours (and is not necessarily
    constant). In other words, if your function processes an event, and then a minute
    later another event occurs, there’s a very good chance the second event will be
    processed using the same instance of your function that was used to process the
    first event. However, if there’s a day or more between events, your function will
    likely experience a cold start for every event. In the past, some people have
    used a “ping hack” to work around this and keep their function “alive,” but in
    late 2019 AWS introduced Provisioned Concurrency (see [“Provisioned Concurrency”](#provisioned-concurrency))
    to solve this kind of concern.
  id: totrans-192
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Lambda会保留函数实例一段时间，以防会有“快”事件发生。关于“快”具体的定义没有文档说明，但可能在几分钟到几小时之间（并不一定是固定的）。换句话说，如果您的函数处理一个事件，然后一分钟后又发生了另一个事件，第二个事件很有可能使用同一个函数实例来处理第一个事件。然而，如果事件之间有一天或更长的时间间隔，您的函数很可能每次事件都会经历冷启动。过去，有些人使用“ping
    hack”来解决这个问题，并保持其函数“活跃”，但在2019年底，AWS推出了预置并发（见[“预置并发”](#provisioned-concurrency)）来解决这种问题。
- en: Even if your Lambda event is fairly active, Amazon doesn’t keep instances around
    forever, even if they’re being used every few seconds. How long AWS will keep
    instances around is, again, undocumented, but at time of writing we see instances
    lasting five to six hours, and after that they’re killed off.
  id: totrans-193
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 即使您的Lambda事件非常活跃，亚马逊也不会永远保留实例，即使它们每隔几秒钟被使用。AWS保留实例的时间在撰写本文时为五到六小时，之后将被销毁。
- en: Finally, a cold start will occur if all current instances of a function are
    already busy processing events and Lambda “scales out,” as we described this earlier
    in this chapter.
  id: totrans-194
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，如果函数的所有当前实例都在忙于处理事件并且Lambda“扩展”，就像我们在本章前面描述的那样，冷启动将会发生。
- en: Identifying Cold Starts
  id: totrans-195
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 识别冷启动
- en: How can you tell when a cold start has occurred? There are many ways of doing
    so, but here are a few.
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 什么时候可以判断发生了冷启动呢？有很多种方法可以做到这一点，以下是其中一些。
- en: First, you’ll notice a latency spike. Cold starts typically add anywhere from
    100 milliseconds to 10 seconds to the latency of your function, depending on the
    makeup of your function. Therefore, if your function typically takes less than
    that, a cold start will be easy to see in the function’s latency metrics.
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，你会注意到延迟急剧增加。冷启动通常会使函数的延迟增加从100毫秒到10秒不等，具体取决于函数的组成。因此，如果你的函数通常需要的时间少于这个范围，冷启动在函数延迟指标中将很容易看到。
- en: Next you’ll be able to tell when a cold start has occurred due to a way that
    Lambda’s logging works. As we discussed in [“Lambda and CloudWatch Logs”](ch07.html#lambda-and-cloudwatch-logs),
    when Lambda functions log, the output is captured in CloudWatch Logs. All of the
    log output for one function is available in one CloudWatch Log *group*, but each
    instance of a function will write to a separate log *stream*, within the log group.
    Therefore if you see the number of log streams within a log group increase then
    you know a cold start has occurred.
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，由于Lambda的日志记录方式，你将能够知道何时发生了冷启动。正如我们在[“Lambda和CloudWatch Logs”](ch07.html#lambda-and-cloudwatch-logs)中讨论的那样，当Lambda函数记录日志时，输出将被捕获在CloudWatch
    Logs中。一个函数的所有日志输出都在一个CloudWatch Log *group*中可用，但是每个函数实例将写入日志 *stream*中的一个单独的流，位于日志组内。因此，如果你看到日志组中的日志流数量增加，那么你就知道发生了冷启动。
- en: Also, you can track cold starts yourself within code. Since the Java object
    encapsulating your handler is instantiated only once per instance of the actual
    function runtime, any instance member or static member initialization will happen
    at cold start, and never again for the lifetime of the function instance. Therefore,
    if you add a constructor, or static initializer, to your code, it will be called
    only when the function is experiencing a cold start. You can add explicit logging
    to your handler class constructor to see a cold start occurring in your function
    logs. Alternatively, we saw examples of identifying cold starts earlier in this
    chapter.
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，你可以在代码中自行跟踪冷启动。由于包装处理程序的Java对象仅在实际函数运行时的每个实例中实例化一次，任何实例成员或静态成员初始化都将发生在冷启动时，并且在函数实例的生命周期内再也不会发生。因此，如果在代码中添加构造函数或静态初始化程序，它将仅在函数经历冷启动时调用。你可以在处理程序类构造函数中添加显式日志记录，以查看函数日志中发生的冷启动。或者，我们在本章前面看到了识别冷启动的示例。
- en: You can also identify cold starts using X-Ray and some third-party Lambda monitoring
    tools.
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 你还可以使用X-Ray和一些第三方Lambda监控工具来识别冷启动。
- en: Impact of Cold Starts
  id: totrans-201
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 冷启动的影响
- en: So far we’ve described what cold starts are, when they happen, and how you can
    identify them. But why should you care about cold starts?
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们已经描述了什么是冷启动，它们何时发生以及如何识别它们。但是，为什么你要关心冷启动呢？
- en: As we just mentioned in the previous section, one way to identify a cold start
    is that you’ll typically see a latency spike in your event processing when one
    occurs, and this is most often why people are concerned about them. While end-to-end
    latency of a small Lambda function might be 50 ms in a usual case, a cold start
    could add *at least* 200 ms to this amount, and, depending on various factors,
    may add seconds, or even tens of seconds. The reasons that cold starts add latency
    are because of all the steps that need to occur during creation of a function
    instance.
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们在前一节中提到的，识别冷启动的一种方法是，当发生冷启动时，你通常会在事件处理中看到延迟急剧增加，这也是人们最关心的原因。虽然一个小型Lambda函数的端到端延迟在正常情况下可能为50毫秒，但是冷启动可能会增加*至少*200毫秒到这个数量，而且根据各种因素，可能会增加秒数，甚至十几秒。冷启动增加延迟的原因是因为在创建函数实例期间需要进行的所有步骤。
- en: Does this mean that we *always* need to care about cold starts? That depends
    a lot on what your Lambda function is doing.
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 这是否意味着我们*总是*需要关心冷启动呢？这在很大程度上取决于你的Lambda函数在做什么。
- en: For instance, say your function is asynchronously processing objects created
    in S3, and you are ambivalent as to whether it takes minutes to process such objects.
    Do you care about cold starts in this situation? Probably not. Especially when
    you consider that S3 has no guaranteed subsecond delivery of events anyway.
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，假设您的函数是异步处理在 S3 中创建的对象，并且您对处理这些对象需要花费几分钟的时间并不在意。在这种情况下，您是否关心冷启动？可能不会。特别是当考虑到
    S3 并没有保证事件的亚秒级交付时。
- en: 'Here’s another example of where you likely won’t care too much about cold starts:
    say that you have a function that is processing messages from Kinesis, that each
    event takes about 100 ms to process, and that there’s typically always enough
    data to keep your Lambda functions busy. In this case, one instance of your Lambda
    function may process 200,000 events before it gets “reaped.” In other words *cold
    starts might only affect 0.0005% of Lambda invocations*. Even if a cold start
    added 10 seconds to your startup latency, it’s highly likely that you’ll be OK
    with such an impact in this scenario, when you consider amortizing that time over
    the lifetime of an instance.'
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 下面是另一个例子，您可能不会太在意冷启动：假设您有一个函数正在处理来自 Kinesis 的消息，每个事件处理大约需要 100 毫秒，通常总是有足够的数据使您的
    Lambda 函数保持繁忙状态。在这种情况下，您的一个 Lambda 函数实例可能会处理 200,000 个事件，然后被“清除”。换句话说，*在 Lambda
    调用中，冷启动可能仅影响 0.0005%*。即使冷启动使启动延迟增加了 10 秒，考虑到在实例的生命周期内对这段时间的摊销，很可能您在这种情况下会接受这样的影响。
- en: On the other hand, say you’re building a web application, and there’s a particular
    element that calls a Lambda function, but that function gets called in AWS only
    once per hour. This might mean you’re getting a cold start every time the function
    is invoked. Further, let’s say for this particular function that the cold start
    overhead is five seconds. Is this a problem? It might be. If so, can this overhead
    be reduced? Perhaps, and we’ll talk about that in the next section.
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 另一方面，假设你正在构建一个 Web 应用程序，并且有一个特定的元素调用了一个 Lambda 函数，但该函数在 AWS 中每小时只被调用一次。这可能意味着每次调用函数时都会出现冷启动。进一步说，假设对于这个特定的函数，冷启动的开销是五秒钟。这会成为问题吗？可能会。如果是这样，这个开销能够减少吗？也许可以，在下一节我们将讨论这个问题。
- en: Although the concern with cold starts is almost always about latency overhead,
    it’s also important to note that if your function loads data from a downstream
    resource at startup, it will be doing that every time a cold start occurs. You
    may want to consider this when you’re thinking about the impact your Lambda functions
    have on downstream resources, especially when all of your instances cold start
    after a deployment.
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管关于冷启动的关注几乎总是涉及延迟开销，但也要注意，如果您的函数在启动时从下游资源加载数据，那么每次发生冷启动时它都会这样做。在考虑 Lambda 函数对下游资源影响时，特别是在部署后所有实例都进行冷启动时，您可能需要考虑这一点。
- en: Mitigating Cold Starts
  id: totrans-209
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 缓解冷启动
- en: Cold starts will always occur with Lambda, and unless we use Provisioned Concurrency
    (described in the next section), such cold starts will always, occasionally, affect
    our function’s performance. If cold starts are causing you a problem, there are
    various techniques you can use to mitigate their impact. Just make sure that they
    really are causing you a problem, though—like other forms of performance optimization,
    you want to make sure you do this work only if it’s truly necessary.
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: Lambda 总是会发生冷启动，除非我们使用预置并发（在下一节中描述），这样的冷启动将会时不时地影响我们函数的性能。如果冷启动给您带来问题，那么有各种技术可以减少它们的影响。但请确保它们确实给您带来问题—就像其他形式的性能优化一样，您希望只在真正需要时才进行这项工作。
- en: Reduce artifact size
  id: totrans-211
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 减少构件大小
- en: 'Often the most effective tool in reducing cold start impact is to reduce the
    size of our code artifact. We can do that in two main ways:'
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 在减少冷启动影响中，最有效的工具通常是减少我们代码构件的大小。我们可以通过两种主要方式实现这一点：
- en: Reduce the amount of our own code in the artifact to just that needed by the
    Lambda function (where “amount” means both size and number of classes).
  id: totrans-213
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 减少我们自己代码在构件中的量，只保留 Lambda 函数所需的部分（其中“量”指的是大小和类的数量）。
- en: Prune dependencies so that only libraries that our Lambda function needs are
    stored in the artifact.
  id: totrans-214
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 精简依赖项，使得构件中仅存储 Lambda 函数所需的库。
- en: There are a couple of follow-on techniques here. First, create a different artifact
    for each of your Lambda functions, and execute the tasks for each artifact. This
    was the point of the effort we went to in [Chapter 5](ch05.html#ch05) when we
    created the multimodule Maven project.
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 这里还有几种后续技术。首先，为每个 Lambda 函数创建一个不同的构件，并为每个构件执行任务。这是我们在[第 5 章](ch05.html#ch05)中所做的努力的目的，当时我们创建了多模块
    Maven 项目。
- en: Second, if you want to optimize library dependencies further, then consider
    *breaking depended-upon libraries apart to just the code you need*. And perhaps
    even re-implement library functionality in your own code. Obviously there’s some
    work necessary here to do this correctly and safely, but it might be a useful
    technique for you.
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 其次，如果你想进一步优化库的依赖关系，那么考虑*将依赖的库拆分为仅包含你需要的代码*。甚至可以在你自己的代码中重新实现库的功能。显然，这需要一些正确和安全地完成的工作，但对你来说可能是一个有用的技术。
- en: These techniques reduce cold starts in two ways. First, there’s simply a smaller
    artifact to copy and unpack before the runtime starts. But furthermore, there’s
    less code for your runtime to load and initialize.
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 这些技术通过两种方式减少了冷启动的问题。首先，启动运行时之前需要复制和解压的文件更少。但更重要的是，运行时需要加载和初始化的代码更少。
- en: All of these techniques are somewhat unusual in modern server-side software
    development. We’ve become used to being able to add dependencies willy-nilly to
    our projects, creating multi-hundred-megabyte deployment artifacts while Maven
    or NPM “download the internet.” This is typically sufficient in traditional server-side
    development since disk space is cheap, networks are fast, and most importantly,
    we don’t care too much about startup time for our servers, at least not on the
    order of a few seconds here and there.
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 所有这些技术在现代服务器端软件开发中都有些不同寻常。我们习惯于可以任意向项目中添加依赖项，创建多百兆字节的部署文件，而 Maven 或 NPM 则“下载互联网”。在传统的服务器端开发中，这通常足够了，因为磁盘空间便宜，网络快速，最重要的是，我们不太关心服务器的启动时间，至少不会在这里或那里几秒钟的顺序上。
- en: But with functions as a service (FaaS), and Lambda in particular, we care about
    startup time to a much more significant extent, so we need to be more judicious
    with how we build and package our software.
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 但是对于函数即服务（FaaS），尤其是 Lambda，我们对启动时间的关注程度要高得多，因此我们需要更审慎地构建和打包我们的软件。
- en: To prune dependencies in JVM projects, you may want to consider using the [Apache
    Maven Dependency plug-in](https://oreil.ly/RZYMF), which will report on how dependencies
    in your project are used, or a similar tool.
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 为了在 JVM 项目中减少依赖关系，你可能希望考虑使用[Apache Maven 依赖插件](https://oreil.ly/RZYMF)，它将报告项目中依赖项的使用情况，或者类似的工具。
- en: Use a more load-speed-efficient packaging format
  id: totrans-221
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 使用更高效的加载速度的打包格式
- en: As we called out in [Chapter 4](ch04.html#ch04), [AWS recommends](https://oreil.ly/_S6Bb)
    the ZIP file approach to packaging a Lambda function, over the uberjar approach,
    because it decreases the time Lambda needs to unpack your deployment artifact.
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们在[第 4 章](ch04.html#ch04)中所提到的，[AWS 建议](https://oreil.ly/_S6Bb)使用 ZIP 文件方法打包
    Lambda 函数，而不是使用 uberjar 方法，因为这样可以减少 Lambda 解压部署文件所需的时间。
- en: Reduce startup logic
  id: totrans-223
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 减少启动逻辑
- en: Later in this chapter, we’ll look at state in Lambda functions. Despite what
    you may have heard, Lambda functions aren’t stateless; they just have an unusual
    model when it comes to thinking about state.
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章后面，我们将讨论 Lambda 函数中的状态问题。不管你之前听到了什么，Lambda 函数并不是无状态的；只是在思考状态时有一个不同寻常的模型。
- en: A fairly common thing to do with Lambda functions is to create or load various
    resources when the function is first invoked. We saw this to a small extent in
    the examples in [Chapter 5](ch05.html#ch05) when we initialized our serialization
    libraries and SDKs. However for some functions, it makes sense to grab this idea
    by the horns and create a large local cache, loaded from some other resources,
    in the name of more quickly handling events during the lifetime of the instance.
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: Lambda 函数中一个非常常见的做法是在首次调用函数时创建或加载各种资源。在[第 5 章](ch05.html#ch05)的示例中，我们在一定程度上看到了这一点，当时我们初始化了序列化库和
    SDK。然而，对于某些函数来说，理解这一思想并创建一个大型的本地缓存，从其他资源加载，以更快地处理实例生命周期中的事件是有意义的。
- en: Such startup logic doesn’t happen for free though, and will increase cold start
    time. If you are loading initial resources at cold start, you may find that you
    have a trade-off to make between how much you improve the performance of subsequent
    invocations versus how long the initial invocation takes. If possible, you may
    want to consider if you can gradually “warm” your function’s local cache over
    a series of initial invocations.
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 这样的启动逻辑并非免费，会增加冷启动时间。如果你在冷启动时加载初始资源，你可能会发现在改善后续调用性能与初始调用时间之间需要做出权衡。如果可能的话，你可能希望考虑是否可以逐渐在一系列初始调用中“预热”函数的本地缓存。
- en: Warning
  id: totrans-227
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 警告
- en: One big cause of slow startup is the use of application frameworks like Spring.
    As we discuss later (see [“Lambda and Java Application Frameworks”](#java-application-frameworks)),
    we strongly discourage the use of such frameworks with Lambda. If cold starts
    are causing you a problem, and you’re using an application framework, then we
    recommend your first course of action should be to investigate whether you can
    remove the framework from your Lambda function.
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: 缓慢启动的一个主要原因是使用像 Spring 这样的应用框架。正如我们稍后讨论的（见 [“Lambda 和 Java 应用框架”](#java-application-frameworks)），我们强烈反对在
    Lambda 中使用这样的框架。如果冷启动给你造成了问题，并且你正在使用应用框架，那么我们建议你首先调查是否可以从 Lambda 函数中移除该框架。
- en: Language choice
  id: totrans-229
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 语言选择
- en: Another area that can impact cold start time is the choice of language runtime.
    JavaScript, Python, and Go simply take less time to start up than the JVM or .NET
    runtime. Therefore, if you’re writing a small function that isn’t called often,
    and you care about reducing cold start impact as much as possible, you may want
    to use either JavaScript, Python, or Go over Java, all other development aspects
    being equal.
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个可能影响冷启动时间的领域是语言运行时的选择。JavaScript、Python 和 Go 启动所需的时间比 JVM 或 .NET 运行时少。因此，如果你编写的是不经常调用的小函数，并且你关心尽可能减少冷启动影响，你可能会希望在其他开发方面相等的情况下选择
    JavaScript、Python 或 Go 而不是 Java。
- en: Because of this difference in startup time, we often hear people dismiss the
    JVM and .NET runtimes as Lambda runtimes in general, but this is a short-sighted
    opinion. For instance, in the situation we described earlier with the Kinesis
    processing function, what if, on average, the JVM function took 80 ms to process
    an event, but a JavaScript equivalent took 120 ms? In this case, you would literally
    be paying twice as much for the JavaScript version of your code to run (since
    billable Lambda time is rounded up to the next 100 ms). In this situation, JavaScript
    may be the wrong choice of runtime.
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: 由于启动时间的差异，我们经常听到人们在一般情况下将 JVM 和 .NET 运行时作为 Lambda 运行时而忽略，但这是一种短视的观点。例如，在我们早些时候描述的
    Kinesis 处理函数的情况中，如果平均情况下 JVM 函数处理一个事件需要 80 毫秒，而 JavaScript 等效函数需要 120 毫秒呢？在这种情况下，你的代码的
    JavaScript 版本运行成本将是 JVM 版本的两倍（因为计费 Lambda 时间会向上取整到下一个 100 毫秒）。在这种情况下，JavaScript
    可能不是运行时的正确选择。
- en: It’s perfectly possible to use alternative (non-Java) JVM languages within Lambda
    (which we talk about more at the end of this chapter). One important aspect to
    remember, though, is that typically these languages come with their own “language
    runtimes” and libraries, and both of these will increase cold start time.
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: 完全可以在 Lambda 中使用替代（非 Java）JVM 语言（我们将在本章末尾进一步讨论）。但要记住的一点是，通常这些语言都带有自己的“语言运行时”和库，这两者都会增加冷启动时间。
- en: Finally, on the topic of language choice, it’s worth keeping some perspective
    when it comes to impact of language on cold start, or event-processing, performance.
    The most important factor in language choice is how effectively you can build
    and maintain your code—the human element of software development. The cost of
    runtime performance differences between Lambda language runtimes may pale in comparison
    with this.
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，在选择语言这个话题上，当涉及到语言对冷启动或事件处理性能的影响时，保持一些视角是值得的。在语言选择中，最重要的因素是你如何有效地构建和维护你的代码——软件开发中的人为因素。与
    Lambda 语言运行时之间的运行时性能差异相比，成本可能微不足道。
- en: Memory and CPU
  id: totrans-234
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 内存和 CPU
- en: Certain aspects of your function’s configuration can also affect cold start
    time. One of the primary examples of this is the `MemorySize` setting you choose.
    A larger memory setting also gives more CPU resources, and therefore a larger
    memory setting may speed up the time it takes your JVM code to JIT compile.
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: 函数配置的某些方面也会影响冷启动时间。其中一个主要例子是你选择的 `MemorySize` 设置。更大的内存设置也会提供更多的 CPU 资源，因此较大的内存设置可能会加快
    JVM 代码的 JIT 编译时间。
- en: Note
  id: totrans-236
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: Until late 2019, another configuration setting of a Lambda function that could
    significantly increase cold start time was whether you were using a *virtual private
    cloud (VPC)*. We discuss VPCs in general later in this chapter, but for now all
    you need to know is that if you see any documentation anywhere warning of awful
    Lamdba startup times because of VPCs, then you can sit happy in the knowledge
    that this has now been resolved. For more details on what AWS did to improve this,
    see [this article](https://oreil.ly/UnES6).
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: 直到2019年底，Lambda函数的另一个配置设置可能会显著增加冷启动时间，即是否使用*虚拟私有云（VPC）*。 我们稍后在本章中详细讨论VPC，但目前您需要知道的是，如果您在任何地方看到有关因VPC导致Lambda启动时间恶化的警告文档，请放心，此问题现在已经解决。
    有关AWS改进此问题的更多详细信息，请参见[此文章](https://oreil.ly/UnES6)。
- en: Provisioned Concurrency
  id: totrans-238
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 预配并发
- en: 'In late 2019 AWS announced a new Lambda feature—*Provisioned Concurrency*.
    Provisioned Concurrency (PC) allows an engineer to effectively “pre-warm” Lambda
    functions, thereby removing (almost) all of the impact of cold starts. Before
    we describe how to use this feature, here are some important caveats:'
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: 2019年底，AWS宣布了一项新的Lambda功能——*预配并发*。 预配并发（PC）允许工程师有效地“预热”Lambda函数，从而消除（几乎）所有冷启动的影响。
    在我们描述如何使用此功能之前，请注意以下一些重要的警告：
- en: 'PC breaks the request-based cost model of Lambda. With PC you pay whether your
    functions are invoked or not. Using Lambda with PC therefore negates one of the
    main benefits of serverless: costs that scale to zero (see [“FaaS as Implemented
    by Lambda”](ch01.html#lambda-as-faas)).'
  id: totrans-240
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: PC会破坏Lambda的基于请求的成本模型。 使用PC，您无论是否调用函数都需要付费。 因此，使用带有PC的Lambda抵消了无服务器的主要好处之一：成本可以缩减到零（请参阅[“Lambda实现的FaaS”](ch01.html#lambda-as-faas)）。
- en: To avoid paying for costs related to peak usage, you need to manually configure
    AWS Auto Scaling with PC (see [this AWS blog article on how to implement this](https://oreil.ly/9x0D6)).
    This is extra operational overhead on your part.
  id: totrans-241
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 为了避免支付与峰值使用相关的成本，您需要手动配置带有PC的AWS自动缩放（请参阅[此AWS博客文章以了解如何实现此操作](https://oreil.ly/9x0D6)）。
    这会增加您的额外运维工作量。
- en: PC adds significant deployment time overhead. In our experiments, at the time
    of writing, deploying a Lambda function with a PC setting of 1 (see below as to
    what this means) has an overhead of about four minutes. Using a setting of 10
    or 100 is about seven minutes.
  id: totrans-242
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: PC会增加显著的部署时间开销。 在我们的实验中，在撰写本文时，部署具有设置为1的PC的Lambda函数的开销约为四分钟。 使用设置为10或100的情况约为七分钟。
- en: PC requires using either versions or aliases, which we described earlier in
    this chapter (see [“Versions and Aliases, Traffic Shifting”](#versions-and-aliases)).
    As we mentioned in that section, we do not recommend using versions or aliases
    in most cases, due to the extra complexity they bring.
  id: totrans-243
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: PC需要使用版本或别名，我们在本章早些时候描述了它们（请参阅[“版本和别名，流量转移”](#versions-and-aliases)）。 如我们在该部分中提到的，我们不建议在大多数情况下使用版本或别名，因为它们带来了额外的复杂性。
- en: Warning
  id: totrans-244
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 警告
- en: Given these significant caveats, our recommendation is that you only reach for
    Provisioned Concurrency if you *absolutely need to*. As we mention in the summary
    of this section, we find that most teams that are concerned initially about cold
    starts find that they are of no effective consequence once they start using Lambda
    at scale in production, especially if the teams follow the other advice we give
    in this chapter about cold start mitigation.
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: 鉴于这些重大注意事项，我们的建议是，只有在您*绝对需要时*才使用预配并发。 正如我们在本节摘要中提到的，我们发现，大多数最初关注冷启动的团队在开始在生产中大规模使用Lambda后，发现冷启动实际上没有什么效果，特别是如果团队遵循本章关于冷启动缓解的其他建议。
- en: Now, we’ve told you why you almost certainly shouldn’t use Provisioned Concurrency,
    let’s talk about what it is!
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们告诉您为什么几乎肯定不应该使用预配并发，让我们谈谈它是什么！
- en: PC, at its simplest, is a numerical value (*n*) that tells the Lambda platform
    to always have *at least* *n* execution environments of your function in a “warm”
    state. “Warm” here means that the execution environment has been created, and
    your Lambda function handler code has been instantiated. In fact, the entire execution
    chain (see [Figure 3-1](ch03.html#lambda-execution-environment)) is performed
    during warming, apart from actually calling your handler method.
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: PC，最简单地说，是一个数值（*n*），告诉Lambda平台始终保持*至少* *n* 个函数执行环境处于“热”状态。 这里的“热”意味着执行环境已创建，并且已实例化您的Lambda函数处理程序代码。
    事实上，在预热期间执行了整个执行链（请参阅[图3-1](ch03.html#lambda-execution-environment)），除了实际调用处理程序方法。
- en: Since under a PC context Lambda won’t call a nonwarmed function (apart from
    one caveat about scaling, which we’ll describe in a moment), this guarantees that
    you won’t have any performance-impacting cold starts at all! In other words, *all*
    of your function invocations will respond in their regular “warm” time.
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: 由于在PC环境下，Lambda不会调用未预热的函数（除了我们稍后描述的一个关于扩展的细节），这确保了您不会有任何性能影响的冷启动！换句话说，*所有*函数调用都将在其常规的“预热”时间内响应。
- en: Another nice aspect to PC is that it is defined solely in deployment configuration—no
    change to your code is required to use it (although you may want to change your
    code, as we will describe about code instantiation in a moment).
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: PC的另一个好处是，它仅在部署配置中定义——您不需要更改代码即可使用它（尽管您可能想要更改代码，我们将在稍后描述关于代码实例化的内容）。
- en: 'Let’s look at an example. Say that we have the following function configured
    in our SAM template:'
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们来看一个例子。假设我们在SAM模板中配置了以下函数：
- en: '[PRE8]'
  id: totrans-251
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: The new lines here are those last three. First you’ll see that we’re using an
    alias—PC requires configuring a `ProvisionedConcurrentExecutions` value for each
    version or alias that we want PC for. We can’t configure a `ProvisionedConcurrentExecutions`
    value for `$LATEST`—the default version.
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: 新增的内容在这里是最后三行。首先，您会看到我们正在使用别名——PC要求为每个版本或别名配置`ProvisionedConcurrentExecutions`值。我们不能为`$LATEST`——默认版本配置`ProvisionedConcurrentExecutions`值。
- en: In this example, we then specify that we want to always have one instance of
    our Lambda function pre-warmed.
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个例子中，我们还指定要始终有一个实例的Lambda函数预热。
- en: When we deploy this function for the first time, Lambda will instantiate the
    Java class `HelloWorld`, which contains our handler, even before any invocations
    occur. Then, when an event is received for the function, Lambda calls this pre-warmed
    function. When we *redeploy* the function, Lambda will keep routing requests to
    the old (warm) version and start using the new version only once all the provisioned
    instances for that version have been created. Again, this makes sure that function
    invocation isn’t impacted by cold starts.
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们首次部署此函数时，Lambda将实例化Java类`HelloWorld`，其中包含我们的处理程序，甚至在发生任何调用之前。然后，当接收到函数的事件时，Lambda将调用这个预热的函数。当我们*重新部署*函数时，Lambda将继续将请求路由到旧版本（预热），并且只有在为该版本创建的所有预置实例之后才开始使用新版本。再次强调，这确保了函数调用不受冷启动的影响。
- en: Tip
  id: totrans-255
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 提示
- en: In other third-party Lambda documentation, you may see recommendations to use
    a secondary, scheduled, “ping” function that calls the application function, to
    avoid cold starts. PC, with a setting of 1, in almost any case is a more effective
    replacement of such a mechanism.
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
  zh: 在其他第三方Lambda文档中，您可能会看到建议使用次要的定时“ping”函数来调用应用程序函数，以避免冷启动。PC，在设置为1的情况下，几乎在任何情况下都是这种机制的更有效替代品。
- en: Now, let’s cover a few details you should be aware of.
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们讨论您应该注意的一些细节。
- en: First, pricing. As mentioned, PC has (at the time of writing) a different cost
    model to regular “on-demand” Lambda. As described in [“How Expensive Is Lambda?”](ch03.html#how-expensive-is-lambda),
    on-demand Lambda costs are based on how many requests your Lambda function receives
    and how long your Lambda function is executing (duration). For PC you still pay
    the request cost, and a (smaller) amount for duration, but you *also* pay a charge
    for the entire time your function is deployed, not just when it is processing
    requests.
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: 首先是定价。正如提到的，在写作时，PC与常规的“按需”Lambda有着不同的成本模型。如[“Lambda的成本有多高？”](ch03.html#how-expensive-is-lambda)中所述，按需Lambda的成本基于您的Lambda函数接收了多少请求以及Lambda函数执行的时间（持续时间）。对于PC，您仍需支付请求成本，以及一个（较小的）持续时间成本，但您还需为函数部署期间的整个时间支付费用，而不仅仅是处理请求时。
- en: Let’s build on [“How Expensive Is Lambda?”](ch03.html#how-expensive-is-lambda),
    specifically the example for the web API. Our cost estimate for just on-demand
    Lambda was $21.60/month. How much does it cost using Provisioned Concurrency?
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们继续探讨[“Lambda的成本有多高？”](ch03.html#how-expensive-is-lambda)中的内容，特别是针对Web API的示例。我们仅使用按需Lambda的成本估算为每月$21.60。使用预置并发的成本是多少呢？
- en: 'Again, we’ll assume 512-MB RAM, less than 100 ms to process a request and 864,000
    requests/day. Let’s start with using a PC value of 10, since that’s what we expect
    to peak up to. In this scenario, our Lambda costs are as follows:'
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: 同样，我们将假设512 MB RAM，少于100 ms来处理请求和864,000次/天的情况。让我们从使用PC值为10开始，因为这是我们预计的峰值。在这种情况下，我们的Lambda成本如下：
- en: The request cost is unchanged at $5.18/month.
  id: totrans-261
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 请求成本每月保持不变为$5.18。
- en: The duration cost is 0.1 × 864000 × 0.5 × $0.000009722 = $0.42/day, or $12.60/month.
  id: totrans-262
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 持续成本为0.1 × 864000 × 0.5 × $0.000009722 = $0.42/天，或$12.60/月。
- en: The Provisioned Concurrency cost is 10 × 0.000004167 × 0.5 × 86400 = $1.80/day,
    or $54/month.
  id: totrans-263
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 预置并发成本为10 × 0.000004167 × 0.5 × 86400 = $1.80/天，或$54/月。
- en: The total cost therefore has increased by a little over three times from approximately
    $22/month to $72/month. Yikes!
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，总成本已经从每月约$22增加到每月$72的三倍多。哎呀！
- en: Now, this is likely a “worst case” since we are setting PC at peak. One option
    we have is to manually configure auto-scaling for PC. This is described on the
    [AWS blog introducing PC](https://oreil.ly/8p8K6). Let’s say that doing this means
    our PC configuration averages around 2. In this case, our total costs are $29/month.
    This is still 30% more expensive than on-demand, plus now we have the added complexity
    of managing PC auto-scaling.
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，这很可能是一个“最坏的情况”，因为我们将PC设置为峰值。我们的一个选择是为PC手动配置自动扩展。这在[AWS博客介绍PC](https://oreil.ly/8p8K6)中有描述。假设这样做意味着我们的PC配置平均约为2。在这种情况下，我们的总成本为每月$29。这仍然比按需贵30%，而且现在我们还增加了管理PC自动扩展的复杂性。
- en: There are some scenarios where if you have a very consistent usage model, then
    PC works out cheaper than on-demand, but in most cases you should expect to pay
    a significant overhead to use PC.
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
  zh: 在某些场景中，如果您有非常一致的使用模式，那么按需使用可能比按需使用更便宜，但在大多数情况下，您应该期望支付显著的额外开销以使用按需。
- en: Another issue related to costs is that you probably want to have different configuration
    for development versus production to avoid paying “always-on” costs for development
    environments. You can do this using CloudFormation techniques, but again this
    is extra mental overhead.
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
  zh: 与成本相关的另一个问题是，您可能希望针对开发和生产使用不同的配置，以避免为开发环境支付“全天候”成本。您可以使用CloudFormation技术来实现这一点，但这会增加额外的心理负担。
- en: That’s enough about costs. Let’s move on to a different subject!
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
  zh: 关于成本的讨论就到此为止。让我们转移到另一个主题！
- en: What happens if at a certain point in time you have more invocations than your
    PC configuration? As we looked at earlier in this chapter, we know that Lambda
    always increases the number of active execution environments to satisfy load.
    For example, say that Lambda needs to use an 11th execution environment for your
    function, but you have a PC setting of 10—what happens now? In this case, Lambda
    will spin up a new execution environment in the “traditional” on-demand model
    to cover the extra load. You will be charged for this extra capacity in the usual
    on-demand fashion, but be warned—the first event using that new extra environment
    will also incur cold-start latency in the normal way!
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: 如果在某个时间点您的PC配置有更多的调用次数，会发生什么情况？正如我们在本章前面所讨论的，Lambda始终会增加活动执行环境的数量以满足负载。例如，假设Lambda需要为您的函数使用第11个执行环境，但您的PC设置为10——现在会发生什么？在这种情况下，Lambda将以“传统”的按需模式为额外负载启动新的执行环境。您将按通常的按需方式收取此额外容量的费用，但请注意——使用该新额外环境的第一个事件也会以正常方式产生冷启动延迟！
- en: Finally, a quick note on making the most of PC. AWS has been doing a great job
    over the last few years in reducing the *platform* overhead of cold starts, so
    the main point of PC is mostly to mitigate *application* overhead—the time taken
    to instantiate your language runtime, code, and handler class. This last element—class
    instantiation—is important since your handler class constructor is called during
    pre-warming. Therefore, you’ll want to move as much application setup as possible
    to class and object instantiation time and not do this in the handler method itself.
    We’ve used this pattern throughout the book, but it’s especially important if
    you’re using PC.
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，快速注意一下如何充分利用按需计算。在过去几年中，AWS在减少*平台*冷启动开销方面表现出色，因此按需计算的主要目的大多是缓解*应用程序*的开销——即实例化语言运行时、代码和处理程序类所需的时间。最后一个元素——类实例化——非常重要，因为在预热期间会调用您的处理程序类构造函数。因此，您应该尽可能将应用程序设置移至类和对象实例化时间，而不是在处理程序方法本身中执行此操作。我们在本书中始终使用此模式，但如果您使用按需计算，则尤为重要。
- en: 'Given all of our dire warnings about using PC, when do we recommend using it?
    Here are a few scenarios where we can imagine PC being useful:'
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
  zh: 鉴于我们对使用按需计算的所有严重警告，我们什么时候建议使用它呢？以下是我们可以想象使用按需计算的几种情况：
- en: When you have a Lambda function called very infrequently (say once per hour,
    or longer) that you always want to return quickly (subsecond), and you are willing
    to pay the cost overhead.
  id: totrans-272
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当您的Lambda函数调用非常不频繁（例如每小时一次或更长时间），而且您希望快速返回（亚秒级），并且愿意承担成本开销时。
- en: If your application has extreme “burst” scale scenarios (see [“Burst limits”](#burst-limits))
    that Lambda can’t handle by default, then you can pre-warm sufficient capacity.
  id: totrans-273
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果你的应用程序具有极端的“突发”规模场景（请参阅[“突发限制”](#burst-limits)），Lambda无法默认处理，则可以预热足够的容量。
- en: If your function itself has significant code-level cold-start time (e.g., several
    seconds) that is not sufficient for application performance, and you have no other
    way to mitigate this. This is typical if you’re using a heavyweight application
    framework within your Lambda code.
  id: totrans-274
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果你的函数本身在代码级别有显着的冷启动时间（例如，几秒钟），这对于应用性能来说是不够的，并且你没有其他方法来缓解这种情况。如果你在Lambda代码中使用了一个庞大的应用程序框架，这种情况很典型。
- en: Cold Start Summary
  id: totrans-275
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 冷启动摘要
- en: Cold starts might be nothing you need to ever spend too much effort on, depending
    on what you use Lambda for, but it’s certainly a topic that you should be aware
    of, since how cold starts are mitigated often runs counter to how we typically
    build and package systems.
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
  zh: 冷启动可能不是你需要花太多精力的事情，这取决于你如何使用 Lambda，但这绝对是一个你应该了解的话题，因为冷启动是如何被缓解的通常与我们通常构建和打包系统的方式相反。
- en: We mentioned *FUD* around cold starts earlier, and cold starts are also often
    “thrown under the bus” for latency problems that turn out to actually have nothing
    to do with cold starts at all. Remember to perform proper latency analysis if
    you’re having latency concerns—make sure your actual problem isn’t, for example,
    how your code is interacting with a downstream system.
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
  zh: 我们之前提到过关于冷启动的*FUD*，而冷启动也经常因实际上与冷启动无关的延迟问题而被“抛弃”。如果你担心延迟，请执行适当的延迟分析——确保你的实际问题不是，例如，你的代码如何与下游系统交互。
- en: Also make sure to continue to test latency over time, especially if you rule
    out a certain use of Lambda because of cold starts. AWS has made, and continues
    to make, significant improvements in this part of the Lambda platform.
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
  zh: 还要确保随着时间的推移继续测试延迟，特别是如果你因为冷启动而排除了Lambda的某种用法。AWS在Lambda平台的这一部分已经做出了，并且正在继续做出重大改进。
- en: In our experience, cold starts concern teams when they first use Lambda, especially
    under spiky development loads, but once they see how Lambda performs under production
    loads, they often never worry about cold starts again.
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
  zh: 根据我们的经验，当团队第一次使用Lambda时，冷启动会引起他们的关注，特别是在开发负载波动较大时，但一旦他们看到Lambda在生产负载下的表现，他们通常再也不会担心冷启动了。
- en: State
  id: totrans-280
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 状态
- en: Almost any application needs to consider state. Such state may be *persistent*—in
    other words, it captures data that is required to fulfill subsequent requests.
    Alternatively, it may be *cached* state—a copy of data that is used to improve
    performance, where the persisted version is stored elsewhere.
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
  zh: 几乎任何应用程序都需要考虑状态。这种状态可能是*持久的*——换句话说，它捕获了需要满足后续请求的数据。或者，它可以是*缓存*状态——数据的副本，用于提高性能，持久化版本存储在其他位置。
- en: Despite how it’s occasionally perceived, Lambda is *not* stateless—data can
    be stored in memory and on disk both during and across requests.
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管它偶尔会被认为是无状态的，Lambda实际上*不是*无状态——数据可以在请求期间和跨请求期间存储在内存和磁盘上。
- en: In-memory state is available via a handler method’s object and class members—any
    data loaded into such members is available the next time that function instance
    is invoked again, and a Lambda function can have up to a total of 3GB RAM (some
    of that will be used by the Lambda runtime).
  id: totrans-283
  prefs: []
  type: TYPE_NORMAL
  zh: 内存中的状态通过处理程序方法的对象和类成员可用——加载到这些成员中的任何数据在下次调用该函数实例时都可用，而且Lambda函数可以最多有3GB RAM（其中一部分将被Lambda运行时使用）。
- en: Lambda function instances also have access to 512MB of local disk storage in
    */tmp*. While this state is not automatically shared across function instances,
    it will, again, be available for subsequent invocations of the same function instance.
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
  zh: Lambda函数实例还可以访问*/tmp*中的512MB本地磁盘存储。虽然这种状态不会自动在函数实例之间共享，但它将在同一函数实例的后续调用中再次可用。
- en: However, the nature of Lambda’s runtime model significantly impacts how such
    state can be used.
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，Lambda的运行时模型的性质显著影响了这种状态如何被使用。
- en: Persistent Application State
  id: totrans-286
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 持久应用程序状态
- en: The way that Lambda creates function instances, especially in the way that it
    scales, has significant implications on architecture. For example, we have absolutely
    no guarantee that sequential requests, for the same upstream client, will be handled
    by the same function instance. There is no “client affinity” for Lambda functions.
  id: totrans-287
  prefs: []
  type: TYPE_NORMAL
  zh: Lambda创建函数实例的方式，特别是它的扩展方式，对架构有重要影响。例如，我们绝对不能保证同一上游客户端的连续请求将由同一函数实例处理。Lambda函数没有“客户端亲和性”。
- en: This means that we *cannot assume* that any state that was available locally
    (in-memory, or on local disk) in a Lambda function for one request will be available
    for a subsequent request. This is true whether our function scales or not—scaling
    just underlines the point.
  id: totrans-288
  prefs: []
  type: TYPE_NORMAL
  zh: 这意味着我们*不能假设*在Lambda函数中一个请求中本地可用的任何状态（内存中或本地磁盘上）将在后续请求中可用。无论我们的函数是否扩展，这都是真实的——扩展只是强调这一点。
- en: Therefore, all persistent application state that we want to keep across Lambda
    function invocations must be *externalized*. In other words, this means that any
    state we want to keep beyond an individual invocation has to be either stored
    downstream of our Lambda function—in a database, external file storage, or other
    downstream service—or it must be returned to the caller in the case of a synchronously
    called function.
  id: totrans-289
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，我们想要在Lambda函数调用之间保留的所有持久应用程序状态都必须是*外部化的*。换句话说，这意味着我们想要在个别调用之外保留的任何状态都必须要么存储在我们的Lambda函数下游——在数据库、外部文件存储或其他下游服务中——要么在同步调用函数的情况下返回给调用者。
- en: This might sound like a massive restriction, but in fact this way of building
    server-side software is not new. Many people have been espousing the virtues of
    the [*12-factor architecture*](https://12factor.net/) for years, and this aspect
    of externalizing state is expressed within the sixth factor of that paradigm.
  id: totrans-290
  prefs: []
  type: TYPE_NORMAL
  zh: 这听起来可能是一个巨大的限制，但事实上，这种构建服务器端软件的方式并不新鲜。多年来，许多人一直在宣扬[*12因素架构*](https://12factor.net/)的优点，这种将状态外部化的方式体现在该范例的第六因素中。
- en: That being said, this definitely is a constraint of Lambda, and may require
    you to significantly re-architect existing applications that you want to move
    to Lambda. It may also mean that some applications that require particularly low
    latency to state (for example, gaming servers) are not good candidate applications
    for Lambda, nor are those that require a large data set in memory in order to
    perform adequately.
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
  zh: 话虽如此，这绝对是Lambda的一个限制，并且可能需要您对要迁移到Lambda的现有应用程序进行重大重新架构。这也可能意味着一些需要对状态进行特别低延迟访问的应用程序（例如，游戏服务器）不适合Lambda，也不适合需要大量数据集在内存中以达到足够性能的应用程序。
- en: 'There are various common services that people use to externalize their application
    state with Lambda:'
  id: totrans-292
  prefs: []
  type: TYPE_NORMAL
  zh: 人们常用的一些服务用于外部化他们与Lambda的应用程序状态：
- en: DynamoDB
  id: totrans-293
  prefs: []
  type: TYPE_NORMAL
  zh: DynamoDB
- en: 'DynamoDB is the NoSQL database of AWS. We used DynamoDB in the API example
    in [“Example: Building a Serverless API”](ch05.html#serverless-api-example). The
    benefits of DynamoDB are that it is fast, fairly easy to operate and configure,
    and has very similar scaling properties to Lambda. The chief drawback to DynamoDB
    is that modeling data can get tricky.'
  id: totrans-294
  prefs: []
  type: TYPE_NORMAL
  zh: DynamoDB是AWS的NoSQL数据库。我们在[“示例：构建无服务器API”](ch05.html#serverless-api-example)中的API示例中使用了DynamoDB。DynamoDB的好处是它快速、操作和配置相对容易，并且具有非常相似的扩展属性。DynamoDB的主要缺点是建模数据可能会变得棘手。
- en: RDS
  id: totrans-295
  prefs: []
  type: TYPE_NORMAL
  zh: RDS
- en: AWS has various relational databases that it groups in the Relational/SQL Database
    Service (RDS) family, and all of these are available for use from Lambda. One
    fairly new option within this family is [*Aurora Serverless*](https://oreil.ly/2Kc4E)—an
    auto-scaling version of Amazon’s own *Aurora* MySQL and Postgres engines, made
    for serverless applications. The benefits of using a SQL database over a NoSQL
    one are decades of experience building such applications. The drawbacks, versus
    DynamoDB at least, typically are higher latencies and more operational overhead
    (with nonserverless RDS).
  id: totrans-296
  prefs: []
  type: TYPE_NORMAL
  zh: AWS有各种关系型数据库，它们都被分组到关系/SQL数据库服务（RDS）家族中，并且所有这些数据库都可以从Lambda中使用。在这个家族中相对新的一个选项是[*Aurora
    Serverless*](https://oreil.ly/2Kc4E)——Amazon自己的*Aurora* MySQL和Postgres引擎的自动扩展版本，专为无服务器应用程序而设计。使用SQL数据库而不是NoSQL数据库的好处是几十年来构建这种应用程序的经验。相对于DynamoDB，缺点通常是更高的延迟和更多的操作开销（非无服务器RDS）。
- en: S3
  id: totrans-297
  prefs: []
  type: TYPE_NORMAL
  zh: S3
- en: Simple Storage Service (S3)—which we’ve used several times throughout this book—can
    be used as a data store for Lambda. It’s simple to use, but isn’t particularly
    low latency, and also has limited querying capabilities in comparison with one
    of the database services, unless you also use [Amazon Athena](https://aws.amazon.com/athena).
  id: totrans-298
  prefs: []
  type: TYPE_NORMAL
  zh: 简单存储服务（S3）——我们在本书中多次使用过——可以用作 Lambda 的数据存储。它易于使用，但在与某些数据库服务相比，查询能力有限，而且延迟并不低，除非您还使用
    [Amazon Athena](https://aws.amazon.com/athena)。
- en: ElastiCache
  id: totrans-299
  prefs: []
  type: TYPE_NORMAL
  zh: ElastiCache
- en: AWS offers a managed version of the Redis persistent cache application as part
    of its [ElastiCache](https://aws.amazon.com/elasticache) family. Of these four
    options, ElastiCache typically offers the fastest performance, but since it isn’t
    a true serverless service, it does require some operational overhead.
  id: totrans-300
  prefs: []
  type: TYPE_NORMAL
  zh: AWS 作为其 [ElastiCache](https://aws.amazon.com/elasticache) 家族的一部分提供了 Redis 持久缓存应用的托管版本。在这四个选项中，ElastiCache
    通常提供最快的性能，但由于它不是真正的无服务器服务，因此需要一些操作开销。
- en: Custom downstream service
  id: totrans-301
  prefs: []
  type: TYPE_NORMAL
  zh: 自定义下游服务
- en: Alternatively, you may choose to implement your own in-memory persistence in
    a downstream service, built using traditional designs.
  id: totrans-302
  prefs: []
  type: TYPE_NORMAL
  zh: 或者，您可以选择在下游服务中实现自己的内存持久化，采用传统设计。
- en: AWS continues to make interesting developments in this area, and we recommend
    that you investigate all recently announced advances whenever you pick a persistence
    solution.
  id: totrans-303
  prefs: []
  type: TYPE_NORMAL
  zh: AWS 在这一领域继续进行有趣的发展，我们建议您在选择持久化解决方案时调查所有最近宣布的进展。
- en: Caching
  id: totrans-304
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 缓存
- en: While we can’t rely on Lambda’s state capabilities for persistent application
    state, we absolutely can use them for caching data that is also stored elsewhere.
    Put another way, while it’s true that we have no guarantee that one Lambda function
    instance will be called multiple times, we do know that it *probably will be*,
    depending on invocation frequency. Because of this, cache state is a candidate
    for Lambda’s local storage.
  id: totrans-305
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管我们不能依赖 Lambda 的状态能力来实现持久的应用程序状态，但我们绝对可以将其用于缓存数据，这些数据也可以存储在其他位置。换句话说，虽然我们无法保证一个
    Lambda 函数实例将被多次调用，但根据调用频率，我们确实知道它*可能会*。因此，缓存状态是 Lambda 本地存储的候选项。
- en: We can use either or both of Lambda’s in-memory or on-disk locations for cached
    data. For example, say that we always need a set of fairly up-to-date reference
    data from a downstream service to process an event, but “fairly up-to-date” is
    on order of “valid within the last day.” In this case, we can load the reference
    data once, for the first invocation of the function instance, and then store that
    data locally in a static or instance member variable. Remember—our handler function
    instance object will be instantiated only once per runtime environment.
  id: totrans-306
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用 Lambda 的内存或磁盘位置来缓存数据。例如，假设我们始终需要一组相当及时的参考数据来处理事件，但“相当及时”的定义是“在最后一天内有效”。在这种情况下，我们可以在函数实例的第一次调用时加载参考数据，然后将该数据存储在本地的静态或实例成员变量中。请记住，我们的处理函数实例对象将仅在运行时环境中实例化一次。
- en: As another example, say that we want to call an external program or library
    as part of our execution—Lambda gives us a full Linux environment with which to
    do this. That program/library may be too big to fit in either a Lambda code artifact
    (which is restricted to at most 250MB when uncompressed) or even a Lambda layer
    (see later in this chapter about layers). Instead, we can copy the external code
    from S3 to */tmp* the first time we need it for a function instance, and then
    for subsequent requests for that instance the code will be available locally already.
  id: totrans-307
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个例子，假设我们希望在执行过程中调用外部程序或库 —— Lambda 为我们提供了一个完整的 Linux 环境来执行此操作。该程序/库可能太大，无法适应
    Lambda 代码存储库（未压缩时最多限制为 250MB）甚至 Lambda 层（请参见本章稍后有关层的部分）。因此，我们可以在函数实例首次需要它时，将外部代码从
    S3 复制到 */tmp*，然后对于后续对该实例的请求，代码将已经在本地可用。
- en: Both of these examples relate to state that consists of chunks of data—application
    data, or libraries and executables. Another form of state in our Lambda applications
    are the runtime structures of our code itself, including those that represent
    connections to external services. These runtime structures either may take some
    amount of time to create when the function is invoked, or in the case of connections
    to services may take time to initialize, e.g., for authentication procedures.
    In either case, in Lambda, we will very often store these structures in program
    elements that live longer than the call to the method itself—in Java this means
    storing them in instance or static members.
  id: totrans-308
  prefs: []
  type: TYPE_NORMAL
  zh: 这两个示例都涉及由数据块组成的状态——应用程序数据或库和可执行文件。我们Lambda应用程序中的另一种形式的状态是代码本身的运行时结构，包括表示与外部服务连接的结构。这些运行时结构在函数调用时可能需要一定时间来创建，在服务连接的情况下可能需要时间来初始化，例如身份验证程序。在Lambda中，我们经常会将这些结构存储在比方法调用本身生命周期更长的程序元素中——在Java中，这意味着将它们存储在实例或静态成员中。
- en: 'We showed examples of this earlier in the book. For example in [Chapter 5](ch05.html#ch05)
    at [Example 5-3](ch05.html#EX5-3) we store the following in instance members:'
  id: totrans-309
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在本书的早些时候展示了这些例子。例如，在[第五章](ch05.html#ch05)的[示例5-3](ch05.html#EX5-3)中，我们将以下内容存储在实例成员中：
- en: The `ObjectMapper` instance, because that is a program structure that takes
    some time to instantiate
  id: totrans-310
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`ObjectMapper`实例，因为这是一个需要一定时间来实例化的程序结构'
- en: The DynamoDB client, which is a connection to the external DynamoDB service
  id: totrans-311
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: DynamoDB客户端，它是连接到外部DynamoDB服务的连接
- en: While we typically use this form of object caching for performance reasons in
    certain situations, it can also significantly improve the cost effectiveness of
    our overall system—see [“Lambda Runtime Model and Cost Impact on Downstream Systems”](ch09.html#cache-to-improve-costs)
    for more detail on this.
  id: totrans-312
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然我们通常出于性能原因在某些情况下使用这种形式的对象缓存，但它也可以显著提高我们整个系统的成本效益——详见[“Lambda运行模型及对下游系统成本影响”](ch09.html#cache-to-improve-costs)了解更多详情。
- en: Sometimes Lambda’s own state capabilities are insufficient—for example, our
    total cache state might be too large to fit in memory, too slow to load up during
    a cold start, or update frequently (updating a locally cached version in a Lambda
    function is a tricky thing to manage, although it can be done). In such a case,
    you may choose to use one of the persistence services mentioned in the previous
    section as a caching solution.
  id: totrans-313
  prefs: []
  type: TYPE_NORMAL
  zh: 有时Lambda自身的状态能力是不足的——例如，我们的总缓存状态可能太大而无法放入内存，加载速度在冷启动期间太慢，或者需要频繁更新（在Lambda函数中更新本地缓存版本是一个棘手的事情，虽然可以做到）。在这种情况下，您可以选择使用前一节中提到的持久化服务作为缓存解决方案。
- en: Lambda and Java Application Frameworks
  id: totrans-314
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Lambda和Java应用程序框架
- en: Note
  id: totrans-315
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: So far in this book most of our guidance has been how to use AWS Lambda, with
    a few warnings along the way. We’re now going to take a brief tangent and talk
    about something we *don’t* recommend doing.
  id: totrans-316
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，本书大部分指导都是关于如何使用AWS Lambda，途中也有一些警告。现在我们将稍作偏离，谈谈一些**不建议**做的事情。
- en: Over the last two decades it’s been very common to build server-side Java applications
    using some kind of container and/or framework. Back in the early 2000s, “Java
    Enterprise Edition” (J2EE) was all the rage, with application servers like WebLogic,
    WebSphere, and JBoss allowing you to build your apps with the Enterprise JavaBeans
    (EJB) or Servlet framework. For those of you not around then we can promise you,
    from personal experience, that this was not a whole bunch of fun.
  id: totrans-317
  prefs: []
  type: TYPE_NORMAL
  zh: 在过去的二十年中，使用某种容器和/或框架构建服务器端Java应用程序非常普遍。早在2000年代初，“Java企业版”（J2EE）非常流行，像WebLogic、WebSphere和JBoss这样的应用服务器允许您使用Enterprise
    JavaBeans（EJB）或Servlet框架构建应用程序。如果您那时不在，我们可以从个人经验向您保证，这并不是一件有趣的事情。
- en: People realized that these big servers were often unwieldy and/or expensive,
    and so they have been largely replaced by more “lightweight” equivalents, of which
    Spring is the most common. Spring itself has evolved along the way, of course,
    into Spring Boot, and people also use various Java web frameworks to build applications.
  id: totrans-318
  prefs: []
  type: TYPE_NORMAL
  zh: 人们意识到这些大型服务器通常难以控制和/或昂贵，因此它们在很大程度上被更“轻量级”的替代品所取代，其中Spring是最常见的。当然，Spring本身也在发展中演变为Spring
    Boot，人们还使用各种Java Web框架来构建应用程序。
- en: Because there is so much institutional knowledge in our industry on how to build
    “Java applications” with these tools, there’s a very large temptation to carry
    on using them, and just port the runtime from a running process to a Lambda function.
    AWS has even put significant effort into supporting precisely this way of thinking,
    via the [serverless Java Container](https://oreil.ly/T_ruW) project.
  id: totrans-319
  prefs: []
  type: TYPE_NORMAL
  zh: 因为我们行业中有很多关于如何使用这些工具构建“Java 应用程序”的机构知识，因此有很大的诱惑继续使用它们，并将运行时从运行中的进程移植到 Lambda
    函数中。AWS 甚至投入了大量精力支持正是这种思维方式，通过 [无服务器 Java 容器](https://oreil.ly/T_ruW) 项目。
- en: While we admire AWS’s desire to “meet people where they are” in this way, we
    *strongly discourage* the use of most Java frameworks when building applications
    with Lambda, for the following reasons.
  id: totrans-320
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管我们钦佩 AWS 以这种方式“接人待物”的愿望，但我们*强烈不建议*在使用 Lambda 构建应用程序时使用大多数 Java 框架，原因如下。
- en: First, building a complete app in a single Lambda function misses the fundamental
    point of Lambda. Lambda functions are meant to be small, individual, short-lived
    functions that are event-driven, and programmed to accept a specific input event.
    “Java applications,” on the other hand, are literally servers that have a lifecycle
    and state, and are typically designed to handle multiple types of request. If
    you’re building miniservers, you’re not thinking serverlessly.
  id: totrans-321
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，在单个 Lambda 函数中构建完整的应用程序违背了 Lambda 的基本理念。Lambda 函数应该是小型、独立、短暂的函数，是事件驱动的，并且被设计为接受特定的输入事件。“Java
    应用程序”，相反，实际上是具有生命周期和状态的服务器，通常设计用于处理多种类型的请求。如果你在构建迷你服务器，那就不是在考虑无服务器的方式了。
- en: Next, most application servers assume that there is some amount of shared state
    from request to request. While it’s possible not to work this way, it’s not a
    natural-feeling way of working in these environments.
  id: totrans-322
  prefs: []
  type: TYPE_NORMAL
  zh: 其次，大多数应用服务器假设从一个请求到另一个请求存在一定的共享状态。虽然可以不按这种方式工作，但在这些环境中这并不是一种自然的工作方式。
- en: 'Another reason we think this is a bad idea is that it detracts from the value
    provided by other AWS serverless services. For example, with the AWS project mentioned
    earlier, API Gateway is used, but in a “full proxy” mode. Here’s a snippet from
    the SAM template from the [Spring Boot example](https://oreil.ly/KZYj3):'
  id: totrans-323
  prefs: []
  type: TYPE_NORMAL
  zh: 我们认为这是一个坏主意的另一个原因是，它削弱了其他 AWS 无服务器服务提供的价值。例如，在前面提到的 AWS 项目中，使用了 API Gateway，但是在“全代理”模式下。这里有一个来自
    [Spring Boot 示例](https://oreil.ly/KZYj3) 的 SAM 模板片段：
- en: '[PRE9]'
  id: totrans-324
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: Using API Gateway in this way means that all requests, no matter the path, are
    sent to one Lambda function, and routing behavior needs to be implemented in the
    Lambda function. While Spring Boot can do that, (a) API Gateway will give you
    that functionality for free, and (b) it clutters up your Java code to keep it
    in the Lambda function.
  id: totrans-325
  prefs: []
  type: TYPE_NORMAL
  zh: 以这种方式使用 API Gateway 意味着所有请求，无论路径如何，都将发送到一个 Lambda 函数，并且需要在 Lambda 函数中实现路由行为。虽然
    Spring Boot 可以做到这一点，(a) API Gateway 将免费提供这个功能，而且 (b) 将它保留在 Lambda 函数中会使你的 Java
    代码变得混乱。
- en: Earlier in the book we mentioned that on the whole we’re wary of using too many
    API Gateway features; for example, see the discussion of request and response
    mapping in [“API Gateway Proxy Events”](ch05.html#api-gateway-proxy-events). However,
    we feel that removing routing is typically a step too far down the line of abstracting
    out the use of API Gateway.
  id: totrans-326
  prefs: []
  type: TYPE_NORMAL
  zh: 本书前面我们提到，总体上我们对使用过多 API Gateway 功能持谨慎态度；例如，参见 [“API Gateway 代理事件”](ch05.html#api-gateway-proxy-events)
    中关于请求和响应映射的讨论。然而，我们认为去除路由通常是在抽象出 API Gateway 使用过程中走得太远的一步。
- en: As we discussed earlier on in the section on cold starts, application frameworks
    typically slow down function initialization. While some people may argue that
    this is a good case to use Provisioned Concurrency, we would counter that this
    is a Band-Aid and not a solution.
  id: totrans-327
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们在冷启动部分讨论过的那样，应用程序框架通常会减慢函数的初始化速度。虽然有些人可能会认为这是使用预置并发的好理由，但我们认为这只是一个权宜之计，而不是解决方案。
- en: Finally, container and framework-based apps tend to have large distributable
    artifacts—partly because of the number of libraries depended upon, and partly,
    again, because such apps usually implement a number of functions. Throughout this
    book we’ve been attempting to reduce the size of artifacts by minimizing dependencies,
    and dividing up applications into multiple distributable elements, all in the
    name of keeping our Lambda functions clean and lean. Using an application framework
    runs counter to this way of thinking.
  id: totrans-328
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，基于容器和框架的应用程序往往具有大型的可分发构件——部分原因是因为依赖的库的数量，部分原因又是因为这类应用程序通常实现了许多功能。在整本书中，我们一直在试图通过最小化依赖关系，并将应用程序划分为多个可分发元素，以保持我们的Lambda函数干净而精简。使用应用程序框架与此思维方式背道而驰。
- en: In summary, building Java Lambda applications in this way is really a “square
    peg and round hole problem.” Yes, you can make it work, but it’s inefficient,
    and you won’t get all the benefits of Lambda if you work in this way. There’s
    a real danger of hitting a “local maximum” of value from Lambda, and assuming
    that there are no further upsides.
  id: totrans-329
  prefs: []
  type: TYPE_NORMAL
  zh: 总而言之，以这种方式构建Java Lambda应用程序实际上是一个“方枘圆凿的问题”。是的，你可以让它工作，但这样做效率低下，并且如果你以这种方式工作，你将无法获得Lambda的所有好处。有一种真正的危险，即在Lambda的价值上达到“局部最大值”，并假设没有进一步的好处。
- en: So if we don’t recommend using these frameworks, how do we suggest you use your
    hard-earned knowledge and skills?
  id: totrans-330
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，如果我们不推荐使用这些框架，我们建议您如何使用您辛苦获得的知识和技能呢？
- en: Typically we find that programmers switching to “pure” Lambda development don’t
    take too long to shake off the frameworks they’ve been used to. There’s a certain
    “lightness” that comes with just writing a handler function. Also, there’s nothing
    wrong with bringing along old Java code to the party, as long as it’s not too
    ingrained in an application framework. If you can extract your domain logic into
    something that just expresses your business needs, then you’re on the right path.
  id: totrans-331
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，我们发现程序员切换到“纯”Lambda开发并不需要太长时间来摆脱他们过去习惯于的框架。只编写处理程序函数会带来一种“轻盈感”。此外，将旧的Java代码带到项目中并没有什么问题，只要它没有太多依赖于应用程序框架。如果您可以将您的领域逻辑提取为仅表达您业务需求的内容，那么您就走在了正确的道路上。
- en: Also, it’s still fine to use an ethos of “dependency injection” (DI), which
    the frameworks often provide. You may choose to “hand roll” such DI (our preference),
    as you’ve seen in some of the examples (see [“Add Constructors”](ch06.html#add-constructors)).
    Alternatively, you can try to use a framework to provide just dependency injection,
    without the other features they often come with.
  id: totrans-332
  prefs: []
  type: TYPE_NORMAL
  zh: 同样，使用“依赖注入”（DI）的理念仍然可以，这通常由框架提供。您可以选择“手工制作”这种DI（我们的偏好），就像您在一些示例中看到的那样（请参见[“添加构造函数”](ch06.html#add-constructors)）。或者，您可以尝试使用框架仅提供依赖注入，而不使用它们通常附带的其他功能。
- en: Virtual Private Clouds
  id: totrans-333
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 虚拟专用云
- en: In all of our examples so far any external resources called by a Lambda function
    have been secured via HTTPS/"layer 7” authentication. For example, when we called
    DynamoDB in the serverless API example in [Example 5-3](ch05.html#EX5-3), that
    connection was secured solely by credentials that were passed to DynamoDB from
    our Lambda function.
  id: totrans-334
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，在我们的所有示例中，由Lambda函数调用的任何外部资源都是通过HTTPS/“第7层”认证进行保护的。例如，当我们在[示例5-3](ch05.html#EX5-3)中的无服务器API示例中调用DynamoDB时，该连接仅通过从我们的Lambda函数传递给DynamoDB的凭据进行保护。
- en: In other words, DynamoDB is not a “firewalled” service—it sits open to the internet,
    and any machine anywhere else on the internet can connect to it.
  id: totrans-335
  prefs: []
  type: TYPE_NORMAL
  zh: 换句话说，DynamoDB不是一个“防火墙”服务——它对互联网开放，并且任何其他地方的互联网上的任何机器都可以连接到它。
- en: While this brave new world of “firewall-less” computing is gathering pace, there
    are still many situations where a Lambda function is going to need to connect
    to a resource that is shielded behind some kind of IP-address limited protection.
    A common way of doing that with AWS is to use a VPC.
  id: totrans-336
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然这个“无防火墙”的新世界正在加速发展，但仍然有许多情况下，Lambda函数将需要连接到一个被某种IP地址限制保护的资源。AWS中完成这种操作的常见方法是使用VPC。
- en: VPCs are a lower-level piece of infrastructure than anything else we’ve discussed
    so far in the book. They require understanding things like IP addresses, elastic
    network interfaces (ENIs), CIDR blocks, and security groups, and also expose the
    fact to us that AWS regions are made up of multiple AZs. In other words, “Here
    be dragons!”
  id: totrans-337
  prefs: []
  type: TYPE_NORMAL
  zh: VPC 比我们在本书中迄今讨论的任何其他内容都要低级。它们需要了解诸如 IP 地址、弹性网络接口（ENIs）、CIDR 块和安全组之类的东西，还向我们展示了
    AWS 区域由多个 AZ 组成的事实。换句话说，“此处有龙！”
- en: 'Lambda functions can be configured to be able to access a VPC. Three typical
    reasons a Lambda function would need this are:'
  id: totrans-338
  prefs: []
  type: TYPE_NORMAL
  zh: Lambda 函数可以配置为能够访问 VPC。Lambda 函数需要这样做的三个典型原因是：
- en: To be able to access an RDS SQL database (see [Figure 8-2](#lambda-with-vpc))
  id: totrans-339
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 要能够访问 RDS SQL 数据库（参见 [图 8-2](#lambda-with-vpc)）
- en: To be able to access ElastiCache
  id: totrans-340
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 要能够访问 ElastiCache
- en: To be able to call an internal microservice running on a container cluster using
    IP/VPC-based security
  id: totrans-341
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 要能够使用基于 IP/VPC 的安全性调用在容器集群上运行的内部微服务
- en: '![images/ch08_image02.png](assets/awsl_0802.png)'
  id: totrans-342
  prefs: []
  type: TYPE_IMG
  zh: '![images/ch08_image02.png](assets/awsl_0802.png)'
- en: Figure 8-2\. Lambda attached to VPC to access RDS database
  id: totrans-343
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 8-2\. 连接到 VPC 以访问 RDS 数据库的 Lambda
- en: You should configure Lambda to use a VPC only if it actually needs it. Adding
    a VPC is not “free”—it impacts other systems, it changes the behavior of how Lambda
    interacts with other services, and it adds complexity to your configuration and
    architecture.
  id: totrans-344
  prefs: []
  type: TYPE_NORMAL
  zh: 只有当 Lambda 实际需要时，才应配置 Lambda 使用 VPC。添加 VPC 不是“免费”的 —— 它会影响其他系统，改变 Lambda 与其他服务交互的行为方式，并给您的配置和架构增加复杂性。
- en: Further, we recommend you configure Lambda to use a VPC only if either (a) you
    understand VPCs and the implications of doing so or (b) you’ve discussed this
    requirement with another team in your organization that understands this.
  id: totrans-345
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，我们建议仅在以下情况下配置 Lambda 使用 VPC：(a) 您理解 VPC 并了解这样做的影响，或者 (b) 您已与组织中了解此要求的其他团队讨论过。
- en: In the rest of this section, we assume that you understand, broadly, VPCs in
    general, but not necessarily any specifics with Lambda and VPCs. As such, there
    are certain VPC terms, like ENIs and security groups, which we’ll mention but
    not explain.
  id: totrans-346
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节的其余部分中，我们假设您对 VPC 有一个广泛的理解，但不一定了解 Lambda 和 VPC 的任何具体信息。因此，有一些 VPC 术语，如 ENIs
    和安全组，我们会提及但不会解释。
- en: Architectural Concerns of Using Lambda with a VPCs
  id: totrans-347
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用 VPC 的 Lambda 的架构上的注意事项
- en: Before you even enable Lambda to use a VPC, there are a few things to be aware
    of that might change your mind!
  id: totrans-348
  prefs: []
  type: TYPE_NORMAL
  zh: 即使在启用 Lambda 使用 VPC 之前，还有一些事项需要注意，这可能会改变您的想法！
- en: First, each *subnet* you specify in your VPC configuration is specific to an
    AZ. One of the nice things about Lambda is that we’ve completely ignored AZs until
    this point. If you’re using Lambda + VPC, you need to make sure you configure
    enough subnets, across enough AZs, to allow you to continue to have the level
    of high availability (HA) you need.
  id: totrans-349
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，在您的 VPC 配置中指定的每个 *子网* 都是特定于一个 AZ 的。Lambda 的一个好处是，到目前为止，我们完全忽略了 AZ。如果您正在使用
    Lambda + VPC，您需要确保配置足够多的子网，涵盖足够多的 AZ，以便您继续拥有所需的高可用性（HA）水平。
- en: Second, when a Lambda function is configured to use a VPC, then *all* network
    traffic from that Lambda will be routed through the VPC. That means if your Lambda
    function is using non-VPC AWS resources (like S3) or is using resources *external*
    to AWS, then you’ll need to consider network routing for those resources, just
    like you would any other service within the VPC. For instance, for S3 you’ll likely
    want to set up a VPC endpoint, and for external services you’ll need to make sure
    your NAT Gateway is correctly configured.
  id: totrans-350
  prefs: []
  type: TYPE_NORMAL
  zh: 其次，当配置 Lambda 函数使用 VPC 时，那么 *所有* 来自该 Lambda 的网络流量都将通过 VPC 路由。这意味着，如果您的 Lambda
    函数正在使用非-VPC AWS 资源（如 S3）或正在使用 *AWS 外部* 的资源，则您需要考虑这些资源的网络路由，就像您对 VPC 内的任何其他服务一样。例如，对于
    S3，您可能需要设置一个 VPC 终端节点，而对于外部服务，则需要确保您的 NAT 网关配置正确。
- en: Configuring Lambda to Use a VPC
  id: totrans-351
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 配置 Lambda 使用 VPC
- en: You’ve read all the warnings, and you’ve figured out which subnets and security
    groups to use. How do you now actually configure your Lambda to use a VPC?
  id: totrans-352
  prefs: []
  type: TYPE_NORMAL
  zh: 您已经阅读了所有警告，并确定了要使用的子网和安全组。现在，您如何实际配置 Lambda 来使用 VPC？
- en: 'Fortunately, SAM comes to the rescue, and makes it fairly simple. By examining
    the [example provided by AWS](https://oreil.ly/388NC) (slightly trimmed), we can
    see the additions that you need to make to each Lambda function:'
  id: totrans-353
  prefs: []
  type: TYPE_NORMAL
  zh: 幸运的是，SAM 来帮忙了，而且使这变得相当简单。通过查看 AWS 提供的 [示例](https://oreil.ly/388NC)（稍作裁剪），我们可以看到您需要对每个
    Lambda 函数进行的更改：
- en: '[PRE10]'
  id: totrans-354
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'In summary, you need to:'
  id: totrans-355
  prefs: []
  type: TYPE_NORMAL
  zh: 总之，您需要：
- en: Add privileges for the Lambda function to attach to the VPC (e.g., by using
    `VPC AccessPolicy`)
  id: totrans-356
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 为Lambda函数添加权限以附加到VPC（例如通过使用`VPC AccessPolicy`）
- en: Add VPC configuration, with a list of security group IDs, and subnet IDs
  id: totrans-357
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 添加VPC配置，包括安全组ID列表和子网ID
- en: And that’s it! This particular example assumes that you’ll use [CloudFormation
    parameters](https://oreil.ly/0xs3v) to pass in the actual security group and subnet
    IDs at deployment time, but you should feel free to hardcode them in your template
    too.
  id: totrans-358
  prefs: []
  type: TYPE_NORMAL
  zh: 就是这样了！这个特定示例假设你将使用[CloudFormation参数](https://oreil.ly/0xs3v)在部署时传递实际的安全组和子网ID，但你也可以随意在模板中硬编码它们。
- en: Alternatives
  id: totrans-359
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 替代方案
- en: Say that all of our dire warnings were enough to put you off of using VPCs with
    Lambda. What should you do instead? Here are a few approaches.
  id: totrans-360
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们所有的严重警告都足以让你不再使用带有Lambda的VPC，那么你应该做什么？以下是几种方法。
- en: The first is to use roughly equivalent services that don’t require a VPC. For
    example, if you were going to use a VPC to access an RDS database, consider using
    DynamoDB instead (although we do acknowledge that DynamoDB is not a relational
    database!). Or think about using Aurora serverless, and its [Data API](https://oreil.ly/uf2KE).
  id: totrans-361
  prefs: []
  type: TYPE_NORMAL
  zh: 第一种方法是使用不需要VPC的大致等效服务。例如，如果你打算使用VPC来访问RDS数据库，考虑改用DynamoDB（尽管我们承认DynamoDB不是关系型数据库！）。或者考虑使用Aurora无服务器和其[Data
    API](https://oreil.ly/uf2KE)。
- en: Next is to re-architect your solution. For example, instead of calling a downstream
    resource directly, would it be possible to use a message bus as an intermediary?
  id: totrans-362
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来是重新架构你的解决方案。例如，是否可以使用消息总线作为中介，而不是直接调用下游资源？
- en: Third—if what you needed to connect to was an internal service, then consider
    giving that internal service a “layer 7” authentication boundary. One way to do
    this is to add an API Gateway to your internal service (or update an existing
    API Gateway if it already has one), and then use API Gateway’s [IAM/Sigv4 authentication
    scheme](https://oreil.ly/RJVSO).
  id: totrans-363
  prefs: []
  type: TYPE_NORMAL
  zh: 第三个——如果你需要连接的是一个内部服务，那么考虑给该内部服务添加一个“第7层”认证边界。一种方法是向内部服务添加一个API Gateway（或者如果它已经有一个，更新现有的API
    Gateway），然后使用API Gateway的[IAM/Sigv4认证方案](https://oreil.ly/RJVSO)。
- en: Finally, if you can’t modify your service, you could do something similar to
    the previous idea, but in this case use [API Gateway as a proxy](https://oreil.ly/OKiid)
    to your downstream service.
  id: totrans-364
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，如果你无法修改你的服务，你可以做类似于前面的想法，但在这种情况下使用[API Gateway作为代理](https://oreil.ly/OKiid)到你的下游服务。
- en: Of course, there is one more option—wait and see what AWS introduces next! For
    example, the Data API for serverless Aurora that we mentioned is fairly new, and
    signals that there may be more functionality coming that will help Lambda developers
    avoid the perils of VPCs!
  id: totrans-365
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，还有一个选择——等待并看看AWS接下来会推出什么！例如，我们提到的无服务器Aurora的数据API是相对较新的，这表明可能会推出更多功能，帮助Lambda开发者避免VPC的危险！
- en: Layers and Runtimes
  id: totrans-366
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 层和运行时
- en: 'If you take a look at one of your Lambda functions in the AWS Web Console,
    you’ll now know what almost everything on there is for. Roles, environment variables,
    memory, VPCs, DLQs, reserved concurrency, and more. However, for the observant
    among you, you’ll see that there’s something towards the top of the page that
    is an omission so far: *layers*. To close out this chapter, we’ll explain what
    layers are, why you (as a Java developer) probably won’t care about them too much,
    and how they relate to another capability known as *custom runtimes*.'
  id: totrans-367
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你在AWS Web控制台中查看Lambda函数之一，现在你几乎知道那里的每一样东西都是用来做什么的了。角色、环境变量、内存、VPCs、DLQs、保留并发等等。然而，对于你们中观察力敏锐的人来说，你会看到页面顶部有一些到目前为止遗漏的内容：*层*。为了结束本章，我们将解释层是什么，为什么你（作为Java开发者）可能不会太在意它们，以及它们与另一种称为*自定义运行时*的能力有什么关系。
- en: What Are Layers?
  id: totrans-368
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 什么是层？
- en: As you know by now, typically when you deploy a new version of a Lambda function,
    you package up the code and all of its dependencies into a ZIP file, and upload
    that file to the Lambda service. As your dependencies get bigger, however, this
    artifact gets bigger, and deployment slows down. Wouldn’t it be nice to be able
    to speed this up?
  id: totrans-369
  prefs: []
  type: TYPE_NORMAL
  zh: 正如你现在所知，通常情况下，当你部署一个Lambda函数的新版本时，你会将代码及其所有依赖项打包成一个ZIP文件，并上传到Lambda服务。然而，随着依赖项的增加，这个构件变得越来越大，部署速度变慢。能不能有一个方法可以加快这个过程呢？
- en: This is where Lambda layers come in. A layer is part of the deployed resources
    of your Lambda function, which is deployed separately from the function itself.
    If your layer stays constant, then when you deploy your Lambda function, you only
    need to deploy the changes to your code that aren’t within the layer.
  id: totrans-370
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是Lambda层的用武之地。层是您Lambda函数的部署资源的一部分，与函数本身分开部署。如果您的层保持不变，那么当您部署Lambda函数时，您只需部署不在层内的代码更改。
- en: Here’s an example. Say that you are implementing the photo processing example
    from way back in [Chapter 1](ch01.html#ch01) ([“File processing”](ch01.html#file-processing-example)),
    and say that the actual part of your Lambda function that performs the image manipulation
    uses a third-party tool like [ImageMagick](https://imagemagick.org/index.php).
  id: totrans-371
  prefs: []
  type: TYPE_NORMAL
  zh: 这里有一个例子。假设您正在实现来自[第一章](ch01.html#ch01)（“文件处理”](ch01.html#file-processing-example)的照片处理示例，假设您Lambda函数实际执行图像处理的部分使用像[ImageMagick](https://imagemagick.org/index.php)这样的第三方工具。
- en: Now, ImageMagick is probably a dependency that changes rarely. With Lambda layers
    you can define a layer (which is just a ZIP artifact containing any content that
    you want) that contains the ImageMagick tool, and then refer to that layer with
    your code in the photo processing Lambda. Now when you update your Lambda function,
    you’ll only need to upload your own code, not your code *and* ImageMagick.
  id: totrans-372
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，ImageMagick可能是一个很少更改的依赖项。使用Lambda层，您可以定义一个层（它只是一个包含任何所需内容的ZIP文件），其中包含ImageMagick工具，然后在照片处理Lambda中引用该层。现在，当您更新Lambda函数时，您只需上传自己的代码，而不是*同时*上传ImageMagick和代码。
- en: Tip
  id: totrans-373
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 提示
- en: ImageMagick is often used by calling an external process from your application,
    rather than via a library API call. It’s perfectly OK to call an external process
    like this from within a Lambda function—the Lambda runtime is a full Linux environment.
  id: totrans-374
  prefs: []
  type: TYPE_NORMAL
  zh: ImageMagick通常通过从应用程序调用外部进程而不是通过库API调用来使用。从Lambda函数内部调用外部进程是完全可以的——Lambda运行时是一个完整的Linux环境。
- en: Another useful aspect to layers is that you can share layers across Lambda functions,
    and other AWS accounts—layers can in fact be shared publicly.
  id: totrans-375
  prefs: []
  type: TYPE_NORMAL
  zh: 层的另一个有用方面是，您可以在Lambda函数之间以及其他AWS账户之间共享层 —— 实际上，层可以公开共享。
- en: When to Use, and Not Use, Layers
  id: totrans-376
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 何时使用层，何时不使用层
- en: When layers were announced, certain parts of the Lambda-using world were very
    excited, since they saw layers as a universal dependency system for Lambda functions.
    This was especially true for people using the Python language, since Python’s
    dependency management tools can be a little tricky for some people (e.g., your
    authors!) to wrap their heads around. The Java ecosystem however, for all its
    faults, has a very strong story to tell around dependency management.
  id: totrans-377
  prefs: []
  type: TYPE_NORMAL
  zh: 当层被宣布时，Lambda使用世界的某些部分非常兴奋，因为他们认为层是Lambda函数的一种通用依赖系统。对于使用Python语言的人来说尤为如此，因为Python的依赖管理工具对某些人（例如，您的作者！）来说可能有点棘手。然而，尽管存在某些缺陷，Java生态系统在依赖管理方面有着非常强大的表现能力。
- en: 'We feel that there are some specific times when layers are useful. However,
    there are also a number of concerns that we have about embracing them wholeheartedly,
    for example:'
  id: totrans-378
  prefs: []
  type: TYPE_NORMAL
  zh: 我们认为有些特定情况下层非常有用。然而，我们对全面采用它们也有一些顾虑，例如：
- en: Since layers are combined with your Lambda function after you’ve uploaded the
    function, it’s not necessarily true that the version of a dependency you’ve used
    at test time (before deployment) is the same as that which is used with the deployed
    version. This, to us, is a (typically) unnecessary headache of coordination that
    needs to be managed.
  id: totrans-379
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 由于层是在上传函数后与Lambda函数结合的，因此在测试时使用的依赖版本与部署版本可能不同。对我们来说，这是一种（通常是）不必要的协调头疼问题，需要加以管理。
- en: Lambda functions are limited to the number of layers that can be used (five),
    and so if you have more than five dependencies, you’re going to need to use a
    local deployment tool anyway, so why add the extra complexity of layers?
  id: totrans-380
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Lambda函数仅限于可以使用的层数（五层），因此如果您有超过五个依赖项，您仍然需要使用本地部署工具，那么为什么要增加层的额外复杂性呢？
- en: Layers don’t particularly provide any functional benefit—they are a deployment
    optimization tool (we’ll talk about cross-cutting behavior as a caveat for this).
  id: totrans-381
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 层并不特别提供任何功能上的好处 —— 它们是一种部署优化工具（我们将讨论跨切面行为作为此的一个警告）。
- en: Particularly for developing Lambda in Java—Java does a pretty good job of defining
    its “own world.” For example, it’s usual to only depend on third-party code in
    Java that itself runs in the JVM, as opposed to calling out to system libraries
    or executables. Given this, and the ubiquity of Maven dependencies, it’s easy
    to have one consolidated dependency management system with a Java application
    that doesn’t include the use of Lambda layers.
  id: totrans-382
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 特别是在开发Java Lambda时，Java非常擅长定义其“独立世界”。例如，在Java中，通常只依赖于在JVM中运行的第三方代码，而不是调用系统库或可执行文件。基于此，以及Maven依赖的普遍性，可以轻松地在不使用Lambda层的Java应用中拥有一个统一的依赖管理系统。
- en: Some people like the fact that a layer can be manually updated for a function
    without having to deploy a new version of the function itself. We personally believe
    strongly that apart from extenuating circumstances, the best way to deploy any
    changes to production is through an automated continuous delivery process, and
    therefore the difference between changing an application library dependency versus
    a configured template layer dependency should almost always be moot.
  id: totrans-383
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 有些人喜欢层可以手动更新函数而无需部署函数本身的事实。我们个人坚信，除非有特殊情况，将任何变更部署到生产环境的最佳方式是通过自动化持续交付过程，因此更改应用程序库依赖与配置模板层依赖的区别几乎总是无关紧要。
- en: We’d be remiss if we didn’t also point out the places that layers can be useful.
  id: totrans-384
  prefs: []
  type: TYPE_NORMAL
  zh: 如果不指出层可以发挥作用的地方，我们会觉得有所遗漏。
- en: First, if part of what a Lambda function executes is unrelated to the application,
    but more related to an organization’s cross-cutting technical platform, then using
    layers as an alternative deployment path can be useful. For example, say that
    there is a security process that needs to be run, but as far as application developers
    are concerned, it’s just a “fire-and-forget” call. In this case, publishing that
    code in a layer, and being able to query all the Lambda function configurations
    across an organization and making sure they’re using the correct version of the
    layer, aids in organizational governance.
  id: totrans-385
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，如果Lambda函数执行的部分与应用程序无关，而更多与组织的横切技术平台相关，则使用层作为替代部署路径可能会有用。例如，假设有一个需要运行的安全流程，但就应用程序开发人员而言，它只是一个“发出并忘记”的调用。在这种情况下，将该代码发布为一个层，并能够查询组织中所有Lambda函数配置，并确保它们使用正确版本的层，有助于组织治理。
- en: Another place where layers are useful is where a dependency is a large, system
    binary that rarely changes. In this case, the extra complexity of using layers
    may be worth the value of improved deployment speed, especially if the number
    of deployments of functions using that layer is on the order of hundreds per day
    or more.
  id: totrans-386
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个层次特别有用的地方是依赖是一个很大且很少更改的系统二进制文件。在这种情况下，使用层的额外复杂性可能值得改进部署速度的价值，特别是如果使用该层的函数的部署次数每天达到数百次或更多。
- en: A helpful example of this second case is where a Lambda function is using a
    custom runtime, which we’ll explore now.
  id: totrans-387
  prefs: []
  type: TYPE_NORMAL
  zh: 这第二种情况的一个有用示例是Lambda函数使用自定义运行时，我们现在将进行探讨。
- en: Custom Runtimes
  id: totrans-388
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 自定义运行时
- en: Throughout this book we have been using the Java Lambda runtime, apart from
    our very first example, which used the Node 10 runtime. AWS offers [a number of
    runtimes](https://oreil.ly/uLMNz) associated with different programming languages,
    and this list is frequently updated.
  id: totrans-389
  prefs: []
  type: TYPE_NORMAL
  zh: 在本书中，除了我们的第一个例子使用了Node 10运行时之外，我们一直在使用Java Lambda运行时。AWS提供了与不同编程语言相关联的[多种运行时](https://oreil.ly/uLMNz)，并且此列表经常更新。
- en: However, what happens if you want to use a language or runtime that AWS don’t
    support? For example, what if you have some Cobol code you want to run in a Lambda
    function? Or, perhaps more likely, what if you want to run a highly customized
    JVM, rather than the one AWS provides?
  id: totrans-390
  prefs: []
  type: TYPE_NORMAL
  zh: 但是，如果您想使用AWS不支持的语言或运行时会发生什么？例如，如果您有一些Cobol代码要在Lambda函数中运行怎么办？或者，更可能的是，如果您想运行一个高度定制的JVM，而不是AWS提供的那一个？
- en: The answer here is to use a *custom runtime*. A custom runtime is a Linux process
    that runs in a Lambda execution environment, and that can process Lambda events.
    There is a [specific execution model](https://oreil.ly/onv6J) that a custom runtime
    needs to fulfill, but the basic idea is that when the runtime instance is started
    by the Lambda platform, it is configured with an instance-specific URL that it
    can query for the next event to process. In other words, custom runtimes use a
    polling architecture.
  id: totrans-391
  prefs: []
  type: TYPE_NORMAL
  zh: 答案在于使用*自定义运行时*。自定义运行时是在 Lambda 执行环境中运行的 Linux 进程，可以处理 Lambda 事件。有一个[特定的执行模型](https://oreil.ly/onv6J)需要自定义运行时满足，但基本思想是当
    Lambda 平台启动运行时实例时，它会配置一个实例特定的 URL，以便查询下一个要处理的事件。换句话说，自定义运行时使用轮询架构。
- en: 'As a Java developer, it will typically be rare that you want or need to use
    a custom runtime for production usages. Two reasons for this are as follows:'
  id: totrans-392
  prefs: []
  type: TYPE_NORMAL
  zh: 作为 Java 开发者，你通常很少需要或需要为生产使用使用自定义运行时。其原因有两点：
- en: The custom runtime code itself needs to be part of your function’s deployed
    assets. While you can package the runtime in a Lambda layer to avoid uploading
    it on every deployment, it will still be using up some of your [250MB total unpacked
    deployment package size limit](https://oreil.ly/02nUm). Most JVMs are going to
    use a considerable part of that, if you want to ship a custom JVM, and so this
    will cut into the space available for your application code.
  id: totrans-393
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 自定义运行时代码本身需要成为函数部署的一部分资产。虽然您可以将运行时打包到 Lambda 层中以避免在每次部署时上传它，但它仍会使用您的[250MB 总解压缩部署包大小限制](https://oreil.ly/02nUm)中的一部分。如果要运行自定义
    JVM，则大多数 JVM 将会占用相当一部分空间，因此这将减少可用于应用代码的空间。
- en: You will need to reimplement in your custom runtime a lot of what AWS has already
    implemented in its standard runtimes, such as deserialization/serialization of
    events and responses, error handling, and more.
  id: totrans-394
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 您需要在自定义运行时中重新实现许多 AWS 标准运行时中已经实现的内容，例如事件和响应的反序列化/序列化、错误处理等。
- en: That being said, for organizations of a certain size, building a custom runtime
    that handles various organizational-platform-related tasks might make actual Lambda
    development even more effective, but we would suggest a through analysis before
    jumping in!
  id: totrans-395
  prefs: []
  type: TYPE_NORMAL
  zh: 话虽如此，对于某些规模的组织来说，构建一个处理各种组织平台相关任务的自定义运行时可能会使 Lambda 开发变得更加高效，但我们建议在投入使用之前进行彻底分析！
- en: Summary
  id: totrans-396
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: In this chapter, we took a deep dive into some advanced aspects of Lambda. Some
    of these behaviors and configurations will be crucial as you deploy your serverless
    applications to production.
  id: totrans-397
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们深入探讨了 Lambda 的一些高级方面。一些行为和配置在您将无服务器应用程序部署到生产环境时将至关重要。
- en: 'You learned about the following:'
  id: totrans-398
  prefs: []
  type: TYPE_NORMAL
  zh: 您了解了以下内容：
- en: The various different error handling strategies of Lambda and how you may choose
    to configure and program your functions to process errors
  id: totrans-399
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Lambda 的各种不同的错误处理策略以及您可能选择配置和编程函数来处理错误的方式
- en: The liberating way that Lambda scales without any effort on your part, how you
    can control that scaling, and what this behavior means in the context of multi-threaded
    programming
  id: totrans-400
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Lambda 如何在您无需任何努力的情况下自动扩展的解放方式，您如何控制这种扩展，并且在多线程编程背景下这种行为意味着什么
- en: What Lambda versions and aliases are, and how to use them with a “traffic shifting”
    approach for releasing new features
  id: totrans-401
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Lambda 版本和别名是什么，以及如何使用它们进行“流量转移”方式发布新功能
- en: What cold starts are, when they occur, whether you should be concerned about
    them, and how to mitigate them if you need to reduce their impact in your applications
  id: totrans-402
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 冷启动是什么时候发生的，是否应该担心它们，以及如何减少它们对应用程序的影响（如果需要的话）
- en: How to consider persistent and cache state in Lambda development
  id: totrans-403
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如何考虑 Lambda 开发中的持久性和缓存状态
- en: How to use Lambda with AWS VPCs
  id: totrans-404
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如何将 Lambda 与 AWS VPCs 配合使用
- en: What Lambda layers and custom runtimes are, and when to think about using them
  id: totrans-405
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Lambda 层和自定义运行时是什么，以及何时考虑使用它们。
- en: In the next chapter, we carry on rounding out our discussion of the more advanced
    aspects of Lambda, but this time in the context of how Lambda interacts with other
    services.
  id: totrans-406
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将继续讨论 Lambda 的更高级方面，但这次是在 Lambda 如何与其他服务交互的背景下。
- en: Exercises
  id: totrans-407
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 练习
- en: 'Update `WeatherQueryLambda` in [“Example: Building a Serverless API”](ch05.html#serverless-api-example)
    to throw an exception. What behavior do you see when you try to call the API?'
  id: totrans-408
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在[“示例：构建无服务器 API”](ch05.html#serverless-api-example)中更新 `WeatherQueryLambda`
    以抛出异常。在尝试调用 API 时会看到什么行为？
- en: If you implemented the exercise from [Chapter 5](ch05.html#ch05) to use an SQS
    queue, then update the Lambda function that reads from SQS to throw an exception.
    Does Lambda’s retry behavior do what you’d expect?
  id: totrans-409
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果你已经按照[第五章](ch05.html#ch05)的练习实现了使用 SQS 队列，那么请更新从 SQS 读取的 Lambda 函数以抛出异常。Lambda
    的重试行为符合你的预期吗？
- en: Investigate what happens with background threads and Lambda—start with the “Hello
    World” example from [Chapter 2](ch02.html#ch02) (see [“Lambda Hello World (the
    Proper Way)”](ch02.html#java-hello-world)) and within the handler use a [`ScheduledExecutorService`](https://oreil.ly/6cz67)
    and its `scheduleAtFixedRate` method to repeatedly log the event that you received.
    What happens? Try using some `Thread.sleep` statements too.
  id: totrans-410
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 研究后台线程和 Lambda 之间的交互——从[第二章](ch02.html#ch02)的“Hello World”示例开始（参见[“Lambda Hello
    World（正确的方式）”](ch02.html#java-hello-world)），在处理程序中使用 [`ScheduledExecutorService`](https://oreil.ly/6cz67)
    及其 `scheduleAtFixedRate` 方法来重复记录接收到的事件。会发生什么？尝试使用一些 `Thread.sleep` 语句。
- en: 'Update [“Example: Building a Serverless API”](ch05.html#serverless-api-example)
    to use traffic shifting, starting with the `Linear10PercentEvery10Minutes` deployment
    preference.'
  id: totrans-411
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 更新[“示例：构建无服务器 API”](ch05.html#serverless-api-example)以使用流量转移，从 `Linear10PercentEvery10Minutes`
    部署偏好开始。
- en: '*Extended task*: If you program on the JVM with a different language—perhaps
    Clojure, Kotlin, or Scala—try building a Lambda function in one of those languages.'
  id: totrans-412
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*扩展任务*：如果你在 JVM 上使用不同的语言编程——比如 Clojure、Kotlin 或 Scala——尝试在其中一种语言中构建一个 Lambda
    函数。'
