- en: Chapter 8\. Advanced AWS Lambda
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第8章。高级 AWS Lambda
- en: As we start getting towards the end of the book, it’s time to learn some of
    the aspects of Lambda that are important as you start to build production-ready
    applications—error handling, scaling, plus a few capabilities of Lambda that we
    don’t use all the time, but are there—and important—when you need them.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 随着我们接近本书的结尾，是时候学习一些 Lambda 的方面了，这些方面对于构建可用于生产的应用程序至关重要——例如错误处理、扩展以及 Lambda 的一些能力，我们并非总是使用，但在需要时很重要。
- en: Error Handling
  id: totrans-2
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 错误处理
- en: All of our examples so far have lived in the wonderful world of rainbows and
    unicorns where no systems fail and no one makes a mistake in writing code. Of
    course, back in the real world, Things Go Wrong, and any useful production application
    and architecture needs to handle the times when errors occur, whether those be
    errors in our code or in the systems we rely on.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们所有的示例都生活在没有系统故障和没有人在编写代码时犯错误的美好世界中。当然，在现实世界中，事情会出错，任何有用的生产应用程序和架构都需要处理错误发生的时间，无论是在我们的代码中还是在我们依赖的系统中。
- en: Since AWS Lambda is a “platform,” it has certain constraints and behavior when
    it comes to errors, and in this section we’ll dig into what kind of errors can
    happen, for which contexts, and how we can handle them. As a language note, we
    use the words *error* and *exception* interchangeably, without the nuance that
    comes between the two terms in the Java world.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 由于 AWS Lambda 是一个“平台”，在处理错误时有一定的限制和行为，本节我们将深入探讨可以发生哪些类型的错误，在哪些情境中发生以及我们如何处理它们。作为语言说明，我们将“错误”和“异常”这两个词互换使用，没有
    Java 世界中两个术语之间的微妙差别。
- en: Classes of Error
  id: totrans-5
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 错误类别
- en: 'When using Lambda, there are several different classes of error that can occur.
    The primary ones are as follows, in order roughly of the time in which they can
    occur through the processing of an event:'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 在使用 Lambda 时，可能会出现几种不同类别的错误。主要错误如下，按照事件处理过程中可能发生的时间顺序大致排列如下：
- en: Error initializing the Lambda function (a problem loading our code, locating
    the handler, or with the function signature)
  id: totrans-7
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 初始化 Lambda 函数时出现的错误（加载我们的代码、定位处理程序或函数签名时的问题）
- en: Error parsing input into specified function parameters
  id: totrans-8
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将输入解析为指定函数参数时出现的错误
- en: Error communicating with an external downstream service (database, etc).
  id: totrans-9
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 与外部下游服务（数据库等）通信时出现的错误。
- en: Error generated within the Lambda function (either within its code or within
    the immediate environment, like an out-of-memory problem)
  id: totrans-10
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在 Lambda 函数内部生成的错误（无论是在其代码中还是在其直接环境中，例如内存不足的问题）
- en: Error caused by function timeout
  id: totrans-11
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 函数超时引起的错误
- en: Another way we can break up errors is into *handled* errors and *unhandled*
    errors.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以将错误分为已处理错误和未处理错误两类另一种方法。
- en: For example, let’s consider the case where we communicate with a downstream
    microservice over HTTP, and it throws an error. In this case, we may choose to
    catch the error within the Lambda function and process it there (a handled error),
    or we may let the error propagate out to the environment (an unhandled error).
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，让我们考虑与下游微服务通过 HTTP 进行通信并且它抛出错误的情况。在这种情况下，我们可以选择在 Lambda 函数内部捕获错误并在那里处理（已处理错误），或者让错误传播到环境中（未处理错误）。
- en: Alternatively, say we specified an incorrect method name in our Lambda configuration.
    In this case, we are unable to catch the error in the Lambda function code, so
    this is always an unhandled error.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 或者，假设我们在 Lambda 配置中指定了一个不正确的方法名。在这种情况下，我们无法在 Lambda 函数代码中捕获错误，因此这始终是一个未处理错误。
- en: If we handle an error ourselves, within code, then Lambda really has nothing
    to do with our particular error handling strategy. We can log to standard error
    if like, but as we saw in [Chapter 7](ch07.html#ch07), standard error is treated
    identically to standard output as far as Lambda as concerned, and no alarms are
    raised if content is sent to it.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们在代码中自行处理错误，那么 Lambda 实际上与我们的特定错误处理策略无关。我们可以选择像日志记录到标准错误一样，但正如我们在[第7章](ch07.html#ch07)中所看到的，Lambda
    将标准错误与标准输出视为相同，如果内容发送到其中，不会引发任何警报。
- en: Therefore, the nuances that come with handling errors in Lambda are all about
    unhandled errors—those that bubble out of our code to the Lambda runtime via an
    uncaught exception or that happen externally to our code. What happens to these
    errors? Interestingly, this depends significantly on the type of event source
    that triggers our Lambda function in the first place, as we will now examine.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，在 Lambda 处理错误时，所有的微妙之处都在于未处理的错误——即通过未捕获的异常将错误传递给 Lambda 运行时或外部发生的错误。这些错误会发生什么？有趣的是，这显著取决于触发
    Lambda 函数的事件源类型，现在我们将详细探讨这一点。
- en: The Various Behaviors of Lambda Error Processing
  id: totrans-17
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Lambda 错误处理的各种行为
- en: 'Lambda divides what it does with errors according to the event source that
    triggers invocation. Every event source is placed into one of the event source
    types we listed in [Chapter 5](ch05.html#ch05) ([Table 5-1](ch05.html#lambda-event-source-types)):'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: Lambda 根据触发调用的事件源来处理错误。我们在第 5 章中列出了每一种事件源类型（[表 5-1](ch05.html#lambda-event-source-types)）：
- en: Synchronous event sources (e.g., API Gateway)
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 同步事件源（例如，API 网关）
- en: Asynchronous event sources (e.g., S3 and SNS)
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 异步事件源（例如，S3 和 SNS）
- en: Stream/queue event sources (e.g., Kinesis Data Streams and SQS)
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 流/队列事件源（例如，Kinesis 数据流和 SQS）
- en: Each of these categories has a different model for processing errors thrown
    by a Lambda function, as follows.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 这些类别中的每一个都有一个不同的模型来处理 Lambda 函数抛出的错误，如下所示。
- en: Synchronous event sources
  id: totrans-23
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 同步事件源
- en: This is the simplest model. For Lambda functions invoked in this way, the error
    is propagated back up to the caller, and no automatic retry is performed. How
    the error is exposed to the upstream client depends on the precise nature of how
    the Lambda function was called, so you should try forcing errors within your code
    to see how such problems are exposed.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 这是最简单的模型。对于以这种方式调用的 Lambda 函数，错误将向上传播到调用者，并且不会执行自动重试。错误如何暴露给上游客户端取决于调用 Lambda
    函数的具体方式，因此您应该在代码中尝试强制错误，以查看此类问题如何暴露。
- en: For example, if API Gateway is the event source, then errors thrown by a Lambda
    function will result in an error being sent back to API Gateway. API Gateway in
    turn returns a 500 HTTP response to the original requestor.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，如果 API 网关是事件源，那么 Lambda 函数抛出的错误将导致错误被发送回 API 网关。API 网关随后向原始请求者返回一个 500 的
    HTTP 响应。
- en: Asynchronous event sources
  id: totrans-26
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 异步事件源
- en: Since this model of invocation is asynchronous, or event oriented, there is
    no upstream caller that can do anything useful with an error, so Lambda has a
    more sophisticated error handling model.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 由于此调用模型是异步的或事件导向的，没有上游调用者可以对错误执行任何有用的操作，因此 Lambda 具有更复杂的错误处理模型。
- en: First, if an error is detected in this model of invocation, then Lambda will
    (by default) retry processing the event up to twice further (for a total of three
    attempts), with a delay between such retries (the precise delay is not documented,
    but we’ll see an example a little later).
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，如果在这种调用模型中检测到错误，则 Lambda 将（默认情况下）重试处理事件多达两次（总共三次尝试），并在重试之间设置延迟（具体延迟未记录，但稍后我们将看到一个示例）。
- en: If the Lambda function fails for all retry attempts, then the event will be
    posted to the function’s error destination and/or dead letter queue if either
    is configured (more on this later); otherwise, the event is discarded and lost.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 如果 Lambda 函数在所有重试尝试失败时，事件将被发布到函数的错误目标和/或死信队列（如果已配置）；否则，事件将被丢弃和丢失。
- en: Stream/queue event sources
  id: totrans-30
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 流/队列事件源
- en: In the absence of a configured error-handling strategy (see [“Handling Kinesis
    and DynamoDB Stream Errors”](#failure-handling-features)), if an error bubbles
    up to the Lambda runtime when processing an event from a stream/queue event source,
    then Lambda will keep retrying the event until either (a) the failing event expires
    in the upstream source or (b) the problem is resolved. This means that the processing
    of the stream or queue is effectively blocked until the error is resolved. Note
    that there are particular nuances here when using streams that are scaled to multiple
    shards, which we recommend you research if this applies to you.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 在没有配置错误处理策略的情况下（参见[“处理 Kinesis 和 DynamoDB 流错误”](#failure-handling-features)），如果在处理来自流/队列事件源的事件时，错误向上冒泡到
    Lambda 运行时，则 Lambda 将持续重试该事件，直到（a）上游源中的失败事件过期或（b）问题解决。这意味着流或队列的处理实际上被阻塞，直到错误解决。请注意，在使用扩展到多个分片的流时，存在特定的细微差别，如果适用，请建议进行研究。
- en: 'The following documentation pages are useful when you are considering error
    handling with Lambda:'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 在考虑Lambda错误处理时，以下文档页面非常有用：
- en: '[Error Handling and Automatic Retries in AWS Lambda](https://oreil.ly/4wxMf)'
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[AWS Lambda中的错误处理和自动重试](https://oreil.ly/4wxMf)'
- en: '[AWS Lambda Function Errors in Java](https://oreil.ly/ag0cu)'
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[AWS Lambda中的Java函数错误](https://oreil.ly/ag0cu)'
- en: Deep Dive into Asynchronous Event Source Errors
  id: totrans-35
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 深入了解异步事件源错误
- en: Asynchronous event sources are a popular use of Lambda and have a complicated
    error processing model, so let’s look at this topic a little deeper by way of
    an example.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 异步事件源是Lambda的一种常见使用方式，并且具有复杂的错误处理模型，因此让我们通过一个例子更深入地了解这个主题。
- en: Retries
  id: totrans-37
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 重试
- en: 'We start with the following code:'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 我们从以下代码开始：
- en: '[PRE0]'
  id: totrans-39
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: We wire this up to an S3 bucket in the same way that we did for the `BatchEvents
    Lambda` function in [Chapter 5](ch05.html#ch05), and we’ll see the SAM template
    for that a little later.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 我们以与第5章中“BatchEvents Lambda”函数相同的方式将其与S3存储桶连接，稍后我们将看到该SAM模板。
- en: If we upload a file to the S3 bucket attached to this function, we see [Figure 8-1](#s3-error-logs)
    in our logs.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们将文件上传到与此函数关联的S3存储桶中，我们在日志中看到[图8-1](#s3-error-logs)。
- en: Notice that Lambda tries to process the S3 event three times—once at 20:44:00,
    then about a minute later, and then about two minutes after that. These are the
    three total attempts to process an event that Lambda promises for an asynchronous
    event source.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，Lambda尝试处理S3事件共三次——首次在20:44:00，然后约一分钟后，再约两分钟后。这是Lambda为异步事件源承诺的三次事件处理尝试。
- en: 'We are able configure the number of retries that Lambda will perform—0, 1,
    or 2—using a separate CloudFormation resource. For example, let’s configure Lambda
    not to attempt any retries for the `SingleEventLambda` function from [“Example:
    Building a Serverless Data Pipeline”](ch05.html#serverless-data-pipeline-example).
    We can add the following resource to the application template:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 我们能够使用单独的CloudFormation资源配置Lambda将执行的重试次数——0、1或2次。例如，让我们配置Lambda不对“SingleEventLambda”函数进行任何重试，该函数来自于[“示例：构建无服务器数据管道”](ch05.html#serverless-data-pipeline-example)。我们可以向应用程序模板添加以下资源：
- en: '[PRE1]'
  id: totrans-44
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: '![images/ch08_image01.png](assets/awsl_0801.png)'
  id: totrans-45
  prefs: []
  type: TYPE_IMG
  zh: '![images/ch08_image01.png](assets/awsl_0801.png)'
- en: Figure 8-1\. Lambda logs during S3 error
  id: totrans-46
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图8-1\. S3错误期间的Lambda日志
- en: If we don’t make any further changes, Lambda won’t do anything more after all
    the retries (if any) are complete—brief data about the original event will be
    logged, but eventually it will be discarded. For something like S3 this isn’t
    too bad—we can always list all of the objects in S3 later. But for other event
    sources, this might be a problem if we can’t go and regenerate the events once
    the cause of the error is fixed. There are two solutions to this problem—DLQs
    and destinations. DLQs have been around longer, so we’ll describe them first,
    but destinations have more capabilities.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们不做进一步的更改，Lambda在所有重试（如果有）完成后将不会再执行任何操作——将会记录关于原始事件的简要数据，但最终将被丢弃。对于像S3这样的情况，这并不太糟糕——我们随时可以稍后列出S3中的所有对象。但对于其他事件源来说，如果在修复错误原因后无法重新生成事件，则可能会成为问题。这个问题有两种解决方案——DLQ和目标。DLQ已存在较长时间，因此我们将首先描述它们，但目标具有更多功能。
- en: Dead letter queues
  id: totrans-48
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 死信队列
- en: Lambda provides the capability of automatically forwarding events (for asynchronous
    sources) that fail all of their retries to a dead letter queue (DLQ). This DLQ
    can be either an SNS topic or an SQS queue. Once the event is in SNS or SQS, you
    can do whatever you want with it either immediately, or manually later, in the
    case of SQS. For example, you may register a separate Lambda function as an SNS
    topic listener that posts a copy of the failing event to an operations Slack channel
    for manual processing.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: Lambda提供了自动转发事件的功能（对于失败所有重试的异步源）到死信队列（DLQ）。此DLQ可以是SNS主题或SQS队列。一旦事件进入SNS或SQS，您可以立即处理，或稍后手动处理（对于SQS而言）。例如，您可以注册一个单独的Lambda函数作为SNS主题的监听器，将失败的事件副本发布到操作Slack频道进行手动处理。
- en: DLQs can be configured along with all the other properties of a Lambda function.
    For example, we can add a DLQ to our example app, and also add a DLQ processing
    function, with the SAM template.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: DLQ可以与Lambda函数的所有其他属性一起配置。例如，我们可以向我们的示例应用程序添加一个DLQ，并且还可以添加一个DLQ处理函数，使用SAM模板。
- en: Example 8-1\. SAM template with DLQ and DLQ listener
  id: totrans-51
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 8-1\. 带有DLQ和DLQ监听器的SAM模板
- en: '[PRE2]'
  id: totrans-52
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'The important elements to observe here are as follows:'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 这里需要注意的重要元素如下：
- en: We define our own SNS topic to act as a DLQ.
  id: totrans-54
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们定义自己的SNS主题以充当DLQ。
- en: Within the application function (`S3ErroringLambda`), we tell Lambda that we
    want a DLQ for the function, that it’s of type SNS, and that DLQ messages should
    be sent to the topic we created in this template.
  id: totrans-55
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We also define a separate function (`DLQProcessingLambda`) that is triggered
    by events sent to the DLQ.
  id: totrans-56
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Our code for `DLQProcessingLambda` is as follows:'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  id: totrans-58
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Now if we upload a file to S3, we see the following in the logs for `DLQProcessing
    Lambda` after the final delivery attempt to `S3ErroringLambda`:'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  id: totrans-60
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: The event sent to the DLQ processing function includes the full original event
    that failed, allowing you to save this off and process later. It also includes
    the `RequestID` of the original event, which allows you to search within the application
    Lambda function’s log for clues as to what went wrong.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
- en: While in this example we included all of the DLQ resources within the same template
    as the application itself, you may choose to use resources outside of the application
    and therefore share those DLQ elements across applications.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
- en: Destinations
  id: totrans-63
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'At the end of 2019 AWS introduced an alternative to DLQs for capturing failed
    events: [*destinations*](https://oreil.ly/XT6Ds). Destinations are actually a
    more powerful feature than DLQ since you can capture both errors *and* successfully
    processed asynchronous events.'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
- en: Further, destinations support more types of target than DLQs. SNS and SQS are
    supported, just as they are with DLQs, but you can also route directly to another
    Lambda function (skipping the message bus part) or EventBridge.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
- en: 'To configure a Destination, we use the same type of `AWS::Lambda::EventInvokeConfig`
    resource we created earlier when configuring retry counts (see [“Retries”](#asynchronous-retries)).
    For example, let’s replace the DLQ in the previous example with a Destination:'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  id: totrans-67
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'There are a few aspects to notice from this example:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
- en: There are no explicit queues or topics.
  id: totrans-69
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The Destination at the end defines that when `S3ErroringLambda` fails, we want
    events to be sent to `ErrorProcessingLambda`.
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The application function needs to be given permission to invoke the error handling
    function, which we enable via the `Policies` property on the `S3Erroring Lambda`
    resource.
  id: totrans-71
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The event that is sent to `ErrorProcessingLambda` is *not* the same type as
    that sent to a DLQ. At time of writing, the `aws-lambda-java-events` library has
    not been updated to include the Destination types, and deserializing these types
    is tricky due to some unfortunate naming of fields within the sent objects. Ideally
    by the time you read this book, this will have been fixed!
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
- en: Destinations will likely replace most usages of DLQ, and we’re also interested
    to see how people use the `OnSuccess` version of destinations to build interesting
    solutions.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
- en: Handling Kinesis and DynamoDB Stream Errors
  id: totrans-74
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In late 2019, AWS added a number of [failure-handling features](https://oreil.ly/gWKX-)
    to the Kinesis and DynamoDB stream event sources. These new features make it possible
    to avoid “poison pill” scenarios, where a single bad record could block stream
    (or shard) processing for up to a week (depending on how long the stream retains
    records).
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
- en: 'The failure-handling features can be configured via SAM (or CloudFormation),
    and are applied when a Lambda function fails to process a batch of records from
    either a Kinesis or DynamoDB stream. The new features are as follows:'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
- en: Bisect on Function Error
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
- en: Instead of simply retrying the entire batch of records for a failed Lambda invocation,
    this feature splits the batch into two. These smaller batches are retried separately.
    This approach can automatically narrow failures down to whichever individual records
    are causing a problem, and those records can be dealt with via the other error-handling
    features.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
- en: Maximum Record Age
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
- en: This instructs the Lambda function to skip records older than a specified Maximum
    Record Age (which can be from 60 seconds to 7 days).
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
- en: Maximum Retry Attempts
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
- en: This feature retries failed batches for a configurable number of times and then
    sends information about the batch of records to the configured *on-failure destination*
    (the next feature in this list).
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
- en: Destination on Failure
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
- en: This is an SNS topic or SQS queue that will receive information about failed
    batches. Note that it doesn’t receive the actual failed records—those have to
    be extracted from the stream before they expire.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
- en: A comprehensive error-handling approach can (and should) combine all of these
    features. For example, a failed batch of records can be split (perhaps several
    times) until there is a single-record batch causing a failure. That single-record
    batch might be retried 10 times or until the record is 15 minutes old, at which
    point the details of the batch (with its single failed record) will be sent to
    an SNS topic. A separate Lambda could be subscribed to that SNS topic, automatically
    retrieve the failed record from the stream, and store it in S3 for later investigation.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
- en: Tracing Errors with X-Ray
  id: totrans-86
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: If you are using AWS X-Ray (discussed in [“Distributed Tracing”](ch07.html#distributed-tracing)),
    then it will be able to show where errors are occurring in your graph of components.
    For more details, see [“Finding Errors”](ch07.html#finding-errors), and the X-Ray
    documentation.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
- en: Error Handling Strategies
  id: totrans-88
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: So given everything we now know about errors, and Lambda’s capabilities and
    behaviors regarding them, how should we choose to deal with errors?
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
- en: For unhandled errors, we should set up monitoring (see [“Alarms”](ch07.html#cloudwatch-alarms)),
    and when errors occur, we will likely need some kind of manual intervention. The
    urgency of this will depend on the context, and also the type of the event source—remember
    in the case of stream/queue event sources that processing is blocked until the
    error is cleared.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
- en: For handled errors, though, we have an interesting choice. Should we process
    the error and rethrow, or should we capture the error and exit the function cleanly?
    Again, this will depend on the context and invocation type, but here are some
    thoughts.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
- en: For synchronous event sources, you will likely want to return some kind of error
    to the original caller. Typically you’ll want to do that explicitly within the
    Lambda code and return a well-formatted error. A problem here, though, is that
    Lambda won’t know if this is an error, so you’ll need to track this metric manually.
    The problem with letting unhandled errors bubble out from synchronously called
    Lambdas is that you have no control over the error returned to the upstream client.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
- en: For asynchronous event sources, what you do will largely depend on whether you
    want to use a DLQ or Destination. If you do, then there’s often no harm in either
    letting an error bubble out or throwing a custom error and then handling the error
    in whatever is processing messages from the DLQ/Destination. If you don’t use
    a DLQ/Destination then you may want to at least log the failing input event if
    the error occurs within your code.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
- en: For Kinesis and DynamoDB stream event sources, using one of the failure-handling
    features described earlier allows processing to continue even if some records
    cause errors. With a properly configured *Destination on Failure*, this is an
    effective error-handling strategy, although it assumes that it is safe for your
    application to potentially process records out of order. If that isn’t the case,
    then consider omitting the failure-handling features and relying on the platform’s
    automatic retry behavior (which in this case would block processing until the
    error is resolved or the records expire).
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
- en: For SQS you’ll typically want to handle errors within your code, since otherwise
    further processing is blocked. An effective way to do this is to put a top-level
    `try-catch` block in your handler function. Within this block, you can set up
    your own retry strategy or log the failing event and exit the function cleanly.
    In certain situations, you really will want to block further event processing
    until the problem causing the error is resolved, in which case you can throw a
    new error from the top-level try-catch block and use the platform’s automatic
    retry behavior.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
- en: Scaling
  id: totrans-96
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In [Chapter 5](ch05.html#ch05) we touched on one of the most valuable aspects
    of Lambda—its ability to auto-scale without any effort (see [Figure 5-10](ch05.html#data-pipeline-fanout)).
    In the data pipeline example we used this auto-scaling ability to implement a
    “fan-out” pattern—processing many small events in parallel.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
- en: This is the key to Lambda’s scaling model—if all current instances of a function
    are currently in use when a new event occurs, then Lambda will automatically create
    a new instance, *scaling out* the function, to handle the new event.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
- en: Eventually, after a period of inactivity, function instances will be *reaped*,
    *scaling in* the function.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 最终，在一段不活动时间之后，函数实例将被*收回*，*扩缩容*函数。
- en: From a cost perspective, Lambda guarantees that we are only charged while our
    function is processing an event, so it costs the same to process one hundred Lambda
    events serially in one function instance as it does to process them in parallel
    in one hundred instances (subject to any extra time costs involved in cold start,
    which we describe later in this chapter).
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 从成本的角度来看，Lambda 保证我们仅在处理事件时收费，因此以串行方式处理一百个 Lambda 事件在一个函数实例中与在一百个实例中并行处理它们的成本相同（在冷启动中可能存在额外的时间成本，我们稍后在本章中描述）。
- en: Lambda scaling has limits, of course, which we’ll examine in a moment, but first
    let’s take a look at Lambda’s magical auto-scaling.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，Lambda 的扩展是有限制的，我们稍后会详细讨论，但首先让我们来看一下 Lambda 的神奇自动扩展。
- en: Observing Lambda Scaling
  id: totrans-102
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 观察 Lambda 的扩展
- en: 'Let’s start with the following code:'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们从以下代码开始：
- en: '[PRE6]'
  id: totrans-104
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Static and instance members of a function handler’s class are instantiated once
    per instance of a function. We discuss this further later, in the section about
    cold starts. Therefore, if we invoke the previous code five times in succession,
    it will always return the same value for the `instanceID` member.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 函数处理程序类的静态和实例成员会每个函数实例实例化一次。我们稍后在冷启动部分进一步讨论这一点。因此，如果我们连续五次调用前面的代码，它将始终为 `instanceID`
    成员返回相同的值。
- en: 'Now let’s change the code a little, adding a `sleep` statement:'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们稍微修改一下代码，加入一个 `sleep` 语句：
- en: '[PRE7]'
  id: totrans-107
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Make sure if you’re deploying this code to include a `Timeout` configuration
    of at least six seconds; otherwise, you’ll see a good example of a timeout error!
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 确保如果您部署此代码，请包括至少六秒的 `Timeout` 配置；否则，您将看到超时错误的一个很好的例子！
- en: Now invoke the function several times in parallel. One way to do this is by
    running the same `aws lambda invoke` command from multiple terminal tabs. Depending
    on how quick on the draw you are for navigating terminal sessions, you’ll now
    see that different container IDs are returned for different invocations.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 现在并行多次调用该函数。一种方法是在多个终端标签页中运行相同的 `aws lambda invoke` 命令。根据您在导航终端会话时的快速程度，您将看到不同的容器
    ID 用于不同的调用。
- en: This behavior is visible because when Lambda receives the second request to
    invoke your function, the previous container that was used for the first request
    is still processing that request, so Lambda creates a new instance, automatically
    scaling out, to handle the second request. This creation of a new instance happens
    for the third and fourth requests too, if you’re fast enough.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 之所以能够观察到这种行为，是因为当 Lambda 收到第二个请求来调用您的函数时，之前用于第一个请求的容器仍在处理该请求，因此 Lambda 会创建一个新实例来处理第二个请求，自动扩展容量。如果您的速度足够快，这种新实例的创建也会发生在第三和第四个请求上。
- en: This is an example of invoking the Lambda function directly, but this is the
    same scaling behavior we see when Lambda is invoked by most event sources, including
    API Gateway, S3, or SNS, whenever one instance of a Lambda function is not sufficient
    to keep up with the event load. Magical auto-scaling, without any effort!
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 这是直接调用 Lambda 函数的一个示例，但当 Lambda 被大多数事件源（包括 API Gateway、S3 或 SNS）调用时，我们看到相同的扩展行为，即当一个
    Lambda 函数实例不足以跟上事件负载时，神奇的自动扩展，毫不费力！
- en: Scaling Limits and Throttling
  id: totrans-112
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 缩放限制和限速
- en: AWS is not an infinite computer, and there are limits to Lambda’s scaling. Amazon
    limits the number of concurrent executions across all functions per AWS account,
    per region. By default, at the time of writing, this limit is one thousand, but
    you can make a support request to have this increased. Partly this limit exists
    because of the physical constraints of living in a material universe and partly
    so that your AWS bill doesn’t explode to astronomical proportions!
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: AWS 并不是一个无限的计算机，Lambda 的扩展是有限制的。亚马逊限制每个 AWS 帐户、每个区域的所有函数的并发执行次数。在撰写本文时，默认情况下，此限制为一千次，但您可以提出支持请求以增加此限制。部分原因是因为生活在物质宇宙的物理限制，部分原因是为了避免您的
    AWS 账单激增到天文数字！
- en: If you reach this limit, you’ll start to experience *throttling*, and you’ll
    know this because the account-wide `Throttles` CloudWatch metric for your Lambda
    functions will suddenly have an amount greater than zero. This makes it a great
    metric to set a Cloudwatch alarm for (we talked about built-in metrics and alarms
    in [“Metrics”](ch07.html#metrics)).
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
- en: 'When your function is throttled, the behavior exhibited by AWS is similar to
    the behavior that occurs when your function throws an error (which we talked about
    earlier in this chapter—[“The Various Behaviors of Lambda Error Processing”](#lambda-error-behaviors))—in
    other words, it depends on the type of event source. In summary:'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
- en: For synchronous event sources (e.g., API Gateway), throttling is treated as
    an error and passed back up to the caller as an HTTP status code 500 error.
  id: totrans-116
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: For asynchronous event sources (e.g., S3), Lambda will retry calling your Lambda
    function for up to six hours, by default. This is configurable, for example, by
    using the `MaximumEventAgeInSeconds` property of the [`AWS::Lambda::EventInvokeConfig`
    CloudFormation resource](https://oreil.ly/by8cO) that we introduced in [“Retries”](#asynchronous-retries).
  id: totrans-117
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: For stream/queue event sources (e.g., Kinesis), Lambda will block and retry
    until successful or the data expires.
  id: totrans-118
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Stream-based sources may also have other scaling restrictions, for example,
    based on the number of shards of your stream and the configured [`ParallelizationFactor`](https://oreil.ly/4RSoj).
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
- en: Since the Lambda concurrency limit is account-wide, one particularly important
    aspect to be aware of is that one Lambda function that has scaled particularly
    wide can impact every other Lambda function in the same AWS account + region pair.
    Because of this, it is strongly recommended that, at the very least, you use separate
    AWS accounts for production and testing—deliberately DoS’ing (denial-of-servicing)
    your production application because of a load test against a staging environment
    is a particularly embarrassing situation to explain!
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
- en: But beyond the production versus test account separation, we also recommend
    using different AWS “subaccounts” within one AWS “organization” for different
    “services” within your ecosystem to further isolate yourself from the problems
    of account-wide limits.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
- en: Burst limits
  id: totrans-122
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The limits and throttling mentioned refer to the total capacity available to
    your Lambda functions. However, there’s another limit to be occasionally aware
    of—the *burst limit*. This refers to *how quickly* (as opposed to *how wide*)
    your Lambda function can scale. By default Lambda can scale out a function by
    up to 500 instances every minute, with perhaps a small boost at the beginning.
    If your workload can burst faster than this (and we’ve seen some that can), then
    you’ll need to be aware of burst limits and may want to consider asking AWS to
    increase your burst limit.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
- en: Reserved concurrency
  id: totrans-124
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: We just mentioned earlier that one Lambda function that has scaled particularly
    wide can impact the rest of the account by using all of the available concurrency.
    Lambda has a tool to help with this—the optional *reserved concurrency* configuration
    that can be applied to a function’s configuration.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 我们刚才提到过一个 Lambda 函数，它的扩展特别广，可能会通过使用所有可用的并发量来影响账户中的其他函数。Lambda 有一个工具可以帮助解决这个问题——可选的
    *保留并发量* 配置，可以应用于函数的配置中。
- en: 'Setting a reserved concurrency value does two things:'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 设置一个保留的并发值会做两件事：
- en: It guarantees that the particular function will always have up to that available
    amount of concurrency, no matter what any other functions are doing in the account.
  id: totrans-127
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它保证该特定函数将始终具有该可用并发量，而不管账户中的其他函数在做什么。
- en: It limits that function to scale *no wider* than that amount of concurrency.
  id: totrans-128
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它将该函数限制在*不超过*该并发量的范围内。
- en: 'This second feature has some useful benefits that we discuss in [“Solution:
    Manage scaling with reserved concurrency”](ch09.html#manage-scaling-with-reserved-concurrency).'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 这个第二个特性有一些有用的好处，我们在 [“解决方案：使用保留的并发管理扩展”](ch09.html#manage-scaling-with-reserved-concurrency)
    中讨论过。
- en: If you are using SAM to define your application’s infrastructure, you can use
    the `ReservedConcurrentExecutions` property of the `AWS::Serverless::Function`
    resource type to declare a reserved concurrency setting.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你正在使用 SAM 来定义应用程序的基础设施，你可以使用 `AWS::Serverless::Function` 资源类型的 `ReservedConcurrentExecutions`
    属性来声明一个保留的并发设置。
- en: Thread Safety
  id: totrans-131
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 线程安全
- en: Because of Lambda’s scaling model, we are guaranteed that at most one event
    will be processed per function instance at any one time. In other words, you never
    need to be concerned about multiple events being processed at the same time within
    a function’s runtime, let alone within a function object instance. Therefore,
    unless you create any of your own threads, Lambda programming is entirely thread
    safe.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 由于 Lambda 的扩展模型，我们可以保证每个函数实例在任何时候最多只处理一个事件。换句话说，在函数的运行时，你永远不需要担心多个事件同时被处理，更不用说在函数对象实例内部了。因此，除非你自己创建了任何线程，Lambda
    编程是完全线程安全的。
- en: Vertical Scaling
  id: totrans-133
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 垂直扩展
- en: Almost all of Lambda’s scaling capability is “horizontal”—that is, its ability
    to scale wider to handle multiple events in parallel. This is in contrast to “vertical”
    scaling—the ability to handle more load by increasing the computational capability
    of an individual node.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: Lambda 几乎所有的扩展能力都是“水平”的——即，它能够扩展以处理多个事件并行处理。这与“垂直”扩展相对应——即通过增加单个节点的计算能力来处理更多的负载。
- en: Lambda also has a rudimentary vertical scaling option, however, in its memory
    configuration. We discussed this in [“Memory and CPU”](ch03.html#memory-and-cpu).
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: Lambda 还有一个基本的垂直扩展选项，但是它是通过内存配置来实现的。我们在 [“内存和 CPU”](ch03.html#memory-and-cpu)
    中讨论过这个问题。
- en: Versions and Aliases, Traffic Shifting
  id: totrans-136
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 版本和别名，流量转移
- en: In your experiments with Lambda so far, you may have occasionally seen the string
    "`$LATEST`" appear. This is a reference to a Lambda function’s *version*. There’s
    more to versions than just `$LATEST` though, so let’s take a look.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 在你迄今为止对 Lambda 进行的实验中，你可能偶尔会看到字符串“`$LATEST`”出现。这是对 Lambda 函数的 *版本* 的引用。不过，版本远不止于
    `$LATEST`，所以让我们来看看吧。
- en: Lambda Versions
  id: totrans-138
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Lambda 版本
- en: Whenever we’ve deployed a new configuration, or new code, for our Lambda functions,
    we’ve always overridden what came before. The old function was dead, long live
    the new function.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 每当我们部署了新的配置或新代码到我们的 Lambda 函数中，我们总是覆盖之前的内容。旧的函数已经过时，新函数永存。
- en: However, Lambda supports keeping those old functions around if you want it to,
    by way of a capability named Lambda Function Versioning.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，Lambda 支持保留这些旧函数，如果你愿意的话，这是通过 Lambda 函数版本控制这个功能来实现的。
- en: Without using versioning explicitly, Lambda has exactly one version of your
    function at any one time. Its name is `$LATEST`, which you can reference explicitly;
    alternatively, if you don’t specify a version (or alias, which we’ll see in a
    moment), you are also referring implicitly to `$LATEST`.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 如果不显式使用版本控制，Lambda 在任何时候都只有一个版本的函数。它的名称是“`$LATEST`”，你可以明确引用它；或者，如果你不指定版本（或别名，我们马上就会看到的），你也隐含地引用了“`$LATEST`”。
- en: When you create or update a function, however, you are able at the time, or
    some time later, to snapshot that function to a version. The identifier of the
    version is a linear counter, starting at 1. You can’t edit a version, which means
    that it only ever makes sense to create a versioned snapshot from the current
    `$LATEST` version.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 当你创建或更新一个函数时，可以在当时或之后某个时间点对该函数进行版本快照。版本的标识符是一个线性计数器，从1开始。你无法编辑一个版本，这意味着只有从当前的`$LATEST`版本创建版本化快照才有意义。
- en: You invoke a version of a function when calling it explicitly by adding a `:VERSION-IDENTIFIER`
    to its ARN, or if using the AWS CLI, you can add a `--qualifier` *`VERSION-IDENTIFIER`*
    parameter to the `aws lambda invoke` command.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 调用函数的一个版本时，可以通过将`：VERSION-IDENTIFIER`添加到其ARN中显式调用它，或者如果使用AWS CLI，则可以在`aws lambda
    invoke`命令的`--qualifier` *`VERSION-IDENTIFIER`*参数中添加它。
- en: You can create a version using various AWS CLI commands or the web console.
    You can’t create a version explicitly using SAM, but you can do so implicitly
    when you use *aliases*, which we’ll explain next.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 可以使用各种AWS CLI命令或Web控制台创建版本。不能直接使用SAM显式创建版本，但在使用*别名*时可以隐式创建版本，我们接下来会解释这一点。
- en: Lambda Aliases
  id: totrans-145
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Lambda别名
- en: While you are able to explicitly reference a numbered version of a Lambda function,
    when using versions, it’s more typical to use an *alias*. An alias is a named
    pointer to a Lambda version—either `$LATEST`, or a numeric, snapshotted version.
    An alias can be updated at any time to point to a different version. For example,
    you may start off pointing to `$LATEST`, but then point to a specific version
    when you want to add stability to the alias.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管可以显式引用Lambda函数的编号版本，但在使用版本时，更典型的是使用*别名*。别名是指向Lambda版本的命名指针——可以是`$LATEST`，也可以是一个数字化的快照版本。可以随时更新别名以指向不同的版本。例如，您可以从`$LATEST`开始，但随后指向特定版本以增加别名的稳定性。
- en: You invoke an alias of a function in precisely the same way as you do with a
    function version—by specifying it in an ARN or in the `--qualifier` argument of
    the CLI. An event source can be configured to point to a specific alias, and if
    the underlying alias is updated to point to a new version, then events from the
    source will flow to that new version.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 您以与函数版本完全相同的方式调用函数的别名——通过在ARN中指定它或在CLI的`--qualifier`参数中指定它。可以配置事件源以指向特定的别名，并且如果基础别名更新以指向新版本，则来自源的事件将流向该新版本。
- en: When you deploy a Lambda function with SAM, you can define an alias that is
    automatically updated to point to the latest, published version. You do this by
    adding the `AutoPublishAlias` property, and giving an alias name as a value.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 在使用SAM部署Lambda函数时，可以定义一个别名，该别名会自动更新以指向最新发布的版本。您可以通过添加`AutoPublishAlias`属性并提供别名名称作为值来实现这一点。
- en: However, there’s a much more powerful way of using aliases with SAM.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，使用SAM时有一种更强大的使用别名的方式。
- en: Traffic Shifting
  id: totrans-150
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 流量转移
- en: If you use the `AutoPublishAlias` property of a Lambda function with SAM, all
    events from an event source immediately get routed to the new version of the function.
    If something goes wrong, you can manually update the alias to point to the previous
    version.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 如果在SAM中使用Lambda函数的`AutoPublishAlias`属性，则来自事件源的所有事件将立即路由到函数的新版本。如果出现问题，您可以手动更新别名以指向前一个版本。
- en: Lambda and SAM also have functionality to improve this process first by giving
    the opportunity to split traffic, sending some to the new version and some to
    the old version. This means that if a problem occurs, and a rollback is required,
    not all traffic has been impacted by the problem.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: Lambda和SAM还具有通过首先给予分流流量的机能来改善此流程的功能，将一些流量发送到新版本，一些流量发送到旧版本。这意味着如果发生问题，并且需要回滚，则并非所有流量都受到问题的影响。
- en: The second improvement is that a rollback can automatically be performed if
    an error is detected, where you have the opportunity to define how the error is
    calculated in a couple of different ways.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 第二个改进是，如果检测到错误，可以自动执行回滚，您可以定义如何以几种不同的方式计算错误。
- en: There are a number of moving pieces involved in getting this working—Lambda
    aliases, Lambda alias update policies, and use of the [AWS CodeDeploy](https://oreil.ly/t2gIB)
    service. Fortunately, SAM does a good job of wrapping all of this up for you so
    that you don’t need to worry about all of the gory details. The main thing you
    need to do is add a `DeploymentPreference` property to your Lambda function in
    your SAM template, which is [thoroughly documented](https://oreil.ly/EhJaS).
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
- en: 'A choice you need to make when using traffic shifting is how you want your
    traffic to be shifted to the new alias. This breaks down into four options:'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
- en: All at once
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
- en: While this may sound the same at first glance as `AutoPublishAlias` it’s actually
    a lot more powerful, since you have the opportunity to automatically roll back
    deployment through “hooks,” as we’ll describe in a moment. This is a fully automated
    implementation of [*Blue Green Deployment*](https://oreil.ly/qowK1) for Lambda.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
- en: Canary
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
- en: Send a small percentage of traffic to the new version, and if it works, then
    send the remaining traffic; otherwise, roll back.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
- en: Linear
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
- en: Similar to Canary, but send increasing percentages of traffic to the new version,
    still allowing for rollback.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
- en: Custom
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
- en: Decide for yourself how you want traffic to split across the old and new aliases.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
- en: As we mentioned already, a powerful element to this feature is that automatic
    rollback can be implemented via two different mechanisms—*hooks* and *alarms*.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
- en: '*Hook*-triggered rollback is available to any of the previous schemes. You
    can define *pretraffic hooks* and/or *posttraffic hooks*. These hooks are simply
    other Lambda functions that will run whatever logic they need to decide whether
    deployment has been successful—either before any traffic is routed to the new
    alias or after all traffic has been shifted.'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
- en: '*Alarms* are available with schemes that offer gradual traffic shifting. You
    can define any number of *CloudWatch Alarms* (which we discussed in [“Alarms”](ch07.html#cloudwatch-alarms)),
    and if any of those alarms transition to their *alarm* state, then a rollback
    to the original alias will be performed.'
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
- en: For more details on Lambda traffic shifting, see the [SAM documentation](https://oreil.ly/SXGLS).
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
- en: When (Not) to Use Versions and Aliases
  id: totrans-168
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Lambda’s traffic shifting capability is very powerful, and if you don’t already
    have a canary release scheme upstream of your Lambda code, then it may well be
    useful for you.
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
- en: However, apart from traffic shifting, we try to steer away from versions and
    aliases. We find that they typically add unnecessary complexity, and instead we
    prefer to use alternative techniques. For example, for separating development
    and production versions of code, we prefer to use different deployed stacks. For
    “rolling back” code, our preference is to use a fast-running deployment pipeline,
    and roll back at the source repository, triggering a new commit through the pipeline.
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
- en: Note
  id: totrans-171
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Very occasionally you’ll see that some event sources use, and recommend, using
    Lambda aliases. One example of this is when integrating Lambda with [AWS Application
    Load Balancer (ALB)](https://oreil.ly/4U1ZD).
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 偶尔您会看到一些事件源使用并推荐使用 Lambda 别名。其中一个例子是将 Lambda 与[AWS 应用负载均衡器（ALB）](https://oreil.ly/4U1ZD)集成时。
- en: 'If you do use versions and aliases, be aware of a couple of “gotchas,” beyond
    the function instance warning earlier:'
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您使用版本和别名，请注意除了之前提到的函数实例警告之外的一些“陷阱”：
- en: Versions do not automatically clean up after themselves, so periodically you’ll
    want to delete old versions. Otherwise, you may find you hit your account-level
    “function and layer storage” limit of 75GB.
  id: totrans-174
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 版本不会自动清理，因此定期删除旧版本很重要。否则，您可能会发现自己达到账户级别的“函数和层存储”限制，即 75GB。
- en: The default CloudWatch metrics views in the AWS Web Console for Lambda are a
    little odd when you’re using aliases and versions. Make sure you’re being explicit
    about which version(s) or alias(es) you want to view data for when you’re using
    CloudWatch metrics in this way.
  id: totrans-175
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当您在使用 CloudWatch 指标时，请确保您明确指定要查看数据的版本或别名，因为 AWS Web 控制台中默认的 CloudWatch 指标视图在使用版本和别名时有点奇怪。
- en: Cold Starts
  id: totrans-176
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 冷启动
- en: Now we move on to the thorny subject of *cold starts*. Depending on who you
    talk to, cold starts may be a minor footnote in the life of a Lambda developer,
    or it may be a complete blocker to Lambda even being considered a valid computation
    platform. We find how best to approach cold starts is somewhere between these
    two points—worth understanding and treating with rigor, but not a deal-breaker
    in most situations.
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们来讨论*冷启动*这个棘手的问题。根据您与谁交流的不同，冷启动可能是 Lambda 开发者生活中的一个小注脚，也可能是阻止 Lambda 被视为有效计算平台的一个完全阻碍因素。我们发现如何最好地处理冷启动在这两个极端之间——值得深入理解和严谨对待，但在大多数情况下并非不可抗拒的因素。
- en: But what are cold starts, when do they happen, what impact do they have, and
    how can we mitigate them? There’s a lot of fear, uncertainty, and doubt (FUD)
    surrounding cold starts, and we hope to remove some of that FUD for you here.
    Let’s dive in.
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 但是冷启动是什么，何时发生，它们会产生什么影响，以及我们如何减轻它们的影响？关于冷启动有很多恐惧、不确定性和怀疑（FUD），我们希望在这里消除其中一些
    FUD。让我们深入探讨。
- en: What Is a Cold Start?
  id: totrans-179
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 什么是冷启动？
- en: Back in [Chapter 3](ch03.html#ch03), we explored the chain of activity ([Figure 3-1](ch03.html#lambda-execution-environment))
    that occurs when a Lambda function is invoked for the first time—from starting
    a host Linux environment through to calling our handler function. In between those
    two activities the JVM will be started, the Lambda Java Runtime will be started,
    our code will be loaded, and depending on the precise nature of our Lambda function,
    more may happen besides. We collectively group this chain into something we call
    a *cold start*, and it results in a new *instance* (an execution environment,
    a runtime, and our code) of our Lambda function being available to process events.
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 回顾[第 3 章](ch03.html#ch03)，我们探讨了当第一次调用 Lambda 函数时发生的活动链（[图 3-1](ch03.html#lambda-execution-environment)）——从启动主机
    Linux 环境到调用我们的处理函数。在这两个活动之间，JVM 将被启动，Lambda Java 运行时将被启动，我们的代码将被加载，根据我们 Lambda
    函数的具体特性，可能会发生更多其他活动。我们将这个链条总称为*冷启动*，它导致我们的 Lambda 函数的新*实例*（执行环境、运行时和我们的代码）可以处理事件。
- en: An important point here is that all of this activity occurs *when our Lambda
    function is invoked*, not before. In other words, Lambda doesn’t create function
    instances solely when Lambda code is deployed—it creates them *on demand*.
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 这里一个重要的观点是，所有这些活动都发生在我们的 Lambda 函数被调用时，而不是之前。换句话说，Lambda 不仅在部署 Lambda 代码时创建函数实例，而是根据需要创建它们。
- en: However, cold starts are special occurrences, rather than something that happens
    on every invocation, because typically Lambda won’t perform a cold start for every
    event that triggers our function. This is because once our function has finished
    executing, Lambda can [*freeze*](https://oreil.ly/YrC-W) the instance and keep
    it around for a little while in case another event happens soon. If an event does
    happen soon, then Lambda will *thaw* the instance and call it with the event.
    For many Lambda functions, cold starts in fact occur less than 1% of the time,
    but it’s still useful to know when they do occur.
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
- en: When Does a Cold Start Occur?
  id: totrans-183
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'A cold start is necessary whenever there is no existing function instance available
    to process an event. This situation happens at the following times:'
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
- en: When a Lambda function’s code or configuration changes (including when the first
    version of a function is deployed)
  id: totrans-185
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: When all previous instances have been expired due to inactivity
  id: totrans-186
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: When all previous instances have been “reaped” due to age
  id: totrans-187
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: When Lambda needs to scale out because all current instances for the required
    function are already processing events
  id: totrans-188
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Let’s look at these four types of occurrence in a little more detail.
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
- en: When we deploy our function for the first time, Lambda will create an instance
    of our function, as we’ve already seen. However, Lambda will also create a new
    instance whenever a function is invoked after we deploy a new version of the function
    code, or when we change the Lambda configuration of our functions. Such configuration
    doesn’t just cover environment variables—it also covers runtime aspects like timeouts,
    memory settings, DLQ, etc.
  id: totrans-190
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: A corollary of this is that one instance of a Lambda function is guaranteed
    to have the same code and configuration no matter how many times it is called.
  id: totrans-191
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Lambda will keep function instances around for a little while in case another
    event happens “soon.” The precise definition of *soon* is not documented, but
    it can be anywhere between a few minutes and a few hours (and is not necessarily
    constant). In other words, if your function processes an event, and then a minute
    later another event occurs, there’s a very good chance the second event will be
    processed using the same instance of your function that was used to process the
    first event. However, if there’s a day or more between events, your function will
    likely experience a cold start for every event. In the past, some people have
    used a “ping hack” to work around this and keep their function “alive,” but in
    late 2019 AWS introduced Provisioned Concurrency (see [“Provisioned Concurrency”](#provisioned-concurrency))
    to solve this kind of concern.
  id: totrans-192
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Even if your Lambda event is fairly active, Amazon doesn’t keep instances around
    forever, even if they’re being used every few seconds. How long AWS will keep
    instances around is, again, undocumented, but at time of writing we see instances
    lasting five to six hours, and after that they’re killed off.
  id: totrans-193
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Finally, a cold start will occur if all current instances of a function are
    already busy processing events and Lambda “scales out,” as we described this earlier
    in this chapter.
  id: totrans-194
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Identifying Cold Starts
  id: totrans-195
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: How can you tell when a cold start has occurred? There are many ways of doing
    so, but here are a few.
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
- en: First, you’ll notice a latency spike. Cold starts typically add anywhere from
    100 milliseconds to 10 seconds to the latency of your function, depending on the
    makeup of your function. Therefore, if your function typically takes less than
    that, a cold start will be easy to see in the function’s latency metrics.
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
- en: Next you’ll be able to tell when a cold start has occurred due to a way that
    Lambda’s logging works. As we discussed in [“Lambda and CloudWatch Logs”](ch07.html#lambda-and-cloudwatch-logs),
    when Lambda functions log, the output is captured in CloudWatch Logs. All of the
    log output for one function is available in one CloudWatch Log *group*, but each
    instance of a function will write to a separate log *stream*, within the log group.
    Therefore if you see the number of log streams within a log group increase then
    you know a cold start has occurred.
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
- en: Also, you can track cold starts yourself within code. Since the Java object
    encapsulating your handler is instantiated only once per instance of the actual
    function runtime, any instance member or static member initialization will happen
    at cold start, and never again for the lifetime of the function instance. Therefore,
    if you add a constructor, or static initializer, to your code, it will be called
    only when the function is experiencing a cold start. You can add explicit logging
    to your handler class constructor to see a cold start occurring in your function
    logs. Alternatively, we saw examples of identifying cold starts earlier in this
    chapter.
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
- en: You can also identify cold starts using X-Ray and some third-party Lambda monitoring
    tools.
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
- en: Impact of Cold Starts
  id: totrans-201
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: So far we’ve described what cold starts are, when they happen, and how you can
    identify them. But why should you care about cold starts?
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
- en: As we just mentioned in the previous section, one way to identify a cold start
    is that you’ll typically see a latency spike in your event processing when one
    occurs, and this is most often why people are concerned about them. While end-to-end
    latency of a small Lambda function might be 50 ms in a usual case, a cold start
    could add *at least* 200 ms to this amount, and, depending on various factors,
    may add seconds, or even tens of seconds. The reasons that cold starts add latency
    are because of all the steps that need to occur during creation of a function
    instance.
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
- en: Does this mean that we *always* need to care about cold starts? That depends
    a lot on what your Lambda function is doing.
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
- en: For instance, say your function is asynchronously processing objects created
    in S3, and you are ambivalent as to whether it takes minutes to process such objects.
    Do you care about cold starts in this situation? Probably not. Especially when
    you consider that S3 has no guaranteed subsecond delivery of events anyway.
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
- en: 'Here’s another example of where you likely won’t care too much about cold starts:
    say that you have a function that is processing messages from Kinesis, that each
    event takes about 100 ms to process, and that there’s typically always enough
    data to keep your Lambda functions busy. In this case, one instance of your Lambda
    function may process 200,000 events before it gets “reaped.” In other words *cold
    starts might only affect 0.0005% of Lambda invocations*. Even if a cold start
    added 10 seconds to your startup latency, it’s highly likely that you’ll be OK
    with such an impact in this scenario, when you consider amortizing that time over
    the lifetime of an instance.'
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
- en: On the other hand, say you’re building a web application, and there’s a particular
    element that calls a Lambda function, but that function gets called in AWS only
    once per hour. This might mean you’re getting a cold start every time the function
    is invoked. Further, let’s say for this particular function that the cold start
    overhead is five seconds. Is this a problem? It might be. If so, can this overhead
    be reduced? Perhaps, and we’ll talk about that in the next section.
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
- en: Although the concern with cold starts is almost always about latency overhead,
    it’s also important to note that if your function loads data from a downstream
    resource at startup, it will be doing that every time a cold start occurs. You
    may want to consider this when you’re thinking about the impact your Lambda functions
    have on downstream resources, especially when all of your instances cold start
    after a deployment.
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
- en: Mitigating Cold Starts
  id: totrans-209
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Cold starts will always occur with Lambda, and unless we use Provisioned Concurrency
    (described in the next section), such cold starts will always, occasionally, affect
    our function’s performance. If cold starts are causing you a problem, there are
    various techniques you can use to mitigate their impact. Just make sure that they
    really are causing you a problem, though—like other forms of performance optimization,
    you want to make sure you do this work only if it’s truly necessary.
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
- en: Reduce artifact size
  id: totrans-211
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Often the most effective tool in reducing cold start impact is to reduce the
    size of our code artifact. We can do that in two main ways:'
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
- en: Reduce the amount of our own code in the artifact to just that needed by the
    Lambda function (where “amount” means both size and number of classes).
  id: totrans-213
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Prune dependencies so that only libraries that our Lambda function needs are
    stored in the artifact.
  id: totrans-214
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: There are a couple of follow-on techniques here. First, create a different artifact
    for each of your Lambda functions, and execute the tasks for each artifact. This
    was the point of the effort we went to in [Chapter 5](ch05.html#ch05) when we
    created the multimodule Maven project.
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
- en: Second, if you want to optimize library dependencies further, then consider
    *breaking depended-upon libraries apart to just the code you need*. And perhaps
    even re-implement library functionality in your own code. Obviously there’s some
    work necessary here to do this correctly and safely, but it might be a useful
    technique for you.
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
- en: These techniques reduce cold starts in two ways. First, there’s simply a smaller
    artifact to copy and unpack before the runtime starts. But furthermore, there’s
    less code for your runtime to load and initialize.
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
- en: All of these techniques are somewhat unusual in modern server-side software
    development. We’ve become used to being able to add dependencies willy-nilly to
    our projects, creating multi-hundred-megabyte deployment artifacts while Maven
    or NPM “download the internet.” This is typically sufficient in traditional server-side
    development since disk space is cheap, networks are fast, and most importantly,
    we don’t care too much about startup time for our servers, at least not on the
    order of a few seconds here and there.
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
- en: But with functions as a service (FaaS), and Lambda in particular, we care about
    startup time to a much more significant extent, so we need to be more judicious
    with how we build and package our software.
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
- en: To prune dependencies in JVM projects, you may want to consider using the [Apache
    Maven Dependency plug-in](https://oreil.ly/RZYMF), which will report on how dependencies
    in your project are used, or a similar tool.
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
- en: Use a more load-speed-efficient packaging format
  id: totrans-221
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: As we called out in [Chapter 4](ch04.html#ch04), [AWS recommends](https://oreil.ly/_S6Bb)
    the ZIP file approach to packaging a Lambda function, over the uberjar approach,
    because it decreases the time Lambda needs to unpack your deployment artifact.
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
- en: Reduce startup logic
  id: totrans-223
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Later in this chapter, we’ll look at state in Lambda functions. Despite what
    you may have heard, Lambda functions aren’t stateless; they just have an unusual
    model when it comes to thinking about state.
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
- en: A fairly common thing to do with Lambda functions is to create or load various
    resources when the function is first invoked. We saw this to a small extent in
    the examples in [Chapter 5](ch05.html#ch05) when we initialized our serialization
    libraries and SDKs. However for some functions, it makes sense to grab this idea
    by the horns and create a large local cache, loaded from some other resources,
    in the name of more quickly handling events during the lifetime of the instance.
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
- en: Such startup logic doesn’t happen for free though, and will increase cold start
    time. If you are loading initial resources at cold start, you may find that you
    have a trade-off to make between how much you improve the performance of subsequent
    invocations versus how long the initial invocation takes. If possible, you may
    want to consider if you can gradually “warm” your function’s local cache over
    a series of initial invocations.
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
- en: Warning
  id: totrans-227
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: One big cause of slow startup is the use of application frameworks like Spring.
    As we discuss later (see [“Lambda and Java Application Frameworks”](#java-application-frameworks)),
    we strongly discourage the use of such frameworks with Lambda. If cold starts
    are causing you a problem, and you’re using an application framework, then we
    recommend your first course of action should be to investigate whether you can
    remove the framework from your Lambda function.
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
- en: Language choice
  id: totrans-229
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Another area that can impact cold start time is the choice of language runtime.
    JavaScript, Python, and Go simply take less time to start up than the JVM or .NET
    runtime. Therefore, if you’re writing a small function that isn’t called often,
    and you care about reducing cold start impact as much as possible, you may want
    to use either JavaScript, Python, or Go over Java, all other development aspects
    being equal.
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
- en: Because of this difference in startup time, we often hear people dismiss the
    JVM and .NET runtimes as Lambda runtimes in general, but this is a short-sighted
    opinion. For instance, in the situation we described earlier with the Kinesis
    processing function, what if, on average, the JVM function took 80 ms to process
    an event, but a JavaScript equivalent took 120 ms? In this case, you would literally
    be paying twice as much for the JavaScript version of your code to run (since
    billable Lambda time is rounded up to the next 100 ms). In this situation, JavaScript
    may be the wrong choice of runtime.
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
- en: It’s perfectly possible to use alternative (non-Java) JVM languages within Lambda
    (which we talk about more at the end of this chapter). One important aspect to
    remember, though, is that typically these languages come with their own “language
    runtimes” and libraries, and both of these will increase cold start time.
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
- en: Finally, on the topic of language choice, it’s worth keeping some perspective
    when it comes to impact of language on cold start, or event-processing, performance.
    The most important factor in language choice is how effectively you can build
    and maintain your code—the human element of software development. The cost of
    runtime performance differences between Lambda language runtimes may pale in comparison
    with this.
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
- en: Memory and CPU
  id: totrans-234
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Certain aspects of your function’s configuration can also affect cold start
    time. One of the primary examples of this is the `MemorySize` setting you choose.
    A larger memory setting also gives more CPU resources, and therefore a larger
    memory setting may speed up the time it takes your JVM code to JIT compile.
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
- en: Note
  id: totrans-236
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Until late 2019, another configuration setting of a Lambda function that could
    significantly increase cold start time was whether you were using a *virtual private
    cloud (VPC)*. We discuss VPCs in general later in this chapter, but for now all
    you need to know is that if you see any documentation anywhere warning of awful
    Lamdba startup times because of VPCs, then you can sit happy in the knowledge
    that this has now been resolved. For more details on what AWS did to improve this,
    see [this article](https://oreil.ly/UnES6).
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
- en: Provisioned Concurrency
  id: totrans-238
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In late 2019 AWS announced a new Lambda feature—*Provisioned Concurrency*.
    Provisioned Concurrency (PC) allows an engineer to effectively “pre-warm” Lambda
    functions, thereby removing (almost) all of the impact of cold starts. Before
    we describe how to use this feature, here are some important caveats:'
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
- en: 'PC breaks the request-based cost model of Lambda. With PC you pay whether your
    functions are invoked or not. Using Lambda with PC therefore negates one of the
    main benefits of serverless: costs that scale to zero (see [“FaaS as Implemented
    by Lambda”](ch01.html#lambda-as-faas)).'
  id: totrans-240
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: To avoid paying for costs related to peak usage, you need to manually configure
    AWS Auto Scaling with PC (see [this AWS blog article on how to implement this](https://oreil.ly/9x0D6)).
    This is extra operational overhead on your part.
  id: totrans-241
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: PC adds significant deployment time overhead. In our experiments, at the time
    of writing, deploying a Lambda function with a PC setting of 1 (see below as to
    what this means) has an overhead of about four minutes. Using a setting of 10
    or 100 is about seven minutes.
  id: totrans-242
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: PC requires using either versions or aliases, which we described earlier in
    this chapter (see [“Versions and Aliases, Traffic Shifting”](#versions-and-aliases)).
    As we mentioned in that section, we do not recommend using versions or aliases
    in most cases, due to the extra complexity they bring.
  id: totrans-243
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Warning
  id: totrans-244
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Given these significant caveats, our recommendation is that you only reach for
    Provisioned Concurrency if you *absolutely need to*. As we mention in the summary
    of this section, we find that most teams that are concerned initially about cold
    starts find that they are of no effective consequence once they start using Lambda
    at scale in production, especially if the teams follow the other advice we give
    in this chapter about cold start mitigation.
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
- en: Now, we’ve told you why you almost certainly shouldn’t use Provisioned Concurrency,
    let’s talk about what it is!
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
- en: PC, at its simplest, is a numerical value (*n*) that tells the Lambda platform
    to always have *at least* *n* execution environments of your function in a “warm”
    state. “Warm” here means that the execution environment has been created, and
    your Lambda function handler code has been instantiated. In fact, the entire execution
    chain (see [Figure 3-1](ch03.html#lambda-execution-environment)) is performed
    during warming, apart from actually calling your handler method.
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
- en: Since under a PC context Lambda won’t call a nonwarmed function (apart from
    one caveat about scaling, which we’ll describe in a moment), this guarantees that
    you won’t have any performance-impacting cold starts at all! In other words, *all*
    of your function invocations will respond in their regular “warm” time.
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
- en: Another nice aspect to PC is that it is defined solely in deployment configuration—no
    change to your code is required to use it (although you may want to change your
    code, as we will describe about code instantiation in a moment).
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s look at an example. Say that we have the following function configured
    in our SAM template:'
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  id: totrans-251
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: The new lines here are those last three. First you’ll see that we’re using an
    alias—PC requires configuring a `ProvisionedConcurrentExecutions` value for each
    version or alias that we want PC for. We can’t configure a `ProvisionedConcurrentExecutions`
    value for `$LATEST`—the default version.
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
- en: In this example, we then specify that we want to always have one instance of
    our Lambda function pre-warmed.
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
- en: When we deploy this function for the first time, Lambda will instantiate the
    Java class `HelloWorld`, which contains our handler, even before any invocations
    occur. Then, when an event is received for the function, Lambda calls this pre-warmed
    function. When we *redeploy* the function, Lambda will keep routing requests to
    the old (warm) version and start using the new version only once all the provisioned
    instances for that version have been created. Again, this makes sure that function
    invocation isn’t impacted by cold starts.
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  id: totrans-255
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: In other third-party Lambda documentation, you may see recommendations to use
    a secondary, scheduled, “ping” function that calls the application function, to
    avoid cold starts. PC, with a setting of 1, in almost any case is a more effective
    replacement of such a mechanism.
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
- en: Now, let’s cover a few details you should be aware of.
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
- en: First, pricing. As mentioned, PC has (at the time of writing) a different cost
    model to regular “on-demand” Lambda. As described in [“How Expensive Is Lambda?”](ch03.html#how-expensive-is-lambda),
    on-demand Lambda costs are based on how many requests your Lambda function receives
    and how long your Lambda function is executing (duration). For PC you still pay
    the request cost, and a (smaller) amount for duration, but you *also* pay a charge
    for the entire time your function is deployed, not just when it is processing
    requests.
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
- en: Let’s build on [“How Expensive Is Lambda?”](ch03.html#how-expensive-is-lambda),
    specifically the example for the web API. Our cost estimate for just on-demand
    Lambda was $21.60/month. How much does it cost using Provisioned Concurrency?
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
- en: 'Again, we’ll assume 512-MB RAM, less than 100 ms to process a request and 864,000
    requests/day. Let’s start with using a PC value of 10, since that’s what we expect
    to peak up to. In this scenario, our Lambda costs are as follows:'
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
- en: The request cost is unchanged at $5.18/month.
  id: totrans-261
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The duration cost is 0.1 × 864000 × 0.5 × $0.000009722 = $0.42/day, or $12.60/month.
  id: totrans-262
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The Provisioned Concurrency cost is 10 × 0.000004167 × 0.5 × 86400 = $1.80/day,
    or $54/month.
  id: totrans-263
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The total cost therefore has increased by a little over three times from approximately
    $22/month to $72/month. Yikes!
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
- en: Now, this is likely a “worst case” since we are setting PC at peak. One option
    we have is to manually configure auto-scaling for PC. This is described on the
    [AWS blog introducing PC](https://oreil.ly/8p8K6). Let’s say that doing this means
    our PC configuration averages around 2. In this case, our total costs are $29/month.
    This is still 30% more expensive than on-demand, plus now we have the added complexity
    of managing PC auto-scaling.
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
- en: There are some scenarios where if you have a very consistent usage model, then
    PC works out cheaper than on-demand, but in most cases you should expect to pay
    a significant overhead to use PC.
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
- en: Another issue related to costs is that you probably want to have different configuration
    for development versus production to avoid paying “always-on” costs for development
    environments. You can do this using CloudFormation techniques, but again this
    is extra mental overhead.
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
- en: That’s enough about costs. Let’s move on to a different subject!
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
- en: What happens if at a certain point in time you have more invocations than your
    PC configuration? As we looked at earlier in this chapter, we know that Lambda
    always increases the number of active execution environments to satisfy load.
    For example, say that Lambda needs to use an 11th execution environment for your
    function, but you have a PC setting of 10—what happens now? In this case, Lambda
    will spin up a new execution environment in the “traditional” on-demand model
    to cover the extra load. You will be charged for this extra capacity in the usual
    on-demand fashion, but be warned—the first event using that new extra environment
    will also incur cold-start latency in the normal way!
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
- en: Finally, a quick note on making the most of PC. AWS has been doing a great job
    over the last few years in reducing the *platform* overhead of cold starts, so
    the main point of PC is mostly to mitigate *application* overhead—the time taken
    to instantiate your language runtime, code, and handler class. This last element—class
    instantiation—is important since your handler class constructor is called during
    pre-warming. Therefore, you’ll want to move as much application setup as possible
    to class and object instantiation time and not do this in the handler method itself.
    We’ve used this pattern throughout the book, but it’s especially important if
    you’re using PC.
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
- en: 'Given all of our dire warnings about using PC, when do we recommend using it?
    Here are a few scenarios where we can imagine PC being useful:'
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
- en: When you have a Lambda function called very infrequently (say once per hour,
    or longer) that you always want to return quickly (subsecond), and you are willing
    to pay the cost overhead.
  id: totrans-272
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If your application has extreme “burst” scale scenarios (see [“Burst limits”](#burst-limits))
    that Lambda can’t handle by default, then you can pre-warm sufficient capacity.
  id: totrans-273
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If your function itself has significant code-level cold-start time (e.g., several
    seconds) that is not sufficient for application performance, and you have no other
    way to mitigate this. This is typical if you’re using a heavyweight application
    framework within your Lambda code.
  id: totrans-274
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Cold Start Summary
  id: totrans-275
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Cold starts might be nothing you need to ever spend too much effort on, depending
    on what you use Lambda for, but it’s certainly a topic that you should be aware
    of, since how cold starts are mitigated often runs counter to how we typically
    build and package systems.
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
- en: We mentioned *FUD* around cold starts earlier, and cold starts are also often
    “thrown under the bus” for latency problems that turn out to actually have nothing
    to do with cold starts at all. Remember to perform proper latency analysis if
    you’re having latency concerns—make sure your actual problem isn’t, for example,
    how your code is interacting with a downstream system.
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
- en: Also make sure to continue to test latency over time, especially if you rule
    out a certain use of Lambda because of cold starts. AWS has made, and continues
    to make, significant improvements in this part of the Lambda platform.
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
- en: In our experience, cold starts concern teams when they first use Lambda, especially
    under spiky development loads, but once they see how Lambda performs under production
    loads, they often never worry about cold starts again.
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
- en: State
  id: totrans-280
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Almost any application needs to consider state. Such state may be *persistent*—in
    other words, it captures data that is required to fulfill subsequent requests.
    Alternatively, it may be *cached* state—a copy of data that is used to improve
    performance, where the persisted version is stored elsewhere.
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
- en: Despite how it’s occasionally perceived, Lambda is *not* stateless—data can
    be stored in memory and on disk both during and across requests.
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
- en: In-memory state is available via a handler method’s object and class members—any
    data loaded into such members is available the next time that function instance
    is invoked again, and a Lambda function can have up to a total of 3GB RAM (some
    of that will be used by the Lambda runtime).
  id: totrans-283
  prefs: []
  type: TYPE_NORMAL
- en: Lambda function instances also have access to 512MB of local disk storage in
    */tmp*. While this state is not automatically shared across function instances,
    it will, again, be available for subsequent invocations of the same function instance.
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
- en: However, the nature of Lambda’s runtime model significantly impacts how such
    state can be used.
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
- en: Persistent Application State
  id: totrans-286
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The way that Lambda creates function instances, especially in the way that it
    scales, has significant implications on architecture. For example, we have absolutely
    no guarantee that sequential requests, for the same upstream client, will be handled
    by the same function instance. There is no “client affinity” for Lambda functions.
  id: totrans-287
  prefs: []
  type: TYPE_NORMAL
- en: This means that we *cannot assume* that any state that was available locally
    (in-memory, or on local disk) in a Lambda function for one request will be available
    for a subsequent request. This is true whether our function scales or not—scaling
    just underlines the point.
  id: totrans-288
  prefs: []
  type: TYPE_NORMAL
- en: Therefore, all persistent application state that we want to keep across Lambda
    function invocations must be *externalized*. In other words, this means that any
    state we want to keep beyond an individual invocation has to be either stored
    downstream of our Lambda function—in a database, external file storage, or other
    downstream service—or it must be returned to the caller in the case of a synchronously
    called function.
  id: totrans-289
  prefs: []
  type: TYPE_NORMAL
- en: This might sound like a massive restriction, but in fact this way of building
    server-side software is not new. Many people have been espousing the virtues of
    the [*12-factor architecture*](https://12factor.net/) for years, and this aspect
    of externalizing state is expressed within the sixth factor of that paradigm.
  id: totrans-290
  prefs: []
  type: TYPE_NORMAL
- en: That being said, this definitely is a constraint of Lambda, and may require
    you to significantly re-architect existing applications that you want to move
    to Lambda. It may also mean that some applications that require particularly low
    latency to state (for example, gaming servers) are not good candidate applications
    for Lambda, nor are those that require a large data set in memory in order to
    perform adequately.
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
- en: 'There are various common services that people use to externalize their application
    state with Lambda:'
  id: totrans-292
  prefs: []
  type: TYPE_NORMAL
- en: DynamoDB
  id: totrans-293
  prefs: []
  type: TYPE_NORMAL
- en: 'DynamoDB is the NoSQL database of AWS. We used DynamoDB in the API example
    in [“Example: Building a Serverless API”](ch05.html#serverless-api-example). The
    benefits of DynamoDB are that it is fast, fairly easy to operate and configure,
    and has very similar scaling properties to Lambda. The chief drawback to DynamoDB
    is that modeling data can get tricky.'
  id: totrans-294
  prefs: []
  type: TYPE_NORMAL
- en: RDS
  id: totrans-295
  prefs: []
  type: TYPE_NORMAL
- en: AWS has various relational databases that it groups in the Relational/SQL Database
    Service (RDS) family, and all of these are available for use from Lambda. One
    fairly new option within this family is [*Aurora Serverless*](https://oreil.ly/2Kc4E)—an
    auto-scaling version of Amazon’s own *Aurora* MySQL and Postgres engines, made
    for serverless applications. The benefits of using a SQL database over a NoSQL
    one are decades of experience building such applications. The drawbacks, versus
    DynamoDB at least, typically are higher latencies and more operational overhead
    (with nonserverless RDS).
  id: totrans-296
  prefs: []
  type: TYPE_NORMAL
- en: S3
  id: totrans-297
  prefs: []
  type: TYPE_NORMAL
- en: Simple Storage Service (S3)—which we’ve used several times throughout this book—can
    be used as a data store for Lambda. It’s simple to use, but isn’t particularly
    low latency, and also has limited querying capabilities in comparison with one
    of the database services, unless you also use [Amazon Athena](https://aws.amazon.com/athena).
  id: totrans-298
  prefs: []
  type: TYPE_NORMAL
- en: ElastiCache
  id: totrans-299
  prefs: []
  type: TYPE_NORMAL
- en: AWS offers a managed version of the Redis persistent cache application as part
    of its [ElastiCache](https://aws.amazon.com/elasticache) family. Of these four
    options, ElastiCache typically offers the fastest performance, but since it isn’t
    a true serverless service, it does require some operational overhead.
  id: totrans-300
  prefs: []
  type: TYPE_NORMAL
- en: Custom downstream service
  id: totrans-301
  prefs: []
  type: TYPE_NORMAL
- en: Alternatively, you may choose to implement your own in-memory persistence in
    a downstream service, built using traditional designs.
  id: totrans-302
  prefs: []
  type: TYPE_NORMAL
- en: AWS continues to make interesting developments in this area, and we recommend
    that you investigate all recently announced advances whenever you pick a persistence
    solution.
  id: totrans-303
  prefs: []
  type: TYPE_NORMAL
- en: Caching
  id: totrans-304
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: While we can’t rely on Lambda’s state capabilities for persistent application
    state, we absolutely can use them for caching data that is also stored elsewhere.
    Put another way, while it’s true that we have no guarantee that one Lambda function
    instance will be called multiple times, we do know that it *probably will be*,
    depending on invocation frequency. Because of this, cache state is a candidate
    for Lambda’s local storage.
  id: totrans-305
  prefs: []
  type: TYPE_NORMAL
- en: We can use either or both of Lambda’s in-memory or on-disk locations for cached
    data. For example, say that we always need a set of fairly up-to-date reference
    data from a downstream service to process an event, but “fairly up-to-date” is
    on order of “valid within the last day.” In this case, we can load the reference
    data once, for the first invocation of the function instance, and then store that
    data locally in a static or instance member variable. Remember—our handler function
    instance object will be instantiated only once per runtime environment.
  id: totrans-306
  prefs: []
  type: TYPE_NORMAL
- en: As another example, say that we want to call an external program or library
    as part of our execution—Lambda gives us a full Linux environment with which to
    do this. That program/library may be too big to fit in either a Lambda code artifact
    (which is restricted to at most 250MB when uncompressed) or even a Lambda layer
    (see later in this chapter about layers). Instead, we can copy the external code
    from S3 to */tmp* the first time we need it for a function instance, and then
    for subsequent requests for that instance the code will be available locally already.
  id: totrans-307
  prefs: []
  type: TYPE_NORMAL
- en: Both of these examples relate to state that consists of chunks of data—application
    data, or libraries and executables. Another form of state in our Lambda applications
    are the runtime structures of our code itself, including those that represent
    connections to external services. These runtime structures either may take some
    amount of time to create when the function is invoked, or in the case of connections
    to services may take time to initialize, e.g., for authentication procedures.
    In either case, in Lambda, we will very often store these structures in program
    elements that live longer than the call to the method itself—in Java this means
    storing them in instance or static members.
  id: totrans-308
  prefs: []
  type: TYPE_NORMAL
- en: 'We showed examples of this earlier in the book. For example in [Chapter 5](ch05.html#ch05)
    at [Example 5-3](ch05.html#EX5-3) we store the following in instance members:'
  id: totrans-309
  prefs: []
  type: TYPE_NORMAL
- en: The `ObjectMapper` instance, because that is a program structure that takes
    some time to instantiate
  id: totrans-310
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The DynamoDB client, which is a connection to the external DynamoDB service
  id: totrans-311
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: While we typically use this form of object caching for performance reasons in
    certain situations, it can also significantly improve the cost effectiveness of
    our overall system—see [“Lambda Runtime Model and Cost Impact on Downstream Systems”](ch09.html#cache-to-improve-costs)
    for more detail on this.
  id: totrans-312
  prefs: []
  type: TYPE_NORMAL
- en: Sometimes Lambda’s own state capabilities are insufficient—for example, our
    total cache state might be too large to fit in memory, too slow to load up during
    a cold start, or update frequently (updating a locally cached version in a Lambda
    function is a tricky thing to manage, although it can be done). In such a case,
    you may choose to use one of the persistence services mentioned in the previous
    section as a caching solution.
  id: totrans-313
  prefs: []
  type: TYPE_NORMAL
- en: Lambda and Java Application Frameworks
  id: totrans-314
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Note
  id: totrans-315
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: So far in this book most of our guidance has been how to use AWS Lambda, with
    a few warnings along the way. We’re now going to take a brief tangent and talk
    about something we *don’t* recommend doing.
  id: totrans-316
  prefs: []
  type: TYPE_NORMAL
- en: Over the last two decades it’s been very common to build server-side Java applications
    using some kind of container and/or framework. Back in the early 2000s, “Java
    Enterprise Edition” (J2EE) was all the rage, with application servers like WebLogic,
    WebSphere, and JBoss allowing you to build your apps with the Enterprise JavaBeans
    (EJB) or Servlet framework. For those of you not around then we can promise you,
    from personal experience, that this was not a whole bunch of fun.
  id: totrans-317
  prefs: []
  type: TYPE_NORMAL
- en: People realized that these big servers were often unwieldy and/or expensive,
    and so they have been largely replaced by more “lightweight” equivalents, of which
    Spring is the most common. Spring itself has evolved along the way, of course,
    into Spring Boot, and people also use various Java web frameworks to build applications.
  id: totrans-318
  prefs: []
  type: TYPE_NORMAL
- en: Because there is so much institutional knowledge in our industry on how to build
    “Java applications” with these tools, there’s a very large temptation to carry
    on using them, and just port the runtime from a running process to a Lambda function.
    AWS has even put significant effort into supporting precisely this way of thinking,
    via the [serverless Java Container](https://oreil.ly/T_ruW) project.
  id: totrans-319
  prefs: []
  type: TYPE_NORMAL
- en: While we admire AWS’s desire to “meet people where they are” in this way, we
    *strongly discourage* the use of most Java frameworks when building applications
    with Lambda, for the following reasons.
  id: totrans-320
  prefs: []
  type: TYPE_NORMAL
- en: First, building a complete app in a single Lambda function misses the fundamental
    point of Lambda. Lambda functions are meant to be small, individual, short-lived
    functions that are event-driven, and programmed to accept a specific input event.
    “Java applications,” on the other hand, are literally servers that have a lifecycle
    and state, and are typically designed to handle multiple types of request. If
    you’re building miniservers, you’re not thinking serverlessly.
  id: totrans-321
  prefs: []
  type: TYPE_NORMAL
- en: Next, most application servers assume that there is some amount of shared state
    from request to request. While it’s possible not to work this way, it’s not a
    natural-feeling way of working in these environments.
  id: totrans-322
  prefs: []
  type: TYPE_NORMAL
- en: 'Another reason we think this is a bad idea is that it detracts from the value
    provided by other AWS serverless services. For example, with the AWS project mentioned
    earlier, API Gateway is used, but in a “full proxy” mode. Here’s a snippet from
    the SAM template from the [Spring Boot example](https://oreil.ly/KZYj3):'
  id: totrans-323
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  id: totrans-324
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: Using API Gateway in this way means that all requests, no matter the path, are
    sent to one Lambda function, and routing behavior needs to be implemented in the
    Lambda function. While Spring Boot can do that, (a) API Gateway will give you
    that functionality for free, and (b) it clutters up your Java code to keep it
    in the Lambda function.
  id: totrans-325
  prefs: []
  type: TYPE_NORMAL
- en: Earlier in the book we mentioned that on the whole we’re wary of using too many
    API Gateway features; for example, see the discussion of request and response
    mapping in [“API Gateway Proxy Events”](ch05.html#api-gateway-proxy-events). However,
    we feel that removing routing is typically a step too far down the line of abstracting
    out the use of API Gateway.
  id: totrans-326
  prefs: []
  type: TYPE_NORMAL
- en: As we discussed earlier on in the section on cold starts, application frameworks
    typically slow down function initialization. While some people may argue that
    this is a good case to use Provisioned Concurrency, we would counter that this
    is a Band-Aid and not a solution.
  id: totrans-327
  prefs: []
  type: TYPE_NORMAL
- en: Finally, container and framework-based apps tend to have large distributable
    artifacts—partly because of the number of libraries depended upon, and partly,
    again, because such apps usually implement a number of functions. Throughout this
    book we’ve been attempting to reduce the size of artifacts by minimizing dependencies,
    and dividing up applications into multiple distributable elements, all in the
    name of keeping our Lambda functions clean and lean. Using an application framework
    runs counter to this way of thinking.
  id: totrans-328
  prefs: []
  type: TYPE_NORMAL
- en: In summary, building Java Lambda applications in this way is really a “square
    peg and round hole problem.” Yes, you can make it work, but it’s inefficient,
    and you won’t get all the benefits of Lambda if you work in this way. There’s
    a real danger of hitting a “local maximum” of value from Lambda, and assuming
    that there are no further upsides.
  id: totrans-329
  prefs: []
  type: TYPE_NORMAL
- en: So if we don’t recommend using these frameworks, how do we suggest you use your
    hard-earned knowledge and skills?
  id: totrans-330
  prefs: []
  type: TYPE_NORMAL
- en: Typically we find that programmers switching to “pure” Lambda development don’t
    take too long to shake off the frameworks they’ve been used to. There’s a certain
    “lightness” that comes with just writing a handler function. Also, there’s nothing
    wrong with bringing along old Java code to the party, as long as it’s not too
    ingrained in an application framework. If you can extract your domain logic into
    something that just expresses your business needs, then you’re on the right path.
  id: totrans-331
  prefs: []
  type: TYPE_NORMAL
- en: Also, it’s still fine to use an ethos of “dependency injection” (DI), which
    the frameworks often provide. You may choose to “hand roll” such DI (our preference),
    as you’ve seen in some of the examples (see [“Add Constructors”](ch06.html#add-constructors)).
    Alternatively, you can try to use a framework to provide just dependency injection,
    without the other features they often come with.
  id: totrans-332
  prefs: []
  type: TYPE_NORMAL
- en: Virtual Private Clouds
  id: totrans-333
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In all of our examples so far any external resources called by a Lambda function
    have been secured via HTTPS/"layer 7” authentication. For example, when we called
    DynamoDB in the serverless API example in [Example 5-3](ch05.html#EX5-3), that
    connection was secured solely by credentials that were passed to DynamoDB from
    our Lambda function.
  id: totrans-334
  prefs: []
  type: TYPE_NORMAL
- en: In other words, DynamoDB is not a “firewalled” service—it sits open to the internet,
    and any machine anywhere else on the internet can connect to it.
  id: totrans-335
  prefs: []
  type: TYPE_NORMAL
- en: While this brave new world of “firewall-less” computing is gathering pace, there
    are still many situations where a Lambda function is going to need to connect
    to a resource that is shielded behind some kind of IP-address limited protection.
    A common way of doing that with AWS is to use a VPC.
  id: totrans-336
  prefs: []
  type: TYPE_NORMAL
- en: VPCs are a lower-level piece of infrastructure than anything else we’ve discussed
    so far in the book. They require understanding things like IP addresses, elastic
    network interfaces (ENIs), CIDR blocks, and security groups, and also expose the
    fact to us that AWS regions are made up of multiple AZs. In other words, “Here
    be dragons!”
  id: totrans-337
  prefs: []
  type: TYPE_NORMAL
- en: 'Lambda functions can be configured to be able to access a VPC. Three typical
    reasons a Lambda function would need this are:'
  id: totrans-338
  prefs: []
  type: TYPE_NORMAL
- en: To be able to access an RDS SQL database (see [Figure 8-2](#lambda-with-vpc))
  id: totrans-339
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: To be able to access ElastiCache
  id: totrans-340
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: To be able to call an internal microservice running on a container cluster using
    IP/VPC-based security
  id: totrans-341
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![images/ch08_image02.png](assets/awsl_0802.png)'
  id: totrans-342
  prefs: []
  type: TYPE_IMG
- en: Figure 8-2\. Lambda attached to VPC to access RDS database
  id: totrans-343
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: You should configure Lambda to use a VPC only if it actually needs it. Adding
    a VPC is not “free”—it impacts other systems, it changes the behavior of how Lambda
    interacts with other services, and it adds complexity to your configuration and
    architecture.
  id: totrans-344
  prefs: []
  type: TYPE_NORMAL
- en: Further, we recommend you configure Lambda to use a VPC only if either (a) you
    understand VPCs and the implications of doing so or (b) you’ve discussed this
    requirement with another team in your organization that understands this.
  id: totrans-345
  prefs: []
  type: TYPE_NORMAL
- en: In the rest of this section, we assume that you understand, broadly, VPCs in
    general, but not necessarily any specifics with Lambda and VPCs. As such, there
    are certain VPC terms, like ENIs and security groups, which we’ll mention but
    not explain.
  id: totrans-346
  prefs: []
  type: TYPE_NORMAL
- en: Architectural Concerns of Using Lambda with a VPCs
  id: totrans-347
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Before you even enable Lambda to use a VPC, there are a few things to be aware
    of that might change your mind!
  id: totrans-348
  prefs: []
  type: TYPE_NORMAL
- en: First, each *subnet* you specify in your VPC configuration is specific to an
    AZ. One of the nice things about Lambda is that we’ve completely ignored AZs until
    this point. If you’re using Lambda + VPC, you need to make sure you configure
    enough subnets, across enough AZs, to allow you to continue to have the level
    of high availability (HA) you need.
  id: totrans-349
  prefs: []
  type: TYPE_NORMAL
- en: Second, when a Lambda function is configured to use a VPC, then *all* network
    traffic from that Lambda will be routed through the VPC. That means if your Lambda
    function is using non-VPC AWS resources (like S3) or is using resources *external*
    to AWS, then you’ll need to consider network routing for those resources, just
    like you would any other service within the VPC. For instance, for S3 you’ll likely
    want to set up a VPC endpoint, and for external services you’ll need to make sure
    your NAT Gateway is correctly configured.
  id: totrans-350
  prefs: []
  type: TYPE_NORMAL
- en: Configuring Lambda to Use a VPC
  id: totrans-351
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: You’ve read all the warnings, and you’ve figured out which subnets and security
    groups to use. How do you now actually configure your Lambda to use a VPC?
  id: totrans-352
  prefs: []
  type: TYPE_NORMAL
- en: 'Fortunately, SAM comes to the rescue, and makes it fairly simple. By examining
    the [example provided by AWS](https://oreil.ly/388NC) (slightly trimmed), we can
    see the additions that you need to make to each Lambda function:'
  id: totrans-353
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  id: totrans-354
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'In summary, you need to:'
  id: totrans-355
  prefs: []
  type: TYPE_NORMAL
- en: Add privileges for the Lambda function to attach to the VPC (e.g., by using
    `VPC AccessPolicy`)
  id: totrans-356
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Add VPC configuration, with a list of security group IDs, and subnet IDs
  id: totrans-357
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: And that’s it! This particular example assumes that you’ll use [CloudFormation
    parameters](https://oreil.ly/0xs3v) to pass in the actual security group and subnet
    IDs at deployment time, but you should feel free to hardcode them in your template
    too.
  id: totrans-358
  prefs: []
  type: TYPE_NORMAL
- en: Alternatives
  id: totrans-359
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Say that all of our dire warnings were enough to put you off of using VPCs with
    Lambda. What should you do instead? Here are a few approaches.
  id: totrans-360
  prefs: []
  type: TYPE_NORMAL
- en: The first is to use roughly equivalent services that don’t require a VPC. For
    example, if you were going to use a VPC to access an RDS database, consider using
    DynamoDB instead (although we do acknowledge that DynamoDB is not a relational
    database!). Or think about using Aurora serverless, and its [Data API](https://oreil.ly/uf2KE).
  id: totrans-361
  prefs: []
  type: TYPE_NORMAL
- en: Next is to re-architect your solution. For example, instead of calling a downstream
    resource directly, would it be possible to use a message bus as an intermediary?
  id: totrans-362
  prefs: []
  type: TYPE_NORMAL
- en: Third—if what you needed to connect to was an internal service, then consider
    giving that internal service a “layer 7” authentication boundary. One way to do
    this is to add an API Gateway to your internal service (or update an existing
    API Gateway if it already has one), and then use API Gateway’s [IAM/Sigv4 authentication
    scheme](https://oreil.ly/RJVSO).
  id: totrans-363
  prefs: []
  type: TYPE_NORMAL
- en: Finally, if you can’t modify your service, you could do something similar to
    the previous idea, but in this case use [API Gateway as a proxy](https://oreil.ly/OKiid)
    to your downstream service.
  id: totrans-364
  prefs: []
  type: TYPE_NORMAL
- en: Of course, there is one more option—wait and see what AWS introduces next! For
    example, the Data API for serverless Aurora that we mentioned is fairly new, and
    signals that there may be more functionality coming that will help Lambda developers
    avoid the perils of VPCs!
  id: totrans-365
  prefs: []
  type: TYPE_NORMAL
- en: Layers and Runtimes
  id: totrans-366
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'If you take a look at one of your Lambda functions in the AWS Web Console,
    you’ll now know what almost everything on there is for. Roles, environment variables,
    memory, VPCs, DLQs, reserved concurrency, and more. However, for the observant
    among you, you’ll see that there’s something towards the top of the page that
    is an omission so far: *layers*. To close out this chapter, we’ll explain what
    layers are, why you (as a Java developer) probably won’t care about them too much,
    and how they relate to another capability known as *custom runtimes*.'
  id: totrans-367
  prefs: []
  type: TYPE_NORMAL
- en: What Are Layers?
  id: totrans-368
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: As you know by now, typically when you deploy a new version of a Lambda function,
    you package up the code and all of its dependencies into a ZIP file, and upload
    that file to the Lambda service. As your dependencies get bigger, however, this
    artifact gets bigger, and deployment slows down. Wouldn’t it be nice to be able
    to speed this up?
  id: totrans-369
  prefs: []
  type: TYPE_NORMAL
- en: This is where Lambda layers come in. A layer is part of the deployed resources
    of your Lambda function, which is deployed separately from the function itself.
    If your layer stays constant, then when you deploy your Lambda function, you only
    need to deploy the changes to your code that aren’t within the layer.
  id: totrans-370
  prefs: []
  type: TYPE_NORMAL
- en: Here’s an example. Say that you are implementing the photo processing example
    from way back in [Chapter 1](ch01.html#ch01) ([“File processing”](ch01.html#file-processing-example)),
    and say that the actual part of your Lambda function that performs the image manipulation
    uses a third-party tool like [ImageMagick](https://imagemagick.org/index.php).
  id: totrans-371
  prefs: []
  type: TYPE_NORMAL
- en: Now, ImageMagick is probably a dependency that changes rarely. With Lambda layers
    you can define a layer (which is just a ZIP artifact containing any content that
    you want) that contains the ImageMagick tool, and then refer to that layer with
    your code in the photo processing Lambda. Now when you update your Lambda function,
    you’ll only need to upload your own code, not your code *and* ImageMagick.
  id: totrans-372
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  id: totrans-373
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: ImageMagick is often used by calling an external process from your application,
    rather than via a library API call. It’s perfectly OK to call an external process
    like this from within a Lambda function—the Lambda runtime is a full Linux environment.
  id: totrans-374
  prefs: []
  type: TYPE_NORMAL
- en: Another useful aspect to layers is that you can share layers across Lambda functions,
    and other AWS accounts—layers can in fact be shared publicly.
  id: totrans-375
  prefs: []
  type: TYPE_NORMAL
- en: When to Use, and Not Use, Layers
  id: totrans-376
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: When layers were announced, certain parts of the Lambda-using world were very
    excited, since they saw layers as a universal dependency system for Lambda functions.
    This was especially true for people using the Python language, since Python’s
    dependency management tools can be a little tricky for some people (e.g., your
    authors!) to wrap their heads around. The Java ecosystem however, for all its
    faults, has a very strong story to tell around dependency management.
  id: totrans-377
  prefs: []
  type: TYPE_NORMAL
- en: 'We feel that there are some specific times when layers are useful. However,
    there are also a number of concerns that we have about embracing them wholeheartedly,
    for example:'
  id: totrans-378
  prefs: []
  type: TYPE_NORMAL
- en: Since layers are combined with your Lambda function after you’ve uploaded the
    function, it’s not necessarily true that the version of a dependency you’ve used
    at test time (before deployment) is the same as that which is used with the deployed
    version. This, to us, is a (typically) unnecessary headache of coordination that
    needs to be managed.
  id: totrans-379
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Lambda functions are limited to the number of layers that can be used (five),
    and so if you have more than five dependencies, you’re going to need to use a
    local deployment tool anyway, so why add the extra complexity of layers?
  id: totrans-380
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Layers don’t particularly provide any functional benefit—they are a deployment
    optimization tool (we’ll talk about cross-cutting behavior as a caveat for this).
  id: totrans-381
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Particularly for developing Lambda in Java—Java does a pretty good job of defining
    its “own world.” For example, it’s usual to only depend on third-party code in
    Java that itself runs in the JVM, as opposed to calling out to system libraries
    or executables. Given this, and the ubiquity of Maven dependencies, it’s easy
    to have one consolidated dependency management system with a Java application
    that doesn’t include the use of Lambda layers.
  id: totrans-382
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Some people like the fact that a layer can be manually updated for a function
    without having to deploy a new version of the function itself. We personally believe
    strongly that apart from extenuating circumstances, the best way to deploy any
    changes to production is through an automated continuous delivery process, and
    therefore the difference between changing an application library dependency versus
    a configured template layer dependency should almost always be moot.
  id: totrans-383
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We’d be remiss if we didn’t also point out the places that layers can be useful.
  id: totrans-384
  prefs: []
  type: TYPE_NORMAL
- en: First, if part of what a Lambda function executes is unrelated to the application,
    but more related to an organization’s cross-cutting technical platform, then using
    layers as an alternative deployment path can be useful. For example, say that
    there is a security process that needs to be run, but as far as application developers
    are concerned, it’s just a “fire-and-forget” call. In this case, publishing that
    code in a layer, and being able to query all the Lambda function configurations
    across an organization and making sure they’re using the correct version of the
    layer, aids in organizational governance.
  id: totrans-385
  prefs: []
  type: TYPE_NORMAL
- en: Another place where layers are useful is where a dependency is a large, system
    binary that rarely changes. In this case, the extra complexity of using layers
    may be worth the value of improved deployment speed, especially if the number
    of deployments of functions using that layer is on the order of hundreds per day
    or more.
  id: totrans-386
  prefs: []
  type: TYPE_NORMAL
- en: A helpful example of this second case is where a Lambda function is using a
    custom runtime, which we’ll explore now.
  id: totrans-387
  prefs: []
  type: TYPE_NORMAL
- en: Custom Runtimes
  id: totrans-388
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Throughout this book we have been using the Java Lambda runtime, apart from
    our very first example, which used the Node 10 runtime. AWS offers [a number of
    runtimes](https://oreil.ly/uLMNz) associated with different programming languages,
    and this list is frequently updated.
  id: totrans-389
  prefs: []
  type: TYPE_NORMAL
- en: However, what happens if you want to use a language or runtime that AWS don’t
    support? For example, what if you have some Cobol code you want to run in a Lambda
    function? Or, perhaps more likely, what if you want to run a highly customized
    JVM, rather than the one AWS provides?
  id: totrans-390
  prefs: []
  type: TYPE_NORMAL
- en: The answer here is to use a *custom runtime*. A custom runtime is a Linux process
    that runs in a Lambda execution environment, and that can process Lambda events.
    There is a [specific execution model](https://oreil.ly/onv6J) that a custom runtime
    needs to fulfill, but the basic idea is that when the runtime instance is started
    by the Lambda platform, it is configured with an instance-specific URL that it
    can query for the next event to process. In other words, custom runtimes use a
    polling architecture.
  id: totrans-391
  prefs: []
  type: TYPE_NORMAL
- en: 'As a Java developer, it will typically be rare that you want or need to use
    a custom runtime for production usages. Two reasons for this are as follows:'
  id: totrans-392
  prefs: []
  type: TYPE_NORMAL
- en: The custom runtime code itself needs to be part of your function’s deployed
    assets. While you can package the runtime in a Lambda layer to avoid uploading
    it on every deployment, it will still be using up some of your [250MB total unpacked
    deployment package size limit](https://oreil.ly/02nUm). Most JVMs are going to
    use a considerable part of that, if you want to ship a custom JVM, and so this
    will cut into the space available for your application code.
  id: totrans-393
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: You will need to reimplement in your custom runtime a lot of what AWS has already
    implemented in its standard runtimes, such as deserialization/serialization of
    events and responses, error handling, and more.
  id: totrans-394
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: That being said, for organizations of a certain size, building a custom runtime
    that handles various organizational-platform-related tasks might make actual Lambda
    development even more effective, but we would suggest a through analysis before
    jumping in!
  id: totrans-395
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  id: totrans-396
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we took a deep dive into some advanced aspects of Lambda. Some
    of these behaviors and configurations will be crucial as you deploy your serverless
    applications to production.
  id: totrans-397
  prefs: []
  type: TYPE_NORMAL
- en: 'You learned about the following:'
  id: totrans-398
  prefs: []
  type: TYPE_NORMAL
- en: The various different error handling strategies of Lambda and how you may choose
    to configure and program your functions to process errors
  id: totrans-399
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The liberating way that Lambda scales without any effort on your part, how you
    can control that scaling, and what this behavior means in the context of multi-threaded
    programming
  id: totrans-400
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: What Lambda versions and aliases are, and how to use them with a “traffic shifting”
    approach for releasing new features
  id: totrans-401
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: What cold starts are, when they occur, whether you should be concerned about
    them, and how to mitigate them if you need to reduce their impact in your applications
  id: totrans-402
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How to consider persistent and cache state in Lambda development
  id: totrans-403
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How to use Lambda with AWS VPCs
  id: totrans-404
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: What Lambda layers and custom runtimes are, and when to think about using them
  id: totrans-405
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In the next chapter, we carry on rounding out our discussion of the more advanced
    aspects of Lambda, but this time in the context of how Lambda interacts with other
    services.
  id: totrans-406
  prefs: []
  type: TYPE_NORMAL
- en: Exercises
  id: totrans-407
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Update `WeatherQueryLambda` in [“Example: Building a Serverless API”](ch05.html#serverless-api-example)
    to throw an exception. What behavior do you see when you try to call the API?'
  id: totrans-408
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: If you implemented the exercise from [Chapter 5](ch05.html#ch05) to use an SQS
    queue, then update the Lambda function that reads from SQS to throw an exception.
    Does Lambda’s retry behavior do what you’d expect?
  id: totrans-409
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Investigate what happens with background threads and Lambda—start with the “Hello
    World” example from [Chapter 2](ch02.html#ch02) (see [“Lambda Hello World (the
    Proper Way)”](ch02.html#java-hello-world)) and within the handler use a [`ScheduledExecutorService`](https://oreil.ly/6cz67)
    and its `scheduleAtFixedRate` method to repeatedly log the event that you received.
    What happens? Try using some `Thread.sleep` statements too.
  id: totrans-410
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Update [“Example: Building a Serverless API”](ch05.html#serverless-api-example)
    to use traffic shifting, starting with the `Linear10PercentEvery10Minutes` deployment
    preference.'
  id: totrans-411
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '*Extended task*: If you program on the JVM with a different language—perhaps
    Clojure, Kotlin, or Scala—try building a Lambda function in one of those languages.'
  id: totrans-412
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
