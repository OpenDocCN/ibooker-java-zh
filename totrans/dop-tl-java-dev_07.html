<html><head></head><body><div id="sbo-rt-content"><section data-type="chapter" epub:type="chapter" data-pdf-bookmark="Chapter 7. Securing Your Binaries"><div class="chapter" id="securing_your_binaries">
<h1><span class="label">Chapter 7. </span>Securing Your Binaries</h1>


<p class="byline">Sven Ruppert</p>

<p class="byline">Stephen Chin</p>
  <blockquote data-type="epigraph" epub:type="epigraph">
    <p>Data is the pollution problem of the information age, and protecting privacy is the <span class="keep-together">environmental</span> challenge.</p>
    <p data-type="attribution">Bruce Schneier, <em>Data and Goliath</em></p>
  </blockquote>

<p>Software security is a critical part of any<a data-type="indexterm" data-primary="security" data-secondary="about" id="idm45310205876272"/> comprehensive DevOps rollout. New breaches uncovered in the past year have called attention to the consequences of weak software security, and have prompted the creation of new government security regulations. The impact of meeting these new regulations spans across the entire software lifecycle, from development through production. As a result, DevSecOps is something that every software developer and DevOps professional needs to understand.</p>

<p>In this chapter, you will learn how to evaluate your product and organizational risk for security vulnerabilities. We will also cover static and dynamic techniques for security testing, and scoring techniques for risk assessment.</p>

<p>Regardless of your role, you will be better prepared to help secure your organization’s software delivery lifecycle. But first let’s look deeper into what happens if you don’t have a focus on security and take steps to secure your software supply chain.</p>






<section data-type="sect1" data-pdf-bookmark="Supply Chain Security Compromised"><div class="sect1" id="idm45310205873504">
<h1>Supply Chain Security Compromised</h1>

<p>It started in early December 2020, when FireEye noticed<a data-type="indexterm" data-primary="security" data-secondary="SolarWinds cyberattack" id="idm45310205871760"/><a data-type="indexterm" data-primary="cyberattack SolarWinds" id="idm45310205870784"/><a data-type="indexterm" data-primary="SolarWinds cyberattack" id="idm45310205870112"/><a data-type="indexterm" data-primary="FireEye tools for cyberattacks" id="idm45310205869440"/> that it had become a victim of a cyberattack, which is remarkable because the company itself specializes in detecting and fending off cyberattacks. Internal analysis showed that the attackers managed to steal FireEye internal tools, which FireEye used to examine its customers’ IT infrastructure for weak points. This highly specialized toolbox is optimized for breaking into networks and IT systems, which in the hands of hackers is a tremendous risk. It wasn’t until later that this breach and a massive cyberattack known as the <em>SolarWinds hack</em> were discovered to be connected. (FireEye has since become Trellix, through a merger.)</p>

<p>SolarWinds, a company based in the United States, specializes in the management of complex IT network structures. For this, the company developed the Orion Platform. The company itself has over 300,000 active customers who use this software internally. The software for managing network components has to be equipped with generous administrative rights within the IT systems in order to be able to carry out its tasks, which is one of the critical points the hackers used in their strategy. It took some time to recognize the connection between the FireEye hack and the later, massive cyberattacks, because the chain of effects was not as direct as previous vulnerability breaches.</p>

<p>Because of the long gap between exploitation of the SolarWinds vulnerability and discovery of the breach, many companies and government organizations ended up being affected by this attack. Over a period of a few weeks 20,000 successful attacks were launched. Because the pattern of the attacks was similar, security researchers were able to identify that these attacks were related. One of the common characteristics was that all of the organizations that suffered an attack used SolarWinds software to manage their network infrastructure.</p>

<p>The attackers used FireEye tools to break into SolarWinds networks. <a data-type="indexterm" data-primary="continuous integration (CI)" data-secondary="SolarWinds cyberattack" id="idm45310205866944"/><a data-type="indexterm" data-primary="deployment" data-secondary="SolarWinds cyberattack" id="idm45310205865952"/>They attacked the CI pipeline, which is responsible for creating the binaries for the Orion software platform. The software delivery production line was modified so that each time a new version was run through, the resulting binary was compromised and included a backdoor prepared by the hackers. <a data-type="indexterm" data-primary="Trojan horse in SolarWinds cyberattack" id="idm45310205864560"/><a data-type="indexterm" data-primary="trust relationships exploited in SolarWinds cyberattack" id="idm45310205863872"/>The Orion Platform was used here as a Trojan horse to deliver the compromised binaries to thousands of networks. Any recipient who checked the fingerprint would see a valid binary because it was signed by SolarWinds, which is a vendor they trust. And this trust relationship is the flaw that this cyberattack takes advantage of to attack downstream networks.</p>

<p>The precise account of the way this attack was executed is as follows. The company, SolarWinds, created an update of its software and made these binaries available to all 300,000 customers via an automatic update process. Almost 20,000 customers then installed this update in a short period of time. The compromised software waited about two weeks after activation and then began to spread in the infected systems. As if that wasn’t bad enough, over time, further malware was then dynamically loaded, making it impossible to repair the compromised system without a full rebuild.</p>

<p>Stepping back a bit, let’s differentiate between the perspective of the SolarWinds company and the perspective of the affected customers. Whose responsibility is it to mitigate this attack, and what does the procedure look like if you are affected yourself? Which tools can you use to identify and address the vulnerability? Who can take action against such attacks, and at what point in the vulnerability timeline?</p>








<section data-type="sect2" data-pdf-bookmark="Security from the Vendor Perspective"><div class="sect2" id="idm45310205862048">
<h2>Security from the Vendor Perspective</h2>

<p>First, let’s start with the perspective of a<a data-type="indexterm" data-primary="security" data-secondary="SolarWinds cyberattack" data-tertiary="vendor perspective" id="idm45310205860752"/><a data-type="indexterm" data-primary="SolarWinds cyberattack" data-secondary="vendor perspective" id="idm45310205859504"/> software manufacturer (in this example, SolarWinds) that distributes software to its customers. When a supply-chain attack is carried out, you have to prepare yourself because you will be only the carrier of the viral software. Compared to a conventional attack, the damage is amplified because you are enabling hackers to open a security hole in thousands of your customers. Preventing this requires a stringent approach in your software development and distribution process.</p>

<p>Securing the tools used in your software delivery pipeline is one of the most important aspects, because they have access to your internal systems and can maliciously modify binaries in your software pipeline. However, this is challenging because the number of direct and indirect tools used in software delivery lifecycles is constantly increasing and expanding the attack surface.</p>
</div></section>













<section data-type="sect2" data-pdf-bookmark="Security from the Customer Perspective"><div class="sect2" id="idm45310205857392">
<h2>Security from the Customer Perspective</h2>

<p>As a customer of a vendor like SolarWinds,<a data-type="indexterm" data-primary="security" data-secondary="SolarWinds cyberattack" data-tertiary="customer perspective" id="idm45310205855984"/><a data-type="indexterm" data-primary="SolarWinds cyberattack" data-secondary="customer perspective" id="idm45310205854736"/> it is essential to consider all elements in the value chain, including all of the tools that a software developer uses daily. You also have to check the binaries generated from your CI/CD system for the possibility of modification or vulnerability injection. It is essential to keep an overview of all components used with a secure and traceable bill of materials. Ultimately, it helps only if you break your own products into their constituent parts and subject each element to a security review.</p>

<p>How can you protect yourself as a consumer? The approach that all elements in the value chain must be subjected to a critical review also applies here. As shown in the SolarWinds case, individual fingerprints and the exclusive use of confidential sources do not provide the best possible protection. The components used must be subjected to a deeper security inspection.</p>
</div></section>













<section data-type="sect2" data-pdf-bookmark="The Full Impact Graph"><div class="sect2" id="idm45310205852128">
<h2>The Full Impact Graph</h2>

<p>A <em>full impact graph</em> represents all areas<a data-type="indexterm" data-primary="full impact graph of security vulnerabilities" id="idm45310205850176"/><a data-type="indexterm" data-primary="security" data-secondary="full impact graph of vulnerabilities" id="idm45310205849344"/> of an application that are affected by the known vulnerability. Analyzing a full impact graph requires tools to check for known weak points. These tools can develop their full potential only if they can recognize and represent the interrelationships across technology boundaries. Without considering a full impact graph, it is easy to focus on just one technology, which can quickly lead to dangerous pseudosecurity.</p>

<p>As an example, let’s say we are building a JAR with Maven; this JAR is used inside a WAR to be deployed inside a servlet container. Additionally, it is a best practice to pack this JAR inside a Docker image to deploy to production. The production configuration is also stored in Helm charts that are used to organize the Docker deployment. Suppose we can identify this compromised JAR inside the WAR that is part of the Docker image deployed by the Helm chart that is part of the active production environment. Tracing the vulnerability from a Helm chart through to the encapsulated JAR requires knowledge about the full impact graph.</p>

<p>The SolarWinds hack demonstrates the need to analyze a full impact graph in order to discover vulnerabilities in a supply chain. If you find a vulnerability in a binary file, the relevance of this vulnerability depends on how the file is used. You need to know where this file is used, and the potential risk caused by this weak point if used in an operational environment. If you don’t use this binary anywhere, the vulnerability can’t do any harm; however, if the use occurs in critical areas within a company, significant risk arises.</p>

<p>Assume that we are focusing on scanning Docker images only. We will get the information that the Docker image contains vulnerabilities and can mitigate the vulnerability in the Docker image. But we are missing information about all other places where this infected binary is used as well. We need to know the usage of this binary in all different layers and technologies. Just focusing on the usage inside Docker images could lead to open security holes in other parts of our environment where the binary is used directly.</p>

<p>In <a data-type="xref" href="#common-vulnerability-sect">“The Common Vulnerability Scoring System”</a>, we will show you how to use the environmental metric to precisely assess the context and use this information to make more-informed risk assessments.</p>
</div></section>





</div></section>













<section data-type="sect1" data-pdf-bookmark="Securing Your DevOps Infrastructure"><div class="sect1" id="idm45310205872880">
<h1>Securing Your DevOps Infrastructure</h1>

<p>Now that you understand the impact<a data-type="indexterm" data-primary="security" data-secondary="DevOps infrastructure" data-tertiary="about" id="idm45310205844336"/> of security vulnerabilities, it is time to look at countermeasures we can utilize to improve the security of our full software development lifecycle. First, let’s shed some light on the procedures and roles used in a DevOps environment.</p>








<section data-type="sect2" data-pdf-bookmark="The Rise of DevSecOps"><div class="sect2" id="idm45310205842832">
<h2>The Rise of DevSecOps</h2>

<p>Let’s briefly go over how development and<a data-type="indexterm" data-primary="security" data-secondary="DevOps infrastructure" data-tertiary="rise of DevSecOps" id="idm45310205841360"/><a data-type="indexterm" data-primary="DevSecOps" id="idm45310205840112"/><a data-type="indexterm" data-primary="DevOps" data-secondary="DevSecOps" id="idm45310205839440"/> operations merged to become DevOps, because it plays a central role in introducing security. DevOps started with the basic recognition that the two areas of developers and operations have to work closer together in order to improve productivity. The fundamental stages of DevOps map directly to the process of building and delivering software to production.</p>

<p>Before DevOps, a big split existed in responsibilities, with a release build used as the handover point between groups. DevOps changes the roles to be more inclusive; developers need to understand the intricacies of doing production deployments, and vice versa. This change requires more-advanced automated tooling and repositories, as well as shared knowledge and processes.</p>

<p>But what about security? Security is not and should never be an explicit step in software development. Safety is a crosscutting issue that goes through all phases of production through operation. This, in turn, brings the realization that no dedicated safety officer can do this work alone. The team as a whole is entrusted with the issue of safety, just as they are, for example, with the issue of quality.</p>

<p>The outcome of this realization was the creation of the term <em>DevSecOps</em>. However, some subtleties here cannot be ignored. Not everyone in the production chain can do all things equally well. Everyone has their own idiosyncrasies and is more efficient in some areas. Accordingly, even in a DevSecOps organization, some team members care more about the dev area, and others have their strengths in the ops area.</p>
</div></section>













<section data-type="sect2" data-pdf-bookmark="The Role of SREs in Security"><div class="sect2" id="idm45310205835856">
<h2>The Role of SREs in Security</h2>

<p>An exception to the dev and ops specialization<a data-type="indexterm" data-primary="security" data-secondary="DevOps infrastructure" data-tertiary="site reliability engineers" id="idm45310205834096"/><a data-type="indexterm" data-primary="site reliability engineering (SRE)" data-secondary="role of site reliability engineer" id="idm45310205832832"/> is the <em>site reliability engineer</em> (SRE) role. The term originally comes from Google and describes the people on a team who deal with the reliability of services. <a data-type="indexterm" data-primary="site reliability engineering (SRE)" data-secondary="failure budget" id="idm45310205831312"/><a data-type="indexterm" data-primary="failure budget" id="idm45310205830304"/>The metric against which an SRE works is called the <em>failure budget</em>. It is assumed that the software has failures and that this is exactly what leads to downtimes. A service has a specific failure budget, or downtime budget. The SRE aims to keep service uptime within the defined budget by reducing downtime due to bugs, damage, or cyberattacks. To meet these goals, the SRE may choose to invest downtime on upgrades that can be used to deploy quality and security improvements to the system.</p>

<p>Therefore, an SRE is a team member whose role is to ensure the balance between the robustness of the systems and the introduction of new features. For this purpose, the SRE is given up to a maximum of 50% of their working time to focus on the operations tasks and responsibilities. This time should be used to automate the systems and improve quality and security. The rest of the SRE’s time is spent working as a developer and involved in implementing new features. And now we come to the exciting question: is an SRE also responsible for security?</p>

<p>This role of an SRE can be in the middle of a DevSecOps structure since the working hours and skills are almost evenly split between the dev and ops areas, so both concepts can coexist inside the same organization.</p>

<p>SREs are usually developers with many years of experience who now specialize in the ops area, or an administrator with many years of professional experience who is now deliberately entering into software development. With this in mind, the position of an SRE is a perfect place to merge the dev and ops strategies for crosscutting issues.</p>

<p>Considering the example of SolarWinds again, the question arises of who has the most influence within the value chain to take action against vulnerabilities. For this purpose, we will look at the two areas dev and ops and the options available there.</p>
</div></section>





</div></section>













<section data-type="sect1" data-pdf-bookmark="Static and Dynamic Security Analysis"><div class="sect1" id="idm45310205826432">
<h1>Static and Dynamic Security Analysis</h1>

<p>Two main types of security analysis exist: static application security testing and dynamic application security testing. Let’s examine what these mean and how the two approaches differ.</p>








<section data-type="sect2" data-pdf-bookmark="Static Application Security Testing"><div class="sect2" id="idm45310205824832">
<h2>Static Application Security Testing</h2>

<p><em>Static application security testing</em> (SAST) analyzes<a data-type="indexterm" data-primary="security" data-secondary="static application security testing" id="idm45310205823072"/><a data-type="indexterm" data-primary="static application security testing (SAST)" id="idm45310205822032"/><a data-type="indexterm" data-primary="testing" data-secondary="static application security testing" id="idm45310205821264"/><a data-type="indexterm" data-primary="SAST" data-see="static application security testing" id="idm45310205820304"/> an application at a specific point in time. It’s static. The focus is on recognizing and localizing the known vulnerabilities.</p>

<p>SAST is a so-called clear-testing process in which you look at the system internals to do the analysis. For this procedure, you need to have access to the source code of the application to be tested. However, an operational runtime environment does not have to be available. The application does not have to be executed for this procedure, which is why the term <em>static</em> is also used. Three types of security threats can be identified using SAST:</p>

<ul>
<li>
<p>Does the source code have gaps in the functional area that allow, for example, “tainted code” to be smuggled in? These are lines that can later infiltrate malware.</p>
</li>
<li>
<p>Do any source code lines allow you to connect to files or certain object classes? The focus is also on detecting and preventing the introduction of malware.</p>
</li>
<li>
<p>Do gaps exist on the application level that allow you to interact with other programs unnoticed?</p>
</li>
</ul>

<p>However, it should be noted that the analysis of the source code is itself a complex matter. The area of static security analysis also includes the tools that enable you to determine and evaluate all contained direct and indirect dependencies.</p>

<p>As a rule, various SAST tools should check the source code at regular intervals. The SAST source code scanners must also be adapted to your organizational needs with an initial implementation to adjust the scanner to your respective domain. <a data-type="indexterm" data-primary="Open Web Application Security Project (OWASP)" id="idm45310205813792"/><a data-type="indexterm" data-primary="security" data-secondary="Open Web Application Security Project" id="idm45310205813056"/><a data-type="indexterm" data-primary="vulnerabilities in security" data-secondary="Open Web Application Security Project" id="idm45310205812096"/>The Open Web Application Security Project (OWASP) Foundation offers assistance; it not only lists typical security vulnerabilities, but also recommends suitable SAST tools.</p>










<section data-type="sect3" data-pdf-bookmark="Advantages of the SAST approach"><div class="sect3" id="idm45310205810672">
<h3>Advantages of the SAST approach</h3>

<p>In comparison with security tests done at later stages<a data-type="indexterm" data-primary="security" data-secondary="static application security testing" data-tertiary="advantages" id="idm45310205809408"/><a data-type="indexterm" data-primary="static application security testing (SAST)" data-secondary="advantages" id="idm45310205808096"/><a data-type="indexterm" data-primary="testing" data-secondary="static application security testing" data-tertiary="advantages" id="idm45310205807056"/> in the software delivery process, a static security analysis approach offers the following advantages:</p>

<ul>
<li>
<p>Because vulnerability detection testing takes place in the development phase, removing the weak points can be carried out much more cost-effectively compared to detection that takes place only at runtime. By accessing the source code, you can also understand how this vulnerability came about and prevent it from recurring in the future. These findings cannot be obtained using an opaque-testing process.</p>
</li>
<li>
<p>Partial analysis can be done, which means that even non-executable source text can be analyzed. The static security analysis can be carried out by the developers themselves, which significantly reduces the need for security experts.</p>
</li>
</ul>

<p>A 100% analysis of the system at the source code level is also possible, which cannot be guaranteed with a dynamic approach. Opaque-testing systems can perform only penetration tests, which are an indirect analysis.</p>
</div></section>













<section data-type="sect3" data-pdf-bookmark="Disadvantages of the SAST approach"><div class="sect3" id="idm45310205802512">
<h3>Disadvantages of the SAST approach</h3>

<p>Since you are starting with the source code, SAST seems like it has the potential to be the most comprehensive security scanning approach. However, in practice it has fundamental problems:</p>

<ul>
<li>
<p>The programming work often suffers, which in turn manifests itself in domain-specific bugs. The developers focus too much on the security tests and related bug fixes.</p>
</li>
<li>
<p>The tools can be problematic. This happens especially if the scanners have not been adapted to your entire tech stack. Most systems are polyglot these days. To get a complete list of known vulnerabilities, you need a tool that supports all direct or indirect technologies.</p>
</li>
<li>
<p>SAST often replaces the subsequent security tests completely. However, all problems that are directly related to an application in operation remain undetected.</p>
</li>
<li>
<p>Focusing on your source code is not enough. The static scan must analyze the binaries and additionally the source code if possible.</p>
</li>
</ul>

<p>In <a data-type="xref" href="#how-much-scanning-sect">“How Much Is Enough?”</a>, we will show why you should focus on scanning binaries first.</p>
</div></section>



</div></section>













<section data-type="sect2" data-pdf-bookmark="Dynamic Application Security Testing"><div class="sect2" id="idm45310205795216">
<h2>Dynamic Application Security Testing</h2>

<p><em>Dynamic application security testing</em> (DAST) is<a data-type="indexterm" data-primary="security" data-secondary="dynamic application security testing" id="ch07-dast"/><a data-type="indexterm" data-primary="dynamic application security testing (DAST)" id="ch07-dast2"/><a data-type="indexterm" data-primary="testing" data-secondary="dynamic application security testing" id="ch07-dast3"/><a data-type="indexterm" data-primary="DAST" data-see="dynamic application security testing" id="idm45310205789696"/> security analysis of a running application (usually a running web application). A wide variety of attack scenarios are performed in order to identify as many of the weak points as possible in the application. The term <em>dynamic</em> indicates that a running application must be available to carry out the tests. It is critical that the test system behaves the same as the production environment. Even minor variations can represent serious differences, including different configurations or upstream load balancers and firewalls.</p>

<p>DAST is an opaque-testing process in which the application is viewed only from the outside. The technologies used do not play a role in the type of security check, as the application is accessed only generically and externally. This means that all information that could be obtained from the source code is invisible for this type of test. It is, therefore, possible for the person testing to test for the typical problems with a generic set of tools. The benchmark OWASP project offers reasonable assistance for selecting a scanner for your own project. This evaluates the performance of the individual tools in relation to the specific application background.</p>










<section data-type="sect3" data-pdf-bookmark="Advantages of DAST"><div class="sect3" id="idm45310205787360">
<h3>Advantages of DAST</h3>

<p>The DAST process has the following advantages:</p>

<ul>
<li>
<p>Security analysis works in a technology-neutral manner.</p>
</li>
<li>
<p>The scanners find errors in the runtime environment in which the test is carried out.</p>
</li>
<li>
<p>The rate of false positives is low.</p>
</li>
<li>
<p>The tools find faulty configurations in basically functional applications. For example, you can identify performance problems that other scanners cannot.</p>
</li>
<li>
<p>The DAST programs can be used in all phases of development and in a later operation.</p>
</li>
</ul>

<p>DAST scanners are based on the same concepts that real attackers use for their malware. They, therefore, provide reliable feedback on weaknesses. Tests have consistently shown that the majority of DAST tools can identify<a data-type="indexterm" data-primary="Open Web Application Security Project (OWASP)" data-secondary="top 10 most common threats" id="idm45310205780432"/><a data-type="indexterm" data-primary="security" data-secondary="Open Web Application Security Project" data-tertiary="top 10 most common threats" id="idm45310205779296"/><a data-type="indexterm" data-primary="vulnerabilities in security" data-secondary="Open Web Application Security Project" data-tertiary="top 10 most common threats" id="idm45310205778048"/> <a href="https://oreil.ly/3MmBn">the top 10 most common threats</a> listed by the OWASP Foundation.</p>
</div></section>













<section data-type="sect3" data-pdf-bookmark="Disadvantages of DAST"><div class="sect3" id="idm45310205775664">
<h3>Disadvantages of DAST</h3>

<p>Using DAST tools has several disadvantages:</p>

<ul>
<li>
<p>The scanners are programmed to carry out specific attacks on functional web apps and can usually be adapted only by security experts with the necessary product knowledge. They, therefore, offer little space for individual scaling.</p>
</li>
<li>
<p>DAST tools are slow; they can take several days to complete their analysis.</p>
</li>
<li>
<p>DAST tools find some security gaps very late in the development cycle that could have been discovered earlier via SAST. The costs of fixing the related problems are therefore higher than they should be.</p>
</li>
<li>
<p>DAST scans are based on known bugs. Scanning for new types of attacks takes a relatively long time. Therefore, modifying the existing tool is often not possible. If it is doable, it requires in-depth knowledge about the attack vector itself and how to implement it inside the DAST tool.<a data-type="indexterm" data-startref="ch07-dast" id="idm45310205770720"/><a data-type="indexterm" data-startref="ch07-dast2" id="idm45310205770016"/><a data-type="indexterm" data-startref="ch07-dast3" id="idm45310205769344"/></p>
</li>
</ul>
</div></section>



</div></section>













<section data-type="sect2" data-pdf-bookmark="Comparing SAST and DAST"><div class="sect2" id="idm45310205768032">
<h2>Comparing SAST and DAST</h2>

<p><a data-type="xref" href="#sast_vs_dast">Table 7-1</a> summarizes the differences<a data-type="indexterm" data-primary="security" data-secondary="static application security testing" data-tertiary="dynamic versus" id="idm45310205765984"/><a data-type="indexterm" data-primary="security" data-secondary="dynamic application security testing" data-tertiary="static versus" id="idm45310205764704"/><a data-type="indexterm" data-primary="testing" data-secondary="dynamic application security testing" data-tertiary="static versus" id="idm45310205763472"/><a data-type="indexterm" data-primary="testing" data-secondary="static application security testing" data-tertiary="dynamic versus" id="idm45310205762240"/><a data-type="indexterm" data-primary="static application security testing (SAST)" data-secondary="dynamic versus" id="idm45310205761008"/><a data-type="indexterm" data-primary="dynamic application security testing (DAST)" data-secondary="static versus" id="idm45310205759968"/> between the SAST and DAST testing approaches.</p>
<table id="sast_vs_dast" style="width: 100%">
<caption><span class="label">Table 7-1. </span>SAST versus DAST</caption>
<thead>
<tr>
<th>SAST</th>
<th>DAST</th>
</tr>
</thead>
<tbody>
<tr>
<td><p>Clear security testing
</p><p>• The tester has access to the underlying framework, design, and implementation.
</p><p>• The application is tested from the inside out.
</p><p>• This type of testing represents the developer approach.</p></td>
<td><p>Opaque security testing
</p><p>• The tester has no knowledge of the technologies or framework that the application is built on.
</p><p>• The application is tested from the outside in.
</p><p>• This type of testing represents the hacker approach.</p></td>
</tr>
<tr>
<td><p>Requires source code
</p><p>• SAST doesn’t require a deployed application.
</p><p>• It analyzes the source code or binary without executing the application.</p></td>
<td><p>Requires a running application
</p><p>• DAST doesn’t require source code or binaries.
</p><p>• It analyzes by executing the application.</p></td>
</tr>
<tr>
<td><p>Find vulnerabilities earlier in the SDLC
</p><p>• The scan can be executed as soon as code is deemed feature complete.</p></td>
<td><p>Finds vulnerabilities toward the end of the SDLC
</p><p>• Vulnerabilities can be discovered after the development cycle is complete.</p></td>
</tr>
<tr>
<td><p>Less expensive to fix vulnerabilities
</p><p>• Since vulnerabilities are found earlier in the SDLC, remediating them is easier and faster.
</p><p>• Finding can often be fixed before the code enters the QA cycle.</p></td>
<td><p>More expensive to fix vulnerabilities
</p><p>• Since vulnerabilities are found toward the end of the SDLC, remediation often gets pushed into the next development cycle.
</p><p>• Critical vulnerabilities may be fixed as an emergency release.</p></td>
</tr>
<tr>
<td><p>Can’t discover runtime and environmental issues
</p><p>• Since the tool scans static code, it cannot discover runtime vulnerabilities.</p></td>
<td><p>Can discover runtime and environmental issues
</p><p>• Since the tool uses dynamic analysis on a running application, it is able to find runtime vulnerabilities.</p></td>
</tr>
<tr>
<td><p>Typically supports all kinds of software
</p><p>• Examples include web applications, web services, and thick clients.</p></td>
<td><p>Typically scans only web apps and web services
</p><p>• DAST is not useful for other types of software.</p></td>
</tr>
</tbody>
</table>

<p>If you look at the advantages and disadvantages of these two types of security testing, you can see that they are not mutually exclusive. On the contrary, these approaches complement each other perfectly. SAST can be used to identify known vulnerabilities. DAST can be used to identify vulnerabilities that are not yet known. This is primarily the case if the new attack is based on the pattern of common vulnerabilities.  You also gain knowledge about the overall system if you carry out these tests on the production system. However, as soon as you run DAST on test systems, you lose these last-mentioned capabilities again.</p>
</div></section>





</div></section>













<section data-type="sect1" data-pdf-bookmark="Interactive Application Security Testing"><div class="sect1" id="idm45310205737872">
<h1>Interactive Application Security Testing</h1>

<p><em>Interactive application security testing</em> (IAST) uses<a data-type="indexterm" data-primary="security" data-secondary="interactive application security testing" id="idm45310205735984"/><a data-type="indexterm" data-primary="testing" data-secondary="interactive application security testing" id="idm45310205734912"/><a data-type="indexterm" data-primary="interactive application security testing (IAST)" id="idm45310205733936"/><a data-type="indexterm" data-primary="IAST" data-see="interactive application security testing" id="idm45310205733232"/> software tools to evaluate application performance and identify vulnerabilities. IAST takes an “agent-like” approach; agents and sensors run to continuously analyze application functions during automated tests, manual tests, or a mixture of both.</p>

<p>The process and feedback occur in real-time in the IDE, CI or QA environment, or during production. The sensors have access to the following:</p>

<ul>
<li>
<p>All source code</p>
</li>
<li>
<p>Data and control flow</p>
</li>
<li>
<p>System configuration data</p>
</li>
<li>
<p>Web components</p>
</li>
<li>
<p>Backend connection data</p>
</li>
</ul>

<p>The main difference between IAST, SAST, and DAST is that IAST runs inside the application. Access to all static components as well as the runtime information enables a comprehensive picture. It is a combination of static and dynamic analysis. However, the part of the dynamic analysis is not a pure opaque test, as it is implemented at DAST.</p>

<p>IAST helps identify potential problems earlier, so IAST minimizes the cost of eliminating potential costs and delays. This is due to a <em>shift left</em> approach, meaning it is carried out in the early stages of the project lifecycle. Similar to SAST, the IAST analysis provides complete lines of data-rich code so that security teams can immediately look out for a specific bug. With the wealth of information that the tool has access to, the source of vulnerabilities can be precisely identified. Unlike other dynamic software tests, IAST can be easily integrated into CI/CD pipelines. The evaluations take place in real time in the production environment.</p>

<p>On the other hand, IAST tools can slow the operation of the application. This is because the agents change the bytecode themselves. This leads to a lower performance of the overall system. The change itself can also lead to problems in the production environment. The use of agents represents a potential source of danger since these agents can also be compromised as happened in the SolarWinds hack.</p>
</div></section>













<section data-type="sect1" data-pdf-bookmark="Runtime Application Self-Protection"><div class="sect1" id="idm45310205724416">
<h1>Runtime Application Self-Protection</h1>

<p><em>Runtime application self-protection</em> (RASP) is<a data-type="indexterm" data-primary="security" data-secondary="runtime application self-protection" id="idm45310205722720"/><a data-type="indexterm" data-primary="runtime application self-protection (RASP)" id="idm45310205721776"/> the approach to secure the application from within. The check takes place at runtime and generally consists of looking for suspicious commands when they are executed.</p>

<p>With the RASP approach, you can examine the entire application context on the production machine in real time.<a data-type="indexterm" data-primary="AI in RASP" id="idm45310205720432"/><a data-type="indexterm" data-primary="machine learning in RASP" id="idm45310205719728"/><a data-type="indexterm" data-primary="RASP" data-see="runtime application self-protection" id="idm45310205719040"/> Here all commands that are processed are examined for possible attack patterns. Therefore, this procedure aims to identify existing security gaps and attack patterns and those that are not yet known. Here it goes clearly into the use of AI and machine learning (ML) techniques.</p>

<p>RASP tools can usually be used in two operating modes. The first operating mode (monitoring) is limited to observing and reporting possible attacks. The second operating mode (protection) then includes implementing defensive measures in real time and directly on the production environment. <a data-type="indexterm" data-primary="static application security testing (SAST)" data-secondary="runtime versus" id="idm45310205716976"/><a data-type="indexterm" data-primary="dynamic application security testing (DAST)" data-secondary="runtime versus" id="idm45310205715968"/><a data-type="indexterm" data-primary="security" data-secondary="static application security testing" data-tertiary="runtime versus" id="idm45310205714992"/><a data-type="indexterm" data-primary="security" data-secondary="dynamic application security testing" data-tertiary="runtime versus" id="idm45310205713760"/><a data-type="indexterm" data-primary="testing" data-secondary="dynamic application security testing" data-tertiary="runtime versus" id="idm45310205712528"/>RASP aims to fill the gap left by application security testing and network perimeter controls. SAST and DAST do not have sufficient visibility into real-time data and event flows to prevent vulnerabilities from sliding through the verification process or to block new threats that were overlooked during development.</p>

<p>RASP is similar to IAST. <a data-type="indexterm" data-primary="interactive application security testing (IAST)" data-secondary="runtime versus" id="idm45310205710784"/><a data-type="indexterm" data-primary="security" data-secondary="interactive application security testing" data-tertiary="runtime versus" id="idm45310205709776"/>The main difference is that IAST focuses on identifying vulnerabilities in the applications, and RASP focuses on protecting against cybersecurity attacks that can exploit these vulnerabilities or other attack vectors.</p>

<p>The RASP technology has the following advantages:</p>

<ul>
<li>
<p>RASP complements SAST and DAST with an additional layer of protection after the application is started (usually in production).</p>
</li>
<li>
<p>RASP can be easily applied with faster development cycles.</p>
</li>
<li>
<p>Unexpected entries are checked and identified in RASP.</p>
</li>
<li>
<p>RASP enables you to react quickly to an attack by providing comprehensive analysis and information about the possible vulnerabilities.</p>
</li>
</ul>

<p>However, since RASP tools sit on the application server, they can adversely affect application performance. In addition, the RASP technology may not be compliant with regulations or internal guidelines, because it allows the installation of other software or the automatic blocking of services. The use of this technology can also give a false sense of security and is not a substitute for application security testing, because it cannot provide comprehensive protection. Finally, the application must also be switched offline until the vulnerability is eliminated.</p>

<p>While RASP and IAST have similar methods and uses, RASP does not perform extensive scans but instead runs as part of the application to examine traffic and activity. Both report attacks as soon as they occur; with IAST, this happens at the time of the test, whereas with RASP, it takes place at runtime in production.</p>
</div></section>













<section data-type="sect1" data-pdf-bookmark="SAST, DAST, IAST, and RASP Summary"><div class="sect1" id="idm45310205702592">
<h1>SAST, DAST, IAST, and RASP Summary</h1>

<p>All approaches result in a wide range<a data-type="indexterm" data-primary="security" data-secondary="static application security testing" id="idm45310205700352"/><a data-type="indexterm" data-primary="security" data-secondary="dynamic application security testing" id="idm45310205699312"/><a data-type="indexterm" data-primary="security" data-secondary="interactive application security testing" id="idm45310205698352"/><a data-type="indexterm" data-primary="interactive application security testing (IAST)" id="idm45310205697312"/><a data-type="indexterm" data-primary="static application security testing (SAST)" id="idm45310205696608"/><a data-type="indexterm" data-primary="dynamic application security testing (DAST)" id="idm45310205695904"/><a data-type="indexterm" data-primary="testing" data-secondary="dynamic application security testing" id="idm45310205695200"/><a data-type="indexterm" data-primary="testing" data-secondary="dynamic application security testing" data-tertiary="runtime versus" id="idm45310205694240"/><a data-type="indexterm" data-primary="testing" data-secondary="dynamic application security testing" data-tertiary="static versus" id="idm45310205693008"/><a data-type="indexterm" data-primary="testing" data-secondary="static application security testing" data-tertiary="dynamic versus" id="idm45310205691776"/><a data-type="indexterm" data-primary="testing" data-secondary="interactive application security testing" id="idm45310205690544"/><a data-type="indexterm" data-primary="interactive application security testing (IAST)" data-secondary="runtime versus" id="idm45310205689568"/><a data-type="indexterm" data-primary="dynamic application security testing (DAST)" data-secondary="runtime versus" id="idm45310205688592"/><a data-type="indexterm" data-primary="dynamic application security testing (DAST)" data-secondary="static versus" id="idm45310205687616"/><a data-type="indexterm" data-primary="static application security testing (SAST)" data-secondary="dynamic versus" id="idm45310205686640"/><a data-type="indexterm" data-primary="static application security testing (SAST)" data-secondary="runtime versus" id="idm45310205685664"/><a data-type="indexterm" data-primary="runtime application self-protection (RASP)" data-secondary="SAST, DAST, IAST versus" id="idm45310205684688"/><a data-type="indexterm" data-primary="security" data-secondary="runtime application self-protection" data-tertiary="SAST, DAST, IAST versus" id="idm45310205683712"/><a data-type="indexterm" data-primary="security" data-secondary="interactive application security testing" data-tertiary="runtime versus" id="idm45310205682480"/><a data-type="indexterm" data-primary="security" data-secondary="dynamic application security testing" data-tertiary="runtime versus" id="idm45310205681232"/><a data-type="indexterm" data-primary="security" data-secondary="dynamic application security testing" data-tertiary="static versus" id="idm45310205680000"/><a data-type="indexterm" data-primary="security" data-secondary="static application security testing" data-tertiary="dynamic versus" id="idm45310205678768"/><a data-type="indexterm" data-primary="security" data-secondary="static application security testing" data-tertiary="runtime versus" id="idm45310205677536"/> of options for arming yourself against known and unknown security gaps. Reconciling your own needs and those of the company is essential when choosing your approach.</p>

<p>With RASP, the application can protect itself against attacks at runtime. The permanent monitoring of your activities and the data transferred to the application enable an analysis based on the runtime environment. Here you can choose between pure monitoring or alerting, and active self-protection. However, software components are added to the runtime environment with RASP approaches to manipulate the system independently. This has an impact on performance. With this approach, RASP concentrates on the detection and defense of current cyberattacks. So it analyzes the data and user behavior in order to identify suspicious activities.</p>

<p>The IAST approach combines the SAST and DAST approaches and is already used within the SDLC—that is, within the development itself. This means that the IAST tools are already further “to the left” compared to the RASP tools. Another difference to the RASP tools is that IAST consists of static, dynamic, and manual tests. Here it also becomes clear that IAST is more in the development phase. The combination of dynamic, static, and manual tests promises a comprehensive security solution. However, we should not underestimate the complexity of the manual and dynamic security tests at this point.</p>

<p>The DAST approach focuses on how a hacker would approach the system. The overall system is viewed as opaque, and the attacks occur without knowing the technologies used. The point here is to harden the production system against the most common vulnerabilities. However, we must not forget at this point that this technology can be used only at the end of the production cycle.</p>

<p>If you have access to all system components, the SAST approach can be used effectively against known security gaps and license problems. This procedure is the only guarantee that the entire tech stack can be subjected to direct control. The focus of the SAST approach is on static semantics and, in turn, is completely blind to security holes in the dynamic context. A huge advantage is that this approach can be used with the first line of source code.</p>

<p>In my experience, if you start with DevSecOps or security in IT in general, the SAST approach makes the most sense. This is where the greatest potential threat can be eliminated with minimal effort. It is also a process that can be used in all steps of the production line. Only when all components in the system are secured against known security gaps do the following methods show their highest potential. After introducing SAST, I would use the IAST approach and, finally, the RASP approach. This also ensures that the respective teams can grow with the task and that no obstacles or delays occur in production.</p>
</div></section>













<section data-type="sect1" data-pdf-bookmark="The Common Vulnerability Scoring System"><div class="sect1" id="common-vulnerability-sect">
<h1>The Common Vulnerability Scoring System</h1>

<p>The basic idea behind the <em>Common Vulnerability Scoring System</em> (CVSS) is<a data-type="indexterm" data-primary="security" data-secondary="Common Vulnerability Scoring System" data-tertiary="about" id="idm45310205670576"/><a data-type="indexterm" data-primary="Common Vulnerability Scoring System (CVSS)" data-secondary="about" id="idm45310205669264"/> to provide a general classification of the severity of a security vulnerability. The weak points found are evaluated from various points of view. These elements are weighed against each other to obtain a standardized number from 0 to 10.</p>

<p>A rating system, like CVSS, allows us to evaluate various weak points abstractly and derive follow-up actions from them. The focus is on standardizing the handling of these weak points. As a result, you can define actions based on the value ranges.</p>

<p>In principle, CVSS can be described so that the probability and the maximum possible damage are related using predefined factors. The basic formula for this is <span class="keep-together">risk = probability</span> of occurrence × damage.</p>

<p>These CVSS metrics are divided into three orthogonal areas that are weighted differently from one another, called Basic Metrics, Temporal Metrics, and Environmental Metrics. Different aspects are queried in each area, which must be assigned a single value. The weighting and the subsequent composition of the three group values gives the final result. The next section explores these metrics in detail.</p>








<section data-type="sect2" data-pdf-bookmark="CVSS Basic Metrics"><div class="sect2" id="idm45310205665600">
<h2>CVSS Basic Metrics</h2>

<p>The <em>basic metrics</em> form the foundation<a data-type="indexterm" data-primary="security" data-secondary="Common Vulnerability Scoring System" data-tertiary="basic metrics" id="idm45310205663472"/><a data-type="indexterm" data-primary="Common Vulnerability Scoring System (CVSS)" data-secondary="basic metrics" id="idm45310205662128"/> of the CVSS rating system. The aim of querying aspects in this area is to record technical details of the vulnerability that will not change over time, so the assessment is independent of other changing elements. Different parties can carry out the calculation of the base value. It can be done by the discoverer, the manufacturer of the project or product concerned, or by a computer emergency response team (CERT) charged with eliminating this weak point. We can imagine that, based on this initial decision, the value itself will turn out different since the individual groups pursue different goals.</p>

<p>The base value evaluates the prerequisites necessary for a successful attack via this security gap. This is the distinction between whether a user account must be available on the target system or whether the system can be compromised without the knowledge about a system user. These prerequisites play a significant role in whether a system is vulnerable over the internet or whether physical access to the affected component is required.</p>

<p>The base value should also reflect how complex the attack is to carry out. In this case, the complexity relates to the necessary technical steps and includes assessing whether the interaction with a regular user is essential. Is it sufficient to encourage any user to interact, or does this user have to belong to a specific system group (e.g., administrator)? The correct classification is not a trivial process; the assessment of a new vulnerability requires exact knowledge of this vulnerability and the systems concerned.</p>

<p>The basic metrics also take into account the damage that this attack could cause to the affected component. The three areas of concern are as follows:</p>
<dl>
<dt>Confidentiality</dt>
<dd>
<p>Possibility of extracting the data from the system</p>
</dd>
<dt>Integrity</dt>
<dd>
<p>Possibility of manipulating the system</p>
</dd>
<dt>Availability</dt>
<dd>
<p>Completely preventing the system’s use</p>
</dd>
</dl>

<p>However, you have to be careful concerning the weighting of these areas of concern. In one case, having stolen data can be worse than changed data. In another case, the unusability of a component can be the worst damage to be assumed.</p>

<p>The <em>scope metric</em> has also been available since CVSS version 3.0. This metric looks at the effects of an affected component on other system components. For example, a compromised element in a virtualized environment enables access to the carrier system. A successful change of this scope represents a greater risk for the overall system and is therefore also evaluated using this factor. This demonstrates that the interpretation of the values also requires adjusting to one’s situation, which brings us to the temporal and environment metrics.</p>
</div></section>













<section data-type="sect2" data-pdf-bookmark="CVSS Temporal Metrics"><div class="sect2" id="idm45310205652352">
<h2>CVSS Temporal Metrics</h2>

<p>The time-dependent components of the<a data-type="indexterm" data-primary="security" data-secondary="Common Vulnerability Scoring System" data-tertiary="temporal metrics" id="idm45310205650848"/><a data-type="indexterm" data-primary="Common Vulnerability Scoring System (CVSS)" data-secondary="temporal metrics" id="idm45310205649632"/> vulnerability assessment are brought together in the <em>temporal metrics</em> group.</p>

<p>The elements that change over time influence these temporal metrics. For example, the availability of tools that support the exploitation of the vulnerability may change. These can be exploits code or step-by-step instructions. A distinction must be made on whether a vulnerability is theoretical or whether a manufacturer has officially confirmed it. All of these events change the base value.</p>

<p>Temporal metrics are unique in that the base value can be only reduced and not increased. The initial rating is intended to represent the worst-case scenario. This has both advantages and disadvantages if you bear in mind that it is during the initial assessment of a vulnerability that interests are competing.</p>

<p>The influence on the initial evaluation comes about through external framework conditions. These take place over an undefined time frame and are not relevant for the actual basic assessment. Even if an exploit is already in circulation during the base values survey, this knowledge will not be included in the primary assessment. However, the base value can only be reduced by the temporal metrics.</p>

<p>And this is where a conflict arises. The person or group who has found a security gap tries to set the base value as high as possible. A high-severity loophole will sell for a higher price and receive more media attention. The reputation of the person/group who found this gap increases as a result. The affected company or the affected project is interested in exactly the opposite assessment. Therefore, it depends on who finds the security gap, how the review process should take place, and by which body the first evaluation is carried out. This value is further adjusted by the environmental metrics.</p>
</div></section>













<section data-type="sect2" data-pdf-bookmark="CVSS Environmental Metrics"><div class="sect2" id="idm45310205645104">
<h2>CVSS Environmental Metrics</h2>

<p>For <em>environmental metrics</em>, your own<a data-type="indexterm" data-primary="security" data-secondary="Common Vulnerability Scoring System" data-tertiary="environmental metrics" id="idm45310205643360"/><a data-type="indexterm" data-primary="Common Vulnerability Scoring System (CVSS)" data-secondary="environmental metrics" id="idm45310205642064"/> system landscape is used to evaluate the risk of the security gap. The evaluation is adjusted based on the real situation. In contrast to temporal metrics, environmental metrics can correct the base value in both directions. The environment can therefore lead to a higher classification and must also be constantly adapted to your own environment changes.</p>

<p>Let’s take an example of a security hole that has an available patch from the manufacturer. The mere presence of this modification leads to a reduction of the total value in the temporal metrics. However, as long as the patch has not been activated in your own systems, the overall value must be drastically corrected upward again via the environmental metrics. This is because as soon as a patch is available, it can be used to better understand the security gap and its effects. The attacker has more detailed information that can be exploited, which reduces the resistance of the not-yet-hardened systems.</p>

<p>At the end of an evaluation, the final score is obtained, calculated from the three previously mentioned values. The resulting value is then assigned to a value group. But one more point is often overlooked. In many cases, the final score is simply carried over without individual adjustments utilizing the environmental score. This behavior leads to a dangerous evaluation that is incorrect for the overall system concerned.</p>
</div></section>













<section data-type="sect2" data-pdf-bookmark="CVSS in Practice"><div class="sect2" id="idm45310205639472">
<h2>CVSS in Practice</h2>

<p>With CVSS, we have a system<a data-type="indexterm" data-primary="security" data-secondary="Common Vulnerability Scoring System" data-tertiary="implementation" id="idm45310205638144"/><a data-type="indexterm" data-primary="Common Vulnerability Scoring System (CVSS)" data-secondary="implementation" id="idm45310205636832"/> for evaluating and rating security gaps in software. Since there are no alternatives, CVSS has become a de facto standard; the system has been in use worldwide for over 10 years and is constantly being developed. The evaluation consists of three components.</p>

<p>First, the basic score depicts a purely technical worst-case scenario. The second component is the evaluation of the time-dependent corrections based on external influences—including further findings, tools, or patches for this security gap—which can be used to reduce the value. The third component of the assessment is your own system environment with regard to this vulnerability. With this consideration, the security gap is adjusted in relation to the real situation on site. Last but not least, an overall evaluation is made from these three values, which results in a number from 0.0 to 10.0.</p>

<p>This final value can be used to control your own organizational response to defend against the security gap. At first glance, everything feels quite abstract, so it takes some practice to get a feel for the application of CVSS, which can be developed through experience with your own systems.</p>
</div></section>





</div></section>













<section data-type="sect1" data-pdf-bookmark="Scoping Security Analysis"><div class="sect1" id="idm45310205672544">
<h1>Scoping Security Analysis</h1>

<p>As soon as we deal with security, the following questions always come up: how much effort is enough, where should you start, and how quickly can you get the first results? In this section, we deal with how to take these first steps. For this, we look at two concepts and consider the associated effects.</p>








<section data-type="sect2" data-pdf-bookmark="Time to Market"><div class="sect2" id="idm45310205632368">
<h2>Time to Market</h2>

<p>You have probably heard of the<a data-type="indexterm" data-primary="security" data-secondary="analysis" data-tertiary="time to market" id="idm45310205630992"/><a data-type="indexterm" data-primary="time to market for security" id="idm45310205629744"/> term <em>time to market</em>, but how does this relate to security? In general terms, this expression means that the desired functionality is transferred as quickly as possible from conception through development into the production environment.  This allows the customer to start benefiting from the new functionality, which increases business value.</p>

<p>At first glance, time to market seems focused on business use cases only, but it is equally relevant when applied to security remediation. Activating the required modifications to the overall system as quickly as possible is also optimal. In short, the term <em>time to market</em> is a common and worthwhile goal for security implementation.</p>

<p>The process for business use cases should be the same as remediating security vulnerabilities. They both require as much automation as possible, and all human interaction must be as short as possible. All interactions that waste time increase the potential that the vulnerability will be used against the production system.</p>
</div></section>













<section data-type="sect2" data-pdf-bookmark="Make or Buy"><div class="sect2" id="idm45310205626608">
<h2>Make or Buy</h2>

<p>Across all layers of a cloud native stack,<a data-type="indexterm" data-primary="security" data-secondary="analysis" data-tertiary="make or buy" id="idm45310205625104"/> the majority of the software and technology is bought or acquired rather than made. We will go through the layers in <a data-type="xref" href="#make_or_buy">Figure 7-1</a> and talk about the software composition at each.</p>

<figure><div id="make_or_buy" class="figure">
<img src="Images/dtjd_0701.png" alt="Architecture diagram of a DevSecOps implementation" width="393" height="800"/>
<h6><span class="label">Figure 7-1. </span>DevSecOps components that you can decide to build or purchase</h6>
</div></figure>

<p>The first layer is the development of the application itself. Assuming that we are working with Java and using Maven as a dependency manager, we are most likely adding more lines of code indirectly as dependencies compared to the number of lines we are writing ourselves. The dependencies are the more prominent part, and third parties develop them. We have to be careful, and it is good advice to check these external binaries for known vulnerabilities. We should have the same behavior regarding compliance and license usage.</p>

<p>The next layer is the operating system, which is typically Linux. And again, we are adding configuration files, and the rest are existing binaries. The result is an application running inside the operating system that is a composition of external binaries based on our configuration.</p>

<p>The two following layers, Docker and Kubernetes, lead us to the same result. Until now, we are not looking at the tool stack for the production line itself. All programs and utilities that are directly or indirectly used under the hood for DevSecOps create dependencies. All layers’ dependencies are the most significant part by far. Checking these binaries against known vulnerabilities is the first logical step.</p>
</div></section>













<section data-type="sect2" data-pdf-bookmark="One-Time and Recurring Efforts"><div class="sect2" id="idm45310205617968">
<h2>One-Time and Recurring Efforts</h2>

<p>Comparing the effort of scanning against known vulnerabilities and for compliance issues, we see a few differences. Let’s start with the compliance issues.</p>










<section data-type="sect3" data-pdf-bookmark="Compliance issues"><div class="sect3" id="idm45310205616544">
<h3>Compliance issues</h3>

<p>The first step in scoping compliance<a data-type="indexterm" data-primary="security" data-secondary="analysis" data-tertiary="compliance" id="idm45310205615216"/><a data-type="indexterm" data-primary="compliance issues" id="idm45310205613968"/> is defining which licenses are allowed at which part of the production line. This definition of allowed licenses includes the dependencies during development and the usage of tools and runtime environments. Defining the noncritical license types should be checked by a specialized compliance process. With this list of allowed license types, we can start using the build automation to scan the full tool stack on a regular basis. After the machine has found a violation, we have to remove this element, and it must be replaced by another that is licensed.</p>
</div></section>













<section data-type="sect3" data-pdf-bookmark="Vulnerabilities"><div class="sect3" id="idm45310205612912">
<h3>Vulnerabilities</h3>

<p>The ongoing effort to scan for vulnerabilities<a data-type="indexterm" data-primary="security" data-secondary="analysis" data-tertiary="vulnerabilities" id="idm45310205611616"/><a data-type="indexterm" data-primary="vulnerabilities in security" data-secondary="about scanning for versus fixing" id="idm45310205610368"/><a data-type="indexterm" data-primary="security" data-secondary="vulnerabilities" data-tertiary="discovery of" id="idm45310205609344"/><a data-type="indexterm" data-primary="vulnerabilities in security" data-secondary="combined into attack vectors" data-tertiary="discovery of vulnerabilities" id="idm45310205608128"/> is low compared to the amount of work required to fix vulnerabilities. A slightly different workflow is needed for the handling of discovered vulnerabilities. With more significant preparations, the build automation can do the work on a regular basis as well. The identification of a vulnerability will trigger a workflow that includes human interaction. The vulnerability must be classified internally, which leads to a decision about the next action to take.</p>
</div></section>



</div></section>













<section data-type="sect2" data-pdf-bookmark="How Much Is Enough?"><div class="sect2" id="how-much-scanning-sect">
<h2>How Much Is Enough?</h2>

<p>So let’s come back to the initial question in this section.<a data-type="indexterm" data-primary="security" data-secondary="analysis" data-tertiary="how much is enough" id="idm45310205604784"/> How much scanning is enough? No change is too small, because all changes that have to do with adding or changing dependencies will cause you to reevaluate the security and run a new scan. Checking for known vulnerabilities or checking the license being used can be carried out efficiently by automation.</p>

<p>Another point that should not be underestimated is that the quality with which such an examination is carried out is constant, as nobody is involved at this point. If the value chain’s speed is not slowed by constantly checking all dependencies, this is a worthwhile investment.</p>
</div></section>













<section data-type="sect2" data-pdf-bookmark="Compliance Versus Vulnerabilities"><div class="sect2" id="idm45310205602064">
<h2>Compliance Versus Vulnerabilities</h2>

<p>One other difference exists between<a data-type="indexterm" data-primary="compliance issues" data-secondary="vulnerabilities versus" id="idm45310205600720"/><a data-type="indexterm" data-primary="security" data-secondary="analysis" data-tertiary="compliance versus vulnerabilities" id="idm45310205599744"/><a data-type="indexterm" data-primary="vulnerabilities in security" data-secondary="compliance issues versus" id="idm45310205598464"/><a data-type="indexterm" data-primary="security" data-secondary="vulnerabilities" data-tertiary="compliance versus" id="idm45310205597488"/> compliance issues and vulnerabilities. If a compliance issue exists, it is a singular point inside the overall environment. Just this single part is a defect and is not influencing other elements of the environment, as shown in <a data-type="xref" href="#compliance">Figure 7-2</a>.</p>

<figure><div id="compliance" class="figure">
<img src="Images/dtjd_0702.png" alt="Circle diagram showing compliance issues in single layers of an application" width="600" height="530"/>
<h6><span class="label">Figure 7-2. </span>Layers of an application where compliance issues can be found</h6>
</div></figure>
</div></section>





</div></section>













<section data-type="sect1" data-pdf-bookmark="Vulnerabilities Can Be Combined into Different Attack Vectors"><div class="sect1" id="idm45310205593024">
<h1>Vulnerabilities Can Be Combined into Different <span class="keep-together">Attack Vectors</span></h1>

<p>Vulnerabilities are a bit different.<a data-type="indexterm" data-primary="security" data-secondary="vulnerabilities" data-tertiary="combined into attack vectors" id="idm45310205590848"/><a data-type="indexterm" data-primary="vulnerabilities in security" data-secondary="combined into attack vectors" id="idm45310205589536"/> They do not exist only at the point where they are located. Additionally, they can be combined with other existing vulnerabilities in any additional layer of the environment, as shown in <a data-type="xref" href="#vulnerabilities">Figure 7-3</a>. Vulnerabilities can be combined into different attack vectors. Every possible attack vector itself must be seen and evaluated. A set of minor vulnerabilities in different layers of the application can be combined into a highly critical risk.</p>

<figure><div id="vulnerabilities" class="figure">
<img src="Images/dtjd_0703.png" alt="Circle diagram showing attack vectors across multiple layers of an application" width="600" height="578"/>
<h6><span class="label">Figure 7-3. </span>Vulnerabilities in multiple layers of an application</h6>
</div></figure>








<section data-type="sect2" data-pdf-bookmark="Vulnerabilities: Timeline from Inception Through Production Fix"><div class="sect2" id="idm45310205585280">
<h2>Vulnerabilities: Timeline from Inception Through Production Fix</h2>

<p>Again and again, we read something in the IT news about security gaps that have been exploited. The more severe the classification of this loophole, the more attention this information will get in the general press. Most of the time, we hear and read nothing about all the security holes found that are not as well-known as the SolarWinds hack. <a data-type="indexterm" data-primary="vulnerabilities in security" data-secondary="combined into attack vectors" data-tertiary="about timeline" id="idm45310205583360"/><a data-type="indexterm" data-primary="security" data-secondary="vulnerabilities" data-tertiary="about timeline" id="idm45310205582080"/>The typical timeline of a vulnerability is shown in <a data-type="xref" href="#vulnerability-timeline">Figure 7-4</a>.</p>

<figure><div id="vulnerability-timeline" class="figure">
<img src="Images/dtjd_0704.png" alt="Timeline showing the lifecycle of a vulnerability" width="289" height="800"/>
<h6><span class="label">Figure 7-4. </span>Timeline of a vulnerability</h6>
</div></figure>










<section data-type="sect3" data-pdf-bookmark="Creation of a vulnerability"><div class="sect3" id="idm45310205577680">
<h3>Creation of a vulnerability</h3>

<p>Let’s start with the birth of a vulnerability.<a data-type="indexterm" data-primary="security" data-secondary="vulnerabilities" data-tertiary="creation of" id="idm45310205576336"/><a data-type="indexterm" data-primary="vulnerabilities in security" data-secondary="combined into attack vectors" data-tertiary="creation of vulnerabilities" id="idm45310205575088"/> This can be done in two ways. On the one hand, it can happen to any developer who has an unfortunate combination of source code pieces that creates a security hole. On the other hand, it can also be based on targeted manipulation. However, this has essentially no effect on the further course of the lifeline of a security vulnerability. In the following, we assume that a security hole has been created and that it is now active in some software. These can be executable programs or libraries integrated into other software projects as a dependency.</p>
</div></section>













<section data-type="sect3" data-pdf-bookmark="Discovery of the vulnerability"><div class="sect3" id="idm45310205572832">
<h3>Discovery of the vulnerability</h3>

<p>In most cases, it is not possible to understand<a data-type="indexterm" data-primary="security" data-secondary="vulnerabilities" data-tertiary="discovery of" id="idm45310205571328"/><a data-type="indexterm" data-primary="vulnerabilities in security" data-secondary="combined into attack vectors" data-tertiary="discovery of vulnerabilities" id="idm45310205570080"/> precisely when a security hole was created, but let’s assume that a security hole exists and that at some point it will be discovered. A few different scenarios could occur, depending on who finds the security hole first.</p>

<p>If a malicious actor finds the security hole, they will probably try to keep it a secret so they can profit from it. The two ways to profit are either to exploit the security hole themselves or to sell information about the security hole to an interested party. In either case, the quicker they are able to profit from the security hole, the less likely it is discovered and patched.</p>

<p>Conversely, if the security hole is found by ethical attackers, they will first verify that the security hole can be exploited without doing any damage, and then disclose it to the affected parties. Often a financial motivation exists for this as well. These can be driven by bug bounties and rewards by companies aware of their potential for security holes and willing to pay to have them disclosed to the company rather than to attackers. Also, companies that maintain vulnerability databases are incentivized to find security holes and disclose them to their customer base in advance of making them publicly known.</p>

<p>And yet another possibility is that the company discovers the security vulnerability by itself. In this case, the company may be inclined to either hide the vulnerability or present it as harmless. However, the best approach is to fix the vulnerability as soon as possible, because a malicious actor could soon discover the vulnerability or perhaps already knows about it and is waiting to exploit it.</p>

<p>Regardless of the route via which the knowledge comes to the vulnerability databases, only when the information has reached one of these points can we assume that this knowledge will be available to the general public over time.</p>
</div></section>













<section data-type="sect3" data-pdf-bookmark="Public availability of the vulnerability"><div class="sect3" id="idm45310205565584">
<h3>Public availability of the vulnerability</h3>

<p>Each provider of security vulnerabilities<a data-type="indexterm" data-primary="security" data-secondary="vulnerabilities" data-tertiary="public availability of" id="idm45310205564160"/><a data-type="indexterm" data-primary="vulnerabilities in security" data-secondary="combined into attack vectors" data-tertiary="public availability of vulnerability" id="idm45310205562912"/> has a subset of all publicly disclosed vulnerabilities. To get a more holistic set of vulnerabilities, you need to aggregate multiple sources. Furthermore, since the vulnerability databases are constantly being updated, this needs to be an automated process.</p>

<p>It is also crucial that the vulnerabilities are processed in such a way that further processing by machines is possible. <a data-type="indexterm" data-primary="CVE (Common Vulnerabilities and Exposures) value" id="idm45310205560768"/><a data-type="indexterm" data-primary="CVSS value" data-seealso="Common Vulnerability Scoring System" id="idm45310205559968"/><a data-type="indexterm" data-primary="metadata" data-secondary="CVSS value" id="idm45310205559008"/><a data-type="indexterm" data-primary="metadata" data-secondary="CVE value" id="idm45310205558064"/><a data-type="indexterm" data-primary="data" data-secondary="metadata" data-tertiary="CVE value" id="idm45310205557120"/><a data-type="indexterm" data-primary="data" data-secondary="metadata" data-tertiary="CVSS value" id="idm45310205555904"/><a data-type="indexterm" data-primary="continuous integration (CI)" data-secondary="CVSS value interrupting process" id="idm45310205554688"/>Critical meta-information such as the CVE or the CVSS value needs to be included. For example, the CVSS value can be used in CI environments to interrupt further processing when a specific threshold value is reached.</p>

<p>As an end user, there is really only one way to go here. Instead of contacting the providers directly, you should rely on services that integrate a wide variety of sources and offer a processed and merged database. Since the information generally represents a considerable financial value, commercial providers of such data sets invest a lot of resources to make sure it is accurate and up-to-date.</p>
</div></section>













<section data-type="sect3" data-pdf-bookmark="Fixing the vulnerability in production"><div class="sect3" id="idm45310205552288">
<h3>Fixing the vulnerability in production</h3>

<p>Once the information is publicly disclosed<a data-type="indexterm" data-primary="security" data-secondary="vulnerabilities" data-tertiary="fixing in production" id="idm45310205550816"/><a data-type="indexterm" data-primary="vulnerabilities in security" data-secondary="fixing in production" id="idm45310205549568"/> and made available to you through one of many security providers, you can start to take action. The key factor is the amount of time it takes for your organization to identify and mitigate the security vulnerability.</p>

<p>The first step is the consumption of the vulnerability from your chosen security provider. This is hopefully fully automated with an API that you can use to consume vulnerabilities, security scanners that are continuously scanning your production deployments, and reporting that notifies you quickly about any new vulnerabilities.</p>

<p>The next step is to develop, test, and deploy a fix that solves the security vulnerability. Only those who have implemented a high degree of automation can enable short response times in the delivery processes. It is also an advantage if the team concerned can easily make the necessary decisions. Lengthy approval processes are counterproductive at this point and can also cause extensive damage to the company.</p>

<p>Another point that can improve the response time is to catch security vulnerabilities in earlier stages of development. By providing security information in all production stages, vulnerabilities can be caught earlier, lowering the cost of mitigation. We’ll come back to this in more detail in <a data-type="xref" href="#shift-left-sect">“Shift Security Left”</a>.</p>
</div></section>



</div></section>













<section data-type="sect2" data-pdf-bookmark="Test Coverage Is Your Safety Belt"><div class="sect2" id="idm45310205545264">
<h2>Test Coverage Is Your Safety Belt</h2>

<p>The best knowledge of security gaps is of<a data-type="indexterm" data-primary="security" data-secondary="vulnerabilities" data-tertiary="test coverage" id="idm45310205543904"/><a data-type="indexterm" data-primary="vulnerabilities in security" data-secondary="test coverage" id="idm45310205542656"/><a data-type="indexterm" data-primary="testing" data-secondary="security vulnerability test coverage" id="idm45310205541744"/> no use if this knowledge cannot be put to use. But what tools do you have in software development to take efficient action against known security gaps? I want to highlight one metric in particular: the test coverage of your own source code parts. If you have strong test coverage, you can make changes to the system and rely on the test suite. If a smooth test of all affected system components has taken place, nothing stands in the way of making the software available from a technical point of view.</p>

<p>But let’s take a closer look at the situation.<a data-type="indexterm" data-primary="version control systems" data-secondary="security vulnerability mitigation" id="idm45310205539696"/> In most cases, known security vulnerabilities are removed by changing the version used for the same dependency. Therefore, efficient version management gives you the agility you need to be able to react quickly. In very few cases, the affected components have to be replaced by semantic equivalents from other manufacturers. And to classify the new composition of versions of the same components as valid, strong test coverage is required. Manual tests would go far beyond the time frame and cannot be carried out with the same quality in every run. Mutation testing gives you much more concrete test coverage than is usually the case with the conventional line or branch coverage.</p>

<p>To get a picture of the full impact graph based on all known vulnerabilities, it is crucial to understand all package managers included by the dependencies. Focusing on just one layer in the tech stack is by far not enough. Package managers like Artifactory provide information, including vendor-specific metadata. This can be augmented with security scanning tools like JFrog Xray that consume this knowledge and can scan all binaries hosted inside the repositories managed by your package manager.</p>
</div></section>





</div></section>













<section data-type="sect1" data-pdf-bookmark="Quality Gate Methodology"><div class="sect1" id="idm45310205537424">
<h1>Quality Gate Methodology</h1>

<p>With respect to a security response,<a data-type="indexterm" data-primary="security" data-secondary="quality gate method" data-tertiary="about" id="idm45310205535456"/><a data-type="indexterm" data-primary="quality gate method" data-secondary="about" id="idm45310205534208"/><a data-type="indexterm" data-primary="vulnerabilities in security" data-secondary="quality gate method" data-tertiary="about" id="idm45310205533264"/> the success of IT projects is dependent on participation and involvement of end users as early as possible, the support of higher management, and the formulation of clear business goals. By managing these factors, a software project can quickly address security vulnerabilities and mitigate risk to the corporation.</p>

<p>The demand for comprehensive support from higher management provides, among other things, systematic control of the quality and progress of IT projects in good time by using criteria in order to be able to intervene. By specifying criteria, management has two ways of controlling the software development process:</p>

<ul>
<li>
<p>The criteria are project management specifications that the developer must adhere to.</p>
</li>
<li>
<p>Project management can intervene in the event of a deviation from the defined target.</p>
</li>
</ul>

<p>The group responsible for setting and enforcing these criteria can be different depending on the management system. The distribution of roles is also controversially discussed again and again. However, it turns out that a more substantial involvement of all team members leads to dynamic and successful structures.</p>

<p>In the context of project control, measures can be taken to counteract undesirable developments within a project. The ideal case for project participants is that security risks do not impact the continuation of the project. In extreme cases, however, it is also possible to cancel the project. Timeliness means being able to take action before significant financial damage can occur.</p>

<p>At the same time, however, this presupposes that relevant and measurable results are available to make effective project control sensible and possible. The end of activity within a project is a suitable time for this, as results are available that can be checked. However, because of the large number of activities within a project, too frequent checks by the project management team would slow the project’s progress. In addition, there would be a more significant burden on project management with many parallel projects (which would all have to be monitored).</p>

<p>A middle ground is to establish control and steering at specific significant points as binding for each project. For this purpose, quality gates offer an opportunity to check the degree of fulfillment of the individual quality goals. A <em>quality gate</em> is a special point in time in a project at which a decision about the continuation or termination of a project is made based on a formal examination of quality-related criteria.</p>

<p>Metaphorically speaking, quality gates are barriers between the various process steps of a project: once the quality gate has been reached, a project can be continued only if all criteria, or at least a sufficiently large number of criteria, are met. This ensures that all results of the project at the time of the quality gate are good enough to be able to continue working with them. Using the criteria of a quality gate, the results on the one hand and the qualitative requirements for the results on the other can be determined. They can then be used to define the interfaces between individual project phases. To establish quality gates, certain structures, activities, roles, documents, and resources are necessary, which are summarized in a quality gate reference process.</p>

<p>The precise design of the quality gate reference process is based on the company’s needs. Quality gates have their origins in automobile development and in the production of technical goods, but they have increasingly found their way into system development projects and recently also into pure software development projects.</p>

<p>Quality gates in series production rely on statistically determined values that can be used as a target for control activities in future projects. Such a starting position does not exist in software development, since software development projects are highly individual. As a result, a quality gate reference process practiced in assembly-line production can be transferred to software development to only a limited extent. Instead, a suitable quality gate reference process must be designed differently in order to do justice to the particular problems of software development. However, it makes sense to use the quality gate reference processes from other domains as they have been developed and optimized over the years.</p>








<section data-type="sect2" data-pdf-bookmark="Quality Gate Strategies"><div class="sect2" id="idm45310205524800">
<h2>Quality Gate Strategies</h2>

<p>When using quality gates, two basic strategies have been identified. Depending on the objective, a company can choose one of these two strategies, described next,  when designing a quality gate reference process.</p>










<section data-type="sect3" data-pdf-bookmark="Quality gates as uniform quality guideline"><div class="sect3" id="idm45310205523344">
<h3>Quality gates as uniform quality guideline</h3>

<p>In the first approach, every project<a data-type="indexterm" data-primary="quality gate method" data-secondary="strategies" data-tertiary="uniform quality guideline" id="idm45310205521888"/><a data-type="indexterm" data-primary="security" data-secondary="quality gate method" data-tertiary="uniform quality guideline" id="idm45310205520576"/><a data-type="indexterm" data-primary="vulnerabilities in security" data-secondary="quality gate method" data-tertiary="uniform quality guideline" id="idm45310205519344"/> has to go through the same quality gates and is measured against the same criteria. The adaptation of a quality gate reference process that follows this strategy is permissible to a minimal extent (if at all). The aim is to achieve at least the same level of quality in every project; a qualitative guideline is thus established for every project.</p>

<p>Quality gates can therefore be used as a uniform measure of progress. We can compare progress between projects by checking which tasks have already passed a particular quality gate and which have not. Management can easily recognize when a project is behind another project (qualitatively) and act accordingly. Quality gates can thus easily be used as an instrument for multiproject management.</p>
</div></section>













<section data-type="sect3" data-pdf-bookmark="Quality gates as a flexible quality strategy"><div class="sect3" id="idm45310205516544">
<h3>Quality gates as a flexible quality strategy</h3>

<p>In the second approach, the number,<a data-type="indexterm" data-primary="quality gate method" data-secondary="strategies" data-tertiary="flexible quality strategy" id="idm45310205515184"/><a data-type="indexterm" data-primary="security" data-secondary="quality gate method" data-tertiary="flexible quality strategy" id="idm45310205513872"/><a data-type="indexterm" data-primary="vulnerabilities in security" data-secondary="quality gate method" data-tertiary="flexible quality strategy" id="idm45310205512640"/> arrangement, and selection of quality gates or criteria can be adapted to the needs of a project. Quality gates and standards can thus be tailored more precisely to a project’s qualitative requirements, improving the quality of results. However, this makes comparing multiple projects more difficult. Fortunately, similar projects will have comparable quality gates and can be measured against similar criteria.</p>

<p>Researching the topic of quality gates<a data-type="indexterm" data-primary="quality gate method" data-secondary="strategies" data-tertiary="not reviews or milestones" id="idm45310205510448"/><a data-type="indexterm" data-primary="security" data-secondary="quality gate method" data-tertiary="not reviews or milestones" id="idm45310205509136"/><a data-type="indexterm" data-primary="vulnerabilities in security" data-secondary="quality gate method" data-tertiary="not reviews or milestones" id="idm45310205507904"/> on the internet and in the literature (dissertations, standard works, and conference volumes) reveals a wide range of terms. Because synonymous terms are used in many places, quality gates are often mistakenly equated with various other concepts. A <em>review</em> or <em>milestone</em>, for example, should not be equated with a quality gate.</p>
</div></section>



</div></section>













<section data-type="sect2" data-pdf-bookmark="Fit with Project Management Procedures"><div class="sect2" id="idm45310205504944">
<h2>Fit with Project Management Procedures</h2>

<p>The question arises whether this methodology<a data-type="indexterm" data-primary="quality gate method" data-secondary="project management" id="idm45310205503504"/><a data-type="indexterm" data-primary="security" data-secondary="quality gate method" data-tertiary="project management" id="idm45310205502528"/><a data-type="indexterm" data-primary="vulnerabilities in security" data-secondary="quality gate method" data-tertiary="project management" id="idm45310205501312"/><a data-type="indexterm" data-primary="project management" data-secondary="quality gate method" id="idm45310205500032"/> can be applied to other project management processes. The answer here is a resounding yes. The quality gate methodology can be integrated into cyclical as well as acyclical project methods. The time sequence is irrelevant at this point and can therefore also be used in classic waterfall projects at the milestone level.</p>

<p>The significant advantage is that this method can still be used in the case of a paradigm shift in project management. The knowledge built up in a team can continue to be used and does not lose its value. This means that the measures described here can be introduced and used regardless of the current project implementation.</p>
</div></section>













<section data-type="sect2" data-pdf-bookmark="Implementing Security with the Quality Gate Method"><div class="sect2" id="idm45310205498320">
<h2>Implementing Security with the Quality Gate Method</h2>

<p>We will introduce, define, and<a data-type="indexterm" data-primary="quality gate method" data-secondary="implementing" id="idm45310205496784"/><a data-type="indexterm" data-primary="security" data-secondary="quality gate method" data-tertiary="implementing" id="idm45310205495808"/><a data-type="indexterm" data-primary="vulnerabilities in security" data-secondary="quality gate method" data-tertiary="implementing" id="idm45310205494592"/><a data-type="indexterm" data-primary="DevSecOps" data-secondary="quality gate method" id="idm45310205493312"/> use a greatly simplified approach to integrate the crosscutting issue of security. In the following, we assume that the quality gate methodology is suitable for implementing any cross-sectional topic. The temporal component is also irrelevant and can therefore be used in any cyclical project management methodology. This approach is therefore ideally suited for integration into the DevSecOps project organization methodology.</p>

<p>The DevOps process is divided into stages. The individual phases are seamlessly connected to one another. It makes no sense to install something at these points that interferes with the entire process. <a data-type="indexterm" data-primary="continuous integration (CI)" data-secondary="quality gate method implementation" id="idm45310205491856"/>However, there are also much better places where cross-cutting issues are located. We are talking about the automated process derivation that can be found in a CI route. Assuming that the necessary process steps to go through a quality gate can be fully automated, a CI route is ideal for doing this regularly occurring work.</p>

<p>Assuming that the CI line carries out an automated process step, two results can occur.</p>










<section data-type="sect3" data-pdf-bookmark="Green: Quality gate has passed"><div class="sect3" id="idm45310205489872">
<h3>Green: Quality gate has passed</h3>

<p>One possible result of this processing step is that all checks have passed successfully. Processing can continue uninterrupted at this point. Only a few log entries are made to ensure complete documentation.</p>
</div></section>













<section data-type="sect3" data-pdf-bookmark="Red: Failed the quality gate"><div class="sect3" id="idm45310205488320">
<h3>Red: Failed the quality gate</h3>

<p>Another possible result is that the check has found something indicating a failure. This interrupts the process, and the cause of the failure must be identified, as well as a way to remediate it. The automatic process usually ends at this point and is replaced by a manual process.</p>
</div></section>



</div></section>













<section data-type="sect2" data-pdf-bookmark="Risk Management in Quality Gates"><div class="sect2" id="idm45310205486416">
<h2>Risk Management in Quality Gates</h2>

<p>Since the quality gate is blocked<a data-type="indexterm" data-primary="quality gate method" data-secondary="risk management" id="idm45310205484896"/><a data-type="indexterm" data-primary="security" data-secondary="quality gate method" data-tertiary="risk management" id="idm45310205483920"/><a data-type="indexterm" data-primary="vulnerabilities in security" data-secondary="quality gate method" data-tertiary="risk management" id="idm45310205482704"/><a data-type="indexterm" data-primary="risk management in quality gates" id="idm45310205481424"/> by identifying a defect, someone needs to be responsible for the following steps:</p>

<ul>
<li>
<p>Risk assessment (identification, analysis, assessment, and prioritization of risks)</p>
</li>
<li>
<p>Design and initiation of countermeasures</p>
</li>
<li>
<p>Tracking of risks in the course of the project</p>
</li>
</ul>

<p>The risk determination was already completed with the creation of the criteria and their operationalization by weighing the requirements on a risk basis. This takes place during the gate review itself.</p>

<p>The conception and initiation of countermeasures is an essential activity of a gate review, at least in the event that a project is not postponed or canceled before going to production. The countermeasures to be taken primarily counteract the risks that arise from criteria that are not met.</p>

<p>The countermeasures of risk management can be divided into preventive measures and emergency measures. The <em>preventive measures</em> include meeting the criteria as quickly as possible. If this is not possible, appropriate countermeasures must be designed. The design of the countermeasures is a creative act; it depends on the risk, its assessment, and the possible alternatives.</p>

<p>The effectiveness of the countermeasures must be tracked to ensure that they are successful. This spans all phases of the project and is critical to ensuring that security vulnerabilities are caught and addressed early in the process.</p>
</div></section>













<section data-type="sect2" data-pdf-bookmark="Practical Applications of Quality Management"><div class="sect2" id="idm45310205474112">
<h2>Practical Applications of Quality Management</h2>

<p>Let’s go through a practical example of<a data-type="indexterm" data-primary="quality gate method" data-secondary="practical application" id="idm45310205472512"/><a data-type="indexterm" data-primary="security" data-secondary="quality gate method" data-tertiary="practical application" id="idm45310205471536"/><a data-type="indexterm" data-primary="vulnerabilities in security" data-secondary="quality gate method" data-tertiary="practical application" id="idm45310205470320"/> quality management in the context of a software release. For this purpose, all required components are generated and collected in the repository, and every binary has an identity and version. All elements necessary for a release are put together in a deployment bundle after they have been created successfully. In this case, a release is a composition of different binaries in their respective versions. The technology plays a subordinate role here, as the most diverse artifacts can come together in a release.</p>

<p>You can also imagine that all crucial documents are part of this compilation at this point. This can include documents such as the release notes and build information that provides information about the manufacturing process itself—for example, which JDK was used on which platform and much more. All information that can be automatically collated at this point increases the traceability and reproduction quality if a postmortem analysis has to be carried out.</p>

<p>We now have everything together and would like to start making the artifacts available. We are talking about promoting the binaries here. This can be done in your own repositories or generally available global repositories. Now the last time has come when you can still make changes.</p>

<p>We are talking about a security check as a promotional gateway. The tools used here should finally check two things. First, known vulnerabilities in the binaries need to be removed. Second, all the licenses used in all the artifacts contained must be adequate for the purpose. What becomes immediately clear here is the need for the check to be carried out independently of the technology used. This brings us back to the full impact graph. At this point, we have to get the full impact graph in order to be able to achieve a high-quality result. The repository manager, who is responsible for providing all dependent artifacts, must be seamlessly integrated with the binary scanner. One example is the combination of Artifactory and Xray.</p>

<p>But is a security check a gateway for the promotion of binaries at the earliest possible time? Where can you start earlier? We now come to the concept of shift left.</p>
</div></section>





</div></section>













<section data-type="sect1" data-pdf-bookmark="Shift Security Left"><div class="sect1" id="shift-left-sect">
<h1>Shift Security Left</h1>

<p>Agile development, DevOps, and<a data-type="indexterm" data-primary="security" data-secondary="shift left" id="ch07-left"/><a data-type="indexterm" data-primary="vulnerabilities in security" data-secondary="shift left" id="ch07-left2"/><a data-type="indexterm" data-primary="security" data-secondary="security paradox" id="idm45310205461248"/><a data-type="indexterm" data-primary="Agile" data-secondary="security and" id="ch07-left3"/><a data-type="indexterm" data-primary="DevOps" data-secondary="Agile and security mutually exclusive" id="ch07-left4"/> the implementation of security have long been considered mutually exclusive. Classic development work was always confronted with the problem that the security of a software product could not be adequately defined as a final, static, end state. This is the <em>security paradox</em> in software development.</p>

<p>It may seem that Agile development is too dynamic to be able to carry out a detailed security analysis of the software product to be developed in every development cycle. The opposite is the case because Agile and secure development techniques complement each other very well. One of the key points of Agile development is the ability to implement changes on short notice as well as changes to requirements within a short period of time.</p>

<p>In the past, security has tended to be viewed as a static process. Accordingly, application of Agile concepts to the security domain is required. The general handling of security requirements must adapt to this development in order to be able to be implemented efficiently. However, we must note that Agile development is feature-oriented. Security requirements are mostly from the category of nonfunctional features, though, and are therefore available in only an implicitly formulated form in most cases. The consequence of this, in combination with faulty security requirements engineering results, is miscalculated development cycles with increased time pressure; the sprint is canceled because of incorrect budget calculations, increased technical debts, persistent weak points, or specific security gaps within the codebase.</p>

<p>Let’s now focus on how the necessary conditions can be created in an Agile development team that improves the codebase’s security level as early as possible. Regardless of the specific project management method used, the following approaches are not restricted in their validity.</p>

<p>It is essential to set the security level so that the respective development team should achieve a security increment when performing a product increment. A team with an implicit and pronounced security focus can immediately gain a different level of security than a team without this focus. Regardless of the experience of each team, a general minimum standard must be defined and adhered to.</p>

<p>The <a href="https://owasp.org/Top10">OWASP Top 10</a> is a<a data-type="indexterm" data-primary="Open Web Application Security Project (OWASP)" data-secondary="top 10 most common threats" id="idm45310205453552"/><a data-type="indexterm" data-primary="security" data-secondary="Open Web Application Security Project" data-tertiary="top 10 most common threats" id="idm45310205452384"/><a data-type="indexterm" data-primary="vulnerabilities in security" data-secondary="Open Web Application Security Project" data-tertiary="top 10 most common threats" id="idm45310205451136"/> list of general security vulnerabilities that developers can avoid with simple measures. Accordingly, they serve as an introduction to the topic and should be part of every developer’s security repertoire. However, code reviews often reveal that teams are not adequately considering the top 10, so this is a good area to focus teams on improvement.</p>

<p>It should also be recognized that developers can do an excellent job in their field but are not security experts. In addition to different levels of experience, developers and security experts have different approaches and ways of thinking that are decisive for their respective tasks. Therefore, the development team must be aware of their limitations with regard to the assessment of attack methods and security aspects. When developing critical components or in the event of problems, the organizational option of calling in a security expert must therefore be determined in advance. Nevertheless, developers should generally be able to evaluate typical security factors and take simple steps to improve the security of the code.</p>

<p>Ideally, each team has a member who has both development and detailed security knowledge. <a data-type="indexterm" data-primary="security" data-secondary="security managers" id="idm45310205448464"/><a data-type="indexterm" data-primary="security managers (SecMs)" id="idm45310205447488"/><a data-type="indexterm" data-primary="SecMs (security managers)" id="idm45310205446800"/>In the context of supported projects, the relevant employees are referred to as security managers (SecMs). They monitor the security aspects of the developed code sections, define the attack surface and attack vectors in each development cycle, support you in assessing the user stories’ effort, and implement mitigation strategies.</p>

<p>To get a global overview of the codebase and its security level, aiming for a regular exchange between the SecMs of the teams involved makes sense. Since a company-wide synchronization of the development cycle phases is unrealistic,  SecMs should meet at regular, fixed times. In small companies or with synchronized sprints, the teams particularly benefit from an exchange during development cycle planning. In this way, cross-component security aspects and the effects of the development cycle on the security of the product increment can be assessed. The latter can currently be achieved only through downstream tests. Based on the development cycle review, a SecM meeting should also occur after implementing new components. In preparation for the next sprint, the participants evaluate the security level according to the increment.</p>

<p>OWASP Security Champions are implemented<a data-type="indexterm" data-primary="Open Web Application Security Project (OWASP)" data-secondary="Security Champions" id="idm45310205444832"/><a data-type="indexterm" data-primary="security" data-secondary="Open Web Application Security Project" data-tertiary="Security Champions" id="idm45310205443760"/><a data-type="indexterm" data-primary="vulnerabilities in security" data-secondary="Open Web Application Security Project" data-tertiary="Security Champions" id="idm45310205442528"/><a data-type="indexterm" data-primary="security managers (SecMs)" data-secondary="OWASP Security Champions versus" id="idm45310205441280"/><a data-type="indexterm" data-primary="OWASP" data-see="Open Web Application Security Project" id="idm45310205440304"/><a data-type="indexterm" data-primary="SecMs (security managers)" data-secondary="OWASP Security Champions versus" id="idm45310205439344"/> differently. These are often developers, possibly junior developers, who acquire additional security knowledge that can be very domain-specific depending on experience. Conceptual overlap occurs with the SecMs; however, a key difference is that a SecM is a full-fledged security expert with development experience who acts on the same level as the senior developer.  When implementing secure software, however, it is crucial to take into account the security-relevant effects of implementation decisions and cross-thematic specialist knowledge.</p>

<p>Regardless of whether a team can create a dedicated role, basic measures should be taken to support the process of developing secure software. <a data-type="indexterm" data-primary="security" data-secondary="shift left" data-tertiary="best practices" id="ch07-best"/><a data-type="indexterm" data-primary="vulnerabilities in security" data-secondary="shift left" data-tertiary="best practices" id="ch07-best2"/>These are the following best practice recommendations and empirical values.<a data-type="indexterm" data-startref="ch07-left" id="idm45310205433984"/><a data-type="indexterm" data-startref="ch07-left2" id="idm45310205433312"/><a data-type="indexterm" data-startref="ch07-left3" id="idm45310205432640"/><a data-type="indexterm" data-startref="ch07-left4" id="idm45310205431968"/></p>








<section data-type="sect2" data-pdf-bookmark="Not All Clean Code Is Secure Code"><div class="sect2" id="idm45310205431168">
<h2>Not All Clean Code Is Secure Code</h2>

<p><em>Clean Code</em> by Robert Martin (Pearson), <a data-type="indexterm" data-primary="Martin, Robert (“Uncle Bob”)" id="idm45310205429472"/><a data-type="indexterm" data-primary="Clean Code (Martin)" id="idm45310205428704"/><a data-type="indexterm" data-primary="clean code versus secure code" id="idm45310205428032"/><a data-type="indexterm" data-primary="security" data-secondary="secure code versus clean code" id="idm45310205427344"/>also known as Uncle Bob, coined the term <em>clean code</em>. However, a common misconception among decision makers is that clean code also covers the security of the code.</p>

<p>Safe and clean code overlap but are not the same. <em>Clean code</em> promotes understandability, maintainability, and reusability of code. <em>Secure code</em>, on the other hand, also requires predefined specifications and compliance with them. However, clean code is often a requirement for safe code. The code can be written cleanly without any security features. However, only a clean implementation opens up the full potential for security measures.</p>

<p>Well-written code is also easier to secure because the relationships between components and functions are clearly defined and delimited. Any development team looking for reasons to promote adherence to and implementation of the clean code principles will find good arguments in the security of the code, which can also be explained economically to decision makers in cost and time savings for security hardening.</p>
</div></section>













<section data-type="sect2" data-pdf-bookmark="Effects on Scheduling"><div class="sect2" id="idm45310205422944">
<h2>Effects on Scheduling</h2>

<p>In general, and particularly in Agile development,<a data-type="indexterm" data-primary="Agile" data-secondary="security and" data-tertiary="scheduling affected" id="idm45310205421552"/><a data-type="indexterm" data-primary="scheduling affected by security" id="idm45310205420304"/> teams do not allow enough time to improve the codebase when planning the next version. In sprint planning, the focus on effort assessment is primarily on time to develop a new function. Hardening is considered explicitly only when a special requirement exists.</p>

<p>The amount of time teams need to implement a function safely depends on the functionality, the status of the product increment, the existing technical debt, and the prior knowledge of the developer. However, as intended in Agile development, it should be up to the team to estimate the actual time required. Since miscalculations are to be expected, especially at the beginning, it can make sense to reduce the number of user stories adopted compared to the previous sprints.</p>
</div></section>













<section data-type="sect2" data-pdf-bookmark="The Right Contact Person"><div class="sect2" id="idm45310205418576">
<h2>The Right Contact Person</h2>

<p>Every team must have access to <a data-type="indexterm" data-primary="project management" data-secondary="security expertise" id="idm45310205417232"/><a data-type="indexterm" data-primary="security" data-secondary="expertise availability" id="idm45310205416256"/>security professionals, but it can be hard to find the right contact person in large organizations. IT security is divided into numerous, sometimes highly specific and complex, subareas for which full-time security experts are responsible. Good programmers are full-time developers and even after IT security training, cannot replace dedicated security experts.</p>

<p>It is the responsibility of project management to ensure that organizational, structural, and financial requirements are met so that teams can quickly draw on technical expertise when needed and during an assessment. This is not the case by default in most organizations.</p>
</div></section>













<section data-type="sect2" data-pdf-bookmark="Dealing with Technical Debt"><div class="sect2" id="idm45310205413872">
<h2>Dealing with Technical Debt</h2>

<p>Technical debt is an integral part of development,<a data-type="indexterm" data-primary="technical debt" id="idm45310205412464"/> and project owners should treat it as such—both in terms of time and budget. Technical debt has a negative impact on the maintainability, development, and security of the codebase. This means a significant increase in individual (new) implementation costs and a sustained slowdown in overall production by blocking developers for a more extended period of time with individual projects. Therefore, it is in the interest of everyone involved—especially management—to keep the technical debt of a codebase low and to continuously reduce it.</p>

<p>Alternatively, the substrategy is to set a fixed portion of the estimated project time for servicing technical debt. The approach is minor, as there is a risk that teams will use the time spent processing technical debt to implement a function instead and misjudge the extent of technical debt under the development cycle pressure.</p>
</div></section>













<section data-type="sect2" data-pdf-bookmark="Advanced Training on Secure Coding"><div class="sect2" id="idm45310205410080">
<h2>Advanced Training on Secure Coding</h2>

<p>A misconception exists that security<a data-type="indexterm" data-primary="training on secure coding" id="idm45310205408688"/><a data-type="indexterm" data-primary="security" data-secondary="training on" id="idm45310205407920"/><a data-type="indexterm" data-primary="Open Web Application Security Project (OWASP)" data-secondary="top 10 most common threats" id="idm45310205406976"/><a data-type="indexterm" data-primary="security" data-secondary="Open Web Application Security Project" data-tertiary="top 10 most common threats" id="idm45310205405920"/><a data-type="indexterm" data-primary="vulnerabilities in security" data-secondary="Open Web Application Security Project" data-tertiary="top 10 most common threats" id="idm45310205404672"/> can be learned in passing and that everyone has access to the necessary materials. Typically, a list of secure coding guidelines is in a public folder somewhere. In addition, the OWASP Top 10 is often published to the general public. As a rule, however, employees do not read such documents or, at best, skim them. Often, after a while, teams no longer know where such documents are, let alone what use they should get from them. Admonitions to encourage reading the guidelines are not very helpful if companies cannot create extra time to focus on secure coding.</p>
</div></section>













<section data-type="sect2" data-pdf-bookmark="Milestones for Quality"><div class="sect2" id="idm45310205403024">
<h2>Milestones for Quality</h2>

<p>Quality gates in development help<a data-type="indexterm" data-primary="quality gate method" data-secondary="definition of done" id="idm45310205401728"/><a data-type="indexterm" data-primary="security" data-secondary="quality gate method" data-tertiary="definition of done" id="idm45310205400752"/><a data-type="indexterm" data-primary="vulnerabilities in security" data-secondary="quality gate method" data-tertiary="definition of done" id="idm45310205399536"/><a data-type="indexterm" data-primary="definition of done (DoD)" id="idm45310205398256"/><a data-type="indexterm" data-primary="CI/CD (continuous integration and deployment)" data-secondary="automated quality checks" id="idm45310205397568"/><a data-type="indexterm" data-primary="continuous integration (CI)" data-secondary="quality gate method implementation" data-tertiary="automated quality checks" id="idm45310205396576"/> check compliance with quality requirements. Analogous to the <em>definition of done</em> (DoD), the team-wide definition of when a task can be viewed as completed, quality gates should not be available only in stationary paper form. Ideally, automated checks are integrated into the CI/CD pipeline through static code analyses (SAST) or the evaluation of all dependencies.</p>

<p>For developers, however, it can be helpful to receive feedback on the code and its dependencies in addition to feedback from the CI/CD pipeline during programming. Language- and platform-dependent IDE plug-ins and separate code analysis tools are available, such as FindBugs/SpotBugs, Checkstyle, and PMD. When using JFrog Xray, the IDE plug-in can be used to make it easier to compare against known vulnerabilities and compliance issues.</p>

<p>An additional upstream process for checking the code in the IDE pursues the goal of familiarizing developers with security aspects during development. As a result, the code security is improved at the points identified by the plug-in and in the entire code since developers are given a security orientation. Another side effect is the reduction in the number of false positives on the build server. The latter is exceptionally high for security quality gates, as security gaps in the code are often context-dependent and require manual verification, which leads to a considerable increase in the development effort.</p>
</div></section>













<section data-type="sect2" data-pdf-bookmark="The Attacker’s Point of View"><div class="sect2" id="idm45310205392880">
<h2>The Attacker’s Point of View</h2>

<p><em>Evil user stories</em> (also called <em>bad user stories</em>) <a data-type="indexterm" data-primary="attacker’s point of view" id="idm45310205390848"/><a data-type="indexterm" data-primary="evil user stories" id="idm45310205390048"/><a data-type="indexterm" data-primary="bad user stories" id="idm45310205389376"/>present the desired functionality from an attacker’s perspective. Analogous to user stories, they are designed so that their focus is not on the technical implementation. Accordingly, people with a limited technical background in IT security can write bad user stories. However, this increases the effort required to generate tasks from the possibly unspecific (bad) user stories.</p>

<p>Ideally, bad user stories try to<a data-type="indexterm" data-primary="attack surface" data-secondary="bad user stories depicting" id="idm45310205387792"/> depict the attack surface. They enable the development team to process identified attack methods in a familiar workflow. This creates <span class="keep-together">awareness</span> of possible attack vectors, but these are limited. Evil user stories are limited not only by the knowledge and experience of their respective authors and their imagination, but also by the developer’s ability to fend off the attack vector in the context of the sprint. It’s not just about whether the developers develop the right damage-control strategy, but also about correctly and comprehensively identifying the use case in the code.</p>

<p>Like conventional user stories, the evil variants<a data-type="indexterm" data-primary="security managers (SecMs)" data-secondary="attacker’s point of view" id="idm45310205384944"/><a data-type="indexterm" data-primary="SecMs (security managers)" data-secondary="attacker’s point of view" id="idm45310205383936"/> are not always easy to write. Teams with little experience in developing secure software, in particular, can encounter difficulties creating meaningful nasty user stories. If a SecM is on the team, that person should take on the task or offer support. Teams without a SecM should either look for external technical expertise or plan a structured process for creating the evil user stories.</p>
</div></section>













<section data-type="sect2" data-pdf-bookmark="Methods of Evaluation"><div class="sect2" id="idm45310205382176">
<h2>Methods of Evaluation</h2>

<p>To establish security as a process within<a data-type="indexterm" data-primary="Agile" data-secondary="security and" data-tertiary="code reviews" id="idm45310205380416"/><a data-type="indexterm" data-primary="CI/CD (continuous integration and deployment)" data-secondary="automated quality checks" id="idm45310205379168"/><a data-type="indexterm" data-primary="continuous integration (CI)" data-secondary="quality gate method implementation" data-tertiary="automated quality checks" id="idm45310205378160"/><a data-type="indexterm" data-primary="attack surface" data-secondary="code reviews" id="idm45310205376896"/> Agile development, regular code reviews must be carried out, with the focus on the security level of the code, both component by component and across segments. Ideally, errors that are easy to avoid and can cause security breaches can be identified and corrected as part of the CI/CD pipeline through quality gates and automated tests. In this case, the component-by-component test is primarily concerned with the investigation of the attack surface of the respective component and the weakening of attack vectors. <a data-type="indexterm" data-primary="attack surface" data-secondary="OWASP Cheat Sheet on" id="idm45310205375824"/><a data-type="indexterm" data-primary="Open Web Application Security Project (OWASP)" data-secondary="attack surfaces cheat sheet" id="idm45310205374880"/><a data-type="indexterm" data-primary="resources for learning" data-secondary="attack surfaces cheat sheet" id="idm45310205373888"/>A cheat sheet for analyzing the attack surface can be found on the <a href="https://oreil.ly/kHLm1">OWASP Cheat Sheet Series on GitHub</a>.</p>

<p>The teams must regularly redefine the attack surface, as it can change with each development cycle. The cross-component check is used to monitor the attack surface of the overall product, as it can also change with every development cycle. Ultimately, only a cross-component view enables the search for attack vectors that result from interactions between components or even dependencies.</p>

<p>If SecMs are not available, a<a data-type="indexterm" data-primary="SecMs (security managers)" data-secondary="code review" id="idm45310205370960"/><a data-type="indexterm" data-primary="security managers (SecMs)" data-secondary="code review" id="idm45310205369920"/><a data-type="indexterm" data-primary="attack surface" data-secondary="code reviews" data-tertiary="OWASP Cornucopia card game" id="idm45310205368960"/><a data-type="indexterm" data-primary="Agile" data-secondary="security and" data-tertiary="OWASP Cornucopia card game" id="idm45310205367728"/><a data-type="indexterm" data-primary="Open Web Application Security Project (OWASP)" data-secondary="Cornucopia card game" id="idm45310205366496"/><a data-type="indexterm" data-primary="Cornucopia card game (OWASP)" id="idm45310205365520"/> security assessment can be carried out through a structured approach and joint training in the team. The <a href="https://oreil.ly/dhQK3">OWASP Cornucopia card game</a> can, among other things, promote such an approach. The players try to apply the attack scenarios depicted on the cards to a domain selected in advance by the team or, if necessary, only to individual methods, such as the codebase. The team must then decide whether the attack scenario of the card played is conceivable. Therefore, the focus is on identifying attack vectors; because of time constraints, mitigation strategies should be discussed elsewhere. The winner of the card game is the one who can successfully play the most difficult cards. The team must document the resulting security analysis at the end.</p>

<p>One benefit of Cornucopia is that it increases awareness of code vulnerabilities across the team. The game also improves the developer’s expertise in IT security. The focus is on the ability of the developer and thus reflects Agile guidelines.<a data-type="indexterm" data-primary="evil user stories" data-secondary="Cornucopia card game" id="idm45310205362656"/><a data-type="indexterm" data-primary="attacker’s point of view" data-secondary="Cornucopia card game" id="idm45310205361680"/><a data-type="indexterm" data-primary="bad user stories" data-secondary="Cornucopia card game" id="idm45310205360672"/> Cornucopia sessions are an excellent tool to generate evil user stories afterward.</p>

<p>The problem with Cornucopia sessions is that they present especially inexperienced teams with a steep learning curve at the beginning. There is also a risk that the team will incorrectly discard a potential attack vector. If the preparation is poor (e.g., components are too large, or the team doesn’t have enough technical knowledge about possible attack vectors), Cornucopia can be inefficient in terms of time. Therefore, it is advisable, especially in the first few sessions, to examine small independent components and, if necessary, to consult security experts.</p>
</div></section>













<section data-type="sect2" data-pdf-bookmark="Be Aware of Responsibility"><div class="sect2" id="idm45310205359088">
<h2>Be Aware of Responsibility</h2>

<p>Overall, developers should not allow the <a data-type="indexterm" data-primary="security" data-secondary="responsibility for" id="idm45310205357792"/>code security scepter to be taken out of their hands. Ideally, the team should jointly insist on sufficient time and financial resources to implement basic security aspects.</p>

<p>Current developers will largely define and shape the world for the years to come. Because of expected digitization and networking, security must not fall victim to budget and time constraints. According to the Agile Manifesto, the codebase remains the product of the team responsible for the outcome.<a data-type="indexterm" data-startref="ch07-best" id="idm45310205355792"/><a data-type="indexterm" data-startref="ch07-best2" id="idm45310205355088"/></p>
</div></section>





</div></section>













<section data-type="sect1" data-pdf-bookmark="Summary"><div class="sect1" id="idm45310205354032">
<h1>Summary</h1>

<p>With the proliferation of supply chain attacks in the industry, addressing security is more critical than ever for the success of your project and organization. The best way to mitigate vulnerabilities quickly is to shift left and start addressing security as a primary concern from day one of every software development project. This chapter introduced you to the basics of security, including various analysis approaches, such as SAST, DAST, IAST, and RASP. You also learned about basic scoring systems like the CVSS. With this knowledge, you will be able to put the right quality gates and criteria in place to improve the security of every project that you work on going forward.</p>
</div></section>







</div></section></div></body></html>