<html><head></head><body><section data-pdf-bookmark="Chapter 3. The Dark Side of Distributed Systems" data-type="chapter" epub:type="chapter"><div class="chapter" id="distributed-system">&#13;
<h1><span class="label">Chapter 3. </span>The Dark Side of Distributed Systems</h1>&#13;
&#13;
&#13;
<p>Now that you have a better understanding of Reactive and had a brief overview of Quarkus, let’s focus on why you would want to use them and, more specifically, build reactive systems.&#13;
The reason emanates from the cloud and, more generally, the need to build <em>better</em> distributed systems. The cloud has been a game changer.&#13;
It’s making the construction of distributed systems easier.&#13;
You can create virtual resources on the fly and use off-the-shelf services.&#13;
However, <em>easier</em> does not mean <em>straightforward</em>.&#13;
Building such systems is a considerable challenge.&#13;
Why? Because the cloud is a distributed system, and distributed systems are complicated.&#13;
We need to understand the kind of animal we are trying to tame.</p>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="What’s a Distributed System?" data-type="sect1"><div class="sect1" id="idm45358832522240">&#13;
<h1>What’s a Distributed System?</h1>&#13;
&#13;
<p><a data-primary="distributed systems" data-secondary="basics" data-type="indexterm" id="ix_distributed-system-adoc0"/>There are many definitions of distributed systems.&#13;
<a data-primary="distributed systems" data-secondary="defined" data-type="indexterm" id="idm45358832519344"/>But let’s start with a loose one, written by professor emeritus Andrew Tanenbaum, and see what we can learn:</p>&#13;
<blockquote>A distributed system is a collection of independent computers that appears to its users as a single coherent system.<br/>&#13;
<br/></blockquote>&#13;
&#13;
<p>This definition highlights two important aspects of distributed systems:</p>&#13;
&#13;
<ul>&#13;
<li>&#13;
<p>A distributed system is composed of <em>independent</em> machines that are autonomous.&#13;
They can be started and stopped at any time.&#13;
These machines operate concurrently and can fail independently without affecting the whole system’s uptime (in theory, at least).</p>&#13;
</li>&#13;
<li>&#13;
<p>Consumers (users) should not be aware of the system’s structure.&#13;
It should provide a consistent experience.&#13;
Typically, you may use an HTTP service, which is served by an API gateway (<a data-type="xref" href="#figure:machine">Figure 3-1</a>), delegating requests to various <em>machines</em>.&#13;
For you, the caller, a distributed system behaves as a single coherent system: you have a single entry point and ignore the underlying structure of the system.</p>&#13;
</li>&#13;
</ul>&#13;
&#13;
<figure><div class="figure" id="figure:machine">&#13;
<img alt="Example of an HTTP service delegating calls to other machines/services" src="assets/rsij_0301.png"/>&#13;
<h6><span class="label">Figure 3-1. </span>Example of an HTTP service delegating calls to other machines/services</h6>&#13;
</div></figure>&#13;
&#13;
<p>To achieve this level of coherence, the autonomous machines must collaborate one way or another.&#13;
This collaboration and the need for good communications that arise from it are the heart of distributed systems but also their primary challenge. But that definition does not explain why we are building distributed systems.&#13;
Initially, distributed systems were workarounds.&#13;
The resources of each machine were too limited.&#13;
Connecting multiple machines was a smart way to extend the whole system’s capacity, making resources available to the other members of the network.&#13;
Today, the motivations are slightly different.&#13;
Using a set of distributed machines gives us more business <em>agility</em>, eases evolution, reduces the time to market, and from an operational standpoint, allows us to scale more quickly, improves resilience via replication, and so on.</p>&#13;
&#13;
<p>Distributed systems morphed from being a workaround to being the norm. Why? We can’t build a single machine powerful enough to handle all the needs of a major corporation, while <em>also</em> being affordable.&#13;
If we could, we’d all use the giant machine and deploy independent applications on it.&#13;
But this necessity for distribution draws new operational and business boundaries based on physical system boundaries.&#13;
Microservices, serverless architecture, service-oriented architecture (SOA), REST endpoints, mobile applications—all are distributed systems.</p>&#13;
&#13;
<p>This distribution is stressing, even more, the need for collaboration among all the components forming the system.&#13;
When an application (for instance, implemented in Java), needs to interact locally, it just uses a method call.&#13;
For example, to collaborate with a <code>service</code> exposing a <code>hello</code> method, you use <code>service.hello</code>. We stay inside the same process. Calls can be synchronous; no network I/O is involved.</p>&#13;
&#13;
<p>However, the dispersed nature of distributed systems implies interprocess communication, and most of the time, crossing the network (<a data-type="xref" href="#figure:network">Figure 3-2</a>).&#13;
Dealing with I/O and traversing the network makes these interactions considerably different.&#13;
A lot of middleware tried to make the distribution transparent, but, don’t be mistaken, complete transparency is a lie, as explained in <a href="https://oreil.ly/iCz3c">“A Note on Distributed Computing”</a> by Jim Waldo et al.&#13;
It always backfires one way or another.&#13;
You need to understand the unique nature of remote communications and realize how distinctive they are in order to build robust distributed systems.</p>&#13;
&#13;
<figure><div class="figure" id="figure:network">&#13;
<img alt="Remote interactions are leaving one process space and crossing into another process space via a network connection." src="assets/rsij_0302.png"/>&#13;
<h6><span class="label">Figure 3-2. </span>Remote interactions leave one process space and cross into another process space via a network connection</h6>&#13;
</div></figure>&#13;
&#13;
<p>The first difference is the duration.&#13;
A remote call is going to take much more time than a local call.&#13;
That time is several degrees of magnitude higher.&#13;
When everything is fine, sending a request from New York City to Los Angeles takes around 72 ms.<sup><a data-type="noteref" href="ch03.html#idm45358832499760" id="idm45358832499760-marker">1</a></sup>&#13;
Calling a local method takes less than a nanosecond.</p>&#13;
&#13;
<p>A remote call also leaves the process space, so we need an exchange protocol.&#13;
This protocol defines all the aspects of the exchange, such as who is initiating the communication, how the information is written to the wire (serialization and deserialization), how the messages are routed to the destination, and so on.</p>&#13;
&#13;
<p>When you develop your application, most of these choices are hidden from you but present under the hood.&#13;
Let’s take a REST endpoint you want to call.&#13;
You will use HTTP and most probably some JSON representation to send data and interpret the response.&#13;
Your code is relatively simple, as you can see in <a data-type="xref" href="#distributed-system::http-example">Example 3-1</a>.</p>&#13;
<div data-type="example" id="distributed-system::http-example">&#13;
<h5><span class="label">Example 3-1. </span>Invoke an HTTP service using a Java built-in client (<em>chapter-3/http-client-example/src/main/java/http/Main.java</em>)</h5>&#13;
&#13;
<pre data-code-language="java" data-type="programlisting"><code class="n">HttpClient</code> <code class="n">client</code> <code class="o">=</code> <code class="n">HttpClient</code><code class="o">.</code><code class="na">newHttpClient</code><code class="o">();</code>&#13;
<code class="n">HttpRequest</code> <code class="n">request</code> <code class="o">=</code> <code class="n">HttpRequest</code><code class="o">.</code><code class="na">newBuilder</code><code class="o">()</code>&#13;
        <code class="o">.</code><code class="na">uri</code><code class="o">(</code><code class="n">URI</code><code class="o">.</code><code class="na">create</code><code class="o">(</code><code class="s">"https://httpbin.org/anything"</code><code class="o">))</code>&#13;
        <code class="o">.</code><code class="na">build</code><code class="o">();</code>&#13;
&#13;
<code class="n">HttpResponse</code><code class="o">&lt;</code><code class="n">String</code><code class="o">&gt;</code> <code class="n">response</code> <code class="o">=</code> <code class="n">client</code><code class="o">.</code><code class="na">send</code><code class="o">(</code><code class="n">request</code><code class="o">,</code>&#13;
        <code class="n">HttpResponse</code><code class="o">.</code><code class="na">BodyHandlers</code><code class="o">.</code><code class="na">ofString</code><code class="o">());</code>&#13;
&#13;
<code class="n">System</code><code class="o">.</code><code class="na">out</code><code class="o">.</code><code class="na">println</code><code class="o">(</code><code class="n">response</code><code class="o">.</code><code class="na">body</code><code class="o">());</code></pre></div>&#13;
&#13;
<p>Let’s describe what’s happening when you execute it:</p>&#13;
<ol>&#13;
<li>&#13;
<p>Your application creates an HTTP request (<code>request</code>).</p>&#13;
</li>&#13;
<li>&#13;
<p>It establishes an HTTP connection with the remote server.</p>&#13;
</li>&#13;
<li>&#13;
<p>It writes the HTTP request following the protocol.</p>&#13;
</li>&#13;
<li>&#13;
<p>The request travels to the server.</p>&#13;
</li>&#13;
<li>&#13;
<p>The server interprets the request and looks for the resource.</p>&#13;
</li>&#13;
<li>&#13;
<p>The server creates an HTTP response with the representation of the resource state in JSON.</p>&#13;
</li>&#13;
<li>&#13;
<p>It writes the response following the protocol.</p>&#13;
</li>&#13;
<li>&#13;
<p>The application receives the response and extracts the body (as <code>String</code> in this example).</p>&#13;
</li>&#13;
&#13;
</ol>&#13;
&#13;
<p>It’s the role of middleware (HTTP server and client, JSON mappers…) to make these interactions easy for us developers.&#13;
In our previous example, steps 2 to 8 are all hidden in the <code>send</code> method.&#13;
But we need to be aware of them.&#13;
Especially today, with the cloud, distributed systems and distributed communications are everywhere.&#13;
It becomes rare to build an application that is not a distributed system.&#13;
As soon as you call a remote web service, print a document, or use an online collaboration tool, you are creating a distributed system.<a data-startref="ix_distributed-system-adoc0" data-type="indexterm" id="idm45358832397808"/></p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="The New Kids on the Block: Cloud Native and Kubernetes Native Applications" data-type="sect1"><div class="sect1" id="distributed-system::cloud-native-kube">&#13;
<h1>The New Kids on the Block: Cloud Native and Kubernetes Native Applications</h1>&#13;
&#13;
<p><a data-primary="cloud native applications" data-secondary="distributed systems and" data-type="indexterm" id="ix_distributed-system-adoc1"/><a data-primary="distributed systems" data-secondary="cloud native applications" data-type="indexterm" id="ix_distributed-system-adoc2"/>The role of the cloud can’t be overstated, and it’s a significant factor in the popularization of distributed systems.&#13;
If you need a new machine, database, API gateway, or persistent storage, the cloud can enable the delivery of these on-demand computing services.&#13;
As a reminder, though, for as much as the cloud improves efficiencies, you must never forget that running your application on the cloud is equivalent to running on someone else’s machine.&#13;
Somewhere there are CPUs, disks, and memory used to execute your application, and while cloud providers are responsible for maintaining these systems and have built a reputation around reliability, the hardware is outside your control.</p>&#13;
&#13;
<p>Cloud providers provide fantastic infrastructure facilities, making running applications much more straightforward.&#13;
Thanks to dynamic resources, you can create many instances of your application and even autotune this number based on the current load.&#13;
It also offers failover mechanisms such as routing requests to a healthy instance if another instance crashed.&#13;
The cloud helps to reach high availability by making your service always available, restarting unhealthy parts of your systems, and so on.&#13;
This is a first step toward elastic and resilient systems.</p>&#13;
&#13;
<p>That being said, it’s not because your application can run in the cloud that it will benefit from it.&#13;
You need to tailor your application to use the cloud efficiently, and the distributed nature of the cloud is a big part of it.&#13;
<em>Cloud native</em> is an approach to building and running applications that exploit the cloud computing delivery model.&#13;
Cloud native applications should be easy to deploy on virtual resources, support elasticity through application instances, rely on location transparency, enforce fault-tolerance, and so on.&#13;
The <a href="https://12factor.net">Twelve-Factor App</a> lists some characteristics to become a <em>good cloud citizen</em>:</p>&#13;
<dl>&#13;
<dt>Codebase</dt>&#13;
<dd>&#13;
<p>One codebase tracked in version control, many deploys.</p>&#13;
</dd>&#13;
<dt>Dependencies</dt>&#13;
<dd>&#13;
<p>Explicitly declare and isolate dependencies.</p>&#13;
</dd>&#13;
<dt>Config</dt>&#13;
<dd>&#13;
<p>store config in the environment.</p>&#13;
</dd>&#13;
<dt>Backing services</dt>&#13;
<dd>&#13;
<p>Treat backing services as attached resources.</p>&#13;
</dd>&#13;
<dt>Build, release, run</dt>&#13;
<dd>&#13;
<p>Strictly separate build and run stages.</p>&#13;
</dd>&#13;
<dt>Processes</dt>&#13;
<dd>&#13;
<p>Execute the app as one or more stateless processes.</p>&#13;
</dd>&#13;
<dt>Port binding</dt>&#13;
<dd>&#13;
<p>Export services via port binding.</p>&#13;
</dd>&#13;
<dt>Concurrency</dt>&#13;
<dd>&#13;
<p>Scale out via the process model.</p>&#13;
</dd>&#13;
<dt>Disposability</dt>&#13;
<dd>&#13;
<p>Maximize the robustness with fast startup and graceful shutdown.</p>&#13;
</dd>&#13;
<dt>Dev/prod parity</dt>&#13;
<dd>&#13;
<p>Keep development, staging, and production as similar as possible.</p>&#13;
</dd>&#13;
<dt>Logs</dt>&#13;
<dd>&#13;
<p>Treat your logs as event streams.</p>&#13;
</dd>&#13;
<dt>Admin processes</dt>&#13;
<dd>&#13;
<p>Run admin/management tasks as one-off processes.</p>&#13;
</dd>&#13;
</dl>&#13;
&#13;
<p>Implementing these factors helps to embrace the cloud native ideology.&#13;
But achieving cloud native is not an easy task.&#13;
Each factor comes with technical challenges and architectural constraints.</p>&#13;
&#13;
<p>In addition, each cloud provider provides its own set of facilities and APIs.&#13;
This heterogeneity makes cloud native applications nonportable from one cloud provider to another.&#13;
Very quickly, you end up in some kind of vendor lock-in, because of a specific API or services, or tooling, or even description format.&#13;
It may not be an issue for you right now, but having the possibility to move and combine multiple clouds improves your agility, availability, and user experience.&#13;
Hybrid cloud applications, for example, run on multiple clouds, mixing private and public clouds, to reduce response time and prevent global unavailability.<a data-startref="ix_distributed-system-adoc2" data-type="indexterm" id="idm45358832369648"/><a data-startref="ix_distributed-system-adoc1" data-type="indexterm" id="idm45358832368880"/></p>&#13;
&#13;
<p><a data-primary="distributed systems" data-secondary="Kubernetes native applications" data-type="indexterm" id="ix_distributed-system-adoc3"/><a data-primary="Kubernetes" data-secondary="running an application with" data-type="indexterm" id="ix_distributed-system-adoc4"/>Fortunately, both public and private clouds tend to converge around Kubernetes, a container orchestration platform.&#13;
Kubernetes abstracts the differences between providers using <em>standard</em> deployment and runtime facilities.</p>&#13;
&#13;
<p><a data-primary="containers" data-type="indexterm" id="ix_distributed-system-adoc5"/>To use Kubernetes, you package and run your application inside a container.&#13;
<a data-primary="containers" data-type="indexterm" id="idm45358832363248"/>A <em>container</em> is a box in which your application is going to run.&#13;
So, your application is somewhat isolated from the other applications running in their own box.</p>&#13;
&#13;
<p>To create containers, you need an image.&#13;
<a data-primary="container image" data-type="indexterm" id="idm45358832361392"/>A <em>container image</em> is a lightweight, executable software package.&#13;
When you deploy a container, you actually deploy an image, and this image is instantiated to create the container.</p>&#13;
&#13;
<p>The image includes everything needed to run an application: code, runtime, system libraries, and configuration.&#13;
You can create container images by using various tools and descriptors such as <em>Dockerfile</em>.&#13;
As you have seen in <a data-type="xref" href="ch02.html#quarkus">Chapter 2</a>, Quarkus offers image creation facilities without having to write a single line of code.</p>&#13;
&#13;
<p>To distribute your image, you push it to an image registry such as <a href="https://hub.docker.com">Docker Hub</a>.&#13;
Then you can pull it and finally instantiate it to start your application (<a data-type="xref" href="#figure:containers">Figure 3-3</a>).</p>&#13;
&#13;
<figure><div class="figure" id="figure:containers">&#13;
<img alt="Creation, Distribution and Execution of Containers" src="assets/rsij_0303.png"/>&#13;
<h6><span class="label">Figure 3-3. </span>Creation, distribution, and execution of containers</h6>&#13;
</div></figure>&#13;
&#13;
<p>While containerization is a well-known technique, when you start having dozens of containers, their management becomes complicated.&#13;
Kubernetes provides facilities to reduce this burden.&#13;
It instantiates containers and monitors them, making sure your application is still running.<sup><a data-type="noteref" href="ch03.html#idm45358832353200" id="idm45358832353200-marker">2</a></sup>&#13;
As you can imagine, this can be useful for implementing the responsiveness and resilience characteristics from reactive systems.</p>&#13;
<div data-type="note" epub:type="note"><h6>Note</h6>&#13;
<p>Though Kubernetes facilitates reactive systems through responsiveness and resilience, that does not mean you cannot implement a reactive system outside of Kubernetes. It’s definitely possible.&#13;
In this book, we use Kubernetes to avoid having to implement the underlying infrastructure features such as deployment, replication, and fault detection.</p>&#13;
</div>&#13;
&#13;
<p>Under the hood, Kubernetes pulls container images, instantiates containers, and monitors them.&#13;
To achieve this, Kubernetes needs to have access to <em>nodes</em> to run the containers.&#13;
This set of nodes forms a <em>cluster</em>.&#13;
Thinking of a machine as a node allows us to insert a layer of abstraction.&#13;
Whether these machines are Amazon Elastic Compute Cloud (EC2) instances, physical hardware from a data center, or virtualized is irrelevant.&#13;
Kubernetes controls these nodes and decides which part of the system will run where.</p>&#13;
&#13;
<p>Once Kubernetes has access to your container image, you can instruct Kubernetes to instantiate the image so that it becomes a running container.&#13;
Kubernetes decides on which node the container is executed.&#13;
It may even move it later to optimize resource utilization, another characteristic that fits with reactive architectures.</p>&#13;
&#13;
<p>Just as applications need to be cloud native to benefit from the cloud, they need to be Kubernetes native to benefit from Kubernetes.&#13;
That includes supporting Kubernetes service discovery, exposing health checks used for monitoring, and, more importantly, running efficiently in a container.&#13;
You will see in the next chapter how these three characteristics are essential from a Reactive point of view.&#13;
You can wrap almost any application in a container.&#13;
But it may not be a good idea.</p>&#13;
&#13;
<p>When running in a container, your application lives in a shared environment.&#13;
Multiple containers share the resources from the <em>host</em>, the machine executing them.&#13;
They share the CPU, the memory, and so on.&#13;
If one container is too greedy, it penalizes the other containers, which may starve.&#13;
Of course, you can use quotas, but how would the greedy container behave under resource restrictions?&#13;
So, yes, containers provide isolation, <em>and</em> enable resource sharing.</p>&#13;
&#13;
<p>One role of containers and Kubernetes is to increase the deployment density: running more using the finite set of available resources.&#13;
Deployment density is becoming essential to many organizations because of the economic benefits.&#13;
It allows reducing costs, either by reducing the monthly cloud bill or by running more applications on the current in-house infrastructure.</p>&#13;
&#13;
<p><a data-type="xref" href="#table::kube">Table 3-1</a> summarizes concepts presented so far around containers and Kubernetes.</p>&#13;
<table id="table::kube">&#13;
<caption><span class="label">Table 3-1. </span>Important concepts around containers and Kubernetes</caption>&#13;
<thead>&#13;
<tr>&#13;
<th>Name</th>&#13;
<th>Description</th>&#13;
<th>Associated command</th>&#13;
</tr>&#13;
</thead>&#13;
<tbody>&#13;
<tr>&#13;
<td><p>Container image</p></td>&#13;
<td><p>Lightweight, executable software package</p></td>&#13;
<td><p><span class="keep-together"><code>docker build -f my-docker-file -t my-image:version</code></span></p></td>&#13;
</tr>&#13;
<tr>&#13;
<td><p>Container</p></td>&#13;
<td><p>A box in which your application is going to run</p></td>&#13;
<td><p><span class="keep-together"><code>docker run my-image:version</code></span></p></td>&#13;
</tr>&#13;
<tr>&#13;
<td><p>Pod</p></td>&#13;
<td><p>The unit of replication in Kubernetes, composed of one or more containers</p></td>&#13;
<td><p><code>kubectl get pods</code></p></td>&#13;
</tr>&#13;
<tr>&#13;
<td><p>Deployment</p></td>&#13;
<td><p>Describes the content of a pod and number of pod instances we need</p></td>&#13;
<td><p><code>kubectl get deployments</code></p></td>&#13;
</tr>&#13;
<tr>&#13;
<td><p>Service</p></td>&#13;
<td><p>A channel of communication delegating to a set of pods, selected by labels</p></td>&#13;
<td><p><code>kubectl get services</code></p></td>&#13;
</tr>&#13;
</tbody>&#13;
</table>&#13;
&#13;
<p>If you missed it, check out <a data-type="xref" href="ch02.html#quarkus::kube-ten">“Kubernetes with Quarkus in 10 Minutes”</a>, where we deployed a Quarkus service to Kubernetes<a data-startref="ix_distributed-system-adoc5" data-type="indexterm" id="idm45358832324928"/>!<a data-startref="ix_distributed-system-adoc4" data-type="indexterm" id="idm45358832324064"/><a data-startref="ix_distributed-system-adoc3" data-type="indexterm" id="idm45358832323344"/></p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section class="pagebreak-before less_space" data-pdf-bookmark="The Dark Side of Distributed Systems" data-type="sect1"><div class="sect1" id="idm45358832396128">&#13;
<h1>The Dark Side of Distributed Systems</h1>&#13;
&#13;
<p><a data-primary="distributed systems" data-secondary="failures in" data-type="indexterm" id="idm45358832321424"/>Our system is simple, but even such a basic system can illustrate the hard reality of distributed systems.&#13;
Cloud providers and Kubernetes provide excellent infrastructure facilities, but the laws of     distributed systems still rule the system you are building.&#13;
The technical complexity around provisioning and delivery has been replaced with fundamental issues from the nature of distributed systems.&#13;
The size and complexity of modern applications make them undeniable.</p>&#13;
&#13;
<p>At the beginning of this chapter, you saw a first definition of distributed systems.&#13;
It was capturing the need for collaboration and communication to provide a consistent experience.&#13;
<a href="http://www.lamport.org">Leslie Lamport</a>, a computer scientist and Turing Award winner, gives a different definition that describes the dark nature of distributed systems: “A distributed system is one in which the failure of a computer you didn’t even know existed can render your own computer unusable.”</p>&#13;
&#13;
<p><a data-primary="failure handling" data-secondary="distributed systems and" data-type="indexterm" id="idm45358832318000"/>In other words, failures are inevitable.&#13;
They are an inherent component of distributed systems.&#13;
No matter how your system is built, it is going to fail.&#13;
As a corollary, the bigger the distributed system, the higher the level of <em>dynamism</em> (the fluctuating availability of the surrounding services) and the greater the chance of failure.</p>&#13;
&#13;
<p>What kind of failures can we encounter?&#13;
There are three types:</p>&#13;
<dl>&#13;
<dt>Transient failure</dt>&#13;
<dd>&#13;
<p><a data-primary="transient failures" data-type="indexterm" id="idm45358832314064"/>Occurs once and then disappears, like a temporary network disruption</p>&#13;
</dd>&#13;
<dt>Intermittent failure</dt>&#13;
<dd>&#13;
<p><a data-primary="intermittent failures" data-type="indexterm" id="idm45358832312000"/>Occurs, then vanishes and then reappears, like a failure happening once in a while for no apparent reason</p>&#13;
</dd>&#13;
<dt>Permanent failure</dt>&#13;
<dd>&#13;
<p><a data-primary="permanent failures" data-type="indexterm" id="idm45358832310144"/>Continues to exist until the faulty component (either software or hardware) is fixed</p>&#13;
</dd>&#13;
</dl>&#13;
&#13;
<p>Each type of failure can have two kinds of consequences.&#13;
<a data-primary="fail-stop failures" data-type="indexterm" id="idm45358832308560"/>First, it can crash the application.&#13;
We call these <em>fail-stop</em> failures.&#13;
There are <em>bad</em>, of course, but we can easily detect them and repair the system.&#13;
<a data-primary="Byzantine failures" data-type="indexterm" id="idm45358832306752"/>Second, a failure may introduce unpredictable responses at random times.&#13;
We call them <em>Byzantine failures</em>.&#13;
They are much harder to detect and to circumvent.</p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section class="pagebreak-before less_space" data-pdf-bookmark="Fallacies of Distributed Computing in a Kubernetes World" data-type="sect1"><div class="sect1" id="idm45358832305392">&#13;
<h1>Fallacies of Distributed Computing in a Kubernetes World</h1>&#13;
&#13;
<p><a data-primary="cloud native applications" data-secondary="false assumptions related to cloud and Kubernetes" data-type="indexterm" id="ix_distributed-system-adoc6"/><a data-primary="distributed systems" data-secondary="false assumptions about" data-type="indexterm" id="ix_distributed-system-adoc7"/><a data-primary="Kubernetes" data-secondary="false assumptions related to cloud and Kubernetes" data-type="indexterm" id="ix_distributed-system-adoc8"/>As developers, imagining and planning for all the types of failure and consequences can be challenging.&#13;
How would you detect them?&#13;
How would you handle them gracefully?&#13;
How can you continue to provide a consistent experience and service if anything can fall apart?&#13;
Building and maintaining distributed systems is a complex topic full of pitfalls and landmines.&#13;
<a data-primary="&quot;Eight Fallacies of Distributed Computing&quot;" data-primary-sortas="Eight Fallacies" data-type="indexterm" id="ix_distributed-system-adoc9"/>The <a href="https://oreil.ly/0g3lL">“Eight Fallacies of Distributed Computing”</a> list, created by L. Peter Deutsch along with others at Sun Microsystems, walks us through many false assumptions around distributed systems:</p>&#13;
<ol>&#13;
<li>&#13;
<p>The network is reliable.</p>&#13;
</li>&#13;
<li>&#13;
<p>Latency is zero.</p>&#13;
</li>&#13;
<li>&#13;
<p>Bandwidth is infinite.</p>&#13;
</li>&#13;
<li>&#13;
<p>The network is secure.</p>&#13;
</li>&#13;
<li>&#13;
<p>Topology doesn’t change.</p>&#13;
</li>&#13;
<li>&#13;
<p>There is one administrator.</p>&#13;
</li>&#13;
<li>&#13;
<p>Transport cost is zero.</p>&#13;
</li>&#13;
<li>&#13;
<p>The network is homogeneous.</p>&#13;
</li>&#13;
&#13;
</ol>&#13;
&#13;
<p>These fallacies were published in 1997, long before the era of the cloud and Kubernetes.&#13;
But these fallacies are still relevant today—even more relevant.&#13;
We won’t discuss all of them but focus on the ones related to the cloud and Kubernetes:</p>&#13;
<dl>&#13;
<dt>The network is reliable</dt>&#13;
<dd>&#13;
<p>The developer often assumes that the network is reliable on the cloud or Kubernetes. Indeed, it’s the role of the infrastructure to handle the network and make sure things work. Health checks, heartbeats, replications, automatic restart—a lot of mechanisms are built in at the infrastructure layer. The network will do its best, but sometimes, bad things happen, and you need to be prepared for that. Data centers can fall apart; parts of the system can become unreachable, and so on.<sup><a data-type="noteref" href="ch03.html#idm45358832286384" id="idm45358832286384-marker">3</a></sup></p>&#13;
</dd>&#13;
<dt>Latency is zero</dt>&#13;
<dd>&#13;
<p>The second fallacy seems obvious: a network call is slower than a local call, and the latency of any given call can vary significantly, even from one invocation to the next. We already discussed this. The latency is not limited to that aspect; it can change over time for various reasons.</p>&#13;
</dd>&#13;
<dt>Bandwidth is infinite <em>and</em> the network is homogeneous</dt>&#13;
<dd>&#13;
<p>You may reach the bandwidth limit, or parts of the system may use a faster network than some other parts because they are running on the same <em>node</em>. Estimating latency is not trivial. Many capacity-planning techniques and time-out computation are based on network latency.</p>&#13;
</dd>&#13;
<dt>Topology doesn’t change</dt>&#13;
<dd>&#13;
<p>On the cloud or on Kubernetes, services, applications, and containers move. Kubernetes can move containers from one node to another anytime. Containers are frequently moving because of the deployment of new applications, updates, rescheduling, optimization, and so on. Mobility is a great benefit as it allows optimizing the whole system, but interacting with services always on the move can be challenging. You may interact with multiple instances of your service, while, for you, it acts as one. Some instances can be close to you (and provide a better response time), while some may be farther or just slower because of limited resources.<sup><a data-type="noteref" href="ch03.html#idm45358832279664" id="idm45358832279664-marker">4</a></sup></p>&#13;
</dd>&#13;
<dt>There is one administrator</dt>&#13;
<dd>&#13;
<p>Managing systems has drastically changed over the past few years. The old-school system administration processes and maintenance downtimes are becoming less common. DevOps philosophies and techniques such as continuous delivery and continuous deployment are reshaping the way we manage applications in production. Developers can easily deploy small incremental changes throughout the day. DevOps tools and site reliability engineers (SREs) work hard to provide an almost constant availability, while a continuous stream of updates provides new features and bug fixes. The administration role is shared among SREs, software engineers, and software. For example, <a href="https://oreil.ly/cX8nN">Kubernetes operators</a> are programs deployed on Kubernetes and responsible for installing, updating, monitoring, and repairing parts of the system &#13;
<span class="keep-together">automatically</span>.</p>&#13;
</dd>&#13;
<dt>Transport cost is zero</dt>&#13;
<dd>&#13;
<p>Considering the network to be free is not only a fallacy, but also an economic mistake. You must pay attention to the cost of network calls and look for optimization. For example, crossing cloud regions, transferring large amounts of data, or (especially) communicating to separate cloud providers can be expensive.<a data-startref="ix_distributed-system-adoc9" data-type="indexterm" id="idm45358832273744"/></p>&#13;
</dd>&#13;
</dl>&#13;
&#13;
<p>So, not that simple, right?&#13;
When you build a distributed system, consider all these issues and take them into account in your architecture and application code.&#13;
Those are just some of the issues.&#13;
Another one is the inability to reach a consensus.<sup><a data-type="noteref" href="ch03.html#idm45358832272336" id="idm45358832272336-marker">5</a></sup> In addition, the CAP theorem prevents a distributed data store from simultaneously providing more than two out of the following three guarantees:<sup><a data-type="noteref" href="ch03.html#idm45358832270720" id="idm45358832270720-marker">6</a></sup></p>&#13;
<dl>&#13;
<dt>Consistency</dt>&#13;
<dd>&#13;
<p>Every read receives the most recent write.</p>&#13;
</dd>&#13;
<dt>Availability</dt>&#13;
<dd>&#13;
<p>Every request receives a response.</p>&#13;
</dd>&#13;
<dt>Partition tolerance</dt>&#13;
<dd>&#13;
<p>The system continues to operate despite an arbitrary number of messages being dropped (or delayed) by the network.</p>&#13;
</dd>&#13;
</dl>&#13;
&#13;
<p>Can things get even darker?&#13;
Oh yes, distributed systems can be wonderfully imaginative to drive us crazy.<a data-startref="ix_distributed-system-adoc8" data-type="indexterm" id="idm45358832263936"/><a data-startref="ix_distributed-system-adoc7" data-type="indexterm" id="idm45358832263184"/><a data-startref="ix_distributed-system-adoc6" data-type="indexterm" id="idm45358832262496"/></p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="A Question of Timing: The Synchronous Communication Drawback" data-type="sect1"><div class="sect1" id="idm45358832261680">&#13;
<h1>A Question of Timing: The Synchronous Communication Drawback</h1>&#13;
&#13;
<p><a data-primary="distributed systems" data-secondary="synchronous communication and time-coupling" data-type="indexterm" id="ix_distributed-system-adoc10"/><a data-primary="synchronous calls, distributed systems and" data-type="indexterm" id="ix_distributed-system-adoc11"/><a data-primary="time-coupling, distributed systems and" data-type="indexterm" id="ix_distributed-system-adoc12"/>Time is an often misunderstood issue.&#13;
When two computers communicate and exchange messages, we make the natural assumption that the two machines are both available and reachable.&#13;
We often trust the network between them.&#13;
Why wouldn’t it be entirely operational?&#13;
Why can’t we invoke remote services as we would for a local service?</p>&#13;
&#13;
<p>But that may not be the case, and not considering this possibility leads to fragility.&#13;
What happens if the machine you want to interact with is not reachable?&#13;
Are you prepared for such a failure?&#13;
Should you propagate the failure? Retry?</p>&#13;
&#13;
<p>In a hypothetical microservices-based example, it’s common to use synchronous HTTP as the main communication protocol between services.&#13;
You send a request and expect a response from the service you invoked.&#13;
Your code is synchronous, waiting for the response before continuing its execution.&#13;
Synchronous calls are simpler to reason about.&#13;
You structure your code sequentially, you do one thing, then the next one, and so on.&#13;
This leads to <em>time-coupling</em>, one of the less considered and often-misunderstood forms of coupling.&#13;
Let’s illustrate this coupling and the uncertainty that derives from it.</p>&#13;
&#13;
<p>In the <em>chapter-3/quarkus-simple-service</em> <a href="https://oreil.ly/vZR3j">directory of the GitHub repository</a>, you will find a simple Hello World Quarkus application.&#13;
This application is similar to the one built in <a data-type="xref" href="ch02.html#quarkus">Chapter 2</a>.&#13;
It contains a single HTTP endpoint, as shown in <a data-type="xref" href="#Jax-rs-simple-service">Example 3-2</a>.</p>&#13;
<div data-type="example" id="Jax-rs-simple-service">&#13;
<h5><span class="label">Example 3-2. </span>JAX-RS simple service (<em>chapter-3/quarkus-simple-service/src/main/java/org/acme/reactive/SimpleService.java</em>)</h5>&#13;
&#13;
<pre data-code-language="java" data-type="programlisting"><code class="kn">package</code> <code class="n">org</code><code class="o">.</code><code class="na">acme</code><code class="o">.</code><code class="na">reactive</code><code class="o">;</code>&#13;
&#13;
<code class="kn">import</code> <code class="nn">javax.ws.rs.GET</code><code class="o">;</code>&#13;
<code class="kn">import</code> <code class="nn">javax.ws.rs.Path</code><code class="o">;</code>&#13;
<code class="kn">import</code> <code class="nn">javax.ws.rs.Produces</code><code class="o">;</code>&#13;
<code class="kn">import</code> <code class="nn">javax.ws.rs.core.MediaType</code><code class="o">;</code>&#13;
&#13;
<code class="nd">@Path</code><code class="o">(</code><code class="s">"/"</code><code class="o">)</code>&#13;
<code class="nd">@Produces</code><code class="o">(</code><code class="n">MediaType</code><code class="o">.</code><code class="na">TEXT_PLAIN</code><code class="o">)</code>&#13;
<code class="kd">public</code> <code class="kd">class</code> <code class="nc">SimpleService</code> <code class="o">{</code>&#13;
&#13;
    <code class="nd">@GET</code>&#13;
    <code class="kd">public</code> <code class="n">String</code> <code class="nf">hello</code><code class="o">()</code> <code class="o">{</code>&#13;
        <code class="k">return</code> <code class="s">"hello"</code><code class="o">;</code>&#13;
    <code class="o">}</code>&#13;
<code class="o">}</code></pre></div>&#13;
&#13;
<p>Hard to have code simpler than this, right?&#13;
Let’s deploy this application to Kubernetes.&#13;
Make sure minikube is started. If it’s not, start it as shown in <a data-type="xref" href="#start-minikube-3-3">Example 3-3</a>.</p>&#13;
<div data-type="example" id="start-minikube-3-3">&#13;
<h5><span class="label">Example 3-3. </span>Start minikube</h5>&#13;
&#13;
<pre data-code-language="shell" data-type="programlisting"><code>&gt;</code><code> </code><code>minikube</code><code> </code><code>start</code><code>&#13;
</code><code>...</code><code>&#13;
</code><code>&gt;</code><code> </code><code class="nb">eval</code><code> </code><code class="k">$(</code><code>minikube</code><code> </code><code>docker-env</code><code class="k">)</code><code> </code><a class="co" href="#callout_the_dark_side_of_distributed_systems_CO1-1" id="co_the_dark_side_of_distributed_systems_CO1-1"><img alt="1" src="assets/1.png"/></a></pre>&#13;
<dl class="calloutlist">&#13;
<dt><a class="co" href="#co_the_dark_side_of_distributed_systems_CO1-1" id="callout_the_dark_side_of_distributed_systems_CO1-1"><img alt="1" src="assets/1.png"/></a></dt>&#13;
<dd><p>Don’t forget to connect the Docker socket to minikube.</p></dd>&#13;
</dl></div>&#13;
&#13;
<p>Verify that everything is fine by running the <code>kubectl get nodes</code> command (<a data-type="xref" href="#get-node-names">Example 3-4</a>).</p>&#13;
<div data-type="example" id="get-node-names">&#13;
<h5><span class="label">Example 3-4. </span>Get the node names and roles</h5>&#13;
&#13;
<pre data-code-language="bash" data-type="programlisting">&gt; kubectl get nodes&#13;
NAME       STATUS   ROLES                  AGE   VERSION&#13;
minikube   Ready    control-plane,master   30s   v1.20.2</pre></div>&#13;
&#13;
<p>Now, navigate in the <em>chapter-3/simple-service</em> directory and run <a data-type="xref" href="#deploy-quarkus-app-to-kubs">Example 3-5</a>.</p>&#13;
<div data-type="example" id="deploy-quarkus-app-to-kubs">&#13;
<h5><span class="label">Example 3-5. </span>Deploy a Quarkus application to Kubernetes</h5>&#13;
&#13;
<pre data-code-language="shell" data-type="programlisting">&gt; mvn verify -Dquarkus.kubernetes.deploy<code class="o">=</code><code class="nb">true</code></pre></div>&#13;
&#13;
<p>Wait for the pod to be <em>ready</em>, as shown in <a data-type="xref" href="#get-list-of-running-pods">Example 3-6</a>.</p>&#13;
<div data-type="example" id="get-list-of-running-pods">&#13;
<h5><span class="label">Example 3-6. </span>Get the list of running pods</h5>&#13;
&#13;
<pre data-code-language="bash" data-type="programlisting">&gt; kubectl get pods&#13;
NAME                                      READY   STATUS    RESTARTS   AGE&#13;
quarkus-simple-service-7f9dd6ddbf-vtdsg   1/1     Running   <code class="m">0</code>          42s</pre></div>&#13;
&#13;
<p>Then expose the service by using <a data-type="xref" href="#retrieving-url-of-service">Example 3-7</a>.</p>&#13;
<div data-type="example" id="retrieving-url-of-service">&#13;
<h5><span class="label">Example 3-7. </span>Retrieve the URL of the service</h5>&#13;
&#13;
<pre data-code-language="bash" data-type="programlisting">&gt; minikube service quarkus-simple-service --url&#13;
🏃  Starting tunnel <code class="k">for</code> service quarkus-simple-service.&#13;
<code class="p">|</code>-----------<code class="p">|</code>------------------------<code class="p">|</code>-------------<code class="p">|</code>------------------------<code class="p">|</code>&#13;
<code class="p">|</code> NAMESPACE <code class="p">|</code>          NAME          <code class="p">|</code> TARGET PORT <code class="p">|</code>          URL           <code class="p">|</code>&#13;
<code class="p">|</code>-----------<code class="p">|</code>------------------------<code class="p">|</code>-------------<code class="p">|</code>------------------------<code class="p">|</code>&#13;
<code class="p">|</code> default   <code class="p">|</code> quarkus-simple-service <code class="p">|</code>             <code class="p">|</code> http://127.0.0.1:63905 <code class="p">|</code>&#13;
<code class="p">|</code>-----------<code class="p">|</code>------------------------<code class="p">|</code>-------------<code class="p">|</code>------------------------<code class="p">|</code>&#13;
http://127.0.0.1:63905&#13;
❗  Because you are using a Docker driver on darwin, the terminal needs to be open to&#13;
    run it.</pre></div>&#13;
&#13;
<p>Don’t forget that the port is assigned randomly, so you will need to replace the port in the following commands.</p>&#13;
&#13;
<p>Finally, let’s invoke our service by running <a data-type="xref" href="#invoking-service">Example 3-8</a> in another terminal.</p>&#13;
<div data-type="example" id="invoking-service">&#13;
<h5><span class="label">Example 3-8. </span>Invoke the service</h5>&#13;
&#13;
<pre data-code-language="bash" data-type="programlisting">&gt; curl http://127.0.0.1:63905&#13;
hello%</pre></div>&#13;
&#13;
<p>So far, so good.&#13;
But this application contains a <em>mechanism</em> to simulate distributed system failures to illustrate the problem of synchronous communication.&#13;
You can look at the implementation in <em>chapter-3/quarkus-simple-service/src/main/java/org/acme/reactive/fault/FaultInjector.java</em>.&#13;
It’s basically a <em>Quarkus route</em> (a kind of interceptor) that monitors the HTTP traffic and allows simulating various failures.&#13;
It intercepts the incoming HTTP request and outgoing HTTP response and introduces delays, losses, or application failures.</p>&#13;
&#13;
<p class="pagebreak-before less_space">When we call our service in a synchronous way (expecting a response, such as with <code>curl</code> or a browser), three types of failure can happen:</p>&#13;
&#13;
<ul>&#13;
<li>&#13;
<p>The request between the caller and the service can be lost.&#13;
This results in the service not being invoked.&#13;
The caller waits until a time-out is reached.&#13;
This simulates a transient network partition.&#13;
This type of failure can be enabled by using the <code>INBOUND_REQUEST_LOSS</code> mode.</p>&#13;
</li>&#13;
<li>&#13;
<p>The service receives the request but fails to handle it correctly.&#13;
It may return an incorrect response or maybe no response at all.&#13;
In the best case, the caller would receive the failure or wait until a time-out is reached.&#13;
This simulates an intermittent bug in the called service.&#13;
This type of failure can be enabled by using the <code>SERVICE_FAILURE</code> mode.</p>&#13;
</li>&#13;
<li>&#13;
<p>The service receives the request, processes it, and writes the response, but &#13;
<span class="keep-together">the response</span> is lost on its way back, or the connection is closed before the response reaches the caller.&#13;
The service got the request, handled it, and produced the response. The caller just doesn’t get it.&#13;
As in the first type of failure noted &#13;
<span class="keep-together">previously</span>, the response is in a transient network partition but happening after the &#13;
<span class="keep-together">service invocation</span>.&#13;
This type of failure can be enabled using the <code>OUTBOUND_RESPONSE_LOSS</code> mode.</p>&#13;
</li>&#13;
</ul>&#13;
<div data-type="tip"><h6>Tip</h6>&#13;
<p>Don’t forget to update the port in the previous and following commands, as minikube randomly picks a port.</p>&#13;
</div>&#13;
&#13;
<p>To illustrate how the system behaves when facing failures, let’s inject some request losses (<a data-type="xref" href="#configure-system-lose-50">Example 3-9</a>).</p>&#13;
<div data-type="example" id="configure-system-lose-50">&#13;
<h5><span class="label">Example 3-9. </span>Configure the system to lose 50% of the incoming requests</h5>&#13;
&#13;
<pre data-code-language="bash" data-type="programlisting">&gt; curl http://127.0.0.1:63905/fault?mode<code class="o">=</code>INBOUND_REQUEST_LOSS&#13;
Fault injection enabled: <code class="nv">mode</code><code class="o">=</code>INBOUND_REQUEST_LOSS, <code class="nv">ratio</code><code class="o">=</code>0.5</pre></div>&#13;
&#13;
<p>This command configures <code>FaultInjector</code> to randomly lose 50% of the incoming requests.&#13;
The caller waits for a response that will never arrive half of the time, and will eventually time out.&#13;
Try the command in <a data-type="xref" href="#invoke-service-timeout">Example 3-10</a> until you experience a time-out.</p>&#13;
<div data-type="example" id="invoke-service-timeout">&#13;
<h5><span class="label">Example 3-10. </span>Invoke the service with a configured time-out</h5>&#13;
&#13;
<pre data-code-language="bash" data-type="programlisting"><code>&gt;</code><code> </code><code>curl</code><code> </code><code>--max-time</code><code> </code><code class="m">5</code><code> </code><code>http://127.0.0.1:63905/</code><code>  </code><a class="co" href="#callout_the_dark_side_of_distributed_systems_CO2-1" id="co_the_dark_side_of_distributed_systems_CO2-1"><img alt="1" src="assets/1.png"/></a><code>&#13;
</code><code>hello%</code><code>&#13;
</code><code>&gt;</code><code> </code><code>curl</code><code> </code><code>--max-time</code><code> </code><code class="m">5</code><code> </code><code>http://127.0.0.1:63905/</code><code>&#13;
</code><code>curl:</code><code> </code><code class="o">(</code><code>28</code><code class="o">)</code><code> </code><code>Operation</code><code> </code><code>timed</code><code> </code><code>out</code><code> </code><code>after</code><code> </code><code class="m">5004</code><code> </code><code>milliseconds</code><code> </code><code>with</code><code> </code><code class="m">0</code><code> </code><code>bytes</code><code> </code><code>received</code></pre>&#13;
<dl class="calloutlist">&#13;
<dt><a class="co" href="#co_the_dark_side_of_distributed_systems_CO2-1" id="callout_the_dark_side_of_distributed_systems_CO2-1"><img alt="1" src="assets/1.png"/></a></dt>&#13;
<dd><p><code>--max-time 5</code> configures a time-out of 5 seconds. Again, do not forget to update the port.</p></dd>&#13;
</dl></div>&#13;
&#13;
<p>To simulate the second type of failure, execute the command in <a data-type="xref" href="#configure-system-inject">Example 3-11</a>.</p>&#13;
<div data-type="example" id="configure-system-inject">&#13;
<h5><span class="label">Example 3-11. </span>Configure the system to inject faulty responses</h5>&#13;
&#13;
<pre data-code-language="bash" data-type="programlisting">&gt; curl http://127.0.0.1:63905/fault?mode<code class="o">=</code>SERVICE_FAILURE</pre></div>&#13;
&#13;
<p>You have now a 50% chance of receiving a faulty response; see <a data-type="xref" href="#invoke-faulty">Example 3-12</a>.</p>&#13;
<div data-type="example" id="invoke-faulty">&#13;
<h5><span class="label">Example 3-12. </span>Invoke the faulty application</h5>&#13;
&#13;
<pre data-code-language="bash" data-type="programlisting">&gt; curl http://127.0.0.1:63905&#13;
hello%&#13;
&gt; curl http://127.0.0.1:63905&#13;
FAULTY RESPONSE!%</pre></div>&#13;
&#13;
<p>Finally, let’s simulate the last type of failure.&#13;
Execute the commands in <a data-type="xref" href="#configure-system-to-lose">Example 3-13</a>.</p>&#13;
<div data-type="example" id="configure-system-to-lose">&#13;
<h5><span class="label">Example 3-13. </span>Configure the system to lose responses</h5>&#13;
&#13;
<pre data-code-language="bash" data-type="programlisting">&gt; curl http://127.0.0.1:63905/fault?mode<code class="o">=</code>OUTBOUND_RESPONSE_LOSS&#13;
&gt; curl http://127.0.0.1:63905&#13;
curl: <code class="o">(</code>52<code class="o">)</code> Empty reply from server</pre></div>&#13;
&#13;
<p>Now, the caller has a 50% chance of getting no response.&#13;
The connection is closed abruptly before the response reaches the caller.&#13;
You don’t get a valid HTTP response.</p>&#13;
&#13;
<p>The purpose of these examples is to illustrate the strong coupling and uncertainty arising from synchronous communication.&#13;
This type of communication, often used because of simplicity, hides the distributed nature of the interaction.&#13;
However, it makes the assumption that everything (including the services and the network) is operational.&#13;
But that’s not always the case.&#13;
As a caller using synchronous communication, you must gracefully handle faulty responses and the absence of response.</p>&#13;
&#13;
<p>So, what can we do?&#13;
We immediately think about a time-out and retries. With <code>curl</code>, you can specify a time-out (<code>-max-time</code>) and retries (<code>--retry</code>), as shown in <a data-type="xref" href="#invoke-app-3-14">Example 3-14</a>.</p>&#13;
<div data-type="example" id="invoke-app-3-14">&#13;
<h5><span class="label">Example 3-14. </span>Invoke the application by using a time-out and <code>retry</code></h5>&#13;
&#13;
<pre data-code-language="bash" data-type="programlisting">&gt; curl --max-time <code class="m">5</code> --retry <code class="m">100</code> --retry-all-errors http://127.0.0.1:63905/&#13;
curl: <code class="o">(</code>28<code class="o">)</code> Operation timed out after <code class="m">5003</code> milliseconds with <code class="m">0</code> bytes received&#13;
Warning: Transient problem: <code class="nb">time</code>-out Will retry in <code class="m">1</code> seconds. <code class="m">100</code> retries left.&#13;
hello%</pre></div>&#13;
&#13;
<p>There is a good chance that we can reach our service with 100 tries.&#13;
However, bad luck and random numbers may decide otherwise, and even 100 may not be enough.&#13;
Note that during the time that the caller (you) is waiting, that’s a rather bad user &#13;
<span class="keep-together">experience</span>.</p>&#13;
&#13;
<p>Yet, do we know for sure that if we get a time-out, the service was not invoked?&#13;
Maybe the service or the network was just slow.&#13;
What would be the ideal duration of the time-out?&#13;
It depends on many factors: where the service is located, the latency of the network, and the load of the service. Maybe there isn’t a single instance of this service but several, all with different characteristics.</p>&#13;
&#13;
<p><a data-primary="retries" data-type="indexterm" id="idm45358831793584"/>Retries are even more sneaky.&#13;
As you can’t know for sure whether the service was invoked, you can’t assume it was not.&#13;
Retrying may reprocess the same request multiple times.&#13;
But you can retry safely only if the service you are calling is idempotent.</p>&#13;
<aside data-type="sidebar" epub:type="sidebar"><div class="sidebar" id="idm45358831792384">&#13;
<h5>Idempotence</h5>&#13;
<p><a data-primary="idempotence" data-type="indexterm" id="idm45358831790976"/><a data-primary="messages" data-secondary="idempotence" data-type="indexterm" id="idm45358831790272"/><em>Idempotence</em> is used to describe  the reliability of messages in a distributed system, specifically about the reception of duplicated messages.&#13;
Because of retries or message broker features, a message sent once can be received multiple times by consumers.</p>&#13;
&#13;
<p>A service is <em>idempotent</em> if processing the same event multiple times results in the same state and output as processing that event just a single time.&#13;
The reception of a duplicated event does not change the application state or behavior.</p>&#13;
&#13;
<p>Most of the time, an idempotent service detects these events and ignores them.&#13;
Idempotence can be implemented using unique identifiers.&#13;
Each event has a unique ID.&#13;
Duplicated events have the same ID.&#13;
Then, the service needs <em>storage</em> to save all processed IDs.&#13;
When a duplicated event arrives, the service checks in this storage, and if the event is a duplicate, ignores it.&#13;
Otherwise, the service processes the event.</p>&#13;
&#13;
<p>Setting up this kind of storage is not as simple as it looks.&#13;
There are many concerns to address, because the storage is ruled by the CAP theorem.&#13;
You will need to understand the characteristics you need and pick the right infrastructure.&#13;
Possibilities include an in-memory data grid such as <a href="https://infinispan.org">Infinispan</a> or <a href="https://hazelcast.com">Hazelcast</a>, an inventory service such as Apache ZooKeeper or etcd), or a dedicated database such as Redis.&#13;
However, never forget that all these solutions come with trade-offs.</p>&#13;
</div></aside>&#13;
&#13;
<p>So, what can we do?&#13;
It’s essential to understand the impact of the time and decouple our communication.&#13;
Complex exchanges involving multiple services cannot expect all the participants and the network to be operational for the complete duration of that exchange.&#13;
The dynamic nature of the cloud and Kubernetes stresses the limit of synchronous communications.&#13;
Bad things happen: partitions, data loss, crashes…</p>&#13;
&#13;
<p>In <a data-type="xref" href="ch04.html#reactive-systems">Chapter 4</a>, you will see how Reactive addresses this issue.&#13;
By using message passing, and spatial and time decoupling, a reactive system not only is more elastic and resilient, but also improves the overall responsiveness.&#13;
In other words, reactive systems are distributed systems done right.&#13;
Also, in <a data-type="xref" href="ch05.html#reactive-programming">Chapter 5</a>, you will see the approaches Reactive is proposing to embrace the asynchronous nature of distributed systems and how we can elegantly develop event-driven and asynchronous code.&#13;
The result not only is concurrent and efficient applications, but also paves the road to new classes of applications such as data streaming, API gateways, and so on.<a data-startref="ix_distributed-system-adoc12" data-type="indexterm" id="idm45358831757984"/><a data-startref="ix_distributed-system-adoc11" data-type="indexterm" id="idm45358831757376"/><a data-startref="ix_distributed-system-adoc10" data-type="indexterm" id="idm45358831756672"/></p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Summary" data-type="sect1"><div class="sect1" id="idm45358832260128">&#13;
<h1>Summary</h1>&#13;
&#13;
<p>Distributed systems are challenging.&#13;
To build distributed systems, you need to understand their nature and always plan for the worst-case scenario.&#13;
Hiding the nature of distributed systems to seek simplicity does not work.&#13;
It results in fragile systems.</p>&#13;
&#13;
<p>This chapter covered the following:</p>&#13;
&#13;
<ul>&#13;
<li>&#13;
<p>The erratic nature of distributed systems</p>&#13;
</li>&#13;
<li>&#13;
<p>The evolution of distributed systems from a workaround to the norm</p>&#13;
</li>&#13;
<li>&#13;
<p>Use of the cloud and Kubernetes to simplify the construction of distributed &#13;
<span class="keep-together">systems</span></p>&#13;
</li>&#13;
<li>&#13;
<p>Potential failures of distributed communications caused by network disruptions, or slowness</p>&#13;
</li>&#13;
</ul>&#13;
&#13;
<p>But we won’t stop on a failure!&#13;
Time to rebound!&#13;
Let’s look a bit more into Reactive and see how it proposes to address these issues.</p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<div data-type="footnotes"><p data-type="footnote" id="idm45358832499760"><sup><a href="ch03.html#idm45358832499760-marker">1</a></sup> You can check the latency between the main American cities at <a href="https://oreil.ly/ws4Xd">the Current Network Latency site</a>.</p><p data-type="footnote" id="idm45358832353200"><sup><a href="ch03.html#idm45358832353200-marker">2</a></sup> Kubernetes provides health checks that constantly verify the state of the application. In addition, <a href="https://prometheus.io">Prometheus</a> is becoming the standard framework for metric collection.</p><p data-type="footnote" id="idm45358832286384"><sup><a href="ch03.html#idm45358832286384-marker">3</a></sup> In 2018, a power loss incident in AWS US-East-1 caused many Amazon service disruptions.</p><p data-type="footnote" id="idm45358832279664"><sup><a href="ch03.html#idm45358832279664-marker">4</a></sup> Kubernetes may move containers to achieve a higher deployment density, but also be instructed to move interacting applications on the same node to reduce the response time.</p><p data-type="footnote" id="idm45358832272336"><sup><a href="ch03.html#idm45358832272336-marker">5</a></sup> See <a href="https://oreil.ly/qRVeD">“Distributed Consensus Revised”</a> by Heidi Howard for a discussion on the problem of consensus in modern distributed system.</p><p data-type="footnote" id="idm45358832270720"><sup><a href="ch03.html#idm45358832270720-marker">6</a></sup> <a href="https://oreil.ly/p33qM">“Perspectives on the CAP Theorem”</a> by Seth Gilbert and Nancy A. Lynch explains the technical implications of the CAP theorem in <em>future</em> distributed systems.</p></div></div></section></body></html>