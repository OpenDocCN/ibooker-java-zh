- en: Chapter 9\. Advanced Serverless Architecture
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第 9 章。高级无服务器架构
- en: In [Chapter 8](ch08.html#ch08) we looked at some more advanced aspects of Lambda
    that are important once you start thinking about productionizing your applications.
    In this chapter, we continue that theme, looking more broadly at the impact of
    Lambda on architecture.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在 [第 8 章](ch08.html#ch08) 中，我们讨论了 Lambda 的一些更高级的方面，这些方面在您开始将应用程序投入生产时变得重要。在本章中，我们继续这一主题，更广泛地探讨
    Lambda 对架构的影响。
- en: Serverless Architecture “Gotchas”
  id: totrans-2
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 无服务器架构中的“陷阱”
- en: First we look at areas of serverless architecture that might cause you problems
    if you don’t consider them, and we offer different solutions for addressing these
    problems depending on your situation.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们来看看无服务器架构的各个领域，如果不考虑它们可能会给您带来问题，并针对您的情况提供不同的解决方案。
- en: At-Least-Once Delivery
  id: totrans-4
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 至少一次交付
- en: 'The Lambda platform guarantees that when an upstream event source triggers
    a Lambda function, or if another application explicitly calls the Lambda [*invoke*
    API call](https://oreil.ly/p1OWt), then the corresponding Lambda function will
    be called. But one thing the platform doesn’t guarantee is *how many times the
    function will be called*: “Occasionally, your function may receive the same event
    multiple times, even if no error occurs.” This is known as “at-least-once delivery,”
    and it exists due to the fact that the Lambda platform is a distributed system.'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: Lambda 平台保证，当上游事件源触发 Lambda 函数，或者另一个应用显式调用 Lambda 的 [*invoke* API 调用](https://oreil.ly/p1OWt)
    时，相应的 Lambda 函数将被调用。但平台不保证 *函数将被调用的次数*：即使没有错误发生，“偶尔，您的函数可能会多次接收相同的事件”。这就是“至少一次交付”，这是因为
    Lambda 平台是分布式系统的原因。
- en: The vast majority of the time a Lambda function will be called only once per
    event. But sometimes, very occasionally (far less than 1% of the time), a Lambda
    function will be called multiple times. Why is this a problem? And how do you
    deal with this behavior? Let’s take a look.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数情况下，Lambda 函数每个事件只会被调用一次。但有时（远少于 1% 的时间），Lambda 函数会被多次调用。这为什么会成为问题？如何处理这种行为？让我们来看一下。
- en: 'Example: Lambda “cron jobs”'
  id: totrans-7
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 示例：Lambda 的“cron job”
- en: If you’ve been developing software in industry long enough, you’ve probably
    come across a server host that runs multiple “cron jobs”—scheduled tasks that
    run perhaps every hour or every day. Because these tasks typically don’t run all
    the time it would be inefficient to run only one on each host, so it’s very typical
    to run multiple types of job on just one host. This is more efficient, but can
    cause operational headaches—dependency clashes, ownership uncertainties, security
    concerns, etc.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您在工业界开发软件已经足够长的时间，您可能会遇到运行多个“cron job”（定时任务，可能每小时或每天运行一次）的服务器主机。因为这些任务通常不会一直运行，因此仅在每个主机上运行一个任务是低效的，因此在一个主机上运行多种类型的任务非常典型。这样做更有效率，但可能会引起运维方面的头痛：依赖冲突、所有权不确定性、安全问题等。
- en: You can implement many kinds of activity that would otherwise be performed in
    a cron job as a Lambda function. To get the schedule behavior of cron, you can
    use a *CloudWatch Scheduled Event* as a trigger. SAM gives you a [concise syntax](https://oreil.ly/vFPnk)
    to specify this as a trigger for a function, and you can even use cron syntax
    to specify a [schedule expression](https://oreil.ly/488um). There are various
    benefits to using Lambda as a cron platform—including improving all the operational
    headaches from the previous paragraph.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以将许多类型的定时任务作为 Lambda 函数实现。要获得 cron 的调度行为，可以使用 *CloudWatch Scheduled Event*
    作为触发器。SAM 为您提供了一种 [简洁的语法](https://oreil.ly/vFPnk) 来指定这一功能的触发器，并且甚至可以使用 cron 语法来指定
    [调度表达式](https://oreil.ly/488um)。使用 Lambda 作为 cron 平台有各种好处，包括解决前面段落中的所有运维头痛。
- en: The chief drawbacks to using Lambda to implement a cron task are if the function
    takes longer than 15 minutes to run (Lambda’s maximum timeout) or if it needs
    more than 3GB memory. In either of these situations, if you can’t break up your
    task into smaller chunks, then you may want to look at [Step Functions](https://oreil.ly/YDDyY)
    and/or [Fargate](https://oreil.ly/NP0Sq) instead.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 Lambda 实现定时任务的主要缺点是，如果函数运行时间超过 15 分钟（Lambda 的最大超时时间）或者需要超过 3GB 的内存。在这两种情况下，如果无法将任务分解为较小的块，则可能需要考虑使用
    [Step Functions](https://oreil.ly/YDDyY) 和/或者 [Fargate](https://oreil.ly/NP0Sq)。
- en: 'But there is one other drawback to using Lambda: *very, very,* occasionally
    your cron job may run more than once at or near its scheduled time. Often this
    won’t be a problem worth considering—maybe your task is a cleanup job where performing
    the same cleanup twice is slightly inefficient but functionally correct. Other
    times, though, this might be a big problem—what if your task is calculating mortgage
    interest for the month—you wouldn’t want to charge that twice to a customer.'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 但是，使用 Lambda 还有另一个缺点：*非常非常地*偶尔您的定时任务可能会在其计划时间或附近运行多次。通常这不会是一个值得考虑的问题——也许您的任务是一个清理工作，两次执行相同的清理操作略微低效但功能上是正确的。然而，有时这可能是一个很大的问题——如果您的任务是计算月度抵押利息，您不希望向客户收取两次费用。
- en: This *at-least-once delivery* characteristic of Lambda applies to all event
    sources and invocations, not just scheduled events. Fortunately, there are a number
    of ways to tackle this problem.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: Lambda 的这种*至少一次交付*特性适用于所有事件源和调用，不仅限于定时事件。幸运的是，有多种方法来解决这个问题。
- en: 'Solution: Build an idempotent system'
  id: totrans-13
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 解决方案：构建一个幂等系统。
- en: The first, and typically the best, solution to this concern is to build an [*idempotent*](https://oreil.ly/rmaFI)
    system. We say that this is “typically the best” solution because it embraces
    the idea that we are building distributed systems when we use Lambda. Instead
    of working around, or ignoring, the attributes of distributed systems, we actively
    design to work with them.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 面对这个问题的第一个，通常也是最好的解决方案是构建一个[*幂等*](https://oreil.ly/rmaFI)系统。我们说这通常是最好的解决方案，是因为它接受我们在使用
    Lambda 时构建分布式系统的思想。与其绕过或忽视分布式系统的特性，我们积极设计来与其协同工作。
- en: A system is idempotent when a specific operation can be applied one or more
    times, and have the same effect no matter how many times it was applied. Idempotence
    is a very common requirement when considering any distributed architecture, let
    alone a serverless one.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 当特定操作可以应用一次或多次，并且无论应用多少次都具有相同效果时，系统是幂等的。考虑到任何分布式架构时，幂等性是一个非常普遍的要求，更不用说无服务器架构了。
- en: An example of an idempotent operation is uploading a file to S3 (ignoring any
    possible triggers!). Whether you upload the same file to the same location once
    or ten times, the net result is that the correct bytes will be stored in S3 at
    the expected key.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 一个幂等操作的例子是将文件上传到 S3（忽略任何可能的触发器！）。无论您将同一文件上传到相同位置一次还是十次，最终结果是预期的键中S3中存储的正确字节。
- en: We can build an idempotent system with Lambda when any significant *side effects*
    of a function are, themselves, idempotent. For example, if our Lambda function
    uploads a file to S3, then the complete system of Lambda + S3 is idempotent. Similarly
    if you are writing to a database you can use an *upsert* operation (“update or
    insert”), like DynamoDB’s [`UpdateItem`](https://oreil.ly/OTfZP) method, to create
    idempotence. Finally, if you are calling any external APIs, you will likely want
    to look to see if they offer idempotent operations.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 当函数的任何重大*副作用*本身是幂等时，我们可以使用 Lambda 构建一个幂等系统。例如，如果我们的 Lambda 函数将文件上传到 S3，则 Lambda
    + S3 的整个系统是幂等的。类似地，如果您在写入数据库时可以使用*upsert*操作（“更新或插入”），如 DynamoDB 的[`UpdateItem`](https://oreil.ly/OTfZP)方法，来创建幂等性。最后，如果您调用任何外部
    API，则可能需要查看它们是否提供幂等操作。
- en: 'Solution: Accept duplicates, and perhaps deal with problems if/when they come
    up'
  id: totrans-18
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 解决方案：接受重复，并在问题出现时进行处理。
- en: Sometimes a perfectly reasonable way to deal with possible multiple invocations
    is to be aware that it can happen, and accept it, especially since it happens
    so rarely. For example, say you have a scheduled task that generates a report
    and then emails it to a company-internal mailing list. Do you care if that email
    occasionally goes out twice? Perhaps not.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 有时处理可能发生的多次调用的一个完全合理的方法是意识到它可能会发生，并接受它，特别是因为它发生得如此之少。例如，假设您有一个定时任务生成报告然后将其电邮发送到公司内部邮件列表。如果偶尔发送两次电子邮件，您是否在意？也许不会。
- en: Similarly, maybe the work to build an idempotent system would be significant,
    but dealing with the impact of very occasional task repetition is actually simple
    and cheap. In this case, rather than building in idempotence, it might be better
    to monitor for a job being run multiple times for one event and then have a manual
    or automated task that performs cleanup if it ever occurs.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 同样地，也许构建一个幂等系统的工作量是显著的，但是处理非常偶尔的任务重复的影响实际上是简单和廉价的。在这种情况下，与其内置幂等性，也许更好的方法是监控某个事件的多次运行，然后有一个手动或自动的任务在它发生时执行清理。
- en: 'Solution: Check for previous processing'
  id: totrans-21
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 解决方案：检查之前的处理
- en: If repeated side effects aren’t ever acceptable, but your Lambda function is
    also using downstream systems that don’t have idempotent operations, then you
    have another way to solve this problem. The idea is to make your Lambda function
    itself idempotent, rather than relying on downstream components to provide idempotence.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 如果重复的副作用从不可接受，但是您的Lambda函数还使用了不具有幂等操作的下游系统，那么您有另一种解决此问题的方式。关键在于使您的Lambda函数本身具有幂等性，而不是依赖下游组件提供幂等性。
- en: But how do you do this, knowing that Lambda may call a function multiple times
    for the same event? The key here is to also know that even if Lambda calls a function
    more than once for the same event, then the *AWS request ID* that Lambda attaches
    to an event will be the same for each call. We can read the AWS request ID by
    calling `.getAwsRequestId()` on the [`Context`](https://oreil.ly/gh-Bw) object
    that we can choose to accept in our handler method.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 但是，您如何做到这一点，知道Lambda可能会多次为同一事件调用函数？关键在于还要知道，即使Lambda为同一事件调用多次函数，Lambda附加到事件的*AWS请求ID*将对每次调用都相同。我们可以通过在我们的处理程序方法中调用`.getAwsRequestId()`来读取AWS请求ID，我们可以选择接受[`Context`](https://oreil.ly/gh-Bw)对象。
- en: Assuming we can keep track of these request IDs, we’ll know if we’ve seen one
    before, and if we have we can choose to discard the second call, guaranteeing
    “exactly-once” overall semantics.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们可以跟踪这些请求ID，我们将知道我们以前是否见过某个请求ID，如果是，则可以选择丢弃第二次调用，从而保证总体语义上的“仅一次”保证。
- en: All we need now is a way of checking, for each invocation of our function, to
    see if the function has already seen the request ID before. Because multiple function
    invocations for an event could in theory overlap, we need a source of *atomicity*
    to provide this capability, and this suggests that using a database would help.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们只需要一种方法来检查每次函数调用是否已经看到过请求ID。因为理论上事件的多个函数调用可能重叠，所以我们需要一个*原子性*的来源来提供这种能力，这表明使用数据库会有所帮助。
- en: DynamoDB can provide this for us by way of its [*conditional writes*](https://oreil.ly/DBne-)
    feature. In a simple scenario, we could have a table with just a primary key of
    `request_id`; we could attempt to write to that table at the beginning of our
    handler with the event’s request ID; immediately stop execution if the DynamoDB
    operation failed; and otherwise continue our Lambda’s functionality as normal,
    knowing that this is the first time an event has been processed (see [Figure 9-1](#checking-for-previous-event-with-dynamodb)).
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: DynamoDB可以通过其[*条件写入*](https://oreil.ly/DBne-)功能为我们提供这一点。在一个简单的场景中，我们可以有一张只有`request_id`主键的表；我们可以在处理程序开始时尝试写入该表，使用事件的请求ID；如果DynamoDB操作失败，则立即停止执行；否则，我们可以像往常一样继续Lambda的功能，知道这是第一次处理事件（参见[图 9-1](#checking-for-previous-event-with-dynamodb)）。
- en: '![images/ch09_image01.png](assets/awsl_0901.png)'
  id: totrans-27
  prefs: []
  type: TYPE_IMG
  zh: '![images/ch09_image01.png](assets/awsl_0901.png)'
- en: Figure 9-1\. Checking for a previous event with DynamoDB
  id: totrans-28
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 9-1\. 使用DynamoDB检查以前的事件
- en: If you choose to go down this path, your actual solution will likely have some
    nuance. For example, you may choose to delete the row in DynamoDB if an error
    occurred (so as to continue to be able to use Lambda’s retry semantics—the retried
    event will also have the same AWS request ID!). And/or you may choose to have
    a more complicated “lock with timeout” style of behavior to allow for overlapping
    calls where the first could fail.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您选择沿着这条路走，您的实际解决方案可能会有一些细微差别。例如，如果发生错误，您可以选择在DynamoDB中删除行（以便继续使用Lambda的重试语义
    - 重试的事件也将具有相同的AWS请求ID！）。或者，您可以选择更复杂的“带超时的锁定”风格行为，以允许第一个调用失败时的重叠调用。
- en: There are also a few DynamoDB concerns to think about with this solution. For
    example, you probably want to set up a [Time to Live (TTL) property](https://oreil.ly/JFDQg)
    on the table to automatically delete rows after a certain period of time to keep
    things clean, typically set to a day or to a week. Also, you may want to consider
    the expected throughput of your Lambda function and use that to analyze costs
    of the DynamoDB table—if the costs are too high, you may want to choose an alternative
    solution. Such alternatives include using a SQL database; building your own (non-Lambda)
    service to manage this repetition; or, in extreme cases, replacing Lambda entirely
    for this particular function with a more traditional compute platform.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 使用这种解决方案时，还需要考虑一些 DynamoDB 的问题。例如，您可能希望在表上设置[存活时间（TTL）属性](https://oreil.ly/JFDQg)，以在一段时间后自动删除行以保持清洁，通常设置为一天或一周。另外，您可能需要考虑
    Lambda 函数的预期吞吐量，并使用它来分析 DynamoDB 表的成本 —— 如果成本太高，您可能需要选择另一种解决方案。此类替代方案包括使用 SQL
    数据库；构建自己的（非 Lambda）服务来管理此重复操作；或者，在极端情况下，将 Lambda 完全替换为具有更传统计算平台的特定功能。
- en: Impacts of Lambda Scaling on Downstream Systems
  id: totrans-31
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Lambda 扩展对下游系统的影响
- en: In [Chapter 8](ch08.html#ch08) we looked at Lambda’s “magical” auto-scaling
    ([“Scaling”](ch08.html#lambda-scaling)). To quickly summarize, Lambda will automatically
    create just as many instances as necessary of your function, and its environment,
    to handle all events to be processed. It will do this, by default, up to one thousand
    Lambda instances per account, and more than that if you ask AWS to increase your
    limit.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 在[第 8 章](ch08.html#ch08)中，我们看到了 Lambda 的“神奇”自动扩展（[“扩展”](ch08.html#lambda-scaling)）。简单总结一下，Lambda
    将自动创建所需数量的函数实例及其环境，以处理所有待处理的事件。默认情况下，它会创建每个帐户最多一千个 Lambda 实例，并且如果您要求 AWS 增加您的限制，它还会创建更多。
- en: This is, in general, a very useful feature, and one of the key reasons people
    find Lambda valuable. However, if your Lambda function interacts with downstream
    systems (and most do!), then you need to consider how such scaling could impact
    those systems. As an exercise, let’s consider the examples in [Chapter 5](ch05.html#ch05).
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 总的来说，这通常是一个非常有用的功能，也是人们发现 Lambda 有价值的关键原因之一。但是，如果您的 Lambda 函数与下游系统进行交互（大多数情况下都是如此！），那么您需要考虑这种扩展如何影响这些系统。作为一项练习，让我们考虑[第
    5 章](ch05.html#ch05)中的示例。
- en: 'In [“Example: Building a Serverless API”](ch05.html#serverless-api-example),
    we had two functions—`WeatherEventLambda` and `WeatherQueryLambda`—that both called
    DynamoDB. We would need to know that DynamoDB could handle the load of however
    many upstream Lambda instances existed. Since we used DynamoDB’s [“on-demand”
    capacity mode](https://oreil.ly/SHRmW), we know that this is, in fact, the case.'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 在 [“示例：构建无服务器 API”](ch05.html#serverless-api-example) 中，我们有两个函数 —— `WeatherEventLambda`
    和 `WeatherQueryLambda` —— 都调用了 DynamoDB。我们需要知道 DynamoDB 是否能够处理存在的任何上游 Lambda 实例的负载。由于我们使用了
    DynamoDB 的[“按需”容量模式](https://oreil.ly/SHRmW)，我们知道事实上情况确实如此。
- en: 'In [“Example: Building a Serverless Data Pipeline”](ch05.html#serverless-data-pipeline-example),
    we also had two functions—`BulkEventsLambda` and `SingleEventLambda`. `BulkEventsLambda`
    calls SNS, specifically to publish messages, so we can look at the [AWS service
    limits documentation](https://oreil.ly/rv4GW) to see how many publish calls we
    can make to the SNS API. That page says that the limit is between 300 and 30,000
    “transactions per second,” depending on the region we’re in.'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 在 [“示例：构建无服务器数据管道”](ch05.html#serverless-data-pipeline-example) 中，我们还有两个函数 ——
    `BulkEventsLambda` 和 `SingleEventLambda`。`BulkEventsLambda` 调用 SNS，具体来说是为了发布消息，因此我们可以查看[AWS
    服务限制文档](https://oreil.ly/rv4GW)以了解我们可以向 SNS API 发出多少发布调用。该页面说限制在每秒 300 到 30,000
    “事务”之间，取决于我们所在的地区。
- en: We can use that data to make a judgment call as to whether we think SNS can
    handle the load we may put on it from our Lambda function. Also, the documentation
    says that this is a *soft limit*—in other words, we can ask AWS to increase it
    for us. It’s worth knowing that should we exceed the limit, then our use of SNS
    will be throttled—we could pass this error back up through our Lambda function
    as an *unhandled error* and therefore use Lambda’s retry mechanism. It’s also
    useful to know that this is an account-wide limit, so any other components using
    SNS in the same account would also be throttled if our Lambda function caused
    us to hit the SNS API limit.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用这些数据来判断我们是否认为 SNS 能够处理我们从 Lambda 函数上可能产生的负载。此外，文档指出这是一个*软限制*——换句话说，我们可以请求
    AWS 为我们增加它。值得知道的是，如果我们超过了限制，那么我们对 SNS 的使用将受到限制——我们可以将此错误通过 Lambda 函数传递回去，作为*未处理的错误*，从而使用
    Lambda 的重试机制。另外，值得一提的是这是一个账户范围的限制，因此，如果我们的 Lambda 函数导致我们达到了 SNS API 的限制，同一账户中使用
    SNS 的任何其他组件也将受到限制。
- en: '`SingleEventLambda` only calls CloudWatch Logs indirectly via the Lambda runtime.
    CloudWatch Logs has limits, but they’re very high, so for now we’ll assume it
    has sufficient capacity.'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: '`SingleEventLambda` 只通过 Lambda 运行时间接调用 CloudWatch Logs。CloudWatch Logs 有限制，但它们非常高，所以目前我们将假设它具有足够的容量。'
- en: In summary, the services that we’ve used in these examples scale up to high
    throughputs. That shouldn’t be surprising—these examples were designed to be good
    examples of serverless architecture.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 总之，我们在这些示例中使用的服务可以扩展到高吞吐量。这应该不足为奇——这些示例被设计为无服务器架构的好例子。
- en: However, what happens if you’re using downstream systems that either (a) don’t
    scale as *much* as your Lambda function may scale or (b) don’t scale as *quickly*
    as your Lambda function may scale? An example of (a) might be a downstream relational
    database—it may only be designed for one hundred concurrent connections, and five
    hundred connections might cause it serious problems. An example of (b) might be
    a downstream microservice using EC2-based auto-scaling—here the service may eventually
    scale wide enough to handle unexpected load, but Lambda can scale in *seconds*,
    as opposed to EC2, which will scale in *minutes*.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，如果你正在使用的下游系统要么（a）不像你的 Lambda 函数可能会扩展的那么*多*，要么（b）不像你的 Lambda 函数可能会扩展的那么*快*，那会发生什么？（a）的一个例子可能是下游关系型数据库——它可能只设计用于一百个并发连接，而五百个连接可能会给它带来严重的问题。
    （b）的一个例子可能是使用基于 EC2 的自动缩放的下游微服务——这里该服务最终可能会扩展到足以处理意外负载，但 Lambda 可以在*秒*内扩展，而不是
    EC2，后者将在*分钟*内扩展。
- en: In either of these cases, unplanned scaling of your Lambda functions can cause
    performance impacts on downstream systems. Often times if such problems occur
    then the effects will also be felt by other clients of those systems, not just
    the Lambda function inflicting the load. Because of this concern, you should always
    consider Lambda’s impact on downstream systems with regards to scaling. There
    are multiple possible solutions to dealing with this.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 在这两种情况下，Lambda 函数的不可预见的扩展可能会对下游系统产生性能影响。通常，如果出现这样的问题，则这些效果也会被这些系统的其他客户感受到，而不仅仅是产生负载的
    Lambda 函数。由于这个原因，你应该始终考虑 Lambda 对下游系统的扩展的影响。有多种可能的解决方案来处理这个问题。
- en: 'Solution: Use like-scaling infrastructure'
  id: totrans-41
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 解决方案：使用相似的扩展基础设施
- en: One solution is, where possible, to use downstream systems that have similar
    scaling behaviors and capacities to Lambda itself. We chose DynamoDB and SNS in
    the [Chapter 5](ch05.html#ch05) examples partly due to this design motivation.
    Similarly, sometimes we may choose to actively migrate away from certain solutions
    precisely because of scaling concerns. For example, if we can easily switch to
    using DynamoDB from an RDS database, it may make sense to do so.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 一种解决方案是，在可能的情况下，使用具有与 Lambda 本身相似的扩展行为和容量的下游系统。我们选择 DynamoDB 和 SNS 在[第五章](ch05.html#ch05)的示例部分是部分由于这个设计动机。同样，有时我们可能会选择积极迁移离开某些解决方案，正是因为扩展的考虑。例如，如果我们可以轻松地从
    RDS 数据库切换到使用 DynamoDB，那么这样做可能是有道理的。
- en: 'Solution: Manage scaling upstream'
  id: totrans-43
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 解决方案：管理上游的扩展
- en: Another way to solve the problem of Lambda scaling too wide for downstream systems
    is to make sure it never needs to scale in the first place, or in other words
    to restrict the number of events that trigger execution. If you’re implementing
    a company-internal serverless API, then this might mean making sure the API’s
    clients do not make too many requests.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个解决 Lambda 扩展超出下游系统的问题的方法是确保它根本不需要扩展，或者换句话说，限制触发执行的事件数量。如果您正在实施公司内部的无服务器 API，则可能意味着确保
    API 的客户端不要发出过多的请求。
- en: Some Lambda event sources also offer functionality to help manage scale. API
    Gateway has rate limiting (with [*usage plans*](https://oreil.ly/FR4eX) and *throttling
    limits*), and Lambda’s SQS integration allows you to [configure a batch size](https://oreil.ly/LxNTp).
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 某些 Lambda 事件源还提供了帮助管理规模的功能。API 网关具有速率限制（具有 [*使用计划*](https://oreil.ly/FR4eX)
    和 *节流限制*），Lambda 的 SQS 集成允许您配置批量大小 [（https://oreil.ly/LxNTp）](https://oreil.ly/LxNTp)。
- en: 'Solution: Manage scaling with reserved concurrency'
  id: totrans-46
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 解决方案：使用保留并发管理扩展性
- en: If you can’t manage scale upstream, but still want to restrict how wide your
    function will scale, you can use Lambda’s reserved concurrency feature that we
    looked at in [“Reserved concurrency”](ch08.html#reserved-concurrency).
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您无法在上游管理规模，但仍希望限制函数的规模，可以使用 Lambda 的保留并发功能，我们在 [“保留并发”](ch08.html#reserved-concurrency)
    中进行了介绍。
- en: When using reserved concurrency, the Lambda platform will only scale out your
    function at most as wide as the configured amount you have given. For example,
    if you set reserved concurrency to 10, then you’ll have at most 10 instances of
    your Lambda function running at any one time. In this case, if 10 instances of
    your Lambda are already processing events when another event arrives, then your
    function is throttled, just as we looked at in [Chapter 8](ch08.html#ch08).
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 当使用保留并发时，Lambda 平台将最多按照您配置的数量扩展函数。例如，如果将保留并发设置为 10，则在任何时候最多运行 10 个 Lambda 函数实例。在这种情况下，如果已有
    10 个 Lambda 实例正在处理事件，当另一个事件到达时，您的函数会被节流，就像我们在 [第 8 章](ch08.html#ch08) 中讨论过的那样。
- en: This kind of scale limitation is great when you have event sources like SNS
    or S3 where you may easily have a “burst” of events—using reserved concurrency
    means that these events are processed over a period of time, rather than all immediately.
    And because of Lambda’s retrying capability for throttling errors and asynchronous
    sources, you’re guaranteed that all of the events will eventually get processed,
    as long as processing can occur within six hours.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 当您的事件源（如 SNS 或 S3）可能会轻松产生“突发”事件时，这种规模限制非常适用——使用保留并发意味着这些事件会在一段时间内处理，而不是立即全部处理。由于
    Lambda 对于节流错误和异步来源的重试能力，您可以确保所有事件最终会被处理，只要在六小时内可以处理完毕。
- en: One behavior you should know about reserved concurrency is that it doesn’t just
    limit concurrency—it *guarantees* concurrency by removing the configured amount
    from the account-global Lambda concurrency pool. If you have 20 functions all
    with a reserved concurrency of 50, then you won’t have any more capacity for other
    Lambda functions, assuming an account-wide concurrency limit of 1,000. This account-wide
    limit can be increased, but that’s a manual task that you’ll need to remember
    to perform.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 您应该了解有关保留并发的一项行为是它不仅限制并发——它通过从全局 Lambda 并发池中移除配置的数量来*保证*并发。如果您有 20 个函数，每个函数的保留并发为
    50，假设全局并发限制为 1,000，则将没有更多容量用于其他 Lambda 函数。全局并发限制可以增加，但这是一个需要记住执行的手动任务。
- en: 'Solution: Architect deliberately hybrid solutions'
  id: totrans-51
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 解决方案：有意构建混合解决方案
- en: A final idea is to build *deliberately* “hybrid” solutions (as opposed to *accidentally*
    hybrid solutions) consisting of serverless and traditional components.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 最后一个想法是有意“混合”构建解决方案（而不是*意外*混合解决方案），包括无服务器和传统组件。
- en: For example, if you used Lambda and Amazon’s (nonserverless) RDS SQL database
    service, without considering the scaling concerns, we’d call this an “accidentally”
    hybrid solution. However, if you put thought into how your RDS database could
    be used more effectively with Lambda, then we’d call this “deliberately” hybrid.
    And to be clear—we think that some architectural solutions are going to be better
    with a mixture of serverless and nonserverless components, due to the nature of
    services like DynamoDB, and Lambda itself.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，如果您使用 Lambda 和亚马逊的（非无服务器）RDS SQL 数据库服务，而没有考虑扩展性问题，我们将这称为“意外”混合解决方案。然而，如果您考虑了如何通过
    Lambda 更有效地使用您的 RDS 数据库，那么我们将其称为“故意”混合。并且明确一点——我们认为某些架构解决方案由于像 DynamoDB 这样的服务和
    Lambda 本身的性质，混合使用无服务器和非无服务器组件会更好。
- en: Let’s consider an example where you are ingesting data into a relational database
    via a Lambda function, perhaps behind an API Gateway ([Figure 9-2](#lambda-relational-direct)).
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们考虑一个例子，您通过 Lambda 函数将数据注入关系数据库，可能是在 API Gateway 的背后（参见[图 9-2](#lambda-relational-direct)）。
- en: '![images/ch09_image02.png](assets/awsl_0902.png)'
  id: totrans-55
  prefs: []
  type: TYPE_IMG
  zh: '![images/ch09_image02.png](assets/awsl_0902.png)'
- en: Figure 9-2\. Direct writes to a relational database from a Lambda function
  id: totrans-56
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 9-2\. 从 Lambda 函数直接写入关系数据库
- en: A concern with this design is that if you have too many inbound requests, then
    you may end up overloading your downstream database.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 此设计的一个问题是，如果您有太多的入站请求，那么您可能会过载您的下游数据库。
- en: The first solution you may consider is to add reserved concurrency to the Lambda
    function backing the API, but the problem here is now your upstream clients will
    have to deal with throttling caused by your concurrency restrictions.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 您可能首先考虑的解决方案是为支持 API 的 Lambda 函数添加保留并发，但问题在于现在您的上游客户端将不得不处理由并发限制引起的节流问题。
- en: A better solution, therefore, might be to introduce a messaging topic, a new
    Lambda function, and use reserved concurrency on the second Lambda function ([Figure 9-3](#lambda-relational-indirect)).
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，更好的解决方案可能是引入一个消息主题、一个新的 Lambda 函数，并在第二个 Lambda 函数上使用保留并发（参见[图 9-3](#lambda-relational-indirect)）。
- en: '![images/ch09_image03.png](assets/awsl_0903.png)'
  id: totrans-60
  prefs: []
  type: TYPE_IMG
  zh: '![images/ch09_image03.png](assets/awsl_0903.png)'
- en: Figure 9-3\. Indirect writes to a relational database from a Lambda function
    via a topic
  id: totrans-61
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 9-3\. 通过主题从 Lambda 函数间接写入关系数据库
- en: With this design, your API Lambda function can still, for example, perform input
    validation, returning an error message to the client if necessary. However, instead
    of writing directly to the database, it would instead publish a message to a topic,
    for example, with SNS, under the assumption that your messaging system can handle
    sudden load more effectively than your database. The listener of that message
    would then be another Lambda function, whose job is purely to perform the database
    write (or “upsert” to handle duplicate invocations!). But this time the Lambda
    function can have reserved concurrency applied to protect the database, while
    at the same time making use of the retry semantics within AWS itself, rather than
    requiring the original external client to perform a retry.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 使用这种设计，例如，您的 API Lambda 函数仍然可以执行输入验证，必要时向客户端返回错误消息。但是，它不会直接写入数据库，而是会将消息发布到一个主题，例如，使用
    SNS，在假设您的消息系统可以比数据库更有效地处理突然负载的情况下。然后，该消息的监听者将是另一个 Lambda 函数，其工作纯粹是执行数据库写入（或“upsert”，以处理重复调用！）。但这次
    Lambda 函数可以应用保留并发以保护数据库，同时利用 AWS 内部的重试语义，而不是要求原始外部客户端执行重试。
- en: While this resulting design has more moving parts, it successfully solves the
    scaling concerns while still mixing serverless and nonserverless components.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然这种结果设计具有更多的移动部件，但它成功解决了扩展性问题，同时仍然混合使用了无服务器和非无服务器组件。
- en: Tip
  id: totrans-64
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 小贴士
- en: In late 2019 Amazon announced the [RDS Proxy](https://oreil.ly/alAqq) service.
    At the time of writing, it is still in “Preview” and so many of the details and
    capabilities it will have when it is released to general availability (GA) aren’t
    yet known. However, it certainly should help with some of the concerns discussed
    in this chapter in connecting Lambda to RDS.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 2019 年底，亚马逊宣布了[RDS 代理](https://oreil.ly/alAqq)服务。截至撰写本文时，该服务仍处于“预览”阶段，因此发布到普遍可用（GA）时的许多细节和功能尚未明确。然而，它肯定会在连接
    Lambda 到 RDS 的一些讨论中帮助解决一些问题。
- en: The “Fine Print” of Lambda Event Sources
  id: totrans-66
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Lambda 事件源的“细则”
- en: The first couple of sections in this chapter have been about architectural concerns
    that come about because of nuances of Lambda itself. There are other areas that
    can impact a serverless design because of the services that exist upstream of
    Lambda. Just like the fact that “at-least-once” delivery isn’t front and center
    of the first document you read about Lambda, you’ll only find some of these nuances
    with upstream services through deep exploration of documentation, or hard-earned
    experience.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 本章的前几节讨论的是 Lambda 本身的微妙架构问题。由于 Lambda 上游存在的服务的细微差别，还有其他领域可能会影响无服务器设计。就像“至少一次”交付不是您在关于
    Lambda 的第一篇文档中看到的核心内容一样，只有通过深入探索文档或艰辛的经验，您才能发现这些服务的一些微妙差别。
- en: When you start to get beyond the “tinkering” stage with any Lambda event source,
    read as much AWS documentation as you can on the services you’re using. Seek out
    non-AWS articles too—while they’re not authoritative, and sometimes wrong, occasionally
    they can nudge you in a direction, architecturally, that you may not have considered
    otherwise.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 当您开始超越任何 Lambda 事件源的“试验性”阶段时，请尽可能阅读关于您正在使用的服务的所有 AWS 文档。也要寻找非 AWS 的文章——尽管它们不具权威性，有时是错误的，但有时候它们可以在架构上推动您朝着可能否则不会考虑的方向前进。
- en: New Patterns of Architecture Enabled by Serverless Thinking
  id: totrans-69
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 由无服务器思维启用的新架构模式
- en: Sometimes when we’re building serverless systems, our architecture, viewed from
    a certain distance, might not look that different than how we could have designed
    it using containers or virtual machines (VMs). “Cloud-native” architecture is
    not the sole domain of Kubernetes, no matter what you may have otherwise heard!
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 有时，当我们构建无服务器系统时，从某种距离来看，我们的架构可能并不比使用容器或虚拟机（VM）设计的方式看起来有多不同。“云原生”架构并不仅仅是 Kubernetes
    的专属领域，无论您之前听到过什么！
- en: 'For example, our serverless API that we built back in [“Example: Building a
    Serverless API”](ch05.html#serverless-api-example), from a “black-box” point of
    view, looked just like any other microservice-style API. In fact, we could replace
    the Lambda functions with an application running in a container and, architecturally,
    the system would have been very similar.'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，我们构建的无服务器 API 回溯到[“示例：构建无服务器 API”](ch05.html#serverless-api-example)，从“黑盒”视角来看，看起来就像任何其他微服务风格的
    API。事实上，我们可以用运行在容器中的应用程序替换 Lambda 函数，从架构上讲，系统将会非常相似。
- en: As serverless starts to mature, however, we’re seeing new architectural patterns
    that either wouldn’t make sense with traditional services, or wouldn’t even be
    possible. We alluded to one of these earlier in [Chapter 5](ch05.html#ch05) when
    we talked about [“Serverless Without Lambda”](ch05.html#serverless-without-lambda).
    To close out this chapter, we’ll look at a couple of other patterns, using Lambda,
    that break into new territory.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 随着无服务器开始成熟，我们看到了一些新的架构模式，这些模式要么在传统服务中没有意义，要么甚至是不可能的。我们在[第五章](ch05.html#ch05)中提到过其中一种，当我们讨论[“无
    Lambda 的无服务器”](ch05.html#serverless-without-lambda)时。在本章的结束部分，我们将看看其他几种模式，使用 Lambda，打破进入新领域。
- en: Published Components with the Serverless Application Repository
  id: totrans-73
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用无服务器应用程序库发布组件
- en: We’ve talked a few times through the book about “serverless applications”—groups
    of components that we collectively deploy as one unit. We had our serverless API,
    using API Gateway, two Lambda functions, and a DynamoDB table, all grouped as
    a unit. We defined this collection of resources using a Serverless Application
    Model (SAM) template.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 在本书中我们多次提到“无服务器应用程序”——作为一个单元部署的组件集合。我们有我们的无服务器 API，使用 API Gateway，两个 Lambda
    函数和一个 DynamoDB 表，全部作为一个单元分组。我们使用 Serverless Application Model（SAM）模板定义了这些资源集合。
- en: AWS provides a way to reuse and share these SAM applications, via the [Serverless
    Application Repository (SAR)](https://oreil.ly/Oa8HO). With SAR you *publish*
    your application, and you can then *deploy* it later, multiple times, to different
    regions, accounts, or even different organizations if you choose to make the SAR
    application publicly available.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: AWS 提供了一种通过[无服务器应用程序库（SAR）](https://oreil.ly/Oa8HO)重用和共享这些 SAM 应用程序的方式。使用 SAR，您可以*发布*您的应用程序，然后稍后可以*部署*它，多次部署到不同的区域、帐户甚至不同的组织，如果您选择将
    SAR 应用程序公开可用的话。
- en: Traditionally you likely have either distributed code or a shipped environment–agnostic
    deployment configuration. With SAR the code (by way of packaged Lambda functions),
    the infrastructure definitions, and the (parameterizable) deployment configuration
    are all wrapped up in one shareable, *versioned*, component.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 传统上，您可能有分发的代码或一个环境无关的部署配置。使用 SAR，代码（通过打包的 Lambda 函数）、基础架构定义和（可参数化的）部署配置全部捆绑在一个可共享的、*版本化的*
    组件中。
- en: There are a couple of different ways that SAR apps can be deployed that make
    them useful in different situations.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: SAR 应用程序可以通过几种不同的部署方式部署，这使它们在不同情况下都很有用。
- en: First, they can be deployed as *standalone applications*, just as if you had
    called `sam deploy` directly on them, rather than using SAR. This is useful when
    you want to deploy the same application in multiple locations or across multiple
    accounts or organizations. In this case, SAR acts somewhat like a repository of
    application deployment templates, but by bundling the code, it also includes the
    actual application code.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，它们可以部署为 *独立应用程序*，就像您直接调用 `sam deploy` 一样，而不是使用 SAR。当您希望在多个位置或跨多个帐户或组织部署相同的应用程序时，这很有用。在这种情况下，SAR
    在某种程度上就像应用程序部署模板的存储库，但通过打包代码，它还包括实际的应用程序代码。
- en: Examples of SAR application suited to this type of usage abound in the [public
    SAR repository](https://oreil.ly/QyOkD)—it’s especially useful for third-party
    software providers who want to make it easier for customers to deploy integration
    components to their AWS account. A good example is this [log forwarder from DataDog](https://oreil.ly/z-s8e).
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 此类用途的 SAR 应用示例在[公共 SAR 存储库](https://oreil.ly/QyOkD)中数不胜数——对于希望简化客户将集成组件部署到其
    AWS 帐户的第三方软件提供商来说，这尤其有用。例如，这是来自 DataDog 的[日志转发器](https://oreil.ly/z-s8e)。
- en: SAR applications can also be used as *embedded* components within other, *parent*,
    serverless applications via [CloudFormation nested stacks](https://oreil.ly/1sJjI).
    SAM enables nesting SAR components via the [`AWS::Serverless::Application` resource
    type](https://oreil.ly/aY0-G). When using SAR in this way, you are abstracting
    higher-level components as SAR apps, and instantiating those components within
    multiple applications. Using SAR in this way is a little like using a [“sidecar”](https://oreil.ly/9k3Xl)
    in container-oriented applications, but without the low-level network-oriented
    communication patterns that sidecars require.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: SAR 应用程序也可以作为其他 *父级* 无服务器应用程序中的 *嵌入式* 组件通过[CloudFormation 嵌套堆栈](https://oreil.ly/1sJjI)使用。SAM
    通过 [`AWS::Serverless::Application` 资源类型](https://oreil.ly/aY0-G) 实现了 SAR 组件的嵌套。当以这种方式使用
    SAR 时，您正在将高级组件抽象为 SAR 应用程序，并在多个应用程序中实例化这些组件。以这种方式使用 SAR 有点像在基于容器的应用程序中使用 [“旁车”](https://oreil.ly/9k3Xl)，但没有旁车需要的低级网络通信模式。
- en: These nested components may include Lambda functions that may be invoked directly,
    or indirectly (e.g., via SNS topic, perhaps also included in the SAR), by the
    parent application. Alternatively, these nested components may not contain any
    functions at all, and instead solely define infrastructural resources. A good
    example here are SAR applications that standardize monitoring resources.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 这些嵌套组件可能包括可以直接调用的 Lambda 函数，也可能是通过父应用程序（例如，通过 SAR 也许也包含在其中的 SNS 主题）间接调用的。或者，这些嵌套组件可能根本不包含任何函数，而是仅定义基础资源。一个很好的例子是标准化监控资源的
    SAR 应用程序。
- en: We prefer the embedded deployment scheme in general, even if there are no other
    components in the parent application. This is because deploying SAR apps, along
    with their parameter values that can be defined as part of the `AWS::Serverless::Application`
    resource in your template file, is no different than deploying any other SAM-defined
    serverless application. Further, if you choose to update the *version* of a deployed
    SAR app, then that too can be tracked in version control just like any other template
    update.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 通常情况下，我们更喜欢嵌入式部署方案，即使父应用程序中没有其他组件。这是因为部署 SAR 应用程序以及可以在模板文件中作为 `AWS::Serverless::Application`
    资源的一部分定义的参数值与部署任何其他 SAM 定义的无服务器应用程序没有任何区别。此外，如果您选择更新已部署的 SAR 应用程序的 *版本*，那么这也可以像任何其他模板更新一样在版本控制中跟踪。
- en: SAR apps can be secured so that they are accessible only to accounts within
    a particular AWS organization, and therefore they are a great way of defining
    standard components that can be used across a whole company. Examples of using
    this with the embedded component deployment scheme are custom authorizers for
    API Gateway, standard operational components (e.g., alarms, log filters, and dashboards),
    and common patterns of message-based inter-service communication.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: '[SAR 应用程序](https://oreil.ly/nhOUb) 可以进行安全设置，以便仅对特定 AWS 组织中的帐户可访问，因此它们是定义可在整个公司中使用的标准组件的绝佳方式。
    使用此功能的示例包括 API Gateway 的自定义授权程序、标准运行组件（例如警报、日志过滤器和仪表板）以及消息传递式跨服务通信的常见模式的使用。'
- en: SAR does have some limitations. For example, you can’t use all CloudFormation
    resource types within it (for example, EC2 instances). However, this is an interesting
    way of building, deploying, and composing Lambda-based applications.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: SAR 确实有一些限制。 例如，您无法在其中使用所有 CloudFormation 资源类型（例如，EC2 实例）。 但是，这是一种有趣的构建、部署和组合基于
    Lambda 的应用程序的方式。
- en: For details on how to publish SAM applications to SAR, see the [documentation](https://oreil.ly/nhOUb),
    and for details of deploying SAR apps see the previous link for the `AWS::Serverless::Application`
    resource type.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 有关如何将 SAM 应用程序发布到 SAR 的详细信息，请参阅[文档](https://oreil.ly/nhOUb)，有关部署 SAR 应用程序的详细信息，请参阅前面链接的
    `AWS::Serverless::Application` 资源类型。
- en: Globally Distributed Applications
  id: totrans-86
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 全球分布式应用程序
- en: In days of yore (i.e., about 15 years ago), most of us building server-based
    applications often had a fairly good idea where our software was physically running,
    at least to within one hundred meters or so, and often closer than that. We could
    pinpoint the data centers, server rooms, and perhaps even the racks or individual
    machines where our code was humming along.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 在很久以前（即大约 15 年前），我们大多数构建基于服务器的应用程序的人通常对我们的软件实际运行的地点有一个相当清楚的概念，至少在一百米左右，甚至更近。
    我们可以准确指出数据中心、服务器房间，甚至我们的代码正在运行的机架或个别机器。
- en: Along came the “cloud,” and our understanding of the geographic deployment of
    our apps got a little, well, cloudy. With EC2, for example, we know, roughly,
    that our code is running in the region of “Northern Virginia” or “Ireland” and
    we also know when two servers are running in the same data center, via their Availability
    Zone (AZ) location. But it’s extremely unlikely that we’d be able to point on
    a map to the building where our software is running.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 然后“云”出现了，我们对应用程序地理部署的理解变得有点，嗯，模糊了。 例如，使用 EC2，我们大致知道我们的代码正在“北弗吉尼亚”或“爱尔兰”等地区运行，我们还知道两台服务器在同一数据中心运行时，通过它们的可用性区域（AZ）位置。
    但是我们极少有可能能够在地图上指出软件运行的建筑物。
- en: Serverless computing immediately expands our radius of consideration a little
    further. Now we’re *only* thinking of the region—the AZ concept is hidden in abstraction.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 无服务器计算立即将我们的考虑半径进一步扩大。 现在我们*只*考虑区域——AZ 概念隐藏在抽象之中。
- en: One of the reasons to know where your applications are running is when you consider
    availability. When we run applications in a data center, we would need to know
    that if the data center lost internet connectivity, then our applications would
    be unavailable.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 知道应用程序运行在何处的原因之一是考虑可用性。 当我们在数据中心运行应用程序时，我们需要知道如果数据中心失去互联网连接，那么我们的应用程序将不可用。
- en: For many companies, certainly those who are used to deploying to one data center,
    this regional level of availability we get with the cloud is sufficient, especially
    since serverless services guarantee high availability across a region.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 对于许多公司，特别是习惯于部署到一个数据中心的公司来说，云提供的这种区域级别的可用性已经足够了，特别是由于无服务器服务保证了区域内的高可用性。
- en: But what if you want to think bigger? For example, what if you want to guarantee
    resilience of your application even if an entire region of AWS becomes unstable?
    This happens—just talk to anyone that’s used us-east-1 for at least a couple of
    years. The good news is that it’s very rare that AWS has any kind of *cross-region*
    outage. The vast majority of AWS downtime is constrained to one region.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 但是如果你想要思考更大的问题呢？ 例如，如果您希望即使 AWS 的整个区域变得不稳定，也能保证应用程序的弹性？ 这种情况时有发生——只要与使用 us-east-1
    的人交谈至少有几年的人。 好消息是 AWS 很少出现任何类型的*跨区域*中断。 绝大多数 AWS 的停机时间都限制在一个区域。
- en: Alternatively, looking beyond just availability, what if your users are spread
    around the world, from Sao Paulo to Seoul, and you want all of them to have low-latency
    access to your applications?
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 或者，不仅仅关注可用性，如果您的用户分布在世界各地，从圣保罗到首尔，您希望他们所有人都能低延迟访问您的应用程序，那怎么办呢？
- en: Solving these problems has been *possible* in the cloud ever since multiple
    regions became available. However, running applications in multiple regions is
    complicated, and can get expensive, especially as you add more regions.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 云中存在多区域后，解决这些问题就变得*可能*。然而，在多个区域中运行应用程序是复杂的，并且随着增加更多区域，成本可能会变得很高。
- en: Serverless, however, makes this problem significantly easier and cheaper. It’s
    now possible to deploy your application to multiple regions around the world,
    without much added complexity, and without breaking your budget.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，Serverless 可显著简化和降低这个问题的成本。现在可以在全球多个区域部署您的应用程序，而不会增加太多复杂性，也不会破坏您的预算。
- en: Global deployment
  id: totrans-96
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 全球部署
- en: When you define your application in a SAM template, you don’t typically hardcode
    any region-specific resources. If you need to refer to the region in which a stack
    is deployed in a CloudFormation string (as we did in the data pipeline example
    in [Chapter 5](ch05.html#ch05)), we recommend using the `AWS::Region` [*pseudo
    parameter*](https://oreil.ly/7Xe9-). For any region-specific resources that you
    need to access, we recommend passing those by reference as a CloudFormation parameter.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 当您在 SAM 模板中定义应用程序时，通常不会将任何特定于区域的资源硬编码。如果您需要在 CloudFormation 字符串中引用堆栈部署的区域（例如我们在
    [第 5 章](ch05.html#ch05) 中的数据管道示例中所做的），我们建议使用 `AWS::Region` [*伪参数*](https://oreil.ly/7Xe9-)。对于需要访问的任何特定于区域的资源，我们建议通过
    CloudFormation 参数引用这些资源。
- en: With these techniques you can define your application template in a *region-neutral*
    way, and you can deploy it to as many AWS regions as you like.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 使用这些技术，您可以以*与区域无关*的方式定义您的应用程序模板，并将其部署到任意数量的 AWS 区域。
- en: Actually deploying your application to multiple regions isn’t quite as easy
    as we’d like it to be. For example, when you deploy an application with CloudFormation
    (e.g., using `sam deploy`) any packages that you refer to in the `CodeUri` properties
    in the template file must be available in a S3 bucket that is located *within
    the same region you are deploying to*. Therefore, if you want to deploy an application
    to multiple regions, then its packaged artifacts need to be available in multiple
    S3 buckets, one per region. This is nothing a little scripting can’t solve, but
    it’s something that you have to think about.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 实际上，将您的应用程序部署到多个区域并不像我们希望的那样容易。例如，使用 CloudFormation 部署应用程序（例如使用 `sam deploy`）时，在模板文件中引用的
    `CodeUri` 属性中的任何包必须在*部署的同一区域内*的 S3 存储桶中可用。因此，如果您希望将应用程序部署到多个区域，则其打包的构件需要在多个 S3
    存储桶中可用，每个区域一个。这并不是无法解决的小问题，但这是您需要考虑的事情。
- en: AWS has improved the experience of multiregion deployment by enabling “cross-region
    actions” in [CodePipeline](https://oreil.ly/E_DJr). CodePipeline is Amazon’s “continuous
    delivery” orchestration tool and allows us to define the source control repository
    for a project; build and package an application by calling out to [CodeBuild](https://oreil.ly/fSD1_);
    and finally deploy it using SAM/CloudFormation. CodePipeline is effectively an
    automation system on top of the commands we’ve been running manually in this book.
    It will do a lot more than this too—the flow here is just an example.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: AWS 通过在 [CodePipeline](https://oreil.ly/E_DJr) 中启用 “跨区域操作”，改善了多区域部署的体验。CodePipeline
    是亚马逊的 “持续交付” 编排工具，允许我们定义项目的源代码存储库；通过调用 [CodeBuild](https://oreil.ly/fSD1_) 构建和打包应用程序；最后使用
    SAM/CloudFormation 部署应用程序。CodePipeline 实际上是在本书中我们手动运行的命令之上的自动化系统。它将做的远不止这些——这里的流程只是一个示例。
- en: '[“Cross-region actions”](https://oreil.ly/6X5vB) within CodePipeline allow
    you to deploy to multiple regions, in parallel, to as many regions as currently
    support CodePipeline at the current time. This means that one CD pipeline can
    deploy an application to the US, Europe, Japan, and South America.'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: '[“跨区域操作”](https://oreil.ly/6X5vB) 在 CodePipeline 中允许您并行部署到多个区域，目前支持 CodePipeline
    的区域数量。这意味着一个 CD 流水线可以将应用程序部署到美国、欧洲、日本和南美。'
- en: There’s still some trickiness to setting all of this up. For more, please see
    our [example project on Github](https://oreil.ly/xzWiI).
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 设置所有这些仍然有些棘手。有关更多信息，请参阅我们在 Github 上的 [示例项目](https://oreil.ly/xzWiI)。
- en: Another tool that helps multiregion deployment is the Serverless Application
    Repository, which we described in the previous section. When you publish an application
    to SAR via one region, it is made available globally to all regions. At the time
    of writing, this is only the case for publicly shared applications, but we hope
    that this feature will be enabled for private apps before too long.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个有助于多区域部署的工具是无服务器应用程序存储库，我们在前一节中描述过。当您通过一个区域将应用程序发布到SAR时，它将在全球所有区域提供。在撰写本文时，这仅适用于公开共享的应用程序，但我们希望这个功能很快也能适用于私有应用程序。
- en: Localized connectivity, with failover
  id: totrans-104
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 本地化连接，具备故障转移能力
- en: Once you’ve deployed your application around the world, how do your users connect
    to a version that’s near to them? One of the points of global deployment, after
    all, is to accept that the speed of light is limited, and therefore to route user
    requests to the closest geographic version of your application to their client,
    giving users the lowest latency experience you can.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦您在全球范围内部署了您的应用程序，用户如何连接到他们附近的版本呢？毕竟，全球部署的一个重要目的是接受光速有限的事实，因此将用户的请求路由到他们客户端附近的应用程序的最接近地理版本，为用户提供尽可能低延迟的体验。
- en: One way is to hardcode the region-specific location, typically a DNS hostname,
    within the client itself. It’s crude, but sometimes effective, especially for
    organization-internal apps.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 一种方法是在客户端内部硬编码区域特定位置，通常是一个DNS主机名。这有点粗糙，但有时是有效的，特别是对于组织内部的应用程序。
- en: An alternative that’s usually better, because it adapts *dynamically* to the
    user’s location, is to embrace Amazon’s Route53 DNS Service, and specifically
    its [*Geolocation*](https://oreil.ly/4RCb2) feature. For example, if users connect
    to your application via an API Gateway deployed in parallel to three different
    regions, then you can set up your DNS in Route53 such that the user is connected
    to the API Gateway in the region closest to them.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个通常更好的选择是，因为它可以 *动态* 适应用户的位置，是采用亚马逊的Route53 DNS服务，特别是其 [*地理位置*](https://oreil.ly/4RCb2)
    功能。例如，如果用户通过部署在三个不同区域并行的API网关连接到您的应用程序，那么您可以在Route53中设置DNS，使用户连接到距离他们最近的API网关所在的区域。
- en: Since you’re already using some advanced features of Route53 by this point,
    you may as well go one step further and use [*Health Checks and DNS Failover*](https://oreil.ly/XlUX9).
    With this feature of Route53, if the version of your application nearest to a
    user becomes unavailable, then Route53 will instead reroute that user to the *next*
    nearest, available, version of the application.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 由于您在这一点上已经在使用Route53的一些高级功能，您可以进一步使用 [*健康检查和DNS故障转移*](https://oreil.ly/XlUX9)。通过Route53的这一特性，如果用户最接近的应用程序版本不可用，那么Route53将将该用户重定向到下一个
    *最* 近可用的应用程序版本。
- en: Now we have active-active versions of our applications *and* localized routing.
    We have built an application that is resilient *and* has better performance. And
    so far there have been no updates to our application architecture, only operational
    updates. However, we should really address the elephant in the room.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们有我们应用程序的主动-主动版本 *和* 本地化路由。我们构建了一个既具有弹性 *又* 性能更好的应用程序。到目前为止，我们的应用程序架构没有更新，只有操作性的更新。然而，我们确实应该面对房间里的大象。
- en: Global state
  id: totrans-110
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 全局状态
- en: We said earlier that serverless makes it possible to deploy your application
    to multiple regions around the world, without much added complexity. We just described
    the deployment process itself, and we talked about how users can access your application
    over the internet.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 我们之前说过，无服务器使得可以将您的应用程序部署到全球多个区域，而几乎不增加复杂性。我们刚刚描述了部署过程本身，并讨论了用户如何通过互联网访问您的应用程序。
- en: A big concern, however, with global applications is how to treat state. The
    simplest solution is to have your state in only one region and have your service
    using that state deployed to multiple regions ([Figure 9-4](#multiple-compute-regions-one-database-region)).
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，全球应用程序的一个重要关注点是如何处理状态。最简单的解决方案是将您的状态仅放在一个区域，并将使用该状态的服务部署到多个区域中（[图9-4](#multiple-compute-regions-one-database-region)）。
- en: '![images/ch09_image04.png](assets/awsl_0904.png)'
  id: totrans-113
  prefs: []
  type: TYPE_IMG
  zh: '![images/ch09_image04.png](assets/awsl_0904.png)'
- en: Figure 9-4\. Multiple compute regions and one database region
  id: totrans-114
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图9-4\. 多个计算区域和一个数据库区域
- en: This is the same model that [content delivery networks (CDNs)](https://oreil.ly/UaAj5)
    use—there is one “origin” somewhere in the world, and then CDNs cache state in
    tens, or hundreds, of “points of presence” around the globe.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 这是[内容传递网络（CDN）](https://oreil.ly/UaAj5)使用的相同模型——世界某处有一个“起点”，然后CDN在全球的数十甚至数百个“点位”上缓存状态。
- en: This is fine for cacheable state, but what about noncacheable situations?
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 这对于可缓存状态是可以接受的，但不可缓存情况怎么办呢？
- en: In this case, the single-region-for-state model breaks down since all of your
    regions will be calling the centralized database region for *every request*. You’ve
    lost the benefit of localized latency, and you run the risk of a regional outage.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，单区域状态模型崩溃，因为所有您的区域将调用集中数据库区域的*每个请求*。您失去了本地化延迟的好处，并且面临区域性故障的风险。
- en: Fortunately, AWS and the other major cloud providers now provide globally replicated
    databases. A good example of this on AWS is [DynamoDB global tables](https://oreil.ly/fEZAG).
    Say you’re using the serverless API pattern from [Chapter 5](ch05.html#ch05)—you
    can replace the DynamoDB table in your design from that example with a *global*
    table. You can then happily deploy your API to multiple regions around the world,
    and AWS will do the hard work of moving your data safely around the planet. This
    gives you resilience, and improved user latency, since the table replication is
    performed by DynamoDB asynchronously ([Figure 9-5](#multiple-regions-with-replicated-database)).
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 幸运的是，AWS和其他主要云提供商现在提供全球复制的数据库。AWS上的一个很好的例子是[DynamoDB全局表](https://oreil.ly/fEZAG)。假设您正在使用[第5章](ch05.html#ch05)中的无服务器API模式——您可以将设计中的DynamoDB表从该示例替换为*全局*表。然后，您可以将您的API快乐地部署到全球多个地区，AWS将为您安全地在全球范围内移动数据。这为您提供了弹性和改进的用户延迟，因为DynamoDB的表复制是异步进行的（见[图9-5](#multiple-regions-with-replicated-database)）。
- en: '![images/ch09_image05.png](assets/awsl_0905.png)'
  id: totrans-119
  prefs: []
  type: TYPE_IMG
  zh: '![images/ch09_image05.png](assets/awsl_0905.png)'
- en: Figure 9-5\. Multiple regions with a replicated database
  id: totrans-120
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图9-5\. 具有复制数据库的多个区域
- en: AWS does charge a premium for global tables, but they’re not too much more expensive
    than having a table per region, especially when compared with building a state
    replication system yourself.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: AWS确实对全球表收取额外费用，但与在每个地区建立状态复制系统相比，费用并不是太高。
- en: Pay-per-use
  id: totrans-122
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 按使用付费
- en: On the subject of costs, this is where serverless computing really clinches
    the deal when it comes to multiregion deployment. Back in [Chapter 1](ch01.html#ch01)
    we said that a specific differentiator of a serverless service is that it “has
    costs that are based on precise usage, up from and down to zero usage.” This applies
    not just to one region but across regions.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 关于成本问题，当涉及到多区域部署时，无服务器计算真正确定交易的地方在这里。在[第1章](ch01.html#ch01)中，我们说无服务器服务的一个具体区别是它“根据精确的使用情况收费，从零使用到高使用。”这不仅适用于一个区域，而是跨区域。
- en: Say, for example, you have deployed a Lambda application to three regions because
    you want to have two backup regions for disaster recovery. If you are using only
    one of those regions, then you are *paying* only for the Lambda usage in that
    one region—the backup versions you have in the other two regions are free! This
    is a huge difference from any other computing paradigm.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，假设您已经将Lambda应用程序部署到三个地区，因为您希望有两个备份地区用于灾难恢复。如果您只使用其中一个地区，那么您只需支付该地区中Lambda使用的费用——您在其他两个地区的备份版本是免费的！这与任何其他计算范式有很大的不同。
- en: On the other hand, say you start off with an application deployed to one region,
    but then you deploy your API Gateway + Lambda application to ten regions, using
    the Geolocation DNS routing we discussed earlier. If you do this, your Lambda
    bill won’t change—whether you run in one region or ten—because Lambda still only
    charges you by the amount of activity that occurs in your functions. Your previous
    usage hasn’t increased; it’s now just distributed across ten regions.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 另一方面，假设您从一个地区部署应用程序开始，然后将您的API Gateway + Lambda应用程序部署到十个地区，使用我们之前讨论过的地理位置DNS路由。如果您这样做，您的Lambda账单不会改变——无论您在一个地区还是十个地区运行，因为Lambda仍然只按您函数中发生的活动量收费。您之前的使用量没有增加；现在只是分布在十个地区之间。
- en: We think that this vastly different cost model, in comparison to traditional
    platforms, will make globally distributed applications much more common than they’ve
    been in the past.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 我们认为，与传统平台相比，这种极其不同的成本模型将使全球分布式应用比过去更加普遍。
- en: Note
  id: totrans-127
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: There’s a slight caveat here to the “no change in costs” point for Lambda. AWS
    may charge slightly differently for Lambda for different regions. That’s an element
    of region-specific pricing, however, not because of running your application across
    multiple regions.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 在 Lambda 成本“没有变化”的观点上，这里有一个小小的警告。AWS 可能会根据不同地区对 Lambda 收费略有不同。然而，这是区域特定定价的一部分，而不是因为在多个地区运行应用程序。
- en: Edge computing/"regionless”
  id: totrans-129
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 边缘计算/“无区域”
- en: The examples we’ve talked about in this section so far are all about deploying
    to multiple regions around the world, but they do still require us to understand
    that Amazon’s entire cloud is broken up into those different regions.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，在本节中我们讨论的示例都是关于在全球多个地区部署，但它们仍然要求我们理解亚马逊的整个云被划分为这些不同的地区。
- en: What if you didn’t need to think about regions at all? What if you were able
    to deploy your code to a global service, and then AWS just did whatever it needed
    to run your code, giving users the best latency possible, and guaranteeing availability
    even if one location went offline?
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你根本不需要考虑地区会怎么样？如果你能够将你的代码部署到一个全球服务，并且 AWS 只需执行运行代码所需的一切操作，以提供用户最佳的延迟，并确保即使一个位置下线也能保持可用性？
- en: 'It turns out that this wild idea of the future is already here. Sort of. First,
    AWS already has some services that are “global services”—IAM and Route53 are two
    of them. But so is [CloudFront: AWS’s CDN](https://oreil.ly/_0EUS). While CloudFront
    does the thing you’d expect of any other CDN—caching HTTP traffic to enable faster
    websites—it also has the capability of being able to invoke a special class of
    Lambda functions via a service named [Lambda@Edge](https://oreil.ly/6D4yw).'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 结果证明，这种未来的疯狂想法已经实现了。有点像。首先，AWS 已经有一些被称为“全球服务”的服务——IAM 和 Route53 就是其中两个。但 AWS
    的 [CloudFront：AWS 的 CDN](https://oreil.ly/_0EUS) 也是。虽然 CloudFront 做了你期望的任何其他 CDN
    所做的事情——缓存 HTTP 流量以加快网站速度——它还具有通过名为 [Lambda@Edge](https://oreil.ly/6D4yw) 的服务调用特殊类别的
    Lambda 函数的能力。
- en: Lambda@Edge functions are mostly similar to Lambda functions—they have the same
    runtime model and mostly the same deployment tooling. When you deploy a Lambda@Edge
    function, AWS replicates your code around the world, so your application truly
    becomes “regionless.”
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: Lambda@Edge 函数与 Lambda 函数大多类似——它们具有相同的运行时模型和大多数相同的部署工具。当你部署一个 Lambda@Edge 函数时，AWS
    会在全球范围内复制你的代码，因此你的应用程序真正变成了“无区域”。
- en: 'There are, however, a number of significant limitations to Lambda@Edge, including:'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，Lambda@Edge 有许多显著的限制，包括：
- en: The only event source available is CloudFront itself—so you can only run Lambda@Edge
    as part of processing an HTTP request within a CloudFront distribution.
  id: totrans-135
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 唯一可用的事件源是 CloudFront 本身——因此，你只能在 CloudFront 发布中的 HTTP 请求处理过程中运行 Lambda@Edge。
- en: Lambda@Edge functions, at the time of writing, can be written only in Node or
    Python.
  id: totrans-136
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Lambda@Edge 函数在撰写本文时，只能用 Node 或 Python 编写。
- en: The Lambda@Edge environment has more restrictions with regard to memory, CPU,
    and timeout than regular Lambda functions.
  id: totrans-137
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Lambda@Edge 环境相比常规 Lambda 函数在内存、CPU 和超时方面有更多限制。
- en: Lambda@Edge functions are fascinating, and even at the time of writing are great
    for solving certain problems. But more than that, they point to a future of *truly*
    global cloud computing, where locality is completely abstracted. If AWS can bring
    Lambda@Edge closer in capability to regular Lambda, then as architects and developers
    we are well on the road to leaving region-thinking behind us. We might still need
    to think about locality when people are running applications on Mars, but we’re
    a few years away from that yet. Lambda promises to be serverless, not planetless!
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: Lambda@Edge 函数令人着迷，即使在撰写本文时，它们也非常适合解决特定问题。但更重要的是，它们指向了*真正*全球化的云计算未来，其中局部性完全抽象化。如果
    AWS 能够将 Lambda@Edge 的能力更接近常规 Lambda，那么作为架构师和开发者，我们将摆脱区域思维的道路已经走得很远。也许当人们在火星上运行应用程序时，我们仍然需要考虑局部性，但这距离还有几年。Lambda
    承诺无服务器，但并非无行星！
- en: Summary
  id: totrans-139
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: When we’re building serverless systems, the amount of effort that we spend on
    code and operations decreases, but some of that effort needs to be exchanged for
    more architectural thinking than we have done in the past, especially about the
    capabilities and limitations of the managed services we’re using. In this chapter,
    you learned more detail of some of these concerns, and examined a number of mitigation
    approaches.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们构建无服务器系统时，我们在代码和运维方面的投入减少了，但其中一部分工作需要用更多的架构思考来代替，特别是关于我们正在使用的托管服务的能力和限制方面。在本章中，您更详细地了解了其中一些问题，并审视了一些缓解方法。
- en: Serverless computing also presents entirely new ways of architecting software.
    You learned about two such ideas—the Serverless Application Repository, and globally
    distributed applications. As Lambda, and serverless more generally, evolves over
    the coming years, we expect to see many more new models of architecting applications.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 无服务器计算还提供了完全新的软件架构方式。您了解到了两个这样的概念——无服务器应用程序仓库和全球分布的应用程序。随着Lambda和无服务器技术的进化，在未来几年中，我们预计会看到更多新的应用程序架构模型的出现。
- en: Exercises
  id: totrans-142
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 练习
- en: 'Update the data pipeline example from [“Example: Building a Serverless Data
    Pipeline”](ch05.html#serverless-data-pipeline-example)—set `SingleEventLambda`
    to have a reserved concurrency of 1. Now upload the sample data—you should see
    throttling occur (if necessary, add a few more elements to the *sampledata.json*
    file). Use the “Throttle” behavior from the Lambda web console to set reserved
    concurrency to zero.'
  id: totrans-143
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 更新从[“示例：构建无服务器数据管道”](ch05.html#serverless-data-pipeline-example)中的数据管道示例——将`SingleEventLambda`的预留并发设置为1。现在上传示例数据——如果需要，请向*sampledata.json*文件中添加几个更多的元素以产生限流现象。使用Lambda
    Web控制台中的“限流”行为将预留并发设置为零。
- en: 'Update [“Example: Building a Serverless API”](ch05.html#serverless-api-example)
    to use a DynamoDB global table—make sure to separate the table itself into its
    own CloudFormation stack! Then deploy just the API component (with its Lambda
    functions) to multiple regions. Are you able to write data to one region and then
    read it from another?'
  id: totrans-144
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 更新[“示例：构建无服务器API”](ch05.html#serverless-api-example)以使用DynamoDB全局表——确保将表本身分离到自己的CloudFormation堆栈中！然后将API组件（及其Lambda函数）部署到多个区域。您能够将数据写入一个区域然后从另一个区域读取吗？
