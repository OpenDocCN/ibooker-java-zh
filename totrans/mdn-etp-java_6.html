<html><head></head><body><div id="sbo-rt-content"><section data-type="chapter" epub:type="chapter" data-pdf-bookmark="Chapter 6. Building Kubernetes-Native Applications"><div class="chapter" id="microservices_architecture">
<h1><span class="label">Chapter 6. </span>Building Kubernetes-Native Applications</h1>


<p>In the previous chapter, we outlined how to migrate from the traditional Java enterprise pattern to a container-centric approach. In this chapter, we will walk through the components needed to migrate to microservices-based architectures and how Kubernetes can connect the dots.</p>

<p>We also learned in previous chapters how much a microservices-based approach helps to make our software reliable, portable, and ready to scale upon demand. Modern architectures are planned with scalability already in the scope since the beginning, and this offers both opportunities and challenges. Enterprise Java developers know their code is usually part of the business logic, relying on frameworks to make it robust and consistent with well-recognized software design patterns. It is more common today that the same application could serve millions of requests running on a public cloud, even distributed geographically. To do that, it has to be architected to fit this model, decoupling functions, avoiding a single point of failure, and distributing the load to several parts of the architecture to avoid service interruptions.</p>






<section data-type="sect1" data-pdf-bookmark="Find the Right Balance Between Scalability &#10;and Complexity"><div class="sect1" id="idm45261444170464">
<h1>Find the Right Balance Between Scalability 
<span class="keep-together">and Complexity</span></h1>

<p>In an ideal world, all applications <a data-type="indexterm" data-primary="Kubernetes-native development" data-secondary="scalability" id="idm45261444168544"/><a data-type="indexterm" data-primary="Kubernetes-native development" data-secondary="complexity and" id="idm45261444167504"/><a data-type="indexterm" data-primary="scalability in Kubernetes-native development" id="idm45261444166544"/>would be stateless, and they could scale up independently. They wouldn’t crash, and the network links would always be reliable. The reality looks different.
The migration from monoliths to microservices-based architectures enables cloud native deployments, and we’ve covered some of the benefits that brings. However, that also brings some challenges: managing multiple points of ingress for your app, keeping the relationships between multiple microservices consistent, and managing distributed databases and schemas.</p>

<p>In <a data-type="xref" href="#fig6-2">Figure 6-1</a>, you can see how the transition from monolithic to microservices-based apps brings a new approach, having multiple interconnections or even multiple databases to work with.</p>

<figure><div id="fig6-2" class="figure">
<img src="Images/moej_0601.png" alt="From Monolith to Microservices Architectures" width="600" height="325"/>
<h6><span class="label">Figure 6-1. </span>From monolith to microservices architectures</h6>
</div></figure>

<p>Similar to the <a href="https://oreil.ly/nruM5">CAP theorem</a>, it is very hard to simultaneously provide scalability without increasing the complexity of a system. That’s why Kubernetes is so helpful because it’s ubiquitous, it runs in any cloud, and you can delegate most of this complexity to this platform. This lets you focus “just” on app development. On the other hand, we need to find a solution <a data-type="indexterm" data-primary="stateful apps, Kubernetes and" id="idm45261444160192"/><a data-type="indexterm" data-primary="Kubernetes" data-secondary="stateful apps and" id="idm45261444159472"/>also for <em>stateful</em> apps in the cloud native world, and we will see that Kubernetes also provides help on this side.</p>
</div></section>













<section data-type="sect1" data-pdf-bookmark="Functional Requirements for Modern Architectures"><div class="sect1" id="idm45261444157744">
<h1>Functional Requirements for Modern Architectures</h1>

<p>Kubernetes is very helpful with defining distributed applications as shown in <a data-type="xref" href="ch03.xhtml#fig3-2">Figure 3-1</a>.  Any Java developer should be well aware of <a href="https://oreil.ly/V4aqC">Design Patterns</a> from Gang of Four, a masterpiece of software engineering where authors define the most-used software <a data-type="indexterm" data-primary="design patterns" id="idm45261444154288"/>design patterns. Kubernetes extends this set of patterns, creating a new set of cloud native specific requirements to make applications resilient to various loads as shown in <a data-type="xref" href="#fig6-3">Figure 6-2</a>. Let’s dig into some of those in the next sections.</p>

<figure><div id="fig6-3" class="figure">
<img src="Images/moej_0602.png" alt="Functional requirements for Modern Architectures" width="600" height="600"/>
<h6><span class="label">Figure 6-2. </span>Functional requirements for modern architectures</h6>
</div></figure>








<section data-type="sect2" data-pdf-bookmark="API-Driven"><div class="sect2" id="idm45261444150240">
<h2>API-Driven</h2>

<p>The microservices mantra is “API first.” If you <a data-type="indexterm" data-primary="microservices" data-secondary="APIs and" id="idm45261444148624"/><a data-type="indexterm" data-primary="API (application programming interface)" data-secondary="microservices and" id="idm45261444147648"/><a data-type="indexterm" data-primary="Kubernetes-native development" data-secondary="microservices" id="idm45261444146736"/>take a look again at <a data-type="xref" href="#fig6-2">Figure 6-1</a>, 
<span class="keep-together">you’ll notice</span> that splitting a monolithic app into a bunch of microservices leads to the first challenge: how to let these pieces of software communicate with each other?
In monoliths, you rely on the app scope of modules, packages. Microservices usually communicate with each other via REST calls, where each one can be either producer or consumer of services. This is not the only way to connect your microservices; it’s also a common use case to use queues, messages, or caches.  But in general, each microservice exposes its primitives or functions through a set of APIs, and this can also be intermediated by an API gateway as we discussed in the Coolstore example in <a data-type="xref" href="ch02.xhtml#changing_technologies">Chapter 2</a>.</p>

<p>Kubernetes itself is API-driven <a data-type="indexterm" data-primary="Kubernetes" data-secondary="APIs and" id="idm45261444142416"/>software. All core components of the platform such as Pods, Services, and Deployments are manipulated through REST APIs. All operations and communications between components and external user commands are <a href="https://oreil.ly/PauGF">REST API calls that the API server handles</a>. When we interact with Kubernetes through <code>kubectl</code> or JKube, we are just invoking an API via HTTPS sending and receiving JSON content. This ecosystem of APIs is the perfect environment for an API-driven architecture, such as one that uses microservices. Now that we know how our microservices communicate,  how do we discover new services?</p>
</div></section>













<section data-type="sect2" class="pagebreak-before less_space" data-pdf-bookmark="Discovery"><div class="sect2" id="idm45261444139232">
<h2>Discovery</h2>

<p>It’s pretty straightforward to let <a data-type="indexterm" data-primary="Kubernetes-native development" data-secondary="discovery and" id="idm45261444137440"/><a data-type="indexterm" data-primary="discovery, Kubernetes-native development" id="idm45261444136400"/>microservices communicate with each other using REST calls. In addition, it would be nice to have the invocation of other components and functions at ease, such as when importing a module or a package into our app. In modern architectures, the number of microservices to invoke and connect could potentially be pretty high, thus it may not be enough to simply store the network endpoints such as IP address or hostnames. As we discussed in <a data-type="xref" href="ch04.xhtml#kubernetes_based_softw_dev_platform">Chapter 4</a>, Kubernetes simplifies networking with the <code>Service</code> object, allowing two or more Pods to talk to each other within the platform’s internal networking.
Kubernetes also provides the capability to list objects inside the cluster from an application, thanks to its API. Java developers can use frameworks such as JKube to have a Java Kubernetes client for this purpose.</p>

<p>Listing Kubernetes Services and Pods, which <a data-type="indexterm" data-primary="Kubernetes" data-secondary="Services and Pods" id="idm45261444133024"/><a data-type="indexterm" data-primary="microservices" data-secondary="Kubernetes Services and Pods" id="idm45261444132048"/>represent some microservices, is the first step to a real-time inventory of components of our software stack, which additionally helps to maintain and extend at runtime applications. Furthermore, Kubernetes enables integration with external tools or frameworks for that, such as Service Mesh, which provides service discovery protocol to detect services as they come up.</p>
<div data-type="tip"><h6>Tip</h6>
<p><a href="https://oreil.ly/jGh80">Service mesh</a> is an increasingly popular choice for microservices-based architectures. It provides a control panel that also interacts with Kubernetes to manage service discovery, mutual authentication, A/B testing, routing, and circuit breaker pattern out of the box. <a href="https://oreil.ly/ECIF4">Further details can be found online</a>.</p>
</div>
</div></section>













<section data-type="sect2" data-pdf-bookmark="Security and Authorization"><div class="sect2" id="idm45261444127824">
<h2>Security and Authorization</h2>

<p>Another challenge that modern <a data-type="indexterm" data-primary="Kubernetes-native development" data-secondary="security" id="idm45261444126304"/><a data-type="indexterm" data-primary="Kubernetes-native development" data-secondary="authorization and" id="idm45261444125264"/><a data-type="indexterm" data-primary="security" data-secondary="Kubernetes-native development" id="idm45261444124304"/><a data-type="indexterm" data-primary="authorization" data-secondary="Kubernetes-native development" id="idm45261444123344"/>app developers need to take into account is security for the entire stack. From the app to the platform, best practices also apply to modern architectures, and the complexity  and the required effort may rise significantly when there are many services to connect, many databases to query, and many endpoints to serve.  Again, Kubernetes comes in to help.</p>

<p>Kubernetes provides <a data-type="indexterm" data-primary="RBAC (role-based access control)" id="idm45261444121280"/><a data-type="indexterm" data-primary="security" data-secondary="RBAC (role-based access control)" id="idm45261444120560"/>security for the entire ecosystem. Role-based access control (RBAC) and fine-grained permission rules are possible. Furthermore, Pods are run by <a data-type="indexterm" data-primary="Kubernetes" data-secondary="pods" data-tertiary="Service Account" id="idm45261444119328"/><a data-type="indexterm" data-primary="Service Account, Kubernetes Pods" id="idm45261444118112"/>a special user called <em>Service Account</em> that has access to the Kubernetes API Server, usually having limited scope to the user’s namespace. Besides that, Kubernetes provides a special API to manage passwords and <a data-type="indexterm" data-primary="Kubernetes-native development" data-secondary="Secrets" id="idm45261444116688"/><a data-type="indexterm" data-primary="Kubernetes" data-secondary="Secrets" id="idm45261444115696"/><a data-type="indexterm" data-primary="Secrets API (Kubernetes)" id="idm45261444114752"/>certificates called <em>Secrets</em>. A Secret is a volume mounted into the Pod by the platform at runtime, with its value stored into Kubernetes’s database etcd, along with cluster state and configurations.</p>
<div data-type="note" epub:type="note"><h6>Note</h6>
<p><a href="https://etcd.io">etcd</a> is a distributed key-value database used by Kubernetes to store the cluster state. The content of the database can be also encrypted, and only the cluster administrator can access its content.</p>
</div>

<p>As we discussed, the communication between microservices is usually done via HTTPS REST calls, whose certificates are managed via Secrets. Containers and Kubernetes provide a good starting point for ensuring security in applications, from which Java developers can start to implement app security best practices.</p>
</div></section>













<section data-type="sect2" data-pdf-bookmark="Monitoring"><div class="sect2" id="idm45261444110672">
<h2>Monitoring</h2>

<p>Measuring resource consumption is <a data-type="indexterm" data-primary="Kubernetes-native development" data-secondary="monitoring" id="idm45261444109168"/><a data-type="indexterm" data-primary="monitoring, Kubernetes-native development" id="idm45261444108224"/>essential in modern architectures, and ever more so in cloud environments with a pay-per-use consumption model. It isn’t easy to estimate how many computational resources your app will need under stress, and overestimation may increase costs.
Kubernetes enables monitoring at the operating system level to application level, with its ecosystem of API and tools.</p>

<p>A popular cloud native tool to gather metrics from <a data-type="indexterm" data-primary="Prometheus" id="idm45261444106560"/><a data-type="indexterm" data-primary="PromQL" id="idm45261444105856"/>the platform and the app is <a href="https://prometheus.io">Prometheus</a>, a time-series database that can export metrics from the Kubernetes cluster and apps using <a href="https://oreil.ly/tYn9Q">a query language called PromQL</a>.</p>

<p>Metrics are also used to help <a data-type="indexterm" data-primary="Kubernetes-native development" data-secondary="metrics" id="idm45261444103088"/>Kubernetes decide when to scale your application up or down according to the monitored load on the app.
You can drive this scale with custom metrics, such as JVM threads or queue size, and make monitoring a proactive tool to empower your services.  Prometheus also provides alerts and alarms, which are useful to schedule automated actions for your applications when they need to react faster.</p>

<p>Java developers can also interact with Prometheus and metrics inside Kubernetes with <a href="https://micrometer.io">Micrometer</a>, an open source tool that provides a registration mechanism for metrics and core metric types. It is available for any JVM-based workloads, and it is the popular choice for both Spring Boot and Quarkus projects to interact with Prometheus and Kubernetes. “Think SLF4J, but for metrics.”</p>
</div></section>













<section data-type="sect2" class="pagebreak-before less_space" data-pdf-bookmark="Tracing"><div class="sect2" id="idm45261444100000">
<h2>Tracing</h2>

<p>Observability is another key <a data-type="indexterm" data-primary="Kubernetes-native development" data-secondary="latency and" id="idm45261444098432"/><a data-type="indexterm" data-primary="latency, Kubernetes-native development" id="idm45261444097392"/>aspect in modern architectures, and measuring latency between REST API calls is an important facet of managing microservices-based apps. It is crucial to ensure that the communication is always clear and the latency is 
<span class="keep-together">minimal</span>. When the number of microservices increases, a small delay in some part of the architecture can result in an acceptable service interruption for the user.  In these situations, Kubernetes is helpful for debugging the majority of operational problems that arise when moving to a distributed architecture.</p>

<p><a href="https://www.jaegertracing.io">Jaeger</a> is a popular open source tool that connects to Kubernetes to provide observability. It uses distributed tracing to follow the path of a request through different microservices. It provides a visual representation of the call flows through a dashboard, and it is often also integrated with Service mesh. Jaeger is very helpful to developers for monitoring distributed transactions, optimizing performance and latency, and performing root cause analysis.</p>
</div></section>













<section data-type="sect2" data-pdf-bookmark="Logging"><div class="sect2" id="idm45261444093552">
<h2>Logging</h2>

<p>As we discussed, a single call in your <a data-type="indexterm" data-primary="Kubernetes-native development" data-secondary="logging" id="idm45261444092048"/><a data-type="indexterm" data-primary="logging" data-secondary="Kubernetes-native development" id="idm45261444091008"/>microservices-based app, such as the Coolstore example,  can invoke different services that interact with each other. It’s important to monitor and observe the app, but also to store relevant pieces of information in logs.
Your application’s logging approach changes with modern apps. While in monoliths we usually rely on multiple log files stored in different paths on the disk, usually managed by the application server, distributed apps <em>stream</em> logs. As your app can scale up rapidly and move to different nodes or even clouds,  it makes no sense to access the single instance to retrieve logs; therefore, a distributed log system is needed.</p>

<p>Kubernetes makes logging easy as well. By default, it provides the capability to access a Pod’s logs by reading the application’s standard streams such as STDOUT (Standard Output) and STDERR (Standard Error). Thus, the app should not write logs into a certain path, but send logs to standard streams.</p>
<div data-type="note" epub:type="note"><h6>Note</h6>
<p>It is still possible to store logs in specific paths that can also be persistent in Kubernetes, but this is considered an antipattern.</p>
</div>

<p>Kubernetes also interacts with <a data-type="indexterm" data-primary="distributed systems" data-secondary="logging systems" id="idm45261444086432"/>distributed logging systems such as <a href="https://elastic.co">Elasticsearch</a>, an open source document-<a data-type="indexterm" data-primary="NoSQL" id="idm45261444084224"/>oriented  NoSQL database based on <a href="https://lucene.apache.org">Apache Lucene</a> to store logs and events. Elasticsearch <a data-type="indexterm" data-primary="Elasticsearch" id="idm45261444082560"/>usually comes with a forwarder, such as <a href="https://fluentd.org">Fluentd</a>, and a dashboard to visualize logs such as <a href="https://elastic.co/kibana">Kibana</a>. Together, this creates <a data-type="indexterm" data-primary="EFK stack (Elasticsearch, Fluentd, Kibana)" id="idm45261444080240"/><a data-type="indexterm" data-primary="Elasticsearch" data-secondary="EFK stack" id="idm45261444079440"/><a data-type="indexterm" data-primary="Fluentd, EFK stack" id="idm45261444078496"/><a data-type="indexterm" data-primary="Kibana, EFK stack" id="idm45261444077824"/>the EFK stack (Elasticsearch, Fluentd, Kibana). With this logging stack, developers consult logs from multiple microservices in an aggregated view through the Kibana dashboard, and they are also able to make queries <a data-type="indexterm" data-primary="KQL (Kibana Query Language)" id="idm45261444076784"/>in a query language called Kibana Query Language (KQL).</p>

<p>Distributed logging is the de facto standard with cloud native apps, and Kubernetes connects and interacts with many offerings such as EFK to provide centralized logging for the whole cluster.</p>
</div></section>













<section data-type="sect2" data-pdf-bookmark="CI/CD"><div class="sect2" id="idm45261444075456">
<h2>CI/CD</h2>

<p>Continuous Integration (CI) is a phase in <a data-type="indexterm" data-primary="Kubernetes-native development" data-secondary="CI/CD (Continuous Integration/Continuous Delivery)" id="idm45261444073760"/><a data-type="indexterm" data-primary="CI/CD (Continuous Integration/Continuous Delivery)" id="idm45261444072720"/><a data-type="indexterm" data-primary="CI (Continuous Integration)" id="idm45261444072016"/>the software development cycle where code from different team members or different features is integrated. This usually involves merging code (integration), building the application (container), and carrying out basic tests, all within an ephemeral environment.</p>

<p>Continuous Delivery (CD) refers to a set of <a data-type="indexterm" data-primary="CD (Continuous Delivery)" id="idm45261444070592"/>practices to automate various aspects of delivery software. One of these practices is called delivery pipeline, which is an automated process to define the steps a change in code or configuration has to go through to reach upper environments and eventually production.</p>

<p>Together, they are often referred to as CI/CD, and it is one of the key technology enablers for DevOps methodology.</p>

<p>Modern services need to react fast to changes or issues.  As we can monitor, trace, and log distributed architectures, we should also be able to update our microservices-based app faster. Pipelines are the best way to deploy apps in production following the phases as shown in <a data-type="xref" href="#fig6-4">Figure 6-3</a>.</p>

<figure><div id="fig6-4" class="figure">
<img src="Images/moej_0603.png" alt="Continuous Integration and Continuous Delivery" width="600" height="199"/>
<h6><span class="label">Figure 6-3. </span>Continuous Integration and Continuous Delivery</h6>
</div></figure>

<p>A <em>pipeline</em> is a series of steps, <a data-type="indexterm" data-primary="pipelines" data-secondary="CI/CD and" id="idm45261444064480"/>sequential or parallel, that build and test the app in all preproduction environments before finally releasing it to production. It can be fully automated or can interact with external tools for manual step approval (e.g., Service Now, JIRA, etc.).
Kubernetes interacts and connects with many external CI/CD tools such as <a href="https://jenkins.io">Jenkins</a>, and also provides a native CI/CD subsystem called <a href="https://tekton.dev">Tekton</a>.</p>

<p>Tekton is a Kubernetes-native CI/CD system, which <a data-type="indexterm" data-primary="Tekton" id="tek"/><a data-type="indexterm" data-primary="CI/CD (Continuous Integration/Continuous Delivery)" data-secondary="Tekton" id="CITek"/><a data-type="indexterm" data-primary="Kubernetes-native development" data-secondary="Tekton" id="kubTek"/>means it extends the Kubernetes API and provides its custom resources that you can use to create your pipelines. It relies <a href="https://oreil.ly/Oxx5P">on a catalog of Tasks</a> that comes already bundled with Tekton to compose your pipelines, such as Maven or Java Source-to-Image Tasks.</p>
<div data-type="tip"><h6>Tip</h6>
<p>Tekton can be installed in Kubernetes with an Operator from <a href="https://operatorhub.io">OperatorHub.io</a>.</p>
</div>

<p>To create Kubernetes-native pipelines, the following <a data-type="indexterm" data-primary="pipelines" data-secondary="Kubernetes-native development" id="idm45261444054160"/><a data-type="indexterm" data-primary="Kubernetes-native development" data-secondary="pipelines" id="idm45261444053168"/><a data-type="indexterm" data-primary="Tekton" data-secondary="pipelines" id="idm45261444052208"/>custom resources are provided by Tekton:</p>
<dl>
<dt>Task</dt>
<dd>
<p>A reusable, loosely coupled number of steps that perform a specific function (e.g., building a container image). Tasks get executed as Kubernetes Pods while steps in a Task map onto containers.</p>
</dd>
<dt>Pipeline</dt>
<dd>
<p>A list of Tasks needed to build and/or deploy your apps.</p>
</dd>
<dt>TaskRun</dt>
<dd>
<p>The execution and result of running an instance of Task.</p>
</dd>
<dt>PipelineRun</dt>
<dd>
<p>The execution and result of running an instance of Pipeline, which includes a number of TaskRuns.</p>
</dd>
</dl>

<p>An example of a Tekton Pipeline for the Inventory Quarkus microservice that we created in <a data-type="xref" href="ch02.xhtml#changing_technologies">Chapter 2</a> is listed next, you can also find it in this <a href="https://oreil.ly/2UUCL">book’s GitHub repository</a>:</p>

<pre data-type="programlisting" data-code-language="yaml"><code class="nt">apiVersion</code><code class="p">:</code> <code class="l-Scalar-Plain">tekton.dev/v1alpha1</code>
<code class="nt">kind</code><code class="p">:</code> <code class="l-Scalar-Plain">Pipeline</code>
<code class="nt">metadata</code><code class="p">:</code>
  <code class="nt">name</code><code class="p">:</code> <code class="l-Scalar-Plain">inventory-pipeline</code>
<code class="nt">spec</code><code class="p">:</code>
  <code class="nt">resources</code><code class="p">:</code>
  <code class="p-Indicator">-</code> <code class="nt">name</code><code class="p">:</code> <code class="l-Scalar-Plain">app-git</code>
    <code class="nt">type</code><code class="p">:</code> <code class="l-Scalar-Plain">git</code>
  <code class="p-Indicator">-</code> <code class="nt">name</code><code class="p">:</code> <code class="l-Scalar-Plain">app-image</code>
    <code class="nt">type</code><code class="p">:</code> <code class="l-Scalar-Plain">image</code>
  <code class="nt">tasks</code><code class="p">:</code>
  <code class="p-Indicator">-</code> <code class="nt">name</code><code class="p">:</code> <code class="l-Scalar-Plain">build</code>
    <code class="nt">taskRef</code><code class="p">:</code>
      <code class="nt">name</code><code class="p">:</code> <code class="l-Scalar-Plain">s2i-java-11</code>
    <code class="nt">params</code><code class="p">:</code>
      <code class="p-Indicator">-</code> <code class="nt">name</code><code class="p">:</code> <code class="l-Scalar-Plain">TLSVERIFY</code>
        <code class="nt">value</code><code class="p">:</code> <code class="s">"false"</code>
    <code class="nt">resources</code><code class="p">:</code>
      <code class="nt">inputs</code><code class="p">:</code>
      <code class="p-Indicator">-</code> <code class="nt">name</code><code class="p">:</code> <code class="l-Scalar-Plain">source</code>
        <code class="nt">resource</code><code class="p">:</code> <code class="l-Scalar-Plain">app-git</code>
      <code class="nt">outputs</code><code class="p">:</code>
      <code class="p-Indicator">-</code> <code class="nt">name</code><code class="p">:</code> <code class="l-Scalar-Plain">image</code>
        <code class="nt">resource</code><code class="p">:</code> <code class="l-Scalar-Plain">app-image</code>
  <code class="p-Indicator">-</code> <code class="nt">name</code><code class="p">:</code> <code class="l-Scalar-Plain">deploy</code>
    <code class="nt">taskRef</code><code class="p">:</code>
      <code class="nt">name</code><code class="p">:</code> <code class="l-Scalar-Plain">kubectl</code>
    <code class="nt">runAfter</code><code class="p">:</code>
      <code class="p-Indicator">-</code> <code class="l-Scalar-Plain">build</code>
    <code class="nt">params</code><code class="p">:</code>
    <code class="p-Indicator">-</code> <code class="nt">name</code><code class="p">:</code> <code class="l-Scalar-Plain">ARGS</code>
      <code class="nt">value</code><code class="p">:</code>
        <code class="p-Indicator">-</code> <code class="l-Scalar-Plain">rollout</code>
        <code class="p-Indicator">-</code> <code class="l-Scalar-Plain">latest</code>
        <code class="p-Indicator">-</code> <code class="l-Scalar-Plain">inventory-pipeline</code></pre>

<p>Java developers may also find it convenient to create and control Tekton Pipelines and Tasks direcly from the code, using Fabric8 Tekton Java client. This option gives the full control from a single point, and you don’t need to maintain external manifests such as YAML files.</p>

<p>First, import Maven dependency in POM file:</p>

<pre data-type="programlisting" data-code-language="xml">    <code class="nt">&lt;dependencies&gt;</code>
        <code class="nt">&lt;dependency&gt;</code>
            <code class="nt">&lt;groupId&gt;</code>io.fabric8<code class="nt">&lt;/groupId&gt;</code>
            <code class="nt">&lt;artifactId&gt;</code>tekton-client<code class="nt">&lt;/artifactId&gt;</code>
            <code class="nt">&lt;version&gt;</code>${tekton-client.version}<code class="nt">&lt;/version&gt;</code>
        <code class="nt">&lt;/dependency&gt;</code>
    <code class="nt">&lt;/dependencies&gt;</code>
    <code class="nt">&lt;properties&gt;</code>
        <code class="nt">&lt;tekton-client.version&gt;</code>4.12.0<code class="nt">&lt;/tekton-client.version&gt;</code>
    <code class="nt">&lt;/properties&gt;</code></pre>

<p>Then you can use Tekton Java API to create Tasks or <a data-type="indexterm" data-primary="Tekton" data-startref="tek" id="idm45261443877744"/><a data-type="indexterm" data-primary="CI/CD (Continuous Integration/Continuous Delivery)" data-secondary="Tekton" data-startref="CITek" id="idm45261443876896"/><a data-type="indexterm" data-primary="Kubernetes-native development" data-secondary="Tekton" data-startref="kubTek" id="idm45261443875616"/>Pipeline:</p>

<pre data-type="programlisting" data-code-language="java"><code class="kn">package</code> <code class="n">io</code><code class="o">.</code><code class="na">fabric8</code><code class="o">.</code><code class="na">tekton</code><code class="o">.</code><code class="na">api</code><code class="o">.</code><code class="na">examples</code><code class="o">;</code>

<code class="kn">import</code> <code class="nn">io.fabric8.tekton.client.*</code><code class="o">;</code>
<code class="kn">import</code> <code class="nn">io.fabric8.tekton.resource.v1alpha1.PipelineResource</code><code class="o">;</code>
<code class="kn">import</code> <code class="nn">io.fabric8.tekton.resource.v1alpha1.PipelineResourceBuilder</code><code class="o">;</code>

<code class="kd">public</code> <code class="kd">class</code> <code class="nc">PipelineResourceCreate</code> <code class="o">{</code>

  <code class="kd">public</code> <code class="kd">static</code> <code class="kt">void</code> <code class="nf">main</code><code class="o">(</code><code class="n">String</code><code class="o">[]</code> <code class="n">args</code><code class="o">)</code> <code class="o">{</code>
    <code class="k">try</code> <code class="o">(</code> <code class="n">TektonClient</code> <code class="n">client</code> <code class="o">=</code> <code class="n">ClientFactory</code><code class="o">.</code><code class="na">newClient</code><code class="o">(</code><code class="n">args</code><code class="o">))</code> <code class="o">{</code>
      <code class="n">String</code> <code class="n">namespace</code> <code class="o">=</code> <code class="s">"coolstore"</code><code class="o">;</code>
      <code class="n">PipelineResource</code> <code class="n">resource</code> <code class="o">=</code> <code class="k">new</code> <code class="n">PipelineResourceBuilder</code><code class="o">()</code>
        <code class="o">.</code><code class="na">withNewMetadata</code><code class="o">()</code>
        <code class="o">.</code><code class="na">withName</code><code class="o">(</code><code class="s">"client-repo"</code><code class="o">)</code>
        <code class="o">.</code><code class="na">endMetadata</code><code class="o">()</code>
        <code class="o">.</code><code class="na">withNewSpec</code><code class="o">()</code>
        <code class="o">.</code><code class="na">withType</code><code class="o">(</code><code class="s">"git"</code><code class="o">)</code>
        <code class="o">.</code><code class="na">addNewParam</code><code class="o">()</code>
        <code class="o">.</code><code class="na">withName</code><code class="o">(</code><code class="s">"revision"</code><code class="o">)</code>
        <code class="o">.</code><code class="na">withValue</code><code class="o">(</code><code class="s">"v4.2.2"</code><code class="o">)</code>
        <code class="o">.</code><code class="na">endParam</code><code class="o">()</code>
        <code class="o">.</code><code class="na">addNewParam</code><code class="o">()</code>
        <code class="o">.</code><code class="na">withName</code><code class="o">(</code><code class="s">"url"</code><code class="o">)</code>
        <code class="o">.</code><code class="na">withValue</code><code class="o">(</code><code class="s">"https://github.com/modernizing-java-applications-book/</code>
<code class="s">          inventory-quarkus.git"</code><code class="o">)</code>
        <code class="o">.</code><code class="na">endParam</code><code class="o">()</code>
        <code class="o">.</code><code class="na">endSpec</code><code class="o">()</code>
        <code class="o">.</code><code class="na">build</code><code class="o">();</code>

      <code class="n">System</code><code class="o">.</code><code class="na">out</code><code class="o">.</code><code class="na">println</code><code class="o">(</code><code class="s">"Created:"</code> <code class="o">+</code> <code class="n">client</code><code class="o">.</code><code class="na">v1alpha1</code><code class="o">().</code><code class="na">pipelineResources</code><code class="o">().</code>
        <code class="n">inNamespace</code><code class="o">(</code><code class="n">namespace</code><code class="o">).</code><code class="na">create</code><code class="o">(</code><code class="n">resource</code><code class="o">).</code><code class="na">getMetadata</code><code class="o">().</code><code class="na">getName</code><code class="o">());</code>
    <code class="o">}</code>
  <code class="o">}</code>
<code class="o">}</code></pre>
</div></section>





</div></section>













<section data-type="sect1" data-pdf-bookmark="Debugging Microservices"><div class="sect1" id="idm45261444157280">
<h1>Debugging Microservices</h1>

<p>While distributed architectures have plenty of benefits, they also pose some challenges. Even if you eventually run your <a data-type="indexterm" data-primary="microservices" data-secondary="debugging" id="idm45261443872624"/><a data-type="indexterm" data-primary="debugging microservices" id="idm45261443871648"/>code inside a Kubernetes cluster, you still develop (in general) locally where you have your IDE, compilers, etc. There are several ways to explain the development cycle. There are two loops, as illustrated in <a data-type="xref" href="#fig4-10">Figure 6-4</a>. The one closer to the developer, called the inner loop, is where you code, test, and debug iteratively. The other loop, further away from the developer, called the outer loop, is where your code runs inside a container image you have to build, push, and deploy, and that takes a lot longer.</p>

<figure><div id="fig4-10" class="figure">
<img src="Images/moej_0604.png" alt="Inner Loop and Outer Loop" width="600" height="276"/>
<h6><span class="label">Figure 6-4. </span>Inner loop and outer loop</h6>
</div></figure>

<p>While the outer loop is part of the CI/CD world, the inner loop is where you start coding and testing your software before launching a Tekton Pipeline to deploy your application into Kubernetes. Debugging microservices is also part of the inner loop.</p>

<p class="pagebreak-before less_space">Developers can follow different approaches to start debugging microservices:</p>

<ul>
<li>
<p>Using <a href="https://oreil.ly/ULV5g">Docker Compose</a> and deploying all the services locally</p>
</li>
<li>
<p>Using <a href="https://oreil.ly/1ogSc">minikube</a>, or any local Kubernetes clusters, and deploying all the services there</p>
</li>
<li>
<p>Mocking up all the services you interact with</p>
</li>
</ul>
<div data-type="note" epub:type="note"><h6>Note</h6>
<p>Docker Compose helps create containers that run in any Docker hosts, without Kubernetes. It is used for managing multiple containers in local development, but it is not mapped to any target Kubernetes clusters; thus, maintaining the local development setup separate from the target one may be difficult.</p>
</div>

<p>They are all valid approaches, but there are times where services are external and reachable only from the remote Kubernetes cluster, or mocking up that part of code is difficult or not possible.</p>

<p><a href="https://microcks.io">Microcks</a> is an open source Kubernetes-native debugging tool for API mocking and testing. It helps turn API contract, collection, or SoapUI projects into live mocks. It can be a convenient way to develop faster on Kubernetes without dependencies.</p>

<p>Let’s look at some additional options for in-Kubernetes microservices debugging.</p>








<section data-type="sect2" data-pdf-bookmark="Port Forwarding"><div class="sect2" id="idm45261443628320">
<h2>Port Forwarding</h2>

<p>Kubernetes offers remote shelling <a data-type="indexterm" data-primary="microservices" data-secondary="debugging" data-tertiary="port forwarding" id="idm45261443627008"/><a data-type="indexterm" data-primary="debugging microservices" data-secondary="port forwarding" id="idm45261443625920"/><a data-type="indexterm" data-primary="port forwarding, debugging microservices" id="idm45261443625072"/>into Pods for quick debugging tasks such as filesystem check. Additionally, <a href="https://oreil.ly/IAu5H">you can set up port forwarding</a> between your local machine connected to a Kubernetes cluster and your app running in a Pod. This option is useful when you want to connect to a database running in a Pod, attach an administrative web interface you don’t want to expose to the public, or, in this case, attach a debugger to the JVM running our application server.</p>

<p>By port forwarding the debugging port for the application server, you can attach the debugger from your IDE and actually
step through the code in the Pod as it is running in real time. Remember, if your app is not in debug mode, you first need to turn on the debug ports.</p>

<p>To start debugging, you need to expose the port for debugging. For example, for debugging the Inventory microservice, you need to access the debugging port 5005:</p>

<pre data-type="programlisting" data-code-language="bash">kubectl port-forward service/inventory-quarkus 5005:5005</pre>

<p>Now when we connect on <em>localhost:5005</em>, it will get forwarded to the Inventory instance running in the Pod.</p>
<div data-type="note" epub:type="note"><h6>Note</h6>
<p>Port forwarding is only active as long as the <code>kubectl port-forward</code> command is allowed to run.  Since we run it in the foreground, we are able to stop port forwarding by hitting Ctrl+C (or Cmd+C on a Mac).</p>
</div>

<p>In order to debug the source code, you can either use your IDE of choice or you can debug from the console as follows:</p>

<pre data-type="programlisting" data-code-language="bash">jdb -sourcepath <code class="k">$(</code><code class="nb">pwd</code><code class="k">)</code>/src/main/java -attach localhost:5005</pre>
</div></section>













<section data-type="sect2" data-pdf-bookmark="Quarkus Remote Development Mode"><div class="sect2" id="idm45261443582304">
<h2>Quarkus Remote Development Mode</h2>

<p>Quarkus provides a <a href="https://oreil.ly/rLflo">Remote Development Mode</a> that allows <a data-type="indexterm" data-primary="microservices" data-secondary="debugging" data-tertiary="Quarkus remote development" id="idm45261443580176"/><a data-type="indexterm" data-primary="debugging microservices" data-secondary="Quarkus remote development" id="idm45261443578832"/><a data-type="indexterm" data-primary="remote development, Quarkus" id="idm45261443577872"/><a data-type="indexterm" data-primary="Quarkus" data-secondary="remote development tools" id="idm45261443577184"/>you to run Quarkus in a container environment such as Kubernetes and have changes made to your local files immediately.</p>

<p>To enable it, add this section in your <code>application.properties</code>:</p>

<pre data-type="programlisting" data-code-language="text"><code>quarkus.package.type=mutable-jar </code><a class="co" id="co_building_kubernetes_native_applications_CO1-1" href="#callout_building_kubernetes_native_applications_CO1-1"><img src="Images/1.png" alt="1" width="12" height="12"/></a><code>
quarkus.live-reload.password=changeit </code><a class="co" id="co_building_kubernetes_native_applications_CO1-2" href="#callout_building_kubernetes_native_applications_CO1-2"><img src="Images/2.png" alt="2" width="12" height="12"/></a><code>
quarkus.live-reload.url=http://my.cluster.host.com:8080 </code><a class="co" id="co_building_kubernetes_native_applications_CO1-3" href="#callout_building_kubernetes_native_applications_CO1-3"><img src="Images/3.png" alt="3" width="12" height="12"/></a></pre>
<dl class="calloutlist">
<dt><a class="co" id="callout_building_kubernetes_native_applications_CO1-1" href="#co_building_kubernetes_native_applications_CO1-1"><img src="Images/1.png" alt="1" width="12" height="12"/></a></dt>
<dd><p>Mutable applications are used in development mode to apply and test changes live in a Quarkus Java application, without reloading the artifact.</p></dd>
<dt><a class="co" id="callout_building_kubernetes_native_applications_CO1-2" href="#co_building_kubernetes_native_applications_CO1-2"><img src="Images/2.png" alt="2" width="12" height="12"/></a></dt>
<dd><p>A password that is used to secure communication between the remote side and the local side.</p></dd>
<dt><a class="co" id="callout_building_kubernetes_native_applications_CO1-3" href="#co_building_kubernetes_native_applications_CO1-3"><img src="Images/3.png" alt="3" width="12" height="12"/></a></dt>
<dd><p>The URL at which your app is going to be running in dev mode.</p></dd>
</dl>

<p>You can generate the mutable JAR with Maven. You can let Quarkus deploy the app to Kubernetes as follows if you are connected with the Kubernetes Registry:</p>

<pre data-type="programlisting" data-code-language="bash"><code class="nb">eval</code> <code class="k">$(</code>minikube docker-env<code class="k">)</code></pre>
<div data-type="note" epub:type="note"><h6>Note</h6>
<p>You can add the Quarkus Kubernetes extension with this command:
<code>./mvnw quarkus:add-extension -Dextensions="kubernetes"</code></p>
</div>

<p>Deploy the app to Kubernetes:</p>

<pre data-type="programlisting" data-code-language="bash">mvn clean install -DskipTests -Dquarkus.kubernetes.deploy<code class="o">=</code><code class="nb">true</code></pre>

<p>Finally, you connect in remote dev mode to the app:</p>

<pre data-type="programlisting" data-code-language="bash">mvn quarkus:remote-dev</pre>

<p>This allows you to use Quarkus to connect the live coding features from your local machine to a remote container environment such as Kubernetes.</p>
</div></section>













<section data-type="sect2" data-pdf-bookmark="Telepresence"><div class="sect2" id="idm45261443581712">
<h2>Telepresence</h2>

<p><a href="https://www.telepresence.io">Telepresence</a> is an open source <a data-type="indexterm" data-primary="microservices" data-secondary="debugging" data-tertiary="Telepresence" id="debugTele"/><a data-type="indexterm" data-primary="debugging microservices" data-secondary="Telepresence" id="microTele"/><a data-type="indexterm" data-primary="Telepresence" id="Telep"/>tool that helps debug microservices in Kubernetes. It runs a single service locally, while connecting that service to a remote Kubernetes cluster.
Telepresence is programming language-agnostic, providing a convenient way to connect your local enviroment to any workload running on Kubernetes to debug.</p>

<p>Debugging apps on Kubernetes with <a data-type="indexterm" data-primary="Kubernetes" data-secondary="Telepresence and" id="KubTele"/>Telepresence is very easy. First, download and install <a href="https://oreil.ly/wkwOC">Telepresence CLI</a> and have an active session to your cluster, as Telepresence will read the <em>~/.kube/config</em> file to connect to Kubernetes.</p>
<div data-type="note" epub:type="note"><h6>Note</h6>
<p>Telepresence will modify the network in Kubernetes so that Services are reachable from your laptop and vice versa.</p>
</div>

<p>Once the CLI is installed and configured in your workstation, you can run this command to initialize and test the connection to your cluster with Telepresence:</p>

<pre data-type="programlisting" data-code-language="bash"><code class="nv">$ </code>telepresence connect</pre>

<p>You should get an output similar to the following:</p>

<pre data-type="programlisting" data-code-language="bash">Connected to context minikube <code class="o">(</code>https://192.168.39.69:8443<code class="o">)</code></pre>

<p>We can start debugging the Inventory microservice that you deployed in the previous steps. Before doing that, let’s list available apps to debug:</p>

<pre data-type="programlisting" data-code-language="bash"><code class="nv">$ </code>telepresence list</pre>

<p>You should get an output similar to the following:</p>

<pre data-type="programlisting" data-code-language="bash">inventory-quarkus-deploy: ready to intercept <code class="o">(</code>traffic-agent not yet installed<code class="o">)</code></pre>

<p>To start debugging this microservice, you need to let Telepresence intercept the internal Kubernetes traffic represented by the Service.</p>

<p class="pagebreak-before less_space">The Inventory’s Kubernetes Service is using port 8080, as you can see with the following command:</p>

<pre data-type="programlisting" data-code-language="bash"><code class="nv">$ </code>kubectl get svc inventory-quarkus-service</pre>

<p>You should get an output similar to the following:</p>

<pre data-type="programlisting" data-code-language="bash">NAME                      TYPE      CLUSTER-IP     EXTERNAL-IP PORT<code class="o">(</code>S<code class="o">)</code>  AGE
inventory-quarkus-service ClusterIP 172.30.117.178 &lt;none&gt;      8080/TCP 84m</pre>

<p>Now you can start intercepting the traffic connecting to your Deployment with the port used by the Service. You can also specify the path to a file on which Telepresence should write the environment variables that your service is currently running with:</p>

<pre data-type="programlisting" data-code-language="bash"><code class="nv">$ </code>telepresence intercept inventory-quarkus-deploy --port 8080:http --env-file
  inventory.env</pre>

<p>You should get an output similar to the following:</p>

<pre data-type="programlisting" data-code-language="bash">Using Deployment inventory-quarkus-deploy
intercepted
    Intercept name         : inventory-quarkus-deploy
    State                  : ACTIVE
    Workload kind          : Deployment
    Destination            : 127.0.0.1:8080
    Service Port Identifier: http
    Volume Mount Point     : /tmp/telfs-844792531
    Intercepting           : all TCP connections</pre>

<p>Look at the content of the environment file <code>inventory.env</code> just created:</p>

<pre data-type="programlisting" data-code-language="bash"><code class="nv">INVENTORY_QUARKUS_SERVICE_PORT</code><code class="o">=</code>tcp://172.30.117.178:8080
<code class="nv">INVENTORY_QUARKUS_SERVICE_PORT_8080_TCP</code><code class="o">=</code>tcp://172.30.117.178:8080
<code class="nv">INVENTORY_QUARKUS_SERVICE_PORT_8080_TCP_ADDR</code><code class="o">=</code>172.30.117.178
<code class="nv">INVENTORY_QUARKUS_SERVICE_PORT_8080_TCP_PORT</code><code class="o">=</code>8080
<code class="nv">INVENTORY_QUARKUS_SERVICE_PORT_8080_TCP_PROTO</code><code class="o">=</code>tcp
<code class="nv">INVENTORY_QUARKUS_SERVICE_SERVICE_HOST</code><code class="o">=</code>172.30.117.178
<code class="nv">INVENTORY_QUARKUS_SERVICE_SERVICE_PORT</code><code class="o">=</code>8080
<code class="nv">INVENTORY_QUARKUS_SERVICE_SERVICE_PORT_HTTP</code><code class="o">=</code>8080
<code class="nv">KO_DATA_PATH</code><code class="o">=</code>/var/run/ko
<code class="nv">KUBERNETES_PORT</code><code class="o">=</code>tcp://172.30.0.1:443
<code class="nv">KUBERNETES_PORT_443_TCP</code><code class="o">=</code>tcp://172.30.0.1:443
<code class="nv">KUBERNETES_PORT_443_TCP_ADDR</code><code class="o">=</code>172.30.0.1
<code class="nv">KUBERNETES_PORT_443_TCP_PORT</code><code class="o">=</code>443
<code class="nv">KUBERNETES_PORT_443_TCP_PROTO</code><code class="o">=</code>tcp
<code class="nv">KUBERNETES_SERVICE_HOST</code><code class="o">=</code>172.30.0.1
<code class="nv">KUBERNETES_SERVICE_PORT</code><code class="o">=</code>443
<code class="nv">KUBERNETES_SERVICE_PORT_HTTPS</code><code class="o">=</code>443
<code class="nv">LOG_LEVEL</code><code class="o">=</code>debug
<code class="nv">NSS_SDB_USE_CACHE</code><code class="o">=</code>no
<code class="nv">TELEPRESENCE_CONTAINER</code><code class="o">=</code>inventory-quarkus
<code class="nv">TELEPRESENCE_MOUNTS</code><code class="o">=</code>/var/run/secrets/kubernetes.io
<code class="nv">TELEPRESENCE_ROOT</code><code class="o">=</code>/tmp/telfs-777636888
<code class="nv">TERM</code><code class="o">=</code>xterm</pre>

<p>Now you can access the Inventory microservice as if you were connected to the internal Kubernetes network, and working with the environment variables just retrieved:</p>

<pre data-type="programlisting" data-code-language="bash">curl http://inventory-quarkus-service.coolstore:8080/api/inventory/329299</pre>

<p>You should get an output similar to the <a data-type="indexterm" data-primary="microservices" data-secondary="debugging" data-tertiary="Telepresence" data-startref="debugTele" id="idm45261443178608"/><a data-type="indexterm" data-primary="debugging microservices" data-secondary="Telepresence" data-startref="microTele" id="idm45261443177360"/><a data-type="indexterm" data-primary="Telepresence" data-startref="Telep" id="idm45261443198208"/><a data-type="indexterm" data-primary="Kubernetes" data-secondary="Telepresence and" data-startref="KubTele" id="idm45261443197264"/>following:</p>

<pre data-type="programlisting" data-code-language="json"><code class="p">{</code><code class="nt">"id"</code><code class="p">:</code><code class="s2">"329299"</code><code class="p">,</code><code class="nt">"quantity"</code><code class="p">:</code><code class="mi">35</code><code class="p">}</code></pre>
</div></section>





</div></section>













<section data-type="sect1" data-pdf-bookmark="Summary"><div class="sect1" id="idm45261443873616">
<h1>Summary</h1>

<p>In this chapter, we discussed how Kubernetes patterns can help Java developers with modernizing their apps, offering a platform that provides many components to extend app capabilities. The API-driven, pluggable architecture of Kubernetes easily enables external tools to provide an ecosystem of software and utilities that reminds, but also extends the application server model for Java enterprise. Essential tasks such as logging, monitoring, or debugging apps are provided in a way that fits the cloud native model, where apps are ubiquituous and can run in multiple places and multiple clouds at the same time.</p>

<p>In the next chapter, we will discuss a new concept of serving and delivering the enterprise application, resource-saving and cloud-ready: the serverless way.</p>
</div></section>







</div></section></div></body></html>