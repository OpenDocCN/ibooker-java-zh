- en: Chapter 7\. Logging, Metrics, and Tracing
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第7章 日志记录、指标和跟踪
- en: In this chapter, we’ll explore how to enhance the observability of Lambda functions
    through logging, metrics, and tracing. Through logging, you’ll learn how to gain
    information from specific events occuring during the execution of your Lambda
    functions. Platform and business metrics will give insight into the operational
    health of our serverless application. Finally, distributed tracing will let you
    see how requests flow to the different managed services and components that make
    up our architecture.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将探讨如何通过日志记录、指标和跟踪来增强Lambda函数的可观察性。通过日志记录，您将学习如何从Lambda函数执行期间发生的特定事件中获取信息。平台和业务指标将揭示我们无服务器应用程序的运行健康状态。最后，分布式跟踪将让您看到请求如何流向组成我们架构的不同托管服务和组件。
- en: We’ll use the Weather API from [Chapter 5](ch05.html#ch05) to explore the wide
    variety of logging, metrics, and tracing options available for serverless applications
    on AWS. Similar to the data pipeline changes we made in [Chapter 6](ch06.html#ch06),
    you’ll notice that the Weather API Lambda functions have been refactored to use
    the `aws-lambda-java-events` library.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用[第五章](ch05.html#ch05)的天气API来探索AWS无服务器应用程序中可用的广泛的日志记录、指标和跟踪选项。类似于我们在[第六章](ch06.html#ch06)中对数据管道所做的更改，您将注意到天气API的Lambda函数已经重构为使用`aws-lambda-java-events`库。
- en: Logging
  id: totrans-3
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 日志记录
- en: Given the following log message, what can we infer about the state of the application
    that generated it?
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 根据以下日志消息，我们能推断出生成它的应用程序的状态是什么？
- en: '[PRE0]'
  id: totrans-5
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: We know the values of some of the data (the temperature measurement and location),
    but not much else. When was this data received or processed? In the larger context
    of our application, what request generated this data? Which Java class and method
    produced this log message? How can we correlate this with other, possibly related,
    log messages?
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 我们知道一些数据的值（温度测量和位置），但不知道其他太多。这些数据是何时接收或处理的？在我们应用程序的更大上下文中，哪个请求生成了这些数据？哪个Java类和方法产生了这条日志消息？我们如何将其与其他可能相关的日志消息进行关联？
- en: Fundamentally, this is an unhelpful log message. It lacks context and specificity.
    If a message like this was repeated hundreds or thousands of times (perhaps with
    different temperature or location values), it would lose meaning. When our log
    messages are prose (e.g., a sentence or phrase), they are more difficult to parse
    without resorting to regular expressions or pattern matching.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 从本质上讲，这是一条没有帮助的日志消息。它缺乏上下文和具体性。如果像这样的消息被重复数百或数千次（可能使用不同的温度或位置值），它将失去意义。当我们的日志消息是散文（例如句子或短语）时，如果不使用正则表达式或模式匹配，解析它们会更加困难。
- en: 'As we explore logging in our Lambda functions, keep in mind a few properties
    of high-value log messages:'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 在探索Lambda函数中的日志记录时，请记住高价值日志消息的几个属性：
- en: Data rich
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 数据丰富
- en: We want to capture as much data as is feasible and cost-effective. The more
    data we have, the more questions we can ask without having to go back and add
    more logging after that fact.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 我们希望捕获尽可能多的数据，既可行又具有成本效益。我们拥有的数据越多，就越不需要在事后返回并添加更多日志记录。
- en: High cardinality
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 高基数
- en: Data values that make a particular log message unique are especially important.
    For example, a field like Request ID will have a large number of unique values,
    whereas a field like Thread Priority may not (especially in a single-threaded
    Lambda function).
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 使特定日志消息唯一的数据值尤为重要。例如，像请求ID这样的字段将具有大量唯一值，而像线程优先级这样的字段可能不会（尤其是在单线程Lambda函数中）。
- en: Machine readable
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 可机读
- en: Using JSON or another standardized format that is easily machine readable (without
    custom parsing logic) will ease analysis by downstream tools.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 使用JSON或其他易于机器读取的标准化格式（无需自定义解析逻辑）将通过下游工具简化分析。
- en: CloudWatch Logs
  id: totrans-15
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: CloudWatch Logs
- en: CloudWatch Logs is, as the name would suggest, AWS’s log collection, aggregation,
    and processing service. Through a variety of mechanisms, it receives log data
    from applications and other AWS services and makes that data accessible through
    a web console as well as via an API.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: CloudWatch Logs正如其名称所示，是AWS的日志收集、聚合和处理服务。通过各种机制，它接收来自应用程序和其他AWS服务的日志数据，并通过Web控制台以及API使这些数据可访问。
- en: The two main organizational components of CloudWatch Logs are log groups and
    log streams. A log group is a top-level grouping for a set of related log streams.
    A log stream is a list of log messages, usually originating from a single application
    or function instance.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: CloudWatch Logs的两个主要组织组件是日志组和日志流。日志组是一组相关日志流的顶层分组。日志流是一系列日志消息的列表，通常来自单个应用程序或函数实例。
- en: Lambda and CloudWatch Logs
  id: totrans-18
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Lambda和CloudWatch Logs
- en: In a serverless application, by default there is one log group per Lambda function,
    which contains many log streams. Each log stream contains the log messages for
    all the function invocations for a particular function instance. Recall from [Chapter 3](ch03.html#ch03)
    that the Lambda runtime captures anything written to standard output (`System.out`
    in Java) or standard error (`System.err`), and forwards that information to CloudWatch
    Logs.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 在无服务器应用程序中，默认情况下每个Lambda函数有一个日志组，其中包含许多日志流。每个日志流包含特定函数实例的所有函数调用的日志消息。回顾[第三章](ch03.html#ch03)，Lambda运行时会捕获写入标准输出（Java中的`System.out`）或标准错误（`System.err`）的任何内容，并将该信息转发给CloudWatch
    Logs。
- en: 'The log output for a Lambda function looks something like this:'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: Lambda函数的日志输出如下所示：
- en: '[PRE1]'
  id: totrans-21
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: The `START`, `END`, and `REPORT` lines are automatically added by the Lambda
    platform. Of particular interest is the UUID value labeled `RequestId`. This is
    an identifier that’s unique for each *requested* Lambda function invocation. The
    most common source of repeated `RequestId` values in logs is when our functions
    have an error and the platform retries the execution (see [“Error Handling”](ch08.html#error-handling)).
    Aside from that, since the Lambda platform (like most distributed systems) has
    “at least once” semantics, the platform may occasionally invoke a function with
    the same `RequestId` more than once even when there are no errors (we examine
    “at least once” behavior in [“At-Least-Once Delivery”](ch09.html#at-least-once-delivery)).
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: '`START`、`END`和`REPORT`行是Lambda平台自动添加的。特别感兴趣的是带有UUID值标记为`RequestId`的值。这是每次*请求的*Lambda函数调用都唯一的标识符。日志中重复的`RequestId`值最常见的来源是当我们的函数出现错误并且平台重试执行时（参见[“错误处理”](ch08.html#error-handling)）。除此之外，由于Lambda平台（像大多数分布式系统一样）具有“至少一次”语义，即使没有错误，平台偶尔也可能多次使用相同的`RequestId`值调用函数（我们在[“至少一次传递”](ch09.html#at-least-once-delivery)中研究了这种行为）。'
- en: LambdaLogger
  id: totrans-23
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: LambdaLogger
- en: The log line between the `START` and `END` lines above was generated using `System.out.println`.
    This is a perfectly reasonable way to get started with logging from simple Lambda
    functions, but there are several other options that provide a combination of sensible
    behavior and customization. The first of these options is the [`LambdaLogger`](https://oreil.ly/lXGJB)
    class that AWS provides.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 上面`START`和`END`行之间的日志行是使用`System.out.println`生成的。这是从简单的Lambda函数开始记录的一个完全合理的方法，但还有几种其他选项可以提供合理的行为和定制的组合。其中的第一种选择是AWS提供的[`LambdaLogger`](https://oreil.ly/lXGJB)类。
- en: 'This logger is accessed via the Lambda `Context` object, so we’ll have to alter
    our `WeatherEvent` Lambda handler function to include that parameter, as follows:'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 此记录器通过Lambda `Context`对象访问，因此我们需要修改我们的`WeatherEvent` Lambda处理函数以包括该参数，如下所示：
- en: '[PRE2]'
  id: totrans-26
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'The output of this log statement looks just as if it had been generated using
    `System.out.println`:'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 此日志语句的输出看起来就像是使用`System.out.println`生成的一样：
- en: '[PRE3]'
  id: totrans-28
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'You can see the difference between `LambdaLogger` and the `System println`
    methods when we have output that includes newlines, like a stack trace:'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 当输出包含换行符（例如堆栈跟踪）时，您可以看到`LambdaLogger`与`System println`方法之间的区别：
- en: '[PRE4]'
  id: totrans-30
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Using `System.err.println` the stack trace is printed on multiple lines, as
    multiple CloudWatch Logs entries ([Figure 7-1](#stack-trace-system-err)).
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 使用`System.err.println`打印的堆栈跟踪会生成多行CloudWatch Logs条目（[图7-1](#stack-trace-system-err)）。
- en: '![images/ch07_image01.png](assets/awsl_0701.png)'
  id: totrans-32
  prefs: []
  type: TYPE_IMG
  zh: '![images/ch07_image01.png](assets/awsl_0701.png)'
- en: Figure 7-1\. Stack trace output in CloudWatch Logs using System.err.println
  id: totrans-33
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图7-1\. 使用System.err.println在CloudWatch Logs中输出的堆栈跟踪
- en: Using LambdaLogger, that stack trace is a single entry (which can be expanded
    in the web console, as shown in [Figure 7-2](#stack-trace-lambda-logger)).
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 使用LambdaLogger，该堆栈跟踪是单个条目（可以在Web控制台中展开，如[图7-2](#stack-trace-lambda-logger)所示）。
- en: This feature alone is a compelling reason to use `LambdaLogger` instead of `System.out.println`
    or `System.err.println`, especially when printing exception stack traces.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 仅这一特性就足以使用`LambdaLogger`而不是`System.out.println`或`System.err.println`，特别是在打印异常堆栈跟踪时。
- en: '![images/ch07_image02.png](assets/awsl_0702.png)'
  id: totrans-36
  prefs: []
  type: TYPE_IMG
  zh: '![images/ch07_image02.png](assets/awsl_0702.png)'
- en: Figure 7-2\. Stack trace output in CloudWatch Logs using LambdaLogger
  id: totrans-37
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 7-2\. 使用 LambdaLogger 在 CloudWatch Logs 中输出堆栈跟踪
- en: Java Logging Frameworks
  id: totrans-38
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Java 日志框架
- en: '`LambdaLogger` is often sufficient for simple Lambda functions. However, as
    you’ll see later in this chapter, it’s often useful to customize log output to
    meet specific requirements, like capturing business metrics or generating application
    alerts. While it’s certainly possible to generate this kind of output using Java’s
    standard library, like [`String.format`](https://oreil.ly/9qlLO), it’s easier
    to use an existing logging framework like Log4J or Java Commons Logging. These
    frameworks provide conveniences like log levels, property or file-based configuration,
    and a variety of output formats. They also make it easy to include relevant system
    and application context (like the AWS request ID) with each log message.'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: '`LambdaLogger` 对于简单的 Lambda 函数通常已经足够了。然而，正如本章后面将要介绍的，定制日志输出以满足特定需求，比如捕获业务指标或生成应用程序警报，通常更为有用。虽然可以使用
    Java 的标准库（比如 [`String.format`](https://oreil.ly/9qlLO)）生成这种类型的输出，但使用像 Log4J 或
    Java Commons Logging 这样的现有日志框架会更容易。这些框架提供了诸如日志级别、基于属性或文件的配置以及各种输出格式等便利功能。它们还可以轻松地在每条日志消息中包含相关的系统和应用程序上下文（如
    AWS 请求 ID）。'
- en: When Lambda was first made available, AWS provided a custom appender for a very
    old, unsupported version of Log4J. Using this old version of a popular logging
    framework made it challenging to integrate newer logging features in Lambda-based
    serverless applications. As a result, we spent a fair amount of time and effort
    to build a more modern logging solution for Lambda functions called `lambda-monitoring`,
    which uses SLF4J and Logback.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 当 Lambda 首次推出时，AWS 提供了一个非常旧且不支持的 Log4J 版本的自定义 appender。在基于 Lambda 的无服务器应用程序中使用这个旧版本的流行日志框架使得集成新的日志功能变得困难。因此，我们花费了相当多的时间和精力为
    Lambda 函数构建了一个更现代化的日志解决方案，称为 `lambda-monitoring`，它使用了 SLF4J 和 Logback。
- en: However, AWS now provides a [library](https://oreil.ly/rywdy) with a custom
    log appender, [which uses `LambdaLogger` under the covers](https://oreil.ly/CrRoX),
    for the most recent version of [Log4J2](https://oreil.ly/8UEaw). We now recommend
    using this setup as AWS has outlined in the [Java logging section](https://oreil.ly/2YP8h)
    of the Lambda documentation. Setting up this method of logging simply involves
    adding a few additional dependencies, adding a *log4j2.xml* configuration file,
    and then using `org.apache.logging.log4j.Logger` in our code.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，AWS 现在提供了一个[库](https://oreil.ly/rywdy)，其中包含一个自定义的日志 appender，[它在底层使用 `LambdaLogger`](https://oreil.ly/CrRoX)，适用于最新版本的
    [Log4J2](https://oreil.ly/8UEaw)。我们现在建议按照 AWS 在 Lambda 文档的 [Java logging section](https://oreil.ly/2YP8h)
    中概述的方式进行设置。设置这种日志记录方法只需添加几个额外的依赖项、添加一个 *log4j2.xml* 配置文件，然后在我们的代码中使用 `org.apache.logging.log4j.Logger`。
- en: 'Here are the *pom.xml* additions for our Weather API project:'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是我们的 Weather API 项目的 *pom.xml* 添加部分：
- en: '[PRE5]'
  id: totrans-43
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'The *log4j2.xml* configuration file should be familiar to anyone who has used
    Log4J. It uses the `Lambda` appender provided by AWS, and allows customization
    of the log pattern:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: '*log4j2.xml* 配置文件对于使用过 Log4J 的人来说应该很熟悉。它使用 AWS 提供的 `Lambda` appender，并允许自定义日志模式：'
- en: '[PRE6]'
  id: totrans-45
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Notice that the log pattern includes the Lambda request ID (`%X{AWSRequestId}`).
    In our previous logging examples, that request ID wasn’t included in most output
    lines—it just showed up at the beginning and end of an invocation. By including
    it in every line, we can tie each piece of output to a specific request, which
    is helpful if we inspect these logs using another tool or download them for offline
    analysis.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 注意日志模式包括 Lambda 请求 ID（`%X{AWSRequestId}`）。在我们之前的日志示例中，大多数输出行中并没有包含该请求 ID ——
    它只在调用的开头和结尾出现。通过在每一行中包含它，我们可以将每个输出片段与特定请求关联起来，这在使用其他工具检查这些日志或进行离线分析时非常有帮助。
- en: 'In our Lambda function, we set up the logger and use its `error` method to
    log out a message at [`ERROR` level](https://oreil.ly/pygbx), as well as the exception:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的 Lambda 函数中，我们设置了日志记录器并使用其 `error` 方法记录了一个 [`ERROR` level](https://oreil.ly/pygbx)
    的消息以及异常信息：
- en: '[PRE7]'
  id: totrans-48
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: The output from the Lambda Log4J2 appender is shown in [Figure 7-3](#log4j2-logger-output).
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: Lambda Log4J2 appender 的输出显示在 [图 7-3](#log4j2-logger-output) 中。
- en: '![images/ch07_image03.png](assets/awsl_0703.png)'
  id: totrans-50
  prefs: []
  type: TYPE_IMG
  zh: '![images/ch07_image03.png](assets/awsl_0703.png)'
- en: Figure 7-3\. Stack trace output in CloudWatch Logs using Log4J2
  id: totrans-51
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 7-3\. 使用 Log4J2 在 CloudWatch Logs 中输出堆栈跟踪
- en: It includes the timestamp, the AWS request ID, the log level (`ERROR` in this
    case), the file and line that called the logging method, and a correctly formatted
    exception. We can use Log4J-provided bridge libraries to route log messages from
    other logging frameworks to our Log4J appender. The most useful application of
    this technique, at least for our `WeatherEventLambda`, is to gain insight into
    the behavior of the AWS Java SDK, which uses Apache Commons Logging (previously
    known as Jakarta Commons Logging, or JCL).
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 它包括时间戳、AWS 请求 ID、日志级别（本例中为 `ERROR`）、调用日志方法的文件和行，以及正确格式化的异常。我们可以使用 Log4J 提供的桥接库将其他日志框架的日志消息路由到我们的
    Log4J appender。这种技术最有用的应用之一，至少对于我们的 `WeatherEventLambda` 来说，是深入了解使用 Apache Commons
    Logging（以前称为 Jakarta Commons Logging 或 JCL）的 AWS Java SDK 的行为。
- en: 'First, we add the Log4J JCL bridge library to the `dependencies` section of
    our *pom.xml* file:'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们将 Log4J JCL 桥接库添加到我们 *pom.xml* 文件的 `dependencies` 部分：
- en: '[PRE8]'
  id: totrans-54
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'Next, we enable debug logging in the `Loggers` section of our *log4j2.xml*
    file:'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们在 *log4j2.xml* 文件的 `Loggers` 部分启用调试日志：
- en: '[PRE9]'
  id: totrans-56
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: Now we can see detailed log information from the AWS Java SDK ([Figure 7-4](#log4j2-jcl-bridge)).
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们可以看到来自 AWS Java SDK 的详细日志信息（参见[图 7-4](#log4j2-jcl-bridge)）。
- en: '![images/ch07_image04.png](assets/awsl_0704.png)'
  id: totrans-58
  prefs: []
  type: TYPE_IMG
  zh: '![images/ch07_image04.png](assets/awsl_0704.png)'
- en: Figure 7-4\. Detailed debug logging from the AWS SDK
  id: totrans-59
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 7-4\. AWS SDK 的详细调试日志
- en: We probably don’t want this information all the time, but it’s useful for debugging
    if there’s a problem—in this case we see exactly what the body of the DynamoDB
    `PutItem` API call contains.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可能不希望始终获取此信息，但是如果出现问题，调试时这将非常有用——在本例中，我们确切地看到了 DynamoDB `PutItem` API 调用的正文内容。
- en: By using more sophisticated logging frameworks, we gain additional insight into
    the context surrounding our log output. We can separate the logs for different
    Lambda requests using the request ID. Using the log level, we can understand if
    some log lines represent errors, or warnings about the state of our application,
    or if other lines might be ignored (or analyzed later) because they contain voluminous
    but less relevant debugging information.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 通过使用更复杂的日志框架，我们可以更深入地了解围绕日志输出的上下文。我们可以使用请求 ID 将不同 Lambda 请求的日志分开。使用日志级别，我们可以了解某些日志行是否表示错误，或者关于应用程序状态的警告，或者其他行是否可以忽略（或稍后分析），因为它们包含大量但不太相关的调试信息。
- en: Structured Logging
  id: totrans-62
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 结构化日志
- en: Our logging system as described in the previous section is capturing a great
    deal of useful information and context, ready to be used to inspect and improve
    our application.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 如前一节所述，我们的日志系统捕获了大量有用的信息和上下文，准备用于检查和改进我们的应用程序。
- en: However, when it comes time to extract some value from this great store of log
    data, it’s often difficult to access, it’s tricky to query, and because the actual
    messages are still essentially free-form text, you usually have to resort to a
    series of inscrutable regular expressions to find exactly the lines you’re looking
    for. There are some standardized formats that have established conventions for
    the values of certain space or tab-delimited fields, but inevitably the regexes
    make an appearance in downstream processes and tooling.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，当我们需要从这些大量的日志数据中提取某些值时，通常很难访问，查询起来很棘手，而且由于实际消息仍然基本上是自由形式的文本，通常必须使用一系列难以理解的正则表达式来精确查找您正在寻找的行。虽然有一些标准化的格式已经为某些空格或制表符分隔字段的值建立了约定，但不可避免地，正则表达式会在下游流程和工具中出现。
- en: Rather than continue with the free-text free-for-all, we can use a technique
    called *structured logging* to standardize our log output and make all of it easily
    searchable via a standard query language.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用一种称为*结构化日志*的技术，而不是继续使用自由文本方式，标准化我们的日志输出，并通过标准查询语言轻松搜索所有日志。
- en: 'Take this JSON log entry as an example:'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 以这条 JSON 日志条目为例：
- en: '[PRE10]'
  id: totrans-67
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: Rather than relying on an ordering of fields to extract information, we can
    use JSON path specifications. For example, if we want to extract the `temperature`
    field, we can use the JSON path `.message.temperature`. The CloudWatch Logs service
    supports this both for searching in the web console (see [Figure 7-5](#cloudwatch-logs-web-console)),
    and for creating Metric Filters, which we’ll discuss later in this chapter.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用 JSON 路径规范来提取信息，而不是依赖字段顺序。例如，如果我们想提取 `temperature` 字段，我们可以使用 JSON 路径 `.message.temperature`。CloudWatch
    Logs 服务支持在 Web 控制台中进行搜索（参见[图 7-5](#cloudwatch-logs-web-console)），以及创建 Metric Filters，我们稍后会在本章中讨论。
- en: '![images/ch07_image05.png](assets/awsl_0705.png)'
  id: totrans-69
  prefs: []
  type: TYPE_IMG
  zh: '![images/ch07_image05.png](assets/awsl_0705.png)'
- en: Figure 7-5\. Using JSON Path expressions to search in the CloudWatch Logs web
    console
  id: totrans-70
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 7-5\. 使用 JSON Path 表达式在 CloudWatch Logs Web 控制台中进行搜索
- en: Structured Logging in Java
  id: totrans-71
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Java 中的结构化日志记录
- en: Now that we understand the benefit of structured logging using the JSON format,
    we unfortunately run into immediate difficulty in trying to log JSON from our
    Java-based Lambda functions. JSON handling in Java is notoriously verbose, and
    adding a large amount of boilerplate code to construct log output doesn’t feel
    like the right way to go.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们理解了使用 JSON 格式进行结构化日志记录的好处，不幸的是，在尝试从基于 Java 的 Lambda 函数记录 JSON 时，我们立即遇到了困难。Java
    中的 JSON 处理以冗长而出名，为构建日志输出添加大量样板代码似乎不是正确的方式。
- en: 'Fortunately, we can use Log4J2 to generate JSON log output ([Log4J2 `JSONLayout`](https://oreil.ly/G4EYb)).
    The following *log4j2.xml* configuration will enable JSON-formatted output to
    `STDOUT`, which for our Lambda functions means that the output will be sent to
    CloudWatch Logs:'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 幸运的是，我们可以使用 Log4J2 生成 JSON 格式的日志输出（[Log4J2 `JSONLayout`](https://oreil.ly/G4EYb)）。以下
    *log4j2.xml* 配置将启用输出到`STDOUT`的 JSON 格式化输出，这对于我们的 Lambda 函数意味着输出将被发送到 CloudWatch
    Logs：
- en: '[PRE11]'
  id: totrans-74
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'In our Lambda code, we set up the Log4J2 logger as a static field:'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的 Lambda 代码中，我们将 Log4J2 日志记录器设置为静态字段：
- en: '[PRE12]'
  id: totrans-76
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'Rather than logging a string like `Recorded a temperature of 78 F from Brooklyn,
    NY`, we’ll instead build up a `Map` with keys and values, as follows:'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 不再像`Recorded a temperature of 78 F from Brooklyn, NY`这样记录字符串，我们将构建一个包含键和值的`Map`，如下所示：
- en: '[PRE13]'
  id: totrans-78
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'Here’s the output from that log line:'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 这是那条日志行的输出：
- en: '[PRE14]'
  id: totrans-80
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: A caveat worth noting—the information relevant to our application is there under
    the `message` key, but it’s buried in a sea of other output. Unfortunately, most
    of that output is baked into the Log4J2 `JsonLayout`, so we can’t remove it without
    some work. As we’ll see in the next section, however, the benefits of JSON-formatted
    log events are well worth the increase in verbosity.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 值得注意的一个警告是，与我们的应用程序相关的信息在`message`键下，但淹没在其他输出中。不幸的是，大部分输出都是 Log4J2 `JsonLayout`
    固有的，因此我们无法在没有一些工作的情况下移除它。正如我们将在下一节看到的那样，然而，使用 JSON 格式化的日志事件的好处远远超过增加的冗长。
- en: CloudWatch Logs Insights
  id: totrans-82
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: CloudWatch Logs Insights
- en: Structured logging enables us to use far more sophisticated tools to analyze
    our logs, both in real time as well as after incidents. While the original CloudWatch
    Logs web console has some support for using JSONPath expressions to query log
    data (as shown earlier), truly sophisticated analysis has, until recently, required
    either downloading logs directly, or forwarding them to another service.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 结构化日志使我们能够使用更复杂的工具来分析我们的日志，无论是实时还是事后。虽然原始的 CloudWatch Logs Web 控制台对使用 JSONPath
    表达式查询日志数据有一定支持（如前所示），但真正复杂的分析直到最近才需要直接下载日志或将其转发到另一个服务。
- en: '[CloudWatch Logs Insights](https://oreil.ly/mPqKe) is a new addition to the
    CloudWatch Logs ecosystem, providing a powerful search engine and purpose-built
    query language ideally suited to analyzing structured logs. Taking our example
    JSON log line from the previous section, let’s now imagine that we had a month’s
    worth of hourly data that has been logged out to CloudWatch Logs. We might want
    to do some quick analysis of that log data to see what the minimum, average, and
    maximum temperatures for each day was, but only for Brooklyn.'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: '[CloudWatch Logs Insights](https://oreil.ly/mPqKe) 是 CloudWatch Logs 生态系统的新成员，提供强大的搜索引擎和专门的查询语言，非常适合分析结构化日志。继续我们之前章节的示例
    JSON 日志行，现在让我们假设我们有一个月的每小时数据已经记录到 CloudWatch Logs。我们可能希望对该日志数据进行一些快速分析，查看每天的最低、平均和最高温度，但仅限于
    Brooklyn。'
- en: 'The following CloudWatch Logs Insights query accomplishes just that:'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 以下 CloudWatch Logs Insights 查询正好实现了这一点：
- en: '[PRE15]'
  id: totrans-86
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'Let’s look at what this query is doing, line by line:'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们逐行查看这个查询在做什么：
- en: First we filter the data down to log events that have a value of `record` in
    the `message.action` field, and a value of “Brooklyn, NY” in the `message.locationName`
    field.
  id: totrans-88
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，我们将数据筛选到具有`message.action`字段中值为`record`和`message.locationName`字段中值为“Brooklyn,
    NY”的日志事件。
- en: In the second line, we pick out the `message.timestamp` field and add three
    zeroes to the end before passing it to the `date_floor` method, which will replace
    a timestamp value (in milliseconds, hence needing to add zeroes) with the earliest
    timestamp value for the given day. We also pick out the `message.temperature`
    field.
  id: totrans-89
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在第二行中，我们提取了`message.timestamp`字段，并在传递给`date_floor`方法之前在末尾添加了三个零，这样可以用给定日期的最早时间戳值替换时间戳值（因为需要添加零以表示毫秒）。我们还提取了`message.temperature`字段。
- en: The third line calculates the minimum, average, and maximum value of the `message.temperature`
    field, for a day’s worth of log events.
  id: totrans-90
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 第三行计算了`message.temperature`字段在一天的日志事件中的最小值、平均值和最大值。
- en: The last line orders the data by day, starting with the earliest day.
  id: totrans-91
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后一行按天对数据进行排序，从最早的一天开始。
- en: We can see the results of this query in the CloudWatch Logs Insights web console
    ([Figure 7-6](#cw-logs-insights)).
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以在 CloudWatch Logs Insights Web 控制台中看到此查询的结果（参见[图 7-6](#cw-logs-insights)）。
- en: '![images/ch07_image06.png](assets/awsl_0706.png)'
  id: totrans-93
  prefs: []
  type: TYPE_IMG
  zh: '![images/ch07_image06.png](assets/awsl_0706.png)'
- en: Figure 7-6\. CloudWatch Logs Insights
  id: totrans-94
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 7-6\. CloudWatch Logs Insights
- en: These results can be exported as a CSV file, or graphed using the built-in visualization
    tool ([Figure 7-7](#cw-logs-insights-visualization)).
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 这些结果可以导出为 CSV 文件，或使用内置的可视化工具绘制图表（参见[图 7-7](#cw-logs-insights-visualization)）。
- en: There are a few caveats to keep in mind with regard to CloudWatch Logs Insights.
    First, while the tool can be used quite effectively for ad hoc exploration of
    log data, it cannot (yet) be used to directly generate additional custom metrics
    or other data products (although we’ll see how to generate custom metrics from
    JSON log data in the next section!). There is an API interface for running queries
    and accessing results, however, so it is possible to roll your own solution. Last
    but not least, pricing for queries is based on the amount of data scanned.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 关于 CloudWatch Logs Insights，需要记住一些注意事项。首先，尽管该工具可以有效地用于对日志数据进行即席探索，但目前还不能直接生成额外的自定义指标或其他数据产品（尽管我们将看到如何从
    JSON 日志数据生成自定义指标的方法！）。但是，它提供了一个 API 接口用于运行查询和访问结果，因此可以自行解决问题。最后但同样重要的是，查询的定价是基于扫描的数据量。
- en: '![images/ch07_image07.png](assets/awsl_0707.png)'
  id: totrans-97
  prefs: []
  type: TYPE_IMG
  zh: '![images/ch07_image07.png](assets/awsl_0707.png)'
- en: Figure 7-7\. CloudWatch Logs Insights visualization
  id: totrans-98
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 7-7\. CloudWatch Logs Insights 可视化
- en: Metrics
  id: totrans-99
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 指标
- en: Log messages are discrete snapshots into the state of a system at a given point
    in time. Metrics, on the other hand, are meant to produce a higher-level view
    of the state of a system over a period of time. While an individual metric is
    a snapshot in time, a series of metrics shows trends and behaviors of a system
    as it runs, over long periods of time.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 日志消息是对系统在特定时间点状态的离散快照。而指标则旨在在一段时间内产生系统状态的更高级别视图。虽然单个指标是时间点的快照，但一系列指标显示了系统在运行过程中的趋势和行为，长时间内的表现。
- en: CloudWatch Metrics
  id: totrans-101
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: CloudWatch 指标
- en: CloudWatch Metrics is AWS’s metrics repository service. It receives metrics
    from most AWS services. At the most fundamental level, a metric is simply a set
    of time-ordered data points. For example, at a given moment, the CPU load of a
    traditional server might be 64%. A few seconds later, it might be 65%. Over a
    given time period, a minimum, a maximum, and other statistics (such as percentiles)
    can be calculated for the metric.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: CloudWatch 指标是 AWS 的指标存储服务。它从大多数 AWS 服务接收指标。在最基本的层次上，指标只是一组按时间排序的数据点。例如，在某一时刻，传统服务器的
    CPU 负载可能为 64%。几秒钟后，它可能是 65%。在给定的时间段内，可以计算指标的最小值、最大值和其他统计数据（例如百分位数）。
- en: Metrics are grouped by namespace (e.g., `/aws/lambda`), and then by metric name
    (e.g., `WeatherEventLambda`). Metrics can also have associated dimensions, which
    are simply more granular identifiers—for example given a metric tracking application
    errors in a nonserverless application, one dimension might be server IP.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 指标按命名空间（例如 `/aws/lambda`）和指标名称（例如 `WeatherEventLambda`）分组。指标也可以有相关的维度，这些维度只是更细粒度的标识符，例如在跟踪非服务器应用程序中的应用程序错误的指标中，一个维度可能是服务器
    IP。
- en: CloudWatch metrics are a primary tool for monitoring the behavior of AWS’s services
    as well as our own applications.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: CloudWatch 指标是监控 AWS 服务及我们自己应用行为的主要工具。
- en: Lambda Platform Metrics
  id: totrans-105
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Lambda 平台指标
- en: Right out of the box, AWS provides a myriad of function and account-level metrics
    with which to monitor the overall health and availability of your serverless applications.
    We’ll refer to these as platform metrics, because they’re provided by the Lambda
    platform without requiring any extra configuration from us.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: AWS 提供了许多功能和账户级别的指标，用于监控无服务器应用程序的整体健康和可用性。我们将这些称为平台指标，因为它们由 Lambda 平台提供，无需额外配置。
- en: 'For individual functions, the Lambda platform provides the following metrics:'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 对于各个函数，Lambda 平台提供以下指标：
- en: '`Invocations`'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: '`调用次数`'
- en: The number of times a function is invoked (whether successful or not).
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 函数被调用的次数（无论成功与否）。
- en: '`Throttles`'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: '`限流`'
- en: The number of times an invocation attempt is throttled by the platform.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 平台限流平台尝试函数调用次数。
- en: '`Errors`'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: '`Errors`'
- en: The number of times a function invocation returns an error.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 函数调用返回错误次数。
- en: '`Duration`'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: '`Duration`'
- en: The number of milliseconds of “elapsed wall clock time” from when a function
    begins executing to when it stops. This metric also supports [percentiles](https://oreil.ly/-Njgn).
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 函数开始执行到停止之间的“经过的墙钟时间”的毫秒数。此指标还支持[百分位数](https://oreil.ly/-Njgn)。
- en: '`ConcurrentExecutions`'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: '`ConcurrentExecutions`'
- en: How many concurrent executions of a function are happening at a given point
    in time.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 特定时间点函数的并发执行次数。
- en: For functions that are invoked by Kinesis or DynamoDB stream event sources,
    an `IteratorAge` metric tracks the number of milliseconds between when the function
    received a batch of records and the time the last record in that batch was written
    to the stream. Effectively, this metric shows you how far behind the stream a
    Lambda function is at a given point in time.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 对于由Kinesis或DynamoDB流事件源调用的函数，`IteratorAge`指标跟踪函数接收记录批次与该批次中最后一条记录写入流之间的毫秒数。该指标有效地显示了Lambda函数在特定时间点在流中落后的程度。
- en: For functions configured with a dead letter queue (DLQ), a `DeadLetterErrors`
    metric is incremented when the function is unable to write a message to the DLQ
    (see [“Error Handling”](ch08.html#error-handling) for more about DLQs).
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 对于配置了死信队列（DLQ）的函数，当函数无法将消息写入DLQ时会增加`DeadLetterErrors`指标（有关DLQ的更多信息，请参见[“错误处理”](ch08.html#error-handling)）。
- en: Additionally, the platform aggregates the `Invocations`, `Throttles`, `Errors`,
    `Duration`, and `ConcurrentExecutions` metrics across all functions in the account
    and region. An `UnreservedConcurrentExecutions` metric aggregates the concurrent
    executions for all functions in the account and region that do not have a custom
    concurrency limit specified.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，平台会跨账户和地区聚合`Invocations`、`Throttles`、`Errors`、`Duration`和`ConcurrentExecutions`这些指标。`UnreservedConcurrentExecutions`指标会聚合账户和地区中所有未指定自定义并发限制的函数的并发执行次数。
- en: 'Metrics that are generated by the Lambda platform include the following extra
    dimensions: `FunctionName`, `Resource` (e.g., function version or alias) and `ExecutedVersion`
    (for alias invocations, which are discussed in the next chapter). Each of the
    per-function metrics mentioned can have these dimensions.'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: Lambda平台生成的指标还包括以下额外维度：`FunctionName`、`Resource`（例如函数版本或别名）和`ExecutedVersion`（用于别名调用，在下一章中讨论）。提到的每个函数级指标都可以具有这些维度。
- en: Business Metrics
  id: totrans-122
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 业务指标
- en: Platform metrics and application logging are important tools for monitoring
    our serverless applications, but neither is useful in assessing whether our application
    is performing its business functions correctly and completely. For example, a
    metric capturing the duration of a Lambda execution is useful to catch unexpected
    performance issues, but it doesn’t tell us if the Lambda function (or the application
    as a whole) is processing events correctly for our customers. On the other hand,
    a metric capturing the number of weather events successfully processed for our
    most popular location tells us that the application (or at least the part related
    to processing weather events) is working correctly, regardless of the underlying
    technical implementation.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 平台指标和应用程序日志是监控无服务器应用程序的重要工具，但在评估我们的应用程序是否正确和完全执行其业务功能方面并不有用。例如，捕获Lambda执行持续时间的指标有助于捕获意外的性能问题，但它并不告诉我们Lambda函数（或整个应用程序）是否正确处理了客户事件。另一方面，捕获为我们最受欢迎的位置成功处理的天气事件数量的指标告诉我们，无论底层技术实现如何，应用程序（或至少与处理天气事件相关的部分）都在正确工作。
- en: These *business metrics* can serve not only as a finger on the pulse of our
    business logic but also as an aggregate metric that’s not tied to specifics of
    an implementation or platform. Using our earlier example, what does it mean if
    Lambda execution time increases? Are we simply processing more data, or did a
    configuration or code change impact the performance of our function? Does it even
    matter? However, if the number of weather events our application processes decreases
    unexpectedly, we know something is wrong and it warrants an immediate investigation.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 这些*业务指标*不仅可以作为我们业务逻辑的脉搏检测，也可以作为不依赖于具体实现或平台的聚合指标。以我们之前的例子为例，如果 Lambda 执行时间增加了，这意味着什么？我们只是在处理更多的数据，还是配置或代码变更影响了函数的性能？这真的重要吗？然而，如果我们的应用处理的天气事件数量意外减少，我们知道有些问题，并且需要立即调查。
- en: In a traditional application, we might use the CloudWatch Metrics API directly,
    by using the [`PutMetricData` API call](https://oreil.ly/zLHuA) to proactively
    push these custom metrics as they’re generated. More sophisticated applications
    might push small batches of metrics at regular intervals instead.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 在传统应用中，我们可能直接使用CloudWatch指标API，通过使用[`PutMetricData` API调用](https://oreil.ly/zLHuA)在生成这些自定义指标时主动推送。更复杂的应用程序可能会定期以小批量推送指标。
- en: Lambda functions have two qualities that make the `PutMetricData` approach untenable.
    First, a Lambda function can scale to hundreds or thousands of concurrent executions
    very quickly. The CloudWatch Metrics API will throttle the `PutMetricData` call
    ([CloudWatch limits](https://oreil.ly/q2jmF)), so there’s a danger that the very
    action that’s attempting to persist important data may in fact cause a dropout
    of metrics. Second, because Lambda functions are ephemeral, there is little opportunity
    or benefit to batching metrics during a single execution. There is no guarantee
    that a subsequent execution will take place in the same runtime instance, so batching
    across invocations isn’t reliable.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: Lambda函数有两个特性使`PutMetricData`方法难以使用。首先，Lambda函数可以快速扩展到数百或数千个并发执行。CloudWatch指标API会对`PutMetricData`调用进行限流（[CloudWatch限制](https://oreil.ly/q2jmF)），因此，试图持久化重要数据的行为可能导致指标丢失。其次，由于Lambda函数是短暂的，几乎没有机会或好处可以在单个执行期间批处理指标。不能保证后续执行会在相同的运行时实例中进行，因此跨调用进行批处理是不可靠的。
- en: Fortunately, there are two features of CloudWatch metrics that handle this situation
    in a scalable and reliable manner by moving the generation of CloudWatch metrics
    data outside of the Lambda execution entirely. The first and newest, called the
    [CloudWatch Embedded Metric Format](https://oreil.ly/pkNXB), uses a special log
    format to automatically create metrics. This special log format isn’t yet supported
    by Log4J (without a lot of extra work), so we won’t use it here, but in other
    cases this is the preferred method for generating metrics in Lambda.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 幸运的是，CloudWatch指标有两个功能以可扩展且可靠的方式处理此情况，通过完全将CloudWatch指标数据的生成移出Lambda执行的过程。第一个和最新的功能称为[CloudWatch嵌入式指标格式](https://oreil.ly/pkNXB)，它使用特殊的日志格式自动创建指标。这种特殊的日志格式目前Log4J还不支持（除非进行大量额外的工作），因此我们不会在这里使用它，但在其他情况下，这是在Lambda中生成指标的首选方法。
- en: The other feature, [CloudWatch metric filters](https://oreil.ly/beOVU), can
    also use CloudWatch Logs data to generate metrics. Unlike the embedded metric
    format, it can access data in columnar and arbitrarily nested JSON structures.
    This makes it a better choice for situations like ours where we can’t easily add
    JSON keys to the top level of our log statements. It generates metric data by
    scraping CloudWatch Logs and pushing metrics in batches to the CloudWatch Metrics
    service.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个功能，[CloudWatch指标过滤器](https://oreil.ly/beOVU)，也可以使用CloudWatch日志数据生成指标。与嵌入式指标格式不同，它可以访问列格式和任意嵌套的JSON结构中的数据。这使得它成为我们这种情况的更好选择，因为我们不能轻松地将JSON键添加到日志语句的顶层。它通过扫描CloudWatch日志并将指标分批推送到CloudWatch指标服务来生成指标数据。
- en: 'Our use of structured logging makes setting up a metric filter trivial, using
    the following addition to our *template.yaml* file:'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用结构化日志记录使得设置度量过滤器变得简单，只需将以下内容添加到我们的*template.yaml*文件中：
- en: '[PRE16]'
  id: totrans-130
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: This metric filter will increment the `BrooklynWeatherEventCount` metric every
    time a JSON log line contains a `message.locationName` field with a “Brooklyn,
    NY” value. We can access and visualize this metric via the CloudWatch Metrics
    web console, and we can configure CloudWatch alarms and actions just as with regular
    platform metrics.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 每当JSON日志行包含`message.locationName`字段为“纽约布鲁克林”时，此指标过滤器将增加`BrooklynWeatherEventCount`指标。我们可以通过CloudWatch
    Metrics Web控制台访问和可视化此指标，也可以像处理常规平台指标一样配置CloudWatch告警和操作。
- en: In this example we’re effectively incrementing a counter every time an event
    occurs, but it’s also possible (when it makes sense to do so with the data) to
    use an actual value from the captured log line. See the [`MetricFilter MetricTransformation`
    documentation](https://oreil.ly/ksKJu) for more details.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个例子中，每次事件发生时我们有效地增加一个计数器，但在适当的情况下也可以（根据捕获日志行的数据）使用实际值。有关更多详情，请参阅[`MetricFilter
    MetricTransformation`](https://oreil.ly/ksKJu)文档。
- en: Alarms
  id: totrans-133
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 告警
- en: As with all CloudWatch metrics, we can use the data to build out alarms to warn
    us in case something is going wrong. At a minimum, we recommend setting alarms
    for the `Errors` and `Throttles` platform metrics, if not on a per-account basis,
    then certainly for production functions.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 与所有CloudWatch指标一样，我们可以使用数据来建立警报，以便在出现问题时发出警告。至少，我们建议为`Errors`和`Throttles`平台指标设置警报，如果不是基于每个帐户的设置，则至少为生产函数设置。
- en: For functions invoked by Kinesis or DynamoDB stream event sources, the `IteratorAge`
    metric is a critical indication of whether a function is keeping up with the number
    of events in the stream (which is a function of the number of shards in the stream,
    the batch size configured in the Lambda event source, the [`ParallelizationFactor`](https://oreil.ly/ogUdK),
    and the performance of the Lambda function itself).
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 对于由Kinesis或DynamoDB流事件源触发的函数，`IteratorAge`指标是函数是否跟上流事件数量的关键指示（这取决于流中的分片数、Lambda事件源中配置的批量大小、[`ParallelizationFactor`](https://oreil.ly/ogUdK)以及Lambda函数本身的性能）。
- en: 'Given the `BrooklynWeatherEventCount` metric we configured in the previous
    section, here’s how the associated CloudWatch alarm is configured. This alarm
    will alert us (via an SNS message) if that metric value drops to zero (indicating
    we’ve stopped receiving weather events for “Brooklyn, NY”) for longer than 60
    seconds:'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一节中我们配置的`BrooklynWeatherEventCount`指标，以下是关联的CloudWatch告警的配置方式。如果该指标值在60秒内降至零（表示我们停止接收“纽约布鲁克林”的天气事件），则此告警将通过SNS消息提醒我们：
- en: '[PRE17]'
  id: totrans-137
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: '[Figure 7-8](#cloudwatch-alarm) shows a view of that alarm in the CloudWatch
    web console.'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: '[图7-8](#cloudwatch-alarm)展示了在CloudWatch Web控制台中查看该告警的视图。'
- en: '![images/ch07_image08.png](assets/awsl_0708.png)'
  id: totrans-139
  prefs: []
  type: TYPE_IMG
  zh: '![images/ch07_image08.png](assets/awsl_0708.png)'
- en: Figure 7-8\. BrooklynWeatherAlarm CloudWatch alarm
  id: totrans-140
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图7-8. BrooklynWeatherAlarm CloudWatch告警
- en: The SNS message generated when the previous alarm is “breached” can be used
    to send a notification email, or to trigger a third-party alert system like [PagerDuty](https://www.pagerduty.com).
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 当前告警“触发”时生成的SNS消息可用于发送通知电子邮件，或触发像[PagerDuty](https://www.pagerduty.com)这样的第三方警报系统。
- en: As with application components like Lambda functions and DynamoDB tables, we
    strongly recommend keeping CloudWatch metric filters, alarms, and all other infrastructure
    in the same *template.yaml* file as everything else. This not only allows us to
    take advantage of intra-template references and dependencies, but it also keeps
    our metrics and alarm configurations tied closely to the application itself. If
    you don’t want to generate these operational resources for development versions
    of your stacks, you can use [CloudFormation’s `Conditions` functionality](https://oreil.ly/iXXkw).
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 与Lambda函数和DynamoDB表等应用组件一样，我们强烈建议将CloudWatch指标过滤器、告警和所有其他基础设施都保存在与其他所有内容相同的*template.yaml*文件中。这不仅允许我们利用模板内部引用和依赖关系，还能将我们的指标和告警配置与应用程序紧密地联系在一起。如果您不希望为堆栈的开发版本生成这些运行资源，可以使用[CloudFormation的`Conditions`功能](https://oreil.ly/iXXkw)。
- en: Distributed Tracing
  id: totrans-143
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 分布式跟踪
- en: The metrics and logging capabilities that we’ve covered thus far provide insight
    into individual application components like Lambda functions. However, in the
    case of nontrivial applications with many components, we would have a hard time
    piecing together the log output and metrics for a request flow that might involve
    an API Gateway, two Lambda functions, and a DynamoDB table.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们介绍的度量和日志功能为我们提供了关于单个应用组件（如 Lambda 函数）的洞察力。然而，在涉及到许多组件的复杂应用中，我们很难将日志输出和度量数据拼凑成一个请求流，例如涉及
    API Gateway、两个 Lambda 函数和 DynamoDB 表的情况。
- en: Fortunately, this use case is covered by AWS’s distributed tracing service,
    X-Ray. This service will essentially “tag” events either coming into or generated
    by our application and will keep track of those events as they flow through our
    application. When a tagged event triggers a Lambda function, X-Ray can then keep
    track of external service calls that the Lambda function makes and add information
    about those calls to the trace. If the called service is also X-Ray enabled, the
    tracing will continue through. In this way, X-Ray not only traces specific events
    but generates a service map of all of the components in our application and how
    they interact with each other.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 幸运的是，AWS 的分布式追踪服务 X-Ray 正好可以处理这种用例。该服务基本上会为进入或由我们的应用程序生成的事件“打标记”，并在这些事件流经我们的应用程序时进行跟踪。当标记的事件触发
    Lambda 函数时，X-Ray 可以跟踪 Lambda 函数所进行的外部服务调用，并将有关这些调用的信息添加到跟踪中。如果调用的服务也启用了 X-Ray，则跟踪将继续进行。通过这种方式，X-Ray
    不仅跟踪特定事件，还生成了我们应用程序中所有组件的服务映射及其相互交互的图。
- en: For AWS Lambda, there are two modes for [X-Ray tracing](https://oreil.ly/juSOL).
    The first is `PassThrough`, which means that if an event triggering a Lambda function
    has already been “tagged” by X-Ray, the invocation of the Lambda function will
    be tracked by X-Ray. If a triggering event hasn’t been tagged, then no trace information
    will be recorded from Lambda. Conversely, `Active` tracing proactively adds X-Ray
    trace IDs to all Lambda invocations.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 对于 AWS Lambda，有两种模式用于 [X-Ray 追踪](https://oreil.ly/juSOL)。第一种是 `PassThrough`，这意味着如果触发
    Lambda 函数的事件已经被 X-Ray “标记”，则 Lambda 函数的调用将由 X-Ray 追踪。如果触发事件尚未被标记，则 Lambda 不会记录任何跟踪信息。相反，`Active`
    追踪会主动将 X-Ray 跟踪 ID 添加到所有 Lambda 调用中。
- en: In the following example, we’ve enabled tracing in our API Gateway, which will
    tag incoming events with an X-Ray trace ID. The Lambda function is configured
    in `PassThrough` mode, so when it’s triggered by a tagged event from the API Gateway,
    it will propagate that trace ID to downstream services. Note that *PassThrough*
    mode is enabled by default if the Lambda’s IAM execution role has permission to
    send data to the X-Ray service; otherwise, it can be configured explicitly as
    we’ve done here (in which case SAM adds the appropriate permissions to the Lambda
    execution role).
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 在以下示例中，我们已启用 API Gateway 的追踪，该功能将为传入事件添加 X-Ray 跟踪 ID。Lambda 函数配置为 `PassThrough`
    模式，因此当它由 API Gateway 的标记事件触发时，它将将该跟踪 ID 传播到下游服务。请注意，如果 Lambda 的 IAM 执行角色具有向 X-Ray
    服务发送数据的权限，则默认情况下启用 *PassThrough* 模式；否则，如我们在此处所做的那样，可以显式配置（在这种情况下，SAM 将向 Lambda
    执行角色添加适当的权限）。
- en: 'Here’s the `Globals` section from our SAM *template.yaml* file from [Chapter 5](ch05.html#ch05),
    updated to enabled API Gateway tracing:'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 这是我们 SAM *template.yaml* 文件中的 `Globals` 部分，从 [第五章](ch05.html#ch05) 更新以启用 API
    Gateway 追踪：
- en: '[PRE18]'
  id: totrans-149
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: With tracing enabled, we can also add the X-Ray libraries to our *pom.xml* file.
    By adding these libraries, we’ll get the benefit of X-Ray tracing for all of the
    interactions our Lambda function has with services like DynamoDB and SNS, without
    having to make any changes to our Java code.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 启用追踪功能后，我们还可以将 X-Ray 库添加到我们的 *pom.xml* 文件中。通过添加这些库，我们将在 Lambda 函数与 DynamoDB
    和 SNS 等服务交互时享受到 X-Ray 追踪的好处，而无需修改我们的 Java 代码。
- en: 'Like the AWS SDK, X-Ray provides a bill of materials (BOM), which keeps version
    numbers in sync across whichever X-Ray libraries we end up using in our project.
    To use the X-Ray BOM, add it to the `<dependencyManagement>` section of the top-level
    *pom.xml* file:'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 像 AWS SDK 一样，X-Ray 提供了一个材料清单（BOM），可以确保我们项目中使用的所有 X-Ray 库的版本保持同步。要使用 X-Ray BOM，请将其添加到顶层
    *pom.xml* 文件的 `<dependencyManagement>` 部分：
- en: '[PRE19]'
  id: totrans-152
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'Now we need to add the three X-Ray libraries that will instrument our Java-based
    Lambda functions:'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们需要添加三个 X-Ray 库，这些库将为我们的基于 Java 的 Lambda 函数进行仪器化：
- en: '[PRE20]'
  id: totrans-154
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: '[Figure 7-9](#x-ray-service-map) shows the X-Ray service map for our API from
    [Chapter 5](ch05.html#ch05), showing the API Gateway, Lambda platform, Lambda
    function, and DynamoDB table:'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: '[图 7-9](#x-ray-service-map) 展示了我们 API 的 X-Ray 服务地图，来自 [第 5 章](ch05.html#ch05)，展示了
    API Gateway、Lambda 平台、Lambda 函数和 DynamoDB 表：'
- en: '![images/ch07_image09.png](assets/awsl_0709.png)'
  id: totrans-156
  prefs: []
  type: TYPE_IMG
  zh: '![images/ch07_image09.png](assets/awsl_0709.png)'
- en: Figure 7-9\. X-Ray service map
  id: totrans-157
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 7-9\. X-Ray 服务地图
- en: We can also view a trace for an individual event (in this case, our HTTP POST),
    which traversed the API Gateway, Lambda, and DynamoDB ([Figure 7-10](#x-ray-trace)).
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还可以查看一个单独事件的追踪（在本例中为我们的 HTTP POST），该事件经过 API Gateway、Lambda 和 DynamoDB（[图 7-10](#x-ray-trace)）。
- en: '![images/ch07_image10.png](assets/awsl_0710.png)'
  id: totrans-159
  prefs: []
  type: TYPE_IMG
  zh: '![images/ch07_image10.png](assets/awsl_0710.png)'
- en: Figure 7-10\. X-Ray trace
  id: totrans-160
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 7-10\. X-Ray 追踪
- en: Finding Errors
  id: totrans-161
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 查找错误
- en: What happens when our Lambda function throws an error? We can investigate errors
    via the X-Ray console, through both the service map and the traces interface.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们的 Lambda 函数抛出错误时会发生什么？我们可以通过 X-Ray 控制台调查错误，通过服务地图和跟踪界面两种方式。
- en: 'First, let’s introduce an error into the `WeatherEvent` Lambda, by removing
    that Lambda’s permission to access DynamoDB:'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，让我们通过移除 `WeatherEvent` Lambda 访问 DynamoDB 的权限，向该 Lambda 函数引入一个错误：
- en: '[PRE21]'
  id: totrans-164
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: After deploying our serverless application stack, we can send an HTTP POST event
    to the `/events` endpoint. When the `WeatherEvent` Lambda attempts to write that
    event to DynamoDB, it fails and throws an exception. [Figure 7-11](#x-ray-service-map-error)
    shows what the X-Ray service map looks like after that happens.
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 在部署我们的无服务器应用程序堆栈后，我们可以向 `/events` 端点发送一个 HTTP POST 事件。当 `WeatherEvent` Lambda
    尝试将该事件写入 DynamoDB 时，它失败并抛出异常。在此之后的 X-Ray 服务地图显示如下（[图 7-11](#x-ray-service-map-error)）。
- en: '![images/ch07_image11.png](assets/awsl_0711.png)'
  id: totrans-166
  prefs: []
  type: TYPE_IMG
  zh: '![images/ch07_image11.png](assets/awsl_0711.png)'
- en: Figure 7-11\. X-Ray service map showing an error
  id: totrans-167
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 7-11\. X-Ray 服务地图显示的错误
- en: And when we drill into the specific request that caused the error, we can see
    that our POST request returned an HTTP 502 error ([Figure 7-12](#x-ray-trace-map-error)).
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 并且当我们深入研究导致错误的具体请求时，我们可以看到我们的 POST 请求返回了一个 HTTP 502 错误（[图 7-12](#x-ray-trace-map-error)）。
- en: '![images/ch07_image12.png](assets/awsl_0712.png)'
  id: totrans-169
  prefs: []
  type: TYPE_IMG
  zh: '![images/ch07_image12.png](assets/awsl_0712.png)'
- en: Figure 7-12\. X-Ray trace showing an error
  id: totrans-170
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 7-12\. X-Ray 追踪显示的错误
- en: We can then easily see the specific Java exception that caused the Lambda function
    to fail by hovering on the error icon next to the portion of the trace that shows
    the Lambda invocation ([Figure 7-13](#x-ray-trace-hover-exception)).
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们可以通过悬停在显示 Lambda 调用轨迹部分的错误图标上，轻松看到导致 Lambda 函数失败的具体 Java 异常（[图 7-13](#x-ray-trace-hover-exception)）。
- en: '![images/ch07_image13.png](assets/awsl_0713.png)'
  id: totrans-172
  prefs: []
  type: TYPE_IMG
  zh: '![images/ch07_image13.png](assets/awsl_0713.png)'
- en: Figure 7-13\. X-Ray trace showing a Java exception
  id: totrans-173
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 7-13\. X-Ray 追踪显示的 Java 异常
- en: Clicking through will then show us the full stack trace, right from the X-Ray
    trace console ([Figure 7-14](#x-ray-trace-stack)).
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 点击后，我们可以从 X-Ray 追踪控制台完整地查看堆栈跟踪，即从 [图 7-14](#x-ray-trace-stack) 开始。
- en: '![images/ch07_image14.png](assets/awsl_0714.png)'
  id: totrans-175
  prefs: []
  type: TYPE_IMG
  zh: '![images/ch07_image14.png](assets/awsl_0714.png)'
- en: Figure 7-14\. X-Ray showing a Java exception stack trace
  id: totrans-176
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 7-14\. X-Ray 显示的 Java 异常堆栈跟踪
- en: Summary
  id: totrans-177
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: In this chapter, we covered the variety of ways we can gain insight into exactly
    how our serverless application is performing and functioning, both at the individual
    function or component level and as a complete application. We showed how using
    structured JSON logging enables observability and gives us the ability to surface
    meaningful business metrics from our highly scalable Lambda functions without
    overwhelming the CloudWatch API.
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们介绍了多种方式，可以详细了解我们的无服务器应用程序的执行和功能，无论是在单个函数或组件级别，还是作为完整应用程序。我们展示了如何使用结构化
    JSON 日志记录实现可观察性，并使我们能够从高度可扩展的 Lambda 函数中提取有意义的业务指标，而无需超负荷使用 CloudWatch API。
- en: Finally, we added a few dependencies to our Maven *pom.xml* and unlocked fully
    featured distributed tracing capabilities, which not only trace individual requests
    but also automatically build out a map of all the components of our serverless
    application and allow us to easily drill into errors or unexpected behavior.
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们向我们的 Maven *pom.xml* 添加了一些依赖项，并解锁了完整功能的分布式跟踪能力，这不仅追踪单个请求，还自动构建了我们无服务器应用程序的所有组件地图，并允许我们轻松地深入错误或意外行为。
- en: With the basics now covered, in the next chapter we’ll dive into the advanced
    Lambda techniques that will make our production serverless systems robust and
    reliable.
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 现在基础知识已经介绍完毕，在下一章中，我们将深入探讨高级 Lambda 技术，使我们的生产无服务器系统更加强大和可靠。
- en: Exercises
  id: totrans-181
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 练习
- en: This chapter builds on the API Gateway code from [Chapter 5](ch05.html#ch05).
    Add X-Ray instrumentation to the updated data pipeline code from [Chapter 6](ch06.html#ch06),
    and observe how the interactions with SNS and S3 show up in the X-Ray console.
  id: totrans-182
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 本章基于[第5章](ch05.html#ch05)的API网关代码进行构建。在来自[第6章](ch06.html#ch06)的更新数据流水线代码中添加X-Ray仪器，观察与SNS和S3的交互如何显示在X-Ray控制台中。
- en: In addition to incrementing a metric as we’ve done in this chapter, CloudWatch
    Logs metric filters can parse a metric value from a log line. Use this technique
    to generate a CloudWatch Logs metric for the temperature in Brooklyn, NY. For
    extra credit, add an alarm for when the the temperature goes below 32 degrees
    Fahrenheit!
  id: totrans-183
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 除了像本章所做的那样增加一个度量标准外，CloudWatch Logs度量过滤器可以解析日志行中的度量值。使用这种技术为纽约布鲁克林的温度生成CloudWatch
    Logs度量标准。为了额外加分，当温度低于32华氏度时，添加一个警报！
