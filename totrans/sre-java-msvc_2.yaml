- en: Chapter 2\. Application Metrics
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第二章 应用程序指标
- en: The complexity of distributed systems comprised of many communicating microservices
    means it is especially important to be able to observe the state of the system.
    The rate of change is high, including new code releases, independent scaling events
    with changing load, changes to infrastructure (cloud provider changes), and dynamic
    configuration changes propagating through the system. In this chapter, we will
    focus on how to measure and alert on the performance of the distributed system
    and some industry best practices to adopt.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 由于由许多通信微服务组成的分布式系统的复杂性，能够观察系统状态变得尤为重要。变化速率很高，包括新代码发布、独立扩展事件随着负载变化、基础设施更改（云提供商更改）以及动态配置更改在系统中传播。在本章中，我们将重点讨论如何测量和对分布式系统性能进行警报，以及采用的一些行业最佳实践。
- en: An organization must commit at a minimum to one or more monitoring solutions.
    There are a wide range of choices including open source, commercial on-premises,
    and SaaS offerings with a broad spectrum of capabilities. The market is mature
    enough that an organization of any size and complexity can find a solution that
    fits its requirements.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 组织至少必须致力于一个或多个监控解决方案。可以选择多种选择，包括开源、商业本地部署和SaaS提供的解决方案，具有广泛的能力范围。市场已经足够成熟，以至于任何规模和复杂性的组织都可以找到适合其需求的解决方案。
- en: The choice of monitoring system is important to preserve the fixed-cost characteristic
    of metrics data. The StatsD protocol, for example, requires an emission to a StatsD
    agent from an application on a per-event basis. Even if this agent is running
    as a sidecar process on the same host, the application still suffers the allocation
    cost of creating the payload on a per-event basis, so this protocol breaks at
    least this advantage of metrics telemetry. This isn’t always (or even commonly)
    catastrophic, but be aware of this cost.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 监控系统的选择对保持指标数据的固定成本特性至关重要。例如，StatsD协议要求应用程序在每个事件基础上向StatsD代理发出发射。即使此代理作为同一主机上的旁路进程运行，应用程序仍会承担每个事件基础上创建有效负载的分配成本，因此，此协议至少破坏了指标遥测的这一优势。这并非总是（甚至通常不是）灾难性的，但请注意此成本。
- en: Black Box Versus White Box Monitoring
  id: totrans-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 黑盒与白盒监控比较
- en: 'Approaches to metrics collection can be categorized according to what the method
    is able to observe:'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 指标收集方法可以根据其能够观察的内容进行分类：
- en: Black box
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 黑盒监控
- en: The collector can observe inputs and outputs (e.g., HTTP requests into a system
    and responses out of it), but the mechanism of the operation is not known to the
    collector. Black box collectors somehow intercept or wrap the observed process
    to measure it.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 收集器可以观察输入和输出（例如，系统中的HTTP请求和响应），但操作的机制对收集器是未知的。黑盒收集器通过某种方式拦截或包装被观察的进程以进行测量。
- en: White box
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 白盒
- en: The collector can observe inputs and outputs and also the internal mechanisms
    of the operation. White box collectors do this in application code.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 收集器可以观察输入和输出以及操作的内部机制。白盒收集器在应用程序代码中执行此操作。
- en: Many monitoring system vendors provide agents that can be attached to application
    processes and that provide black box monitoring. Sometimes these agent collectors
    reach so deep into well-known application frameworks that they start to resemble
    white box collectors in some ways. Still, black box monitoring in whatever form
    is limited to what the writer of the agent can generalize about all applications
    that might apply the agent. For example, an agent might be able to intercept and
    time Spring Boot’s mechanism for database transactions. An agent will never be
    able to reason that a `java.util.Map` field in some class represents a form of
    near-cache and instrument it as such.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 许多监控系统供应商提供可以附加到应用程序进程的代理，并提供黑盒监控。有时，这些代理收集器可以深入到众所周知的应用程序框架中，以至于在某些方面开始类似于白盒收集器。尽管如此，以任何形式的黑盒监控都受制于代理编写者能够概括所有可能应用代理的应用程序的内容的限制。例如，代理可能能够拦截并计时Spring
    Boot用于数据库事务的机制。代理永远无法推断某个类中的`java.util.Map`字段代表近缓存的形式并作为此类仪表进行操作。
- en: Service-mesh-based instrumentation is also black box and is generally less capable
    than an agent. While agents can observe and decorate individual method invocations,
    a service mesh’s finest-grained observation is at the RPC level.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 基于服务网格的仪表化也是黑盒的，并且通常比代理功能更弱。虽然代理可以观察和装饰单个方法调用，但服务网格的最细粒度观察是在RPC级别。
- en: 'On the other side, white box collection sounds like a lot of work. Some useful
    metrics are truly generalizable across applications (e.g., HTTP request timings,
    CPU utilization) and are well instrumented by black box approaches. A white box
    instrumentation library with some of these generalizations encapsulated when paired
    with an application autoconfiguration mechanism resembles a black box approach.
    White box instrumentation autoconfigured requires the same level of developer
    effort as black box instrumentation: specifically *none*!'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 另一方面，白盒收集听起来像是很多工作。一些有用的度量标准确实可以跨应用程序进行泛化（例如，HTTP 请求时间，CPU 利用率），并且通过黑盒方法进行了很好的仪表化。当一个白盒仪表化库与一个应用程序自动配置机制配对时，其中一些概括化部分类似于黑盒方法。自动配置的白盒仪表化需要与黑盒仪表化相同的开发人员工作水平：具体来说是*零*！
- en: Good white box metrics collectors should capture everything that a black box
    collector does but also support capturing more internal details that black box
    collectors by definition cannot. The difference between the two for your engineering
    practices are minimal. For a black box agent, you must alter your delivery practice
    to package and configure the agent (or couple yourself to a runtime platform integration
    that does this for you). For autoconfigured white box metrics collection that
    captures the same set of detail, you must include a binary dependency at build
    time.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 优秀的白盒度量收集器应该捕获与黑盒收集器相同的所有内容，但还应支持捕获更多黑盒收集器根据定义无法捕获的内部细节。对于你的工程实践来说，这两者之间的区别是微不足道的。对于黑盒代理，你必须修改你的交付实践以打包和配置代理（或者与运行时平台集成以替代这个过程）。对于自动配置的白盒度量收集，它捕获了相同的细节集，你必须在构建时包含一个二进制依赖项。
- en: Vendor-specific instrumentation libraries don’t tend to have this black box
    feel with a white box approach because framework and library authors aren’t inclined
    to add a wide range of proprietary instrumentation clients even as optional dependencies
    and instrument their code N different times. A vendor-neutral instrumentation
    facade like Micrometer has the advantage of the “write once, publish anywhere”
    experience for framework and library authors.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 供应商特定的仪表化库倾向于不具有白盒方法的黑盒感，因为框架和库的作者不倾向于添加各种专有仪表化客户端，即使作为可选依赖项，并且在其代码中多次进行仪表化。像
    Micrometer 这样的供应商中立的仪表化外观具有“写一次，随处发布”的优势，供框架和库的作者使用。
- en: Black box and white box collectors can of course be complementary, even when
    there is some overlap between them. There is no across-the-boards requirement
    to choose one over the other.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，黑盒和白盒收集器可以互补，即使它们之间存在一些重叠。没有普遍要求选择其中一个而不是另一个。
- en: Dimensional Metrics
  id: totrans-16
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 维度度量
- en: Most modern monitoring systems employ a dimensional naming scheme that consists
    of a metric name and a series of key-value tags.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数现代监控系统采用了由度量名称和一系列键值标签组成的维度命名方案。
- en: While the storage mechanism varies substantially from one monitoring system
    to another, in general every unique combination of name and tags is represented
    as a distinct entry or row in storage. The total cost in storage terms of a metric
    then is the product of the cardinality of its tag set (meaning the total number
    of unique key-value tag pairs).
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然监控系统的存储机制在很大程度上有所不同，但总的来说，每个唯一的名称和标签组合都表示为存储中的一个独特条目或行。因此，度量标准的存储成本是其标签集的基数的乘积（即唯一键值标签对的总数）。
- en: For example, an application-wide counter metric named `http.server.requests`
    that contains a tag for an HTTP method of which only GET and POST are ever observed,
    an HTTP status code where the service returns one of three status codes, and a
    URI of which there are two in the application results in up to <math alttext="2
    asterisk 3 asterisk 2 equals 12"><mrow><mn>2</mn> <mo>*</mo> <mn>3</mn> <mo>*</mo>
    <mn>2</mn> <mo>=</mo> <mn>12</mn></mrow></math> distinct time series sent to and
    stored in the monitoring system. This metric could be represented in storage roughly
    like in [Table 2-1](part0006_split_002.html#storage_dimensional_metric). Coordination
    between tags, like the fact that only endpoint `/a1` will ever have a `GET` method
    and only `/a2` will ever have a `POST` method can limit the total number of unique
    time series below the theoretical maximum, to only six rows in this example. In
    many dimensional time series databases, for each row representing a unique set
    of name and tags, there will be a value ring buffer that holds the samples for
    this metric over a defined period of time. When the system contains a bounded
    ring buffer like this, the total cost of your metrics is fixed to the product
    of the number of permutations of unique metric names/tags and the size of the
    ring buffer.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，一个应用程序范围的计数器指标，名为 `http.server.requests`，包含一个标签，用于观察到的 HTTP 方法，其中仅观察到 GET
    和 POST 两种方法，一个服务返回三种状态代码中的一种，以及两个应用程序中的一个 URI，导致最多 <math alttext="2 asterisk 3
    asterisk 2 equals 12"><mrow><mn>2</mn> <mo>*</mo> <mn>3</mn> <mo>*</mo> <mn>2</mn>
    <mo>=</mo> <mn>12</mn></mrow></math> 个不同的时间序列被发送到监控系统并存储。在此示例中，此指标在存储中的表示大致如 [表
    2-1](part0006_split_002.html#storage_dimensional_metric)所示。例如，协调标签，例如仅端点 `/a1`
    将具有 `GET` 方法，仅 `/a2` 将具有 `POST` 方法，可以将唯一时间序列的总数限制在理论最大值以下，在此示例中仅为六行。在许多维度时间序列数据库中，对于每一行代表的唯一名称和标签集，将有一个值环形缓冲区，用于在定义的时间段内保存此指标的样本。当系统包含类似这样的有界环形缓冲区时，您的指标的总成本固定为唯一指标名称/标签的排列数乘以环形缓冲区的大小。
- en: Table 2-1\. The storage of a dimensional metric
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 表 2-1\. 维度指标的存储
- en: '| Metric name and tags | Values |'
  id: totrans-21
  prefs: []
  type: TYPE_TB
  zh: '| 指标名称和标签 | 值 |'
- en: '| --- | --- |'
  id: totrans-22
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| http.server.requests{method=GET,status=200,uri=/a1} | [10,11,10,10] |'
  id: totrans-23
  prefs: []
  type: TYPE_TB
  zh: '| http.server.requests{method=GET,status=200,uri=/a1} | [10,11,10,10] |'
- en: '| http.server.requests{method=GET,status=400,uri=/a1} | [1,0,0,0] |'
  id: totrans-24
  prefs: []
  type: TYPE_TB
  zh: '| http.server.requests{method=GET,status=400,uri=/a1} | [1,0,0,0] |'
- en: '| http.server.requests{method=GET,status=500,uri=/a1} | [0,0,0,4] |'
  id: totrans-25
  prefs: []
  type: TYPE_TB
  zh: '| http.server.requests{method=GET,status=500,uri=/a1} | [0,0,0,4] |'
- en: '| http.server.requests{method=POST,status=200,uri=/a2} | [10,11,10,10] |'
  id: totrans-26
  prefs: []
  type: TYPE_TB
  zh: '| http.server.requests{method=POST,status=200,uri=/a2} | [10,11,10,10] |'
- en: '| http.server.requests{method=POST,status=400,uri=/a2} | [0,0,0,1] |'
  id: totrans-27
  prefs: []
  type: TYPE_TB
  zh: '| http.server.requests{method=POST,status=400,uri=/a2} | [0,0,0,1] |'
- en: '| http.server.requests{method=POST,status=500,uri=/a2} | [1,1,1,1] |'
  id: totrans-28
  prefs: []
  type: TYPE_TB
  zh: '| http.server.requests{method=POST,status=500,uri=/a2} | [1,1,1,1] |'
- en: In some cases, metrics are periodically moved to long-term storage. At this
    point, there is an opportunity to squash or drop tags to reduce storage cost at
    the expense of some dimensional granularity.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 在某些情况下，指标会定期移动到长期存储。在这一点上，有机会压缩或丢弃标签，以减少存储成本，尽管会牺牲一些维度的粒度。
- en: Hierarchical Metrics
  id: totrans-30
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 层次指标
- en: Before dimensional metrics systems became popular, many monitoring systems employed
    a hierarchical scheme. In these systems, metrics were defined only by name, with
    no key-value tag pairs. Tags are so useful that a convention emerged to append
    tag-like data to metric names with something like dot separators. So a dimensional
    metric like `httpServerRequests`, which has a `method` tag of `GET` in a dimensional
    system, might be represented as `httpServerRequests.method.GET` in a hierarchical
    system. Out of this arose query features like wildcard operators to allow simple
    aggregation across “tags,” as in [Table 2-2](part0006_split_003.html#hierarchical_metrics_aggregation).
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 在维度指标系统变得流行之前，许多监控系统采用了层次结构方案。在这些系统中，指标仅通过名称定义，没有键值标签对。标签非常有用，以至于出现了一种约定，将类似标签的数据附加到指标名称中，例如用点分隔符。因此，维度系统中具有
    `method` 标签为 `GET` 的维度指标 `httpServerRequests`，可能在层次结构系统中表示为 `httpServerRequests.method.GET`。由此产生了查询功能，如通配符运算符，允许跨“标签”进行简单聚合，如[表
    2-2](part0006_split_003.html#hierarchical_metrics_aggregation)所示。
- en: Table 2-2\. Aggregation of hierarchical metrics with wildcards
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 表 2-2\. 使用通配符聚合层次指标
- en: '| Metric query | Value |'
  id: totrans-33
  prefs: []
  type: TYPE_TB
  zh: '| 指标查询 | 值 |'
- en: '| --- | --- |'
  id: totrans-34
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| httpServerRequests.method.GET | 10 |'
  id: totrans-35
  prefs: []
  type: TYPE_TB
  zh: '| httpServerRequests.method.GET | 10 |'
- en: '| httpServerRequests.method.POST | 20 |'
  id: totrans-36
  prefs: []
  type: TYPE_TB
  zh: '| httpServerRequests.method.POST | 20 |'
- en: '| httpServerRequests.method.* | 30 |'
  id: totrans-37
  prefs: []
  type: TYPE_TB
  zh: '| httpServerRequests.method.* | 30 |'
- en: Still, tags are not a first-class citizen in hierarchical systems, and wildcarding
    like this breaks down. In particular, when an organization decides that a metric
    like `httpServerRequests` that is common to many applications across the stack
    should receive a new tag, it has the potential to break existing queries. In [Table 2-3](part0006_split_003.html#hierarchical_metrics_aggregation_failures),
    the true number of requests independent of method is 40, but since some application
    in the stack has introduced a new status tag in the metric name, it is no longer
    included in the aggregation. Even assuming we can agree as a whole organization
    to standardize on this new tag, our wildcarding queries (and therefore any dashboards
    or alerts built off of them) misrepresent the state of the system from the time
    the tag is introduced in the first application until it is fully propagated through
    the codebase and redeployed everywhere.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，在分层系统中，标签并不是一等公民，像这样的通配符会失效。特别是当组织决定像`httpServerRequests`这样在整个堆栈中的许多应用程序中通用的度量标签应该接收一个新标签时，它有可能破坏现有的查询。在[表 2-3](part0006_split_003.html#hierarchical_metrics_aggregation_failures)中，独立于方法的请求的真实数量是40，但由于堆栈中的某些应用程序在度量名称中引入了一个新的状态标签，它不再包含在聚合中。即使我们可以作为整个组织同意标准化使用这个新标签，我们的通配符查询（以及任何基于它们构建的仪表板或警报）也会误代表自标签首次在第一个应用程序中引入直到完全在代码库中传播并重新部署的时间内的系统状态。
- en: Table 2-3\. Failures of aggregation of hierarchical metrics with wildcards
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 表 2-3\. 使用通配符的分层度量聚合失败
- en: '| Metric query | Value |'
  id: totrans-40
  prefs: []
  type: TYPE_TB
  zh: '| Metric query | Value |'
- en: '| --- | --- |'
  id: totrans-41
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| httpServerRequests.method.GET | 10 |'
  id: totrans-42
  prefs: []
  type: TYPE_TB
  zh: '| httpServerRequests.method.GET | 10 |'
- en: '| httpServerRequests.method.POST | 20 |'
  id: totrans-43
  prefs: []
  type: TYPE_TB
  zh: '| httpServerRequests.method.POST | 20 |'
- en: '| httpServerRequests.status.200.method.GET | 10 |'
  id: totrans-44
  prefs: []
  type: TYPE_TB
  zh: '| httpServerRequests.status.200.method.GET | 10 |'
- en: '| httpServerRequests.method.* | 30 (!!) |'
  id: totrans-45
  prefs: []
  type: TYPE_TB
  zh: '| httpServerRequests.method.* | 30 (!!) |'
- en: Effectively, the hierarchical approach has forced an ordering of tags when they
    are really independent key-value pairs.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 事实上，层次方法迫使标签在它们实际上是独立的键值对时强加了一个顺序。
- en: If you are starting with real-time application monitoring now, you should be
    using a dimensional monitoring system. This means you will also have to use a
    dimensional metrics instrumentation library in order to record metrics in a way
    that fully takes advantage of the name/tag combination that makes these systems
    so powerful. If you already have some instrumentation using a hierarchical collector,
    the most popular being Dropwizard Metrics, you are going to have to ultimately
    rewrite this instrumentation. It’s possible to flatten dimensional metrics into
    hierarchical metrics by developing a naming convention that in some way iterates
    over all the tags and combines them with the metric name. Going the other direction
    is difficult to generalize, because the lack of consistency in naming schemes
    makes it difficult to split a hierarchical name into dimensional metrics.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您现在开始进行实时应用程序监控，您应该使用维度监控系统。这意味着您还必须使用维度度量仪表化库以便以充分利用使这些系统如此强大的名称/标签组合的方式记录度量。如果您已经有一些使用分层收集器的仪表化，其中最流行的是Dropwizard
    Metrics，您最终将不得不重写此仪表化。通过开发某种方式遍历所有标签并将它们与度量名称组合的命名约定，可以将维度度量转换为分层度量。反向操作很难泛化，因为命名方案的不一致使得将分层名称拆分为维度度量变得困难。
- en: From this point on, we’ll be examining dimensional metrics instrumentation alone.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 从这一点开始，我们将仅研究维度度量指标的仪表化。
- en: Micrometer Meter Registries
  id: totrans-49
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Micrometer Meter Registries
- en: 'The remainder of this chapter will use [Micrometer](https://micrometer.io),
    a dimensional metrics instrumentation library for Java that supports many of the
    most popular monitoring systems on the market. There are only two main alternatives
    to Micrometer available:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 本章的其余部分将使用[Micrometer](https://micrometer.io)，这是一个支持市场上大多数流行监控系统的Java维度度量仪表化库。现在只有两个Micrometer的主要替代品可用：
- en: Monitoring system vendors often provide Java API clients
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 监控系统供应商通常会提供Java API客户端。
- en: While these work for white box instrumentation at the application level, there
    is little to no chance that the remainder of the Java ecosystem, especially of
    third-party open source libraries, will adopt a particular vendor’s instrumentation
    client for its metrics collection. Probably the closest we have come to this is
    some spotty adoption in open source libraries of the Prometheus client.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管这些适用于应用程序级别的白盒子仪器，但很少有可能会有整个 Java 生态系统，特别是第三方开源库，会采用特定供应商的仪器客户端进行指标收集。迄今为止，我们可能最接近的是在
    Prometheus 客户端的一些开源库中的零星采用。
- en: '[OpenTelemetry](https://oreil.ly/xV0Aa)'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: '[OpenTelemetry](https://oreil.ly/xV0Aa)'
- en: OpenTelemetry is a hybrid metrics and tracing library. At the time of this writing,
    OpenTelemetry does not have a 1.0 release, and its focus has certainly been more
    on tracing than metrics, so metrics support is much more basic.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: OpenTelemetry 是一个混合度量和跟踪库。在撰写本文时，OpenTelemetry 还没有 1.0 发布，其关注点显然更多地集中在跟踪而不是度量上，因此度量支持要简单得多。
- en: While there is some variation in capabilities from one dimensional metrics instrumentation
    library to another, most of the key concepts described apply to each of them,
    or at least you should develop an idea of how alternatives should be expected
    to mature.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然从一个维度的度量仪器库到另一个维度的仪器库的功能可能会有所不同，但描述的大多数关键概念都适用于它们中的每一个，或者至少你应该开发出对替代方案预期成熟度的理解。
- en: In Micrometer, a `Meter` is the interface for collecting a set of measurements
    (which we individually call metrics) about your application.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 在 Micrometer 中，`Meter`是收集关于您的应用程序的一组测量（我们称之为度量）的接口。
- en: Meters are created from and held in a `MeterRegistry`. Each supported monitoring
    system has an implementation of `MeterRegistry`. How a registry is created varies
    for each implementation.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 计量器是从并保存在`MeterRegistry`中创建的。每个支持的监控系统都有一个`MeterRegistry`的实现。如何创建注册表因每个实现而异。
- en: 'Each `MeterRegistry` implementation that is supported by the Micrometer project
    has a library published to Maven Central and JCenter (e.g., `io.micrometer:micrometer-registry-prometheus`,
    `io.micrometer:micrometer-registry-atlas`):'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: Micrometer 项目支持的每个`MeterRegistry`实现都发布了一个库到 Maven Central 和 JCenter（例如，`io.micrometer:micrometer-registry-prometheus`，`io.micrometer:micrometer-registry-atlas`）：
- en: '[PRE0]'
  id: totrans-59
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: '`MeterRegistry` implementations with more options contain a fluent builder
    as well, for example the InfluxDB registry shown in [Example 2-1](part0006_split_004.html#influx_fluent_builder).'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 更多选项的`MeterRegistry`实现同样包含流畅构建器，例如在[示例 2-1](part0006_split_004.html#influx_fluent_builder)中显示的
    InfluxDB 注册表。
- en: Example 2-1\. Influx fluent builder
  id: totrans-61
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 2-1\. Influx 流畅构建器
- en: '[PRE1]'
  id: totrans-62
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Metrics can be published to multiple monitoring systems simultaneously with
    `CompositeMeterRegistry`.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 可以使用`CompositeMeterRegistry`同时将度量发布到多个监控系统。
- en: In [Example 2-2](part0006_split_004.html#composite_meter_registry), a composite
    registry is created that ships metrics to both Prometheus and Atlas. Meters should
    be created with the composite.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 在[示例 2-2](part0006_split_004.html#composite_meter_registry)中，创建了一个将指标发送到 Prometheus
    和 Atlas 的复合注册表。应该使用复合体创建计量器。
- en: Example 2-2\. Composite meter registry that ships to Prometheus and Atlas
  id: totrans-65
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 2-2\. 将指标发送到 Prometheus 和 Atlas 的复合计量器注册表
- en: '[PRE2]'
  id: totrans-66
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Micrometer packs with a global static `CompositeMeterRegistry` that can be used
    in a similar way that we use an SLF4J `LoggerFactory`. The purpose of this static
    registry is to allow for instrumentation in components that cannot leak Micrometer
    as an API dependency by offering a way to dependency-inject a `MeterRegistry`.
    [Example 2-3](part0006_split_004.html#using_static_registry) shows the similarity
    between the use of the global static registry and what we are used to from logging
    libraries like SLF4J.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: Micrometer 包含一个全局静态的`CompositeMeterRegistry`，可以类似于使用 SLF4J 的`LoggerFactory`那样使用。这个静态注册表的目的是允许在不能通过
    API 依赖泄漏 Micrometer 的组件中进行仪表化，通过提供一种依赖注入`MeterRegistry`的方式。[示例 2-3](part0006_split_004.html#using_static_registry)展示了全局静态注册表的使用方式与我们从日志库（如
    SLF4J）中习惯的方式的相似性。
- en: Example 2-3\. Using the static global registry
  id: totrans-68
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 2-3\. 使用全局静态注册表
- en: '[PRE3]'
  id: totrans-69
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: By adding any `MeterRegistry` implementations that you wire in your application
    to the global static registry, any low-level libraries using the global registry
    like this wind up registering metrics to your implementations. Composite registries
    can be added to other composite registries. In [Figure 2-1](part0006_split_004.html#global_registry_relationship),
    we’ve created a composite registry in our application that publishes metrics to
    both Prometheus and Stackdriver (i.e., we’ve called `CompositeMeterRegistry#add(MeterRegistry)`
    for both the Prometheus and Stackdriver registries). Then we’ve added *that* composite
    to the global static composite. The composite registry you created can be dependency-injected
    by something like Spring, CDI, or Guice throughout your application for your components
    to register metrics against. But other libraries are often outside of this dependency-injection
    context, and since they don’t want Micrometer to leak through their API signatures,
    they register with the static global registry. In the end, metrics registration
    flows down this hierarchy of registries. So library metrics flow down from the
    global composite to your application composite to the individual registries. Application
    metrics flow down from the application composite to the individual Prometheus
    and Stackdriver registries.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 通过将你在应用程序中引入的任何 MeterRegistry 实现添加到全局静态注册表，任何使用全局注册表的底层库都会将指标注册到你的实现中。复合注册表可以添加到其他复合注册表中。在
    [Figure 2-1](part0006_split_004.html#global_registry_relationship) 中，我们在应用程序中创建了一个复合注册表，它同时向
    Prometheus 和 Stackdriver 发布指标（即我们对 Prometheus 和 Stackdriver 注册表都调用了 `CompositeMeterRegistry#add(MeterRegistry)`）。然后我们将该复合注册表添加到全局静态复合中。你创建的复合注册表可以通过
    Spring、CDI 或 Guice 等框架在整个应用程序中进行依赖注入，以便你的组件向其注册指标。但其他库通常不在此依赖注入的上下文中，因为它们不希望 Micrometer
    通过其 API 签名泄露，所以它们会向静态全局注册表注册。最终，指标注册沿着注册表层次结构向下流动。因此，库指标从全局复合流向你的应用程序复合，再流向各个注册表。应用程序指标从应用程序复合流向各个
    Prometheus 和 Stackdriver 注册表。
- en: '![srej 0201](../images/00111.png)'
  id: totrans-71
  prefs: []
  type: TYPE_IMG
  zh: '![srej 0201](../images/00111.png)'
- en: Figure 2-1\. Relationship between global static registry and your application’s
    registries
  id: totrans-72
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 2-1\. 全局静态注册表与应用程序注册表的关系
- en: Spring Boot Autoconfiguration of MeterRegistry
  id: totrans-73
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Spring Boot 自动配置 MeterRegistry
- en: Spring Boot autoconfigures a composite registry and adds a registry for each
    supported implementation that it finds on the classpath. A dependency on `micrometer-registry-{system}`
    in your runtime classpath along with any required configuration for that system
    causes Spring Boot to configure the registry. Spring Boot also adds any `MeterRegistry`
    found as a `@Bean` to the global static composite. In this way, any libraries
    that you add to your application that provide Micrometer instrumentation automatically
    ship their metrics to your monitoring system! This is how the black-box-like experience
    is achieved through white box instrumentation. As the developer, you don’t need
    to explicitly register these metrics; just their presence in your application
    makes it work.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: Spring Boot 会自动配置一个复合注册表，并为在类路径上找到的每个支持的实现添加注册表。在你的运行时类路径上依赖`micrometer-registry-{system}`以及该系统的任何必需配置，将导致
    Spring Boot 配置注册表。Spring Boot 还会将任何作为`@Bean`的 MeterRegistry 添加到全局静态复合中。通过这种方式，你添加到应用程序中的任何提供
    Micrometer 仪表盘的库将自动将它们的指标发送到监控系统！这就是通过白盒仪表化实现黑盒般的体验。作为开发者，你无需显式注册这些指标；它们存在于你的应用程序中就能工作。
- en: Creating Meters
  id: totrans-75
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 创建 Meter
- en: Micrometer provides two styles to register metrics for each supported `Meter`
    type, depending on how many options you need. The fluent builder, as shown in
    [Example 2-4](part0006_split_006.html#meter_fluent_builder), provides the most
    options. Generally, core libraries should use the fluent builder because the extra
    verbosity required to provide robust description and base unit detail adds value
    to all of their users. In instrumentation for a particular microservice with a
    small set of engineers, opting for more compact code and less detail is fine.
    Some monitoring systems support attaching description text and base units to metrics,
    and for those, Micrometer will publish this data. Furthermore, some monitoring
    systems will use base unit information on a metric to automatically scale and
    label the *y*-axis of charts in a way that is human readable. So if you publish
    a metric with a base unit of “bytes,” a sophisticated monitoring system will recognize
    this and scale the *y*-axis to megabytes or gigabytes, or whatever is the most
    human-readable value for the range of this metric. It’s much easier to read “2
    GB” than “2147483648 bytes.” Even for those monitoring systems that don’t fundamentally
    support base units, charting user interfaces like [Grafana](https://grafana.com)
    allow you to manually specify the units of a chart, and Grafana will do this kind
    of intelligent human-readable scaling for you.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 对于每种支持的 `Meter` 类型，Micrometer 提供了两种样式来注册指标，具体取决于您需要多少选项。如示例 2-4（part0006_split_006.html#meter_fluent_builder）所示，流畅构建器提供了最多的选项。通常，核心库应该使用流畅构建器，因为为了为所有用户提供健壮的描述和基本单位详细信息，额外的冗长性增加了价值。在具有少量工程师的特定微服务的仪器化中，选择更紧凑的代码和更少的详细信息是可以接受的。一些监控系统支持附加描述文本和基本单位到指标，对于这些系统，Micrometer
    将发布这些数据。此外，一些监控系统将使用指标的基本单位信息自动缩放和标记图表的 *y* 轴，使其以人类可读的方式。因此，如果您发布带有“bytes”基本单位的指标，复杂的监控系统将识别此并将
    *y* 轴缩放为兆字节或千兆字节，或者任何对于此指标范围最为人类可读的值。阅读“2 GB”比“2147483648 bytes”要容易得多。即使对于那些从根本上不支持基本单位的监控系统，诸如
    [Grafana](https://grafana.com) 这样的图表用户界面也允许您手动指定图表的单位，而 Grafana 将为您执行这种智能的人类可读缩放。
- en: Example 2-4\. Meter fluent builder
  id: totrans-77
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 2-4\. Meter 流畅构建器
- en: '[PRE4]'
  id: totrans-78
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: '`MeterRegistry` contains convenience methods to construct `Meter` instances
    with a shorter form, as in [Example 2-5](part0006_split_006.html#meter_short_form).'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: '`MeterRegistry` 包含方便的方法，用于使用较短的形式构造 `Meter` 实例，如 [示例 2-5](part0006_split_006.html#meter_short_form)
    所示。'
- en: Example 2-5\. Meter construction convenience methods
  id: totrans-80
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 2-5\. Meter 构造便利方法
- en: '[PRE5]'
  id: totrans-81
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Regardless of which of the two methods you use to construct a meter, you will
    have to decide on its name and which tags to apply.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 无论您使用哪种方法来构造计量器，您都必须决定其名称以及应用哪些标签。
- en: Naming Metrics
  id: totrans-83
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 指标命名
- en: To get the most out of metrics, they need to be structured in such a way that
    selecting just the name and aggregating over all tags yields a meaningful (if
    not always useful) value. For example, if a metric is named `http.server.requests`,
    then tags may identify application, region (in the public cloud sense), API endpoint,
    HTTP method, response status code, etc. An aggregate measure like throughput for
    this metric of all unique combinations of tags yields a measure of throughput
    for every interaction with many applications across your application stack. The
    ability to pivot on this name into various tags makes this useful. We could explode
    this metric dimensionally by region and observe a regional outage or drill down
    on a particular application—for example, for successful responses to a particular
    API endpoint to reason about throughput through that one key endpoint.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 要充分利用指标，它们需要以一种结构化的方式进行组织，以便仅选择名称并对所有标签进行聚合能够产生一个有意义的（尽管不一定总是有用的）值。例如，如果一个指标命名为
    `http.server.requests`，那么标签可以识别应用程序、区域（按照公共云的概念）、API 终端、HTTP 方法、响应状态码等。对此指标的所有唯一标签组合进行的聚合测量将为您的应用程序栈中的许多应用程序的每次交互产生吞吐量的测量。在此名称上切换到各种标签的能力使其变得有用。我们可以按区域将此指标在度量上扩展，并观察区域性故障或详细查看特定应用程序，例如，成功响应特定
    API 终端以推理通过该关键终端的吞吐量。
- en: Assuming many applications are instrumented with some metric such as `http.server.requests`,
    when building a visualization on `http.server.requests` the monitoring system
    will display an aggregate of the performance of all of the `http.server.requests`
    across all applications, regions, etc. until you decide to dimensionally drill
    down on something.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 假设许多应用程序都使用某种度量标准，如`http.server.requests`，当在`http.server.requests`上构建可视化时，监控系统将显示所有应用程序、地区等的`http.server.requests`性能的聚合，直到您决定对某些内容进行维度钻取。
- en: Not everything should be a tag, however. Suppose we are trying to measure the
    number of HTTP requests and the number of database calls separately.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，并非所有的都应该是标签。假设我们试图分别测量 HTTP 请求的数量和数据库调用的数量。
- en: Micrometer employs a naming convention that separates lowercase words with a
    . (dot) character. The naming shown in [Example 2-6](part0006_split_007.html#recommended_naming)
    provides enough context so that if just the name is selected the value is at least
    potentially meaningful. For example, if we select `database.queries` we can see
    the total number of calls to all databases. Then we can group by or select by
    database to drill down further or perform comparative analysis on the contribution
    of calls to each database.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: Micrometer 使用一个命名约定，用`.`（点）字符分隔小写单词。[示例 2-6](part0006_split_007.html#recommended_naming)
    中显示的命名提供了足够的上下文，以便如果只选择名称，则值至少在潜在上是有意义的。例如，如果我们选择`database.queries`，我们可以看到对所有数据库的调用总数。然后我们可以按数据库分组或选择以进一步进行钻取或执行对每个数据库调用贡献的比较分析。
- en: Example 2-6\. Recommended approach
  id: totrans-88
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 2-6\. 推荐方法
- en: '[PRE6]'
  id: totrans-89
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: With the approach shown in [Example 2-7](part0006_split_007.html#bad_naming),
    if we select the metric `calls` we will get a value that is an aggregate of the
    number of calls to the database and HTTP requests. This value is not useful without
    dimensionally drilling down further.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 [示例 2-7](part0006_split_007.html#bad_naming) 中展示的方法，如果我们选择度量`calls`，我们将得到一个聚合值，该值是数据库调用和
    HTTP 请求的总数。如果没有进一步进行维度钻取，这个值是没有用处的。
- en: 'Example 2-7\. Bad practice: using a type tag where the meter name should be
    different instead'
  id: totrans-91
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 2-7\. 不良实践：在应该有不同计量名称的地方使用类型标签
- en: '[PRE7]'
  id: totrans-92
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: '[Figure 2-2](part0006_split_007.html#bad_metric_naming) shows the effect of
    this bad naming. Suppose for every HTTP request you make 10 database calls. If
    you just chart `calls`, you get the top-line rate of approximately 11,000 calls.
    But 11,000 is an awkward sum of two types of calls which are always an order of
    magnitude off in frequency. To get any utility out of this, we need to break down
    by type dimensionally, at which point we discover the 10x relationship of database
    calls to HTTP requests. Having to drill down right away to build an intelligible
    chart is a sign that something isn’t right about the metric naming scheme.'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: '[图 2-2](part0006_split_007.html#bad_metric_naming) 显示了这种错误命名的影响。假设每个 HTTP 请求您都进行了
    10 次数据库调用。如果只绘制`calls`，您将得到约 11,000 次的顶线速率。但是 11,000 是两种类型调用的笨拙总和，其频率始终相差一个数量级。要从中获得任何实用性，我们需要按维度分解，此时我们发现了数据库调用与
    HTTP 请求之间的 10 倍关系。必须立即进行维度钻取才能构建可理解的图表，这表明度量命名方案存在问题。'
- en: '![srej 0202](../images/00020.png)'
  id: totrans-94
  prefs: []
  type: TYPE_IMG
  zh: '![srej 0202](../images/00020.png)'
- en: Figure 2-2\. The effect of bad naming on chart usability
  id: totrans-95
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 2-2\. 错误命名对图表可用性的影响
- en: 'It is a good practice to group related data together, such as by prefixing
    metric names with namespaces like “jvm” or “db.” For example, a suite of metrics
    related to JVM garbage collection could be prefixed with `jvm.gc`:'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 将相关数据分组是一个良好的做法，比如通过为度量名称添加像“jvm”或“db”这样的命名空间前缀。例如，与 JVM 垃圾回收相关的一组指标可以用`jvm.gc`作为前缀：
- en: '[PRE8]'
  id: totrans-97
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'This namespacing not only helps group related metrics alphabetically in many
    monitoring system UIs and dashboarding utilities, but also can be used to affect
    a group of metrics in one pass with a `MeterFilter`. For example, to disable all
    `jvm.gc` metrics, we can apply a deny `MeterFilter` on this name:'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 这种命名空间不仅有助于在许多监控系统 UI 和仪表板工具中按字母顺序分组相关指标，还可以用于通过`MeterFilter`一次性影响一组指标。例如，要禁用所有`jvm.gc`指标，我们可以在这个名称上应用一个拒绝`MeterFilter`：
- en: '[PRE9]'
  id: totrans-99
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: Different monitoring systems have different recommendations regarding naming
    convention, and some naming conventions may be incompatible for one system and
    not another. Recall that Micrometer employs a naming convention that separates
    lowercase words with a *.* (dot) character. Each Micrometer implementation for
    a monitoring system comes with a naming convention that transforms lowercase dot
    notation names into the monitoring system’s recommended naming convention.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 不同的监控系统对命名约定有不同的建议，有些命名约定可能对某一系统不兼容。请记住，Micrometer使用一个命名约定，用`.`（点）字符分隔小写单词。每个用于监控系统的Micrometer实现都有一个命名约定，将小写点表示法名称转换为该监控系统推荐的命名约定。
- en: 'Additionally, this naming convention sanitizes metric names and tags of special
    characters that are disallowed by the monitoring system. The convention turns
    out to be more than just a play at appearing more idiomatic. If shipped in this
    form without any naming convention normalization two metrics, `http.server.requests`
    and `http.client.requests`, would break Elasticsearch indexing, which treats dots
    as a form of hierarchy for the purpose of indexing. If these metrics were *not*
    shipped with dots to SignalFx, we wouldn’t be able to take advantage of UI presentation
    in SignalFx that hierarchizes metrics with dot separators in them. These two differing
    opinions on the dot character are mutually exclusive. With naming convention normalization,
    these metrics are shipped as `httpServerRequests` and `httpClientRequests` to
    Elastic and with the dot notation to SignalFx. So the application code maintains
    maximum portability without having to change instrumentation. When using Micrometer,
    meter names and tag keys should follow these guidelines:'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 另外，此命名约定还会清理度量名称和标签中的特殊字符，这些字符是监控系统禁止使用的。该约定事实证明不仅仅是为了看起来更惯用。如果以这种形式发货而没有任何命名约定规范化，两个度量，`http.server.requests`和`http.client.requests`，将会破坏Elasticsearch索引，因为Elasticsearch将点视为用于索引的层次结构形式。如果这些度量没有以点分隔符的形式发送到SignalFx，我们将无法利用SignalFx中用点分隔符对度量进行层次化的UI呈现功能。这两种关于点字符的不同观点是互斥的。通过命名约定规范化，这些度量被发送到Elastic作为`httpServerRequests`和`httpClientRequests`，并且带有点符号发送到SignalFx。因此，应用程序代码在不更改工具的情况下保持最大的可移植性。使用Micrometer时，米器名称和标签键应遵循这些准则：
- en: Always use dots to separate parts of the name.
  id: totrans-102
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 始终使用点来分隔名称的各个部分。
- en: Avoid adding unit names or words like `total` to meter names.
  id: totrans-103
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 避免在米器名称中添加单位名称或诸如`total`等字词。
- en: So choose `jvm.gc.memory.promoted` instead of `jvmGcMemoryPromoted` or `jvm_gc_memory_promoted`.
    If you prefer one of the latter (or if your monitoring system requires it), configure
    the naming convention on the registry to do this conversion. But using dot separators
    in metric names up and down the whole software stack yields consistent outcomes
    for a variety of monitoring systems.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，选择`jvm.gc.memory.promoted`而不是`jvmGcMemoryPromoted`或`jvm_gc_memory_promoted`。如果您喜欢后者之一（或者如果您的监控系统要求这样做），请在注册表上配置命名约定以进行此转换。但是，在整个软件堆栈中使用点分隔符作为度量名称，可以为各种监控系统提供一致的结果。
- en: For some monitoring systems, the presence of unit names and the like are part
    of the idiomatic naming scheme. Again, naming conventions can add these bits where
    appropriate. For example, Prometheus’s naming convention adds `_total` to the
    suffix of counters and `_seconds` to the end of timers. Also, the base unit of
    time varies based on the monitoring system. With a Micrometer `Timer`, you record
    in whatever granularity you’d like and the time values are scaled at publishing
    time. Even if you always record in a certain granularity, including the unit name
    in the meter name is inaccurate. For example, [Example 2-8](part0006_split_007.html#timer_with_unit_in_name)
    shows up as `requests_millis_seconds` in Prometheus, which is awkward.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 对于某些监控系统，单位名称等的存在是惯用命名方案的一部分。再次强调，命名约定可以在适当的情况下添加这些部分。例如，Prometheus的命名约定在计数器的后缀上添加了`_total`，在定时器的末尾添加了`_seconds`。此外，基本时间单位根据监控系统而异。使用Micrometer的`Timer`，您可以以任何粒度记录，并且时间值在发布时进行了缩放。即使您总是以特定粒度记录，包含单位名称在米器名称中也是不准确的。例如，[示例
    2-8](part0006_split_007.html#timer_with_unit_in_name) 在Prometheus中显示为`requests_millis_seconds`，这显得很尴尬。
- en: 'Example 2-8\. Bad practice: adding a unit to the meter name'
  id: totrans-106
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 2-8\. 不良做法：在米器名称中添加单位
- en: '[PRE10]'
  id: totrans-107
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: The default naming convention of a `MeterRegistry` can be overridden with a
    custom one, which can build upon some basic building blocks provided in the `NamingConvention`
    interface, as shown in [Example 2-9](part0006_split_007.html#custom_naming_convention).
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 可以用自定义命名约定重写 `MeterRegistry` 的默认命名约定，该命名约定可以建立在 `NamingConvention` 接口提供的一些基本构建块上，如[示例 2-9](part0006_split_007.html#custom_naming_convention)所示。
- en: Example 2-9\. A custom naming convention that adds base units as a suffix
  id: totrans-109
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 2-9\. 一个自定义的命名约定，将基本单位作为后缀添加
- en: '[PRE11]'
  id: totrans-110
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: '[![1](../images/00112.png)](part0006_split_007.html#co_application_metrics_CO1-1)'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: '[![1](../images/00112.png)](part0006_split_007.html#co_application_metrics_CO1-1)'
- en: '`NamingConvention` is a functional interface, so this can be simplified to
    a lambda, but for the sake of clarity here we leave the anonymous class.'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: '`NamingConvention` 是一个函数式接口，因此这可以简化为一个 lambda，但为了清晰起见，我们在这里保留了匿名类。'
- en: As mentioned in [“Dimensional Metrics”](part0006_split_002.html#dimensional_metrics_instrumentation),
    the total storage cost of a metric is the product of the cardinality of the value
    set of each of its tags. Choose tag names that help identify the failure mode
    of a piece of software. For example, if monitoring an auto insurance rating application,
    tagging policy metrics with vehicle class is more useful than tagging with a unique
    vehicle identification number. As a result of a bug or downstream service outage,
    a class of vehicles like classic trucks may start failing. Responding to an alert
    on a policy rating error ratio that exceeds a predetermined threshold, an engineer
    may quickly identify that the handling of classic trucks is problematic based
    on the top three rating failures by vehicle class.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 如[“维度度量”](part0006_split_002.html#dimensional_metrics_instrumentation)中所述，度量的总存储成本是其每个标记的值集的基数的乘积。选择有助于识别软件故障模式的标记名称。例如，如果监控汽车保险评级应用程序，则将策略度量标记为车辆类别比将其标记为唯一车辆识别号更有用。由于错误或下游服务中断，某一类车辆（如经典卡车）可能开始失败。在超过预定阈值的策略评级错误比率警报上作出响应时，工程师可能会快速确定经典卡车处理存在问题，这是基于车辆类别中前三个评级失败的情况。
- en: Limit Total Unique Tag Values to Control Storage Cost
  id: totrans-114
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 限制总唯一标记值以控制存储成本
- en: Beware of the potential for tag values coming from user-supplied sources to
    blow up the cardinality of a metric. You should always carefully normalize and
    bound user-supplied input. Sometimes the cause is sneaky. Consider the URI tag
    for recording HTTP requests on service endpoints. If we don’t constrain 404s to
    a value like “NOT_FOUND,” the dimensionality of the metric would grow with each
    resource that can’t be found. Even more tricky, an application that redirects
    all nonauthenticated requests to a login endpoint could return a 403 for a resource
    that ultimately will not be found once authenticated, and so a reasonable URI
    tag for a 403 might be “REDIRECTION.” Allowing a tag value set to grow without
    bound can result in an overrun of storage in your monitoring system, increasing
    cost and potentially destabilizing a core part of your observability stack.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 要注意来自用户提供的来源的标记值可能导致度量的基数增加。您应该始终仔细规范化和限制用户提供的输入。有时候原因很隐蔽。考虑记录服务端点上的 HTTP 请求时的
    URI 标记。如果我们不将 404s 限制为像“NOT_FOUND”这样的值，那么度量的维度将随着每个无法找到的资源而增长。更加棘手的是，一个将所有非经过身份验证的请求重定向到登录端点的应用程序可能会为最终将在经过身份验证后找不到的资源返回
    403，并且因此，403 的一个合理的 URI 标记可能是“REDIRECTION”。允许标记值集合无限增长可能会导致监控系统中的存储溢出，增加成本并可能使您的可观察性堆栈的核心部分不稳定化。
- en: In general, avoid recording tags on unique values like user ID unless it is
    known that the population is small.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 一般来说，避免在像用户 ID 这样的唯一值上记录标记，除非已知该人口规模很小。
- en: Tag values must be nonnull and ideally nonblank. Even though Micrometer technically
    supports blank tag values in limited situations, like for the Datadog registry
    implementation, blank tag values are not portable to other monitoring systems
    that don’t support them.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 标记值必须是非空的，最好是非空白的。尽管 Micrometer 在技术上支持有限情况下的空白标记值，比如对于 Datadog 注册表实现，但空白的标记值在其他不支持它们的监控系统中不具备可移植性。
- en: Limit Total Unique Tag Values to Control Query Cost
  id: totrans-118
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 限制总唯一标记值以控制查询成本
- en: In addition to increases to storage costs with an increasing number of unique
    tag values, query costs (in both time and resources) also increase as more and
    more time series need to be aggregated in query results.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 除了随着唯一标记值数量的增加而增加存储成本外，查询成本（包括时间和资源）也会随着需要在查询结果中聚合更多时间序列而增加。
- en: Common Tags
  id: totrans-120
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 常见标记
- en: When lower-level libraries provide common instrumentation (Micrometer provides
    meter binders out of the box—see [“Meter Binders”](part0007_split_023.html#meter_binders)),
    they cannot know the context of the application this instrumentation will be collected
    in. Is the app running in a private datacenter on one of a small set of named
    VMs whose names never change? On infrastructure-as-a-service public cloud resources?
    In Kubernetes? In virtually every case, there is more than one running copy of
    a particular application that might ship metrics, even if there is just one copy
    in production and one in a lower-level testing environment. It’s useful if we
    can partition in some way the metrics streaming out of these various instances
    of an application by some dimensions that allow us to attribute a behavior back
    to a particular instance.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 当低级别库提供常见的仪表化时（Micrometer提供开箱即用的计量器绑定器——参见[“计量器绑定器”](part0007_split_023.html#meter_binders)），它们无法知道此仪表化将在何种应用程序上收集。应用程序是在私有数据中心运行，还是在一组名为的小型VM之一上运行，而这些名称从不改变？是在基础设施即服务的公共云资源上？在Kubernetes中？几乎每种情况下，特定应用程序的多个运行副本都可能输出指标，即使在生产环境中只有一个副本，在低级测试环境中也只有一个。如果我们能以某种方式对这些不同应用程序实例输出的指标进行分区，以允许我们通过某些维度将行为归因于特定实例，那将非常有用。
- en: 'Meter filters (covered in more detail in [“Meter Filters”](part0007_split_016.html#6LLJE-2d714b853a094e9a910510217e0e3d73))
    allow you to add common tags to accomplish exactly this, enriching every metric
    published from an application with additional tags. Pick common tags that help
    turn your metrics data into action. Following are common tags that are always
    useful:'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 计量过滤器（详细介绍请参阅[“计量过滤器”](part0007_split_016.html#6LLJE-2d714b853a094e9a910510217e0e3d73)）允许您添加常见标签来实现这一点，从而丰富从应用程序发布的每个指标。选择帮助将您的指标数据转化为行动的常见标签。以下是一些始终有用的常见标签：
- en: Application name
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 应用程序名称
- en: Consider that some metrics, like HTTP request metrics instrumented by the framework,
    will have the same name across various applications, e.g., `http.server.requests`
    for HTTP endpoints served by the application, and `http.client.requests` for outbound
    requests to other services. By tagging with application name, you could then,
    for example, reason about all outbound requests to some particular service endpoint
    across multiple callers.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑到一些指标，比如框架提供的HTTP请求指标，将在各种应用程序中具有相同的名称，例如，应用程序服务的`http.server.requests`和向其他服务发出的`http.client.requests`的出站请求。通过应用程序名称进行标记，您可以例如推断出关于跨多个调用者的某个特定服务端点的所有出站请求的情况。
- en: Cluster and server group name
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 集群和服务器组名称
- en: In [“Delivery Pipelines”](part0010_split_003.html#delivery_definitions) we talk
    more about the formal definition of a cluster and server group. If you have such
    a topology, tagging with cluster and server group is always useful. Some organizations
    don’t have this level of complexity, and that’s OK too.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 在[“交付管道”](part0010_split_003.html#delivery_definitions)中，我们更多地讨论了集群和服务器组的正式定义。如果您拥有这样的拓扑结构，使用集群和服务器组的标签总是有益的。有些组织并不具备这种复杂程度，这也是可以接受的。
- en: Instance name
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 实例名称
- en: This may be the machine’s host name in some situations, but not always (and
    this helps explain why Micrometer doesn’t preemptively tag with things like host
    name, because it really does depend on the deployed environment). In public cloud
    environments, host name may not be the right tag. AWS EC2, for example, has local
    and external host names that are distinct from the instance ID. Instance ID is
    actually the easiest of these three to locate a particular instance with in the
    AWS console, and it does uniquely identify the instance. So in this context, instance
    ID is a better tag than host name. In Kubernetes, the pod ID is the right instance-level
    tag.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 在某些情况下，这可能是机器的主机名，但并非总是如此（这有助于解释为什么Micrometer不会预先使用诸如主机名之类的标签，因为它确实取决于部署的环境）。在公共云环境中，主机名可能不是正确的标签。例如，AWS
    EC2具有与实例ID不同的本地和外部主机名。实例ID实际上是这三个中最容易在AWS控制台中找到特定实例的标签，而且确实能唯一标识该实例。因此，在这种情况下，实例ID是比主机名更好的标签。在Kubernetes中，Pod
    ID是正确的实例级标签。
- en: Stack
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 栈
- en: “Stack” in this context means development versus production. You may have multiple
    levels of nonproduction environments. Shelter Insurance at one point had “devl,”
    “test,” “func,” and “stage” nonproduction environments, each of which served its
    own purpose (and I might be forgetting one or two). It’s nice to practice monitoring
    even on unstable lower-level environments to baseline your expectations about
    the performance and number of errors produced by a piece of code as it progresses
    along its promotion path on the route to production.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个背景下，“堆栈”意味着开发与生产。您可能有多个非生产环境的级别。Shelter Insurance曾经有“devl”，“test”，“func”和“stage”等多个非生产环境，每个环境都有自己的用途（我可能忘记了其中一个或两个）。在不稳定的低级环境上实践监控是件好事，这样您可以基准您对代码性能和错误数量的预期，随着其在推广路径上向生产线路前进。
- en: Some other ideas for tags for different deployed environments are included in
    [Table 2-4](part0006_split_010.html#tags_per_provider).
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 在[Table 2-4](part0006_split_010.html#tags_per_provider)中还包括了针对不同部署环境的标签的其他想法。
- en: Table 2-4\. Common tags by cloud provider
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 表2-4. 云提供商的通用标签
- en: '| Provider | Common tags |'
  id: totrans-133
  prefs: []
  type: TYPE_TB
  zh: '| Provider | 通用标签 |'
- en: '| --- | --- |'
  id: totrans-134
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| AWS | Instance ID, ASG name, region, zone, AMI ID, account |'
  id: totrans-135
  prefs: []
  type: TYPE_TB
  zh: '| AWS | 实例ID，ASG名称，区域，区域，AMI ID，账户 |'
- en: '| Kubernetes | Pod ID, namespace, cluster name, Deployment/StatefulSet name,
    ReplicaSet name |'
  id: totrans-136
  prefs: []
  type: TYPE_TB
  zh: '| Kubernetes | Pod ID, namespace, cluster name, Deployment/StatefulSet name,
    ReplicaSet name |'
- en: '| Cloud Foundry | CF app name (which may be distinct from the application name),
    organization name, space name, instance ordinal, foundation name |'
  id: totrans-137
  prefs: []
  type: TYPE_TB
  zh: '| Cloud Foundry | CF应用名称（可能与应用程序名称不同），组织名称，空间名称，实例序数，基金会名称 |'
- en: 'This table illustrates why Micrometer doesn’t add these tags by default. The
    singular concept of “namespace” has three different names across these cloud providers:
    region, namespace, and organization/space. Where AWS and Kubernetes have a single-value
    namespace concept, CloudFoundry has two: organization and space!'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 此表说明了为什么Micrometer默认不添加这些标签。在这些云提供商中，“命名空间”这一单一概念在AWS和Kubernetes中有三个不同的名称：区域，命名空间和组织/空间。CloudFoundry有两个：组织和空间！
- en: The application of common tags is a great place to begin thinking as a platform
    engineering organization about how to encapsulate and standardize for your organization.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 应用通用标签是作为平台工程组织开始思考如何为您的组织封装和标准化的好地方。
- en: '[Example 2-10](part0006_split_010.html#property_based_common_tags) shows how
    in Spring Boot, you can apply common tags via property-based configuration.'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: '[Example 2-10](part0006_split_010.html#property_based_common_tags)展示了在Spring
    Boot中如何通过基于属性的配置应用通用标签。'
- en: Example 2-10\. Adding common tags by property in Spring Boot
  id: totrans-141
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例2-10. 在Spring Boot中通过属性添加通用标签
- en: '[PRE12]'
  id: totrans-142
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: Alternatively, you could apply tags in an autoconfigurable `@Configuration`
    class, as in [Example 2-11](part0006_split_010.html#programmatic_common_tags).
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 或者，您可以在自动配置的`@Configuration`类中应用标签，就像[Example 2-11](part0006_split_010.html#programmatic_common_tags)中所示。
- en: Example 2-11\. Adding common tags programmatically in Spring Boot
  id: totrans-144
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例2-11. 在Spring Boot中以编程方式添加通用标签
- en: '[PRE13]'
  id: totrans-145
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: '[![1](../images/00112.png)](part0006_split_010.html#co_application_metrics_CO2-1)'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: '[![1](../images/00112.png)](part0006_split_010.html#co_application_metrics_CO2-1)'
- en: This should be sourced from the environment as well.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 这也应该来自环境。
- en: Assuming you have some central dynamic configuration server, like Spring Cloud
    Config Server, that applications interrogate at startup for properties, the property-based
    configuration allows you to deliver these common tag opinions across your application
    stack immediately and with no code changes or dependency requirements for each
    application.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您有某些中央动态配置服务器，例如Spring Cloud Config Server，应用在启动时会查询属性，基于属性的配置允许您立即在整个应用堆栈中交付这些通用标签意见，而无需进行任何代码更改或每个应用的依赖要求。
- en: The programmatic form can be delivered via an explicit runtime binary dependency
    from each app or by injecting a dependency into the deployed form of the app or
    a container running it, like Tomcat.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 程序化形式可以通过每个应用的显式运行时二进制依赖项或将依赖项注入应用或运行其容器的形式（如Tomcat）来交付。
- en: Classes of Meters
  id: totrans-150
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 米（Meters）的类
- en: Many metrics collectors provide several classes of meters, each of which may
    emit one or more metrics or statistics. The most common are gauges, counters,
    and timers/summaries. More specialized meters include long task timers, time gauges,
    and interval counters. Strive to use the most specialized meter available for
    the task. Timers, for example, always emit a count to measure throughput. There
    is little advantage to counting executions of a particular block of code, when
    timing it would have generated the same count statistic but also richer information
    about the latency distribution of that block of code.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 许多度量收集器提供几类计量器，每种计量器可能会发出一个或多个度量或统计数据。最常见的是规模、计数器和计时器/摘要。更专业的计量器包括长任务计时器、时间规模和间隔计数器。努力使用最适合任务的最专业的计量器。例如，计时器总是发出一个计数以衡量吞吐量。对于计数特定代码块的执行次数而言，测量其时间会生成相同的计数统计信息，但还会提供关于该代码块延迟分布更丰富的信息，这几乎没有任何优势。
- en: A decision guide for which built-in meter type to choose follows the introduction
    of each type in [“Choosing the Right Meter Type”](part0007_split_011.html#choosing_meter_type).
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 在每种类型的介绍后，选择内置计量器类型的决策指南如 [“选择正确的计量器类型”](part0007_split_011.html#choosing_meter_type)
    所述。
- en: Gauges
  id: totrans-153
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 规模
- en: Gauges are a measure of an instantaneous value that may increase and decrease
    over time. A time series plot of a gauge is a collection of samples of instantaneous
    values at intervals where metrics were published from the application. Because
    they are sampled instantaneous values, it is possible and even likely that the
    value would have been higher or lower if it had been sampled at a different point
    in time.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 规模是随时间增加和减少的瞬时值的测量。规模的时间序列图是在应用程序发布度量时瞬时值的样本集合。由于它们是采样的瞬时值，因此可能甚至很可能在不同时间点进行采样时，值会更高或更低。
- en: The speedometer and fuel level on a vehicle are classic examples of gauges.
    As you drive along the road, you periodically glance at the speedometer (hopefully).
    Seeing a periodic instantaneous measurement of your speed is enough to keep speed
    under control, but it is still true that you miss the variations in speed that
    occurred between looks.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 车辆上的速度表和油量表是规模的经典示例。当您沿着道路行驶时，您会定期瞥一眼速度表（希望如此）。周期性地看到您的速度的瞬时测量足以控制速度，但仍然是真实的，您错过了在看的时候发生的速度变化。
- en: In applications, typical examples for gauges would be the size of a collection
    or map or the number of threads in a running state. Memory and CPU measurements
    are also taken using gauges. [Figure 2-3](part0006_split_012.html#jvm_memory_used)
    is a gauge time series of a single metric, `jvm.memory.used`, that is tagged with
    several dimensions, including the memory space. This stack chart shows one way
    in which making a single concept like memory consumption dimensional provides
    richness to its representation in a chart.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 在应用程序中，规模的典型示例可以是集合或映射的大小，或者是运行状态下的线程数。内存和CPU的测量也使用规模。[图 2-3](part0006_split_012.html#jvm_memory_used)
    展示了单个指标 `jvm.memory.used` 的规模时间序列，该指标标记了几个维度，包括内存空间。这个堆叠图表展示了将内存消耗这样的单一概念维度化如何丰富其在图表中的表示。
- en: '![An image of JVM heap usage, one meter with several tags represented in a
    stack chart](../images/00017.png)'
  id: totrans-157
  prefs: []
  type: TYPE_IMG
  zh: '![JVM堆使用情况图像，一个具有多个标签的计量器在堆叠图表中表示](../images/00017.png)'
- en: Figure 2-3\. Heap used by space
  id: totrans-158
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 2-3\. 堆内存使用情况
- en: Micrometer takes the stance that gauges should be sampled and not be set, so
    there is no information about what might have occurred between samples. After
    all, any intermediate values set on a gauge are lost by the time the gauge value
    is reported to a metrics backend anyway, so there seems to be little value in
    setting those intermediate values in the first place.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: Micrometer 认为规模应该被采样，而不是被设置，因此没有关于在采样之间可能发生的情况的信息。毕竟，任何在规模值报告给度量后端之前设置的中间值都会丢失，因此似乎在第一次设置这些中间值时几乎没有任何价值。
- en: Think of a gauge as a meter that only changes when it is observed. Every other
    class of meter accumulates intermediate counts toward the point where the data
    is sent to the metrics backend.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 将规模视为仅在观察时才会更改的计量器。其他所有类型的计量器都会累积中间计数，直到将数据发送到度量后端为止。
- en: The `MeterRegistry` interface contains methods, some of which are shown in [Example 2-12](part0006_split_012.html#gauge_create),
    for building gauges to observe numeric values, functions, collections, and maps.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: '`MeterRegistry` 接口包含方法，其中一些显示在 [示例 2-12](part0006_split_012.html#gauge_create)
    中，用于构建观察数值、函数、集合和映射的规模。'
- en: Example 2-12\. Creating gauges
  id: totrans-162
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: Example 2-12\. 创建规模
- en: '[PRE14]'
  id: totrans-163
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: In the first case, a slightly more common form of gauge is one that monitors
    some nonnumeric object. The last argument establishes the function that is used
    to determine the value of the gauge when the gauge is observed. Micrometer provides
    convenience methods for monitoring map and collection size, since these are such
    common cases.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 在第一种情况下，稍微常见的规模形式是监视某些非数值对象的规模。最后一个参数确定观察规模时用于确定规模值的函数。Micrometer提供了便利方法来监视映射和集合的大小，因为这些情况非常常见。
- en: Most forms of creating a gauge maintain only a *weak reference* to the object
    being observed, so as not to prevent garbage collection of the object. It is your
    responsibility to hold a strong reference to the state object that you are measuring
    with a gauge. Micrometer is careful to not create strong references to objects
    that would otherwise be garbage collected. Once the object being gauged is de-referenced
    and is garbage collected, Micrometer will start reporting a NaN or nothing for
    a gauge, depending on the registry implementation.
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数形式的规模创建仅保持对被观察对象的*弱引用*，以免阻止对象的垃圾回收。您有责任保持对状态对象的强引用，该对象由规模测量。Micrometer谨慎地不会创建对本应被垃圾回收的对象的强引用。一旦被测量的对象取消引用并被垃圾回收，Micrometer将开始报告一个NaN或空值，具体取决于注册表的实现。
- en: Generally the returned `Gauge` instance is not useful except in testing, as
    the gauge is already set up to track a value automatically upon registration.
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 通常返回的`Gauge`实例除了在测试中不实用外，在注册时已设置好以自动跟踪值。
- en: In addition to the shortcut methods for creating a gauge directly from a `MeterRegistry`,
    Micrometer provides a gauge fluent builder (see [Example 2-13](part0006_split_012.html#gauge_fluent_builder))
    as well, which has more options. Notice the `strongReference` option, which does
    prevent garbage collection of the monitored object, contrary to the default behavior.
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 使用直接从`MeterRegistry`创建规模的快捷方法之外，Micrometer还提供了一个规模流畅构建器（参见[Example 2-13](part0006_split_012.html#gauge_fluent_builder)），它具有更多选项。注意`strongReference`选项，它与默认行为相反，防止监视对象被垃圾回收。
- en: Example 2-13\. Fluent builder for gauges
  id: totrans-168
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: Example 2-13\. 规模的流畅构建器
- en: '[PRE15]'
  id: totrans-169
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: Micrometer has built-in metrics that include several gauges. Some examples are
    given in [Table 2-5](part0006_split_012.html#gauge_examples).
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: Micrometer具有包括几个规模在内的内置度量标准。一些示例列在[Table 2-5](part0006_split_012.html#gauge_examples)中。
- en: Table 2-5\. Examples of gauges in Micrometer built-in instrumentation
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 表 2-5\. Micrometer内置仪表规的示例
- en: '| Metric name | Description |'
  id: totrans-172
  prefs: []
  type: TYPE_TB
  zh: '| 指标名称 | 描述 |'
- en: '| --- | --- |'
  id: totrans-173
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| jvm.threads.live | The current number of live threads, including both daemon
    and nondaemon threads |'
  id: totrans-174
  prefs: []
  type: TYPE_TB
  zh: '| jvm.threads.live | 当前活动线程数，包括守护线程和非守护线程 |'
- en: '| jvm.memory.used | The amount of used memory in bytes |'
  id: totrans-175
  prefs: []
  type: TYPE_TB
  zh: '| jvm.memory.used | 使用的内存量（以字节为单位） |'
- en: '| db.table.size | The total number of rows in a database table |'
  id: totrans-176
  prefs: []
  type: TYPE_TB
  zh: '| db.table.size | 数据库表中行数的总数 |'
- en: '| jetty.requests.active | Number of requests currently active |'
  id: totrans-177
  prefs: []
  type: TYPE_TB
  zh: '| jetty.requests.active | 当前活动请求数 |'
- en: A special kind of `Gauge` called a `TimeGauge` is specifically used for gauging
    values that are measuring time (see [Table 2-6](part0006_split_012.html#time_gauge_examples)).
    Like a `Gauge`, there is no need to set a `TimeGauge`, since its value changes
    when observed. The only difference between them is that the value of a `TimeGauge`
    will be scaled to the monitoring system’s base unit of time as it is published.
    In other cases, follow the general rule that values should be measured in whatever
    the natural base unit is (e.g., bytes for storage, connections for connection
    pool utilization). Monitoring systems only differ in their expectation of what
    the base unit is when describing time.
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 特殊类型的`Gauge`称为`TimeGauge`，专门用于测量时间值（参见[Table 2-6](part0006_split_012.html#time_gauge_examples)）。像`Gauge`一样，不需要设置`TimeGauge`，因为其值在观察时会改变。它们之间唯一的区别在于，`TimeGauge`的值将按监视系统的基本时间单位进行缩放，并在发布时显示。在其他情况下，请遵循值应该以自然的基本单位来测量的一般规则（例如，存储的字节，连接池利用率的连接）。监控系统只在描述时间的基本单位时有所不同的期望。
- en: Table 2-6\. Examples of time gauges in Micrometer built-in instrumentation
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 表 2-6\. Micrometer内置仪表中时间规模的示例
- en: '| Metric name | Description |'
  id: totrans-180
  prefs: []
  type: TYPE_TB
  zh: '| 指标名称 | 描述 |'
- en: '| --- | --- |'
  id: totrans-181
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| process.uptime | The uptime of the Java virtual machine, as reported by Java’s
    Runtime MXBean |'
  id: totrans-182
  prefs: []
  type: TYPE_TB
  zh: '| process.uptime | Java虚拟机的正常运行时间，由Java的Runtime MXBean报告 |'
- en: '| kafka.consumer.fetch.latency.avg | The average time taken for a group sync,
    as calculated and reported by the Kafka Java client |'
  id: totrans-183
  prefs: []
  type: TYPE_TB
  zh: '| kafka.consumer.fetch.latency.avg | 由 Kafka Java 客户端计算和报告的组同步平均时间 |'
- en: Kafka consumer fetch latency average is an example of where sometimes Java client
    libraries only provide coarse statistics like average where, if we could affect
    the Kafka client code directly, a timer would have been more suitable. In addition
    to seeing the average, we’d have information about decaying max latency, percentiles,
    etc.
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: Kafka 消费者获取延迟平均值是一个例子，有时 Java 客户端库只提供粗略的统计数据，比如平均值，如果我们可以直接影响 Kafka 客户端代码，那么计时器可能更合适。除了查看平均值外，我们还可以得到有关衰减最大延迟、百分位等的信息。
- en: One last special type of `Gauge` is a `MultiGauge`, which helps manage the gauging
    of a growing or shrinking list of criteria. Often this feature is used when we
    want to select a well-bounded but slightly changing set of criteria from something
    like a SQL query and report some metric for each row as a `Gauge`. It doesn’t
    have to be data fetched from a database, of course. The gauge could be built off
    a map-like structure in memory, or any other structure with rows containing a
    number of columns with at least one numeric column to use for the gauge value.
    [Example 2-14](part0006_split_012.html#multi_gauge) shows how a `MultiGauge` is
    created.
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 最后一种特殊类型的 `Gauge` 是 `MultiGauge`，用于管理增长或缩减的一组标准的测量。通常在我们想要从像 SQL 查询之类的东西中选择一组受界限但略有变化的标准时，会使用此功能，并为每行报告某些指标作为
    `Gauge`。当然，不一定要从数据库获取数据。该测量器可以构建在内存中类似于映射的结构上，或任何其他行数包含至少一个数值列的结构上。[Example 2-14](part0006_split_012.html#multi_gauge)
    展示了如何创建 `MultiGauge`。
- en: Example 2-14\. Creating a multi-gauge
  id: totrans-186
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: Example 2-14\. 创建多测量器
- en: '[PRE16]'
  id: totrans-187
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: Before trying to build a gauge to report a rate at which something in your application
    is happening, consider a counter, which is better suited for this purpose.
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 在尝试构建报告应用程序中某个事件发生速率的测量器之前，请考虑使用计数器，这更适合此目的。
- en: Should I Use a Gauge or a Counter?
  id: totrans-189
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 应该使用计数器还是测量器？
- en: Never gauge something you can count.
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 永远不要对可以计数的事物进行测量。
- en: Counters
  id: totrans-191
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 计数器
- en: Counters report a single metric, a count. The `Counter` interface allows you
    to increment by a fixed amount, which must be positive.
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 计数器报告单个指标，即计数。`Counter`接口允许您按固定数量增加，此数量必须为正数。
- en: It is possible, though rare, to increment a counter by a fractional amount.
    For example, you could be counting sums of a base unit like dollars, which naturally
    have fractional amounts (although it would probably be more useful to count sales
    with a different meter type, as shown in [“Distribution Summaries”](part0007_split_009.html#distribution_summaries)).
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 可能，尽管罕见，可以通过分数增加计数器。例如，您可以计算像美元这样的基本单位的总和，这些自然有分数金额（尽管将销售计数为另一种计量类型可能更有用，如 [“分布摘要”](part0007_split_009.html#distribution_summaries)
    所示）。
- en: The `MeterRegistry` interface contains convenience methods for creating counters,
    as shown in [Example 2-15](part0006_split_014.html#counter_create).
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: '`MeterRegistry` 接口包含便利方法，用于创建计数器，如 [Example 2-15](part0006_split_014.html#counter_create)
    中所示。'
- en: Example 2-15\. Creating counters
  id: totrans-195
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: Example 2-15\. 创建计数器
- en: '[PRE17]'
  id: totrans-196
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: '[![1](../images/00112.png)](part0006_split_014.html#co_application_metrics_CO3-1)'
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: '[![1](../images/00112.png)](part0006_split_014.html#co_application_metrics_CO3-1)'
- en: This is not specific to counters—there are similar APIs we will see on other
    meter types.
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 这并非专属于计数器 —— 在其他计量类型上我们将看到类似的 API。
- en: The `Counter` fluent builder, as seen in [Example 2-16](part0006_split_014.html#counter_fluent_builder),
    contains more options.
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: '`Counter` 流畅构建器，如 [Example 2-16](part0006_split_014.html#counter_fluent_builder)
    所示，包含更多选项。'
- en: Example 2-16\. Fluent builder for counters
  id: totrans-200
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: Example 2-16\. 计数器的流畅构建器
- en: '[PRE18]'
  id: totrans-201
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: Micrometer has built-in metrics that include several counters. Some examples
    are given in [Table 2-7](part0006_split_014.html#counter_examples).
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: Micrometer 包含多个内置指标，其中包括多个计数器。一些示例见 [Table 2-7](part0006_split_014.html#counter_examples)。
- en: Table 2-7\. Examples of counters in Micrometer built-in instrumentation
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 表格 2-7\. Micrometer 内置仪表中计数器的示例
- en: '| Metric name | Description |'
  id: totrans-204
  prefs: []
  type: TYPE_TB
  zh: '| 指标名称 | 描述 |'
- en: '| --- | --- |'
  id: totrans-205
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| jetty.async.requests | Total number of async requests |'
  id: totrans-206
  prefs: []
  type: TYPE_TB
  zh: '| jetty.async.requests | 异步请求总数 |'
- en: '| postgres.transactions | Total number of transactions executed (commits +
    rollbacks) |'
  id: totrans-207
  prefs: []
  type: TYPE_TB
  zh: '| postgres.transactions | 执行的事务总数（提交 + 回滚） |'
- en: '| jvm.classes.loaded | The number of classes that are currently loaded in the
    Java virtual machine |'
  id: totrans-208
  prefs: []
  type: TYPE_TB
  zh: '| jvm.classes.loaded | 当前加载到 Java 虚拟机中的类数 |'
- en: '| jvm.gc.memory.promoted | Count of positive increases in the size of the old
    generation memory pool before GC to after GC |'
  id: totrans-209
  prefs: []
  type: TYPE_TB
  zh: '| jvm.gc.memory.promoted | 老年代内存池在 GC 前后正增长大小的计数 |'
- en: When building graphs and alerts off of counters, generally you should be most
    interested in measuring the rate at which some event is occurring over a given
    time interval. Consider a simple queue. Counters could be used to measure things
    like the rate at which items are being inserted and removed.
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 在构建图表和警报时，通常应该最关注某个事件在给定时间间隔内发生的速率。考虑一个简单的队列。计数器可用于测量诸如插入和删除项目的速率。
- en: When a Counter Measures Occurrences, It Measures Throughput
  id: totrans-211
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 当计数器测量事件发生时，它测量的是吞吐量。
- en: When we talk about the rate of occurrences of things happening, conceptually
    we are talking about *throughput*. When displaying counters as a rate on a chart,
    we are displaying a measure of throughput, the rapidity with which this counter
    is being incremented. When you have the opportunity to instrument an operation
    with metrics for each individual occurrence, you should almost always use timers
    (see [“Timers”](part0006_split_017.html#5N4J5-2d714b853a094e9a910510217e0e3d73))
    instead, which provide a measure of throughput in addition to other useful statistics.
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们谈论事件发生率时，概念上我们在谈论*吞吐量*。在图表上显示计数器作为速率时，我们显示的是吞吐量的度量，即增加计数器的快速程度。当您有机会为每个单独事件操作添加指标时，几乎总是应该使用计时器（参见[“计时器”](part0006_split_017.html#5N4J5-2d714b853a094e9a910510217e0e3d73)），它们不仅提供吞吐量的度量，还提供其他有用的统计信息。
- en: You might want at first to conceive of visualizing absolute counts rather than
    a rate, but the absolute count is usually both a function of the rapidity with
    which something is used and the longevity of the application instance under instrumentation.
    Building dashboards and alerts of the rate of a counter per some interval of time
    disregards the longevity of the app, letting you see aberrant behavior long after
    the application has started.
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 起初，您可能希望构想可视化绝对计数而不是速率，但绝对计数通常是某些东西使用的快速程度和应用程序实例在仪表化下的寿命的函数。构建仪表板和警报以某个时间间隔内的计数器速率来忽略应用程序的寿命，使您能够在应用程序启动后长时间查看异常行为。
- en: In many cases, when we’ve dug into why engineers attempt to visualize absolute
    counts, it is to show some true business-related number (number of sales, revenue,
    etc.). Remember that metrics instrumentation is optimized for signaling availability,
    so its implementation is naturally going to trade off durability for instrumentation
    performance. Any given metrics publishing interval can fail due to things like
    (physical or virtual) machine failure or network issues between the application
    and the metrics backend, and it won’t be retried because the assumption is you’ll
    just catch up on the next interval. Even with cumulative counters, if the final
    value before shutdown doesn’t make it to the backend, it is lost. Mission-critical
    counts, such as those required for legal reporting, should use some other durable
    storage instead of being shipped as a metric (or maybe *in addition* to being
    shipped as a metric).
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 在许多情况下，当我们深入探讨工程师试图可视化绝对计数时，这是为了展示某些真实的与业务相关的数字（销售数量，收入等）。请记住，指标仪表化是为了信号可用性而优化的，因此其实现自然会在持久性和性能之间进行权衡。任何给定的指标发布间隔都可能因为诸如（物理或虚拟）机器故障或应用程序与指标后端之间的网络问题而失败，并且不会重试，因为假设是您会在下一个间隔上追赶。即使是累积计数器，如果关闭前的最终值未能传送到后端，它也会丢失。对于像法定报告所需的关键计数，应该使用其他耐久性存储而不是仅仅作为指标发布（或者也可以*额外*作为指标发布）。
- en: For some monitoring systems, like Atlas, counters are published as a rate from
    Micrometer. Querying for and plotting a counter in Atlas, as seen in [Example 2-17](part0006_split_015.html#atlas_counter_rate),
    displays a chart whose *y*-axis is a rate.
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 对于某些监控系统，例如 Atlas，计数器以 Micrometer 的速率发布。在 Atlas 中查询并绘制计数器，如[示例 2-17](part0006_split_015.html#atlas_counter_rate)所示，显示的图表其*y*轴是速率。
- en: Example 2-17\. Atlas counter rate
  id: totrans-216
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 2-17\. Atlas 计数器速率
- en: '[PRE19]'
  id: totrans-217
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: Still, some monitoring systems expect counters to be published as a cumulative
    statistic. It is only at query time that the counter is converted to a rate for
    display, as in [Example 2-18](part0006_split_015.html#prometheus_counter_rate).
    In this case, we have to use the specific `rate` function to convert the cumulative
    statistic into a rate. In almost every monitoring scenario, you’ll use this `rate`
    function when accessing counters.
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，一些监控系统期望计数器以累积统计数据的形式发布。只有在查询时，计数器才会转换为速率以供显示，例如 [Example 2-18](part0006_split_015.html#prometheus_counter_rate)。在这种情况下，我们需要使用特定的
    `rate` 函数将累积统计转换为速率。在几乎所有监控场景中，访问计数器时都会使用这个 `rate` 函数。
- en: Example 2-18\. Prometheus counter rate
  id: totrans-219
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 2-18\. Prometheus 计数器速率
- en: '[PRE20]'
  id: totrans-220
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: It is tempting to count something like errors emitted from a particular method,
    or the total number of successful invocations of a method, but it is even better
    to record these events with a timer, because they include a count and other useful
    information about the latency of the operation.
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 很容易统计从特定方法发出的错误数量，或者方法的成功调用总数，但最好还是用计时器记录这些事件，因为它们包括计数和关于操作延迟的其他有用信息。
- en: Should I Use a Counter or a Timer (or a Distribution Summary)?
  id: totrans-222
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 我应该使用计数器、计时器（或分布摘要）吗？
- en: 'Never count something you can time. And if the base unit is not a unit of time,
    then the corollary is, awkwardly: never count something you can record with a
    distribution summary.'
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: 永远不要统计可以计时的事物。如果基本单位不是时间单位，那么推论是，尴尬地说：永远不要统计可以用分布摘要记录的事物。
- en: Timers
  id: totrans-224
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 计时器
- en: 'Timers are for measuring short-duration latencies and the frequency of such
    events. All implementations of `Timer` report at least a few individual statistics:'
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: 计时器用于测量短时延迟和这类事件的频率。所有 `Timer` 的实现至少报告几个单独的统计数据：
- en: Count
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 计数
- en: A measure of the number of individual recordings of this timer. For a `Timer`
    measuring an API endpoint, this count is the number of requests to the API. Count
    is a measure of throughput.
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: 衡量此计时器的个别记录数量。对于测量 API 端点的 `Timer`，此计数是发送到 API 的请求次数。计数是吞吐量的度量。
- en: Sum
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: 总和
- en: The sum of the time it took to satisfy all requests. So if there are three requests
    to an API endpoint that took 5 ms, 10 ms, and 15 ms, then the sum is <math alttext="5
    plus 10 plus 15 equals 30 m s"><mrow><mn>5</mn> <mo>+</mo> <mn>10</mn> <mo>+</mo>
    <mn>15</mn> <mo>=</mo> <mn>30</mn> <mi>m</mi> <mi>s</mi></mrow></math> . The sum
    may be shipped literally as 30 ms, or as a rate, depending on the monitoring system.
    We’ll discuss shortly how to interpret this.
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: 满足所有请求所花费的时间总和。因此，如果有三个请求发送到一个API端点，分别耗时 5 毫秒、10 毫秒和 15 毫秒，那么总和为 <math alttext="5
    plus 10 plus 15 equals 30 m s"><mrow><mn>5</mn> <mo>+</mo> <mn>10</mn> <mo>+</mo>
    <mn>15</mn> <mo>=</mo> <mn>30</mn> <mi>m</mi> <mi>s</mi></mrow></math> 。这个总和可能直接展示为
    30 毫秒，或者根据监控系统的设置以速率的形式展示。我们将很快讨论如何解释这一点。
- en: Maximum
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: 最大值
- en: The individual timing that took the longest, but decaying over an interval.
    Micrometer maintains a series of overlapping intervals in a ring buffer and keeps
    track of maximum in each of these intervals. The maximum value is then a little
    sticky in a sense. The important thing to keep in mind is that this isn’t a maximum
    of all samples seen from the beginning of the app (this wouldn’t be very useful),
    but the maximum value seen “recently.” It is possible to configure the recency
    to make this value decay faster or slower.
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: 单个计时器中最长的计时，但是在一定时间间隔内衰减。Micrometer 在一个环形缓冲区中维护一系列重叠的时间间隔，并在每个时间间隔内跟踪最大值。这个最大值在某种意义上是有些粘性的。需要牢记的重要一点是，这不是从应用程序启动以来看到的所有样本的最大值（这并不是非常有用），而是最近看到的最大值。可以配置最近性来使这个值的衰减速度更快或更慢。
- en: 'In addition, timers can *optionally* ship other statistics:'
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，计时器还可以选择性地输出其他统计数据：
- en: Service level objective (SLO) boundaries
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: 服务水平目标（SLO）边界
- en: The count (i.e., total number) of requests observed that are less than or equal
    to a particular boundary value—for example, how many requests to an API endpoint
    took less than 100 ms. Since this is a count, it can be divided by the overall
    count to arrive at an idea of what percentage of requests met your service level
    objective, and is very cheap to calculate provided you know in advance what objectives
    you want to set.
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: 观察到小于或等于特定边界值的请求总数。例如，到 API 端点的请求中有多少请求花费时间少于 100 毫秒。由于这是一个计数，可以通过总体计数来计算达到服务水平目标的百分比，而且计算起来非常便宜，只要预先知道你想要设置的目标。
- en: Percentiles
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: 百分位数
- en: Precomputed percentiles which cannot be combined with percentiles from other
    tags (e.g., percentiles for several instances in a cluster cannot be combined).
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: 预计算的百分位数无法与其他标签的百分位数结合使用（例如，集群中几个实例的百分位数无法结合）。
- en: Histograms
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: 直方图
- en: Similar to SLO boundaries, histograms are comprised of a series of counts for
    a set of buckets. Histograms can be summed together across dimensions (e.g., sum
    the counts for like buckets across a series of instances) and be used to create
    percentile approximations by some monitoring systems. We’ll discuss histograms
    in more detail in [“Histograms”](part0007_split_007.html#6LKA8-2d714b853a094e9a910510217e0e3d73).
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: 类似于 SLO 边界，直方图由一系列存储桶的计数组成。直方图可以跨维度求和（例如，跨多个实例对相似存储桶的计数求和），并且可以通过某些监控系统创建百分位数近似值。我们将在
    [“直方图”](part0007_split_007.html#6LKA8-2d714b853a094e9a910510217e0e3d73) 中详细讨论直方图。
- en: Let’s go through a couple of examples of how these statistics might be used
    and the relationship between them.
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们通过几个例子来看看这些统计数据可能如何使用及其之间的关系。
- en: “Count” Means “Throughput”
  id: totrans-240
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: “Count” 意味着 “吞吐量”
- en: The count statistic of a timer is individually useful. It is a measure of *throughput*,
    the rate at which the timed operation is happening. When timing an API endpoint,
    it’s the number of requests to that endpoint. When measuring messages on a queue,
    it’s the number of messages being placed on the queue.
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: 计时器的计数统计量是单独有用的。它是*吞吐量*的衡量标准，即定时操作发生的速率。在计时 API 端点时，它是对该端点的请求次数。在衡量队列上的消息时，它是放入队列的消息数量。
- en: The count statistic should be used exactly as described in [“Counters”](part0006_split_014.html#5N4C9-2d714b853a094e9a910510217e0e3d73),
    as a rate. Depending on the monitoring system. this statistic will be either a
    cumulative count or a rate when shipped from Micrometer.
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: 计数统计应完全按照 [“计数器”](part0006_split_014.html#5N4C9-2d714b853a094e9a910510217e0e3d73)
    中描述的方式使用，作为速率。根据监控系统的不同，这个统计量将作为累积计数或从 Micrometer 发送时的速率。
- en: “Count” and “Sum” Together Mean “Aggregable Average”
  id: totrans-243
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: “Count” 和 “Sum” 一起意味着 “可聚合平均”
- en: With the one exception we’ll discuss shortly, sum is not really meaningful on
    its own. Without being considered in relation to the rate at which operations
    are occurring, a sum has no purpose. A sum of 1 second may be bad for an individual
    request to a user-facing API endpoint, but 1,000 requests of 1 ms each yielding
    a sum of 1 second sounds quite good!
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: 除了我们马上要讨论的一个例外，总和本身并不真正有意义。如果不考虑操作发生的速率，总和就没有任何意义。对于一个面向用户的 API 端点的单个请求的 1 秒总和可能不好，但是
    1,000 个每个 1 毫秒的请求，总和为 1 秒听起来相当不错！
- en: Sum and count together can be used to create an *aggregable* average. If we
    instead published the average of a timer directly, it couldn’t be combined with
    the average data from other dimensions (such as other instances) to reason about
    the overall average.
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: 总和和计数可以一起用来创建*可聚合*平均值。如果我们直接发布计时器的平均值，它就不能与其他维度的平均数据（例如其他实例）结合起来推断整体平均值。
- en: Consider the scenario described in [Figure 2-4](part0006_split_019.html#timer_sum_count),
    where a load balancer has distributed seven requests to four application instances.
    Three of these application instances are in Region 1 and, one instance is in Region
    2.
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑 [图 2-4](part0006_split_019.html#timer_sum_count) 中描述的场景，负载均衡器已将七个请求分发给四个应用程序实例。其中三个应用程序实例位于
    Region 1，一个实例位于 Region 2。
- en: '![srej 0204](../images/00120.png)'
  id: totrans-247
  prefs: []
  type: TYPE_IMG
  zh: '![srej 0204](../images/00120.png)'
- en: Figure 2-4\. Timings for requests going to a hypothetical application
  id: totrans-248
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图2-4\. 发送到假设应用程序的请求时间
- en: 'Suppose we’ve tagged the timer metrics for each of these instances with the
    instance ID and region. The monitoring system then sees time series for timers
    with four different combinations of tags:'
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们已为每个实例的计时器指标打了标签，包括实例 ID 和区域。然后监控系统将看到带有四种不同标签组合的计时器时间序列：
- en: Instance=1, Region=1
  id: totrans-250
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Instance=1, Region=1
- en: Instance=2, Region=1
  id: totrans-251
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Instance=2, Region=1
- en: Instance=3, Region=1
  id: totrans-252
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Instance=3, Region=1
- en: Instance=4, Region=2
  id: totrans-253
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Instance=4, Region=2
- en: There will be time series for count and sum for each of these timers. In [Table 2-8](part0006_split_019.html#timer_sum_count_table),
    after these seven requests have occurred, a cumulative monitoring system will
    have values for sum and count for their corresponding tags. Also included is the
    average for that instance individually.
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: 每个计时器的计数和总和将有时间序列。在 [表 2-8](part0006_split_019.html#timer_sum_count_table) 中，这七个请求发生后，累积监控系统将具有相应标签的总和和计数的值。同时还包括该实例的平均值。
- en: Table 2-8\. Cumulative sum and count for each timer
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: 表2-8\. 每个计时器的累积和与计数
- en: '| Instance | Region | Count (operations) | Sum (seconds) | Average (seconds/operation)
    |'
  id: totrans-256
  prefs: []
  type: TYPE_TB
  zh: '| 实例 | 区域 | 计数（操作） | 总计（秒） | 平均（秒/操作） |'
- en: '| --- | --- | --- | --- | --- |'
  id: totrans-257
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- |'
- en: '| 1 | 1 | 2 | 0.022 | 0.011 |'
  id: totrans-258
  prefs: []
  type: TYPE_TB
  zh: '| 1 | 1 | 2 | 0.022 | 0.011 |'
- en: '| 2 | 1 | 2 | 0.018 | 0.009 |'
  id: totrans-259
  prefs: []
  type: TYPE_TB
  zh: '| 2 | 1 | 2 | 0.018 | 0.009 |'
- en: '| 3 | 1 | 2 | 0.020 | 0.010 |'
  id: totrans-260
  prefs: []
  type: TYPE_TB
  zh: '| 3 | 1 | 2 | 0.020 | 0.010 |'
- en: '| 4 | 2 | 1 | 0.100 | 0.100 |'
  id: totrans-261
  prefs: []
  type: TYPE_TB
  zh: '| 4 | 2 | 1 | 0.100 | 0.100 |'
- en: To find the average latency for this timer across all instances in both regions
    of this application, we add the sums and divide that by the sum of the counts
    (see [Equation 2-1](part0006_split_019.html#computing_aggregable_average)).
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: 要找出此应用程序的所有实例和区域中此计时器的平均延迟，我们将总和除以计数的总和（参见[方程 2-1](part0006_split_019.html#computing_aggregable_average)）。
- en: Equation 2-1\. Computing the cluster average
  id: totrans-263
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 方程 2-1\. 计算集群平均
- en: <math alttext="StartFraction 0.022 plus 0.018 plus 0.020 plus 0.100 Over 2 plus
    2 plus 2 plus 1 EndFraction equals 0.017 s e c o n d s slash o p equals 17 m i
    l l i s e c o n d s slash o p" display="block"><mrow><mfrac><mrow><mn>0</mn><mo>.</mo><mn>022</mn><mo>+</mo><mn>0</mn><mo>.</mo><mn>018</mn><mo>+</mo><mn>0</mn><mo>.</mo><mn>020</mn><mo>+</mo><mn>0</mn><mo>.</mo><mn>100</mn></mrow>
    <mrow><mn>2</mn><mo>+</mo><mn>2</mn><mo>+</mo><mn>2</mn><mo>+</mo><mn>1</mn></mrow></mfrac>
    <mo>=</mo> <mn>0</mn> <mo>.</mo> <mn>017</mn> <mi>s</mi> <mi>e</mi> <mi>c</mi>
    <mi>o</mi> <mi>n</mi> <mi>d</mi> <mi>s</mi> <mo>/</mo> <mi>o</mi> <mi>p</mi> <mo>=</mo>
    <mn>17</mn> <mi>m</mi> <mi>i</mi> <mi>l</mi> <mi>l</mi> <mi>i</mi> <mi>s</mi>
    <mi>e</mi> <mi>c</mi> <mi>o</mi> <mi>n</mi> <mi>d</mi> <mi>s</mi> <mo>/</mo> <mi>o</mi>
    <mi>p</mi></mrow></math>
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
  zh: <math alttext="StartFraction 0.022 plus 0.018 plus 0.020 plus 0.100 Over 2 plus
    2 plus 2 plus 1 EndFraction equals 0.017 s e c o n d s slash o p equals 17 m i
    l l i s e c o n d s slash o p" display="block"><mrow><mfrac><mrow><mn>0</mn><mo>.</mo><mn>022</mn><mo>+</mo><mn>0</mn><mo>.</mo><mn>018</mn><mo>+</mo><mn>0</mn><mo>.</mo><mn>020</mn><mo>+</mo><mn>0</mn><mo>.</mo><mn>100</mn></mrow>
    <mrow><mn>2</mn><mo>+</mo><mn>2</mn><mo>+</mo><mn>2</mn><mo>+</mo><mn>1</mn></mrow></mfrac>
    <mo>=</mo> <mn>0</mn> <mo>.</mo> <mn>017</mn> <mi>s</mi> <mi>e</mi> <mi>c</mi>
    <mi>o</mi> <mi>n</mi> <mi>d</mi> <mi>s</mi> <mo>/</mo> <mi>o</mi> <mi>p</mi> <mo>=</mo>
    <mn>17</mn> <mi>m</mi> <mi>i</mi> <mi>l</mi> <mi>l</mi> <mi>i</mi> <mi>s</mi>
    <mi>e</mi> <mi>c</mi> <mi>o</mi> <mi>n</mi> <mi>d</mi> <mi>s</mi> <mo>/</mo> <mi>o</mi>
    <mi>p</mi></mrow></math>
- en: If instead Micrometer only shipped averages from each instance, we wouldn’t
    have an easy way of calculating this same value. Averaging the averages, as shown
    in [Equation 2-2](part0006_split_019.html#average_of_averages), is not correct.
    The “average” here is too high. Several more requests went to Region 1 than Region
    2, and Region 1 was serving responses much more quickly.
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
  zh: 如果 Micrometer 只从每个实例发送平均值，我们将无法轻松计算相同的值。像[方程 2-2](part0006_split_019.html#average_of_averages)
    中显示的对平均值的平均化是不正确的。这里的“平均值”太高了。与区域 2 相比，区域 1 的请求要多得多，并且区域 1 提供的响应速度要快得多。
- en: Equation 2-2\. An INCORRECT calculation of cluster average
  id: totrans-266
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 方程 2-2\. 集群平均值的不正确计算
- en: <math alttext="StartFraction 0.011 plus 0.009 plus 0.010 plus 0.100 Over 4 i
    n s t a n c e s EndFraction equals 0.032 s e c o n d s slash r e q u e s t equals
    32 m i l l i s e c o n d s slash r e q u e s t" display="block"><mrow><mfrac><mrow><mn>0</mn><mo>.</mo><mn>011</mn><mo>+</mo><mn>0</mn><mo>.</mo><mn>009</mn><mo>+</mo><mn>0</mn><mo>.</mo><mn>010</mn><mo>+</mo><mn>0</mn><mo>.</mo><mn>100</mn></mrow>
    <mrow><mn>4</mn><mi>i</mi><mi>n</mi><mi>s</mi><mi>t</mi><mi>a</mi><mi>n</mi><mi>c</mi><mi>e</mi><mi>s</mi></mrow></mfrac>
    <mo>=</mo> <mn>0</mn> <mo>.</mo> <mn>032</mn> <mi>s</mi> <mi>e</mi> <mi>c</mi>
    <mi>o</mi> <mi>n</mi> <mi>d</mi> <mi>s</mi> <mo>/</mo> <mi>r</mi> <mi>e</mi> <mi>q</mi>
    <mi>u</mi> <mi>e</mi> <mi>s</mi> <mi>t</mi> <mo>=</mo> <mn>32</mn> <mi>m</mi>
    <mi>i</mi> <mi>l</mi> <mi>l</mi> <mi>i</mi> <mi>s</mi> <mi>e</mi> <mi>c</mi> <mi>o</mi>
    <mi>n</mi> <mi>d</mi> <mi>s</mi> <mo>/</mo> <mi>r</mi> <mi>e</mi> <mi>q</mi> <mi>u</mi>
    <mi>e</mi> <mi>s</mi> <mi>t</mi></mrow></math>
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
  zh: <math alttext="StartFraction 0.011 plus 0.009 plus 0.010 plus 0.100 Over 4 i
    n s t a n c e s EndFraction equals 0.032 s e c o n d s slash r e q u e s t equals
    32 m i l l i s e c o n d s slash r e q u e s t" display="block"><mrow><mfrac><mrow><mn>0</mn><mo>.</mo><mn>011</mn><mo>+</mo><mn>0</mn><mo>.</mo><mn>009</mn><mo>+</mo><mn>0</mn><mo>.</mo><mn>010</mn><mo>+</mo><mn>0</mn><mo>.</mo><mn>100</mn></mrow>
    <mrow><mn>4</mn><mi>i</mi><mi>n</mi><mi>s</mi><mi>t</mi><mi>a</mi><mi>n</mi><mi>c</mi><mi>e</mi><mi>s</mi></mrow></mfrac>
    <mo>=</mo> <mn>0</mn> <mo>.</mo> <mn>032</mn> <mi>s</mi> <mi>e</mi> <mi>c</mi>
    <mi>o</mi> <mi>n</mi> <mi>d</mi> <mi>s</mi> <mo>/</mo> <mi>r</mi> <mi>e</mi> <mi>q</mi>
    <mi>u</mi> <mi>e</mi> <mi>s</mi> <mi>t</mi> <mo>=</mo> <mn>32</mn> <mi>m</mi>
    <mi>i</mi> <mi>l</mi> <mi>l</mi> <mi>i</mi> <mi>s</mi> <mi>e</mi> <mi>c</mi> <mi>o</mi>
    <mi>n</mi> <mi>d</mi> <mi>s</mi> <mo>/</mo> <mi>r</mi> <mi>e</mi> <mi>q</mi> <mi>u</mi>
    <mi>e</mi> <mi>s</mi> <mi>t</mi></mrow></math>
- en: The demonstration for how average is calculated across the cluster here assumes
    that Micrometer was shipping a cumulative value for sum and count. How does it
    work out if Micrometer was shipping a rate instead? [Table 2-9](part0006_split_019.html#timer_sum_count_table_rate)
    shows rate-normalized values such as those that would be shipped to Atlas. For
    the sake of this table, assume that the seven requests shown in [Figure 2-4](part0006_split_019.html#timer_sum_count)
    happened over a one-minute interval and that this interval is aligned with the
    interval in which we push metrics to Atlas.
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
  zh: 这里展示的集群平均值演示假设 Micrometer 以累计值形式传输 sum 和 count。如果 Micrometer 改为传输速率会怎样？[表 2-9](part0006_split_019.html#timer_sum_count_table_rate)
    展示了标准化为速率的值，例如传输到 Atlas 的值。在本表中，假设在一分钟内发生的七个请求与 [图 2-4](part0006_split_019.html#timer_sum_count)
    中显示的间隔对齐，并且此间隔与我们推送指标到 Atlas 的间隔一致。
- en: Table 2-9\. Rate-normalized sum and count for each timer
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: 表 2-9\. 每个计时器的速率标准化的总和和计数
- en: '| Instance | Region | Count (requests/second) | Sum (unitless) | Average (seconds/request)
    |'
  id: totrans-270
  prefs: []
  type: TYPE_TB
  zh: '| 实例 | 区域 | 计数（请求/秒） | 总计（无单位） | 平均（秒/请求） |'
- en: '| --- | --- | --- | --- | --- |'
  id: totrans-271
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- |'
- en: '| 1 | 1 | 0.033 | 0.00037 | 0.011 |'
  id: totrans-272
  prefs: []
  type: TYPE_TB
  zh: '| 1 | 1 | 0.033 | 0.00037 | 0.011 |'
- en: '| 2 | 1 | 0.033 | 0.00030 | 0.009 |'
  id: totrans-273
  prefs: []
  type: TYPE_TB
  zh: '| 2 | 1 | 0.033 | 0.00030 | 0.009 |'
- en: '| 3 | 1 | 0.033 | 0.00033 | 0.010 |'
  id: totrans-274
  prefs: []
  type: TYPE_TB
  zh: '| 3 | 1 | 0.033 | 0.00033 | 0.010 |'
- en: '| 4 | 2 | 0.017 | 0.00167 | 0.100 |'
  id: totrans-275
  prefs: []
  type: TYPE_TB
  zh: '| 4 | 2 | 0.017 | 0.00167 | 0.100 |'
- en: The count column now has a unit of “requests/second” rather than just “requests.”
    It will be requests/second no matter what the publishing interval is. In this
    case, we’re publishing every minute; so since we saw two requests to Instance
    1, we conclude that the requests/second rate of requests to this instance is [Equation
    2-3](part0006_split_019.html#rate_avg_instance1).
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
  zh: 现在的计数列单位是“每秒请求数”而不仅仅是“请求”。无论发布间隔是什么，都将是每秒请求数。在本例中，我们每分钟发布一次；因此，由于我们看到向 Instance
    1 的两个请求，我们得出结论：向该实例的请求/秒速率是[方程 2-3](part0006_split_019.html#rate_avg_instance1)。
- en: Equation 2-3\. The rate of throughput to Instance 1
  id: totrans-277
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 方程 2-3\. 向实例 1 的吞吐量速率
- en: <math alttext="2 r e q u e s t s slash m i n u t e equals 2 r e q u e s t s
    slash 60 s e c o n d s equals 0.033 r e q u e s t s slash s e c o n d" display="block"><mrow><mn>2</mn>
    <mi>r</mi> <mi>e</mi> <mi>q</mi> <mi>u</mi> <mi>e</mi> <mi>s</mi> <mi>t</mi> <mi>s</mi>
    <mo>/</mo> <mi>m</mi> <mi>i</mi> <mi>n</mi> <mi>u</mi> <mi>t</mi> <mi>e</mi> <mo>=</mo>
    <mn>2</mn> <mi>r</mi> <mi>e</mi> <mi>q</mi> <mi>u</mi> <mi>e</mi> <mi>s</mi> <mi>t</mi>
    <mi>s</mi> <mo>/</mo> <mn>60</mn> <mi>s</mi> <mi>e</mi> <mi>c</mi> <mi>o</mi>
    <mi>n</mi> <mi>d</mi> <mi>s</mi> <mo>=</mo> <mn>0</mn> <mo>.</mo> <mn>033</mn>
    <mi>r</mi> <mi>e</mi> <mi>q</mi> <mi>u</mi> <mi>e</mi> <mi>s</mi> <mi>t</mi> <mi>s</mi>
    <mo>/</mo> <mi>s</mi> <mi>e</mi> <mi>c</mi> <mi>o</mi> <mi>n</mi> <mi>d</mi></mrow></math>
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
  zh: <math alttext="2 r e q u e s t s slash m i n u t e equals 2 r e q u e s t s
    slash 60 s e c o n d s equals 0.033 r e q u e s t s slash s e c o n d" display="block"><mrow><mn>2</mn>
    <mi>r</mi> <mi>e</mi> <mi>q</mi> <mi>u</mi> <mi>e</mi> <mi>s</mi> <mi>t</mi> <mi>s</mi>
    <mo>/</mo> <mi>m</mi> <mi>i</mi> <mi>n</mi> <mi>u</mi> <mi>t</mi> <mi>e</mi> <mo>=</mo>
    <mn>2</mn> <mi>r</mi> <mi>e</mi> <mi>q</mi> <mi>u</mi> <mi>e</mi> <mi>s</mi> <mi>t</mi>
    <mi>s</mi> <mo>/</mo> <mn>60</mn> <mi>s</mi> <mi>e</mi> <mi>c</mi> <mi>o</mi>
    <mi>n</mi> <mi>d</mi> <mi>s</mi> <mo>=</mo> <mn>0</mn> <mo>.</mo> <mn>033</mn>
    <mi>r</mi> <mi>e</mi> <mi>q</mi> <mi>u</mi> <mi>e</mi> <mi>s</mi> <mi>t</mi> <mi>s</mi>
    <mo>/</mo> <mi>s</mi> <mi>e</mi> <mi>c</mi> <mi>o</mi> <mi>n</mi> <mi>d</mi></mrow></math>
- en: The sum column now is unitless rather than being in seconds. It’s unitless because
    the numerator of the rate is seconds as well as the denominator, and these units
    cancel out. So for Instance 1, the sum is [Equation 2-4](part0006_split_019.html#rate_sum_instance1).
    This unitless nature of sum in a rate-normalized system serves to underscore its
    meaninglessness independent of being combined with count (or some other dimensioned
    value).
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
  zh: 现在的总计列是无单位的，而不再是秒。这是因为速率的分子和分母都是秒，这些单位会相互抵消。因此，对于实例 1，总计是[方程 2-4](part0006_split_019.html#rate_sum_instance1)。在速率标准化系统中，总计的无单位性质强调了其无意义性，独立于与计数（或其他有尺寸的值）的组合。
- en: Equation 2-4\. The rate-normalized sum of Instance 1
  id: totrans-280
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 方程 2-4\. 实例 1 的速率标准化总和
- en: <math alttext="22 m i l l i s e c o n d s slash m i n u t e equals 0.022 s e
    c o n d s slash 60 s e c o n d s equals 0.00037" display="block"><mrow><mn>22</mn>
    <mi>m</mi> <mi>i</mi> <mi>l</mi> <mi>l</mi> <mi>i</mi> <mi>s</mi> <mi>e</mi> <mi>c</mi>
    <mi>o</mi> <mi>n</mi> <mi>d</mi> <mi>s</mi> <mo>/</mo> <mi>m</mi> <mi>i</mi> <mi>n</mi>
    <mi>u</mi> <mi>t</mi> <mi>e</mi> <mo>=</mo> <mn>0</mn> <mo>.</mo> <mn>022</mn>
    <mi>s</mi> <mi>e</mi> <mi>c</mi> <mi>o</mi> <mi>n</mi> <mi>d</mi> <mi>s</mi> <mo>/</mo>
    <mn>60</mn> <mi>s</mi> <mi>e</mi> <mi>c</mi> <mi>o</mi> <mi>n</mi> <mi>d</mi>
    <mi>s</mi> <mo>=</mo> <mn>0</mn> <mo>.</mo> <mn>00037</mn></mrow></math>
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
  zh: <math alttext="22 m i l l i s e c o n d s slash m i n u t e equals 0.022 s e
    c o n d s slash 60 s e c o n d s equals 0.00037" display="block"><mrow><mn>22</mn>
    <mi>m</mi> <mi>i</mi> <mi>l</mi> <mi>l</mi> <mi>i</mi> <mi>s</mi> <mi>e</mi> <mi>c</mi>
    <mi>o</mi> <mi>n</mi> <mi>d</mi> <mi>s</mi> <mo>/</mo> <mi>m</mi> <mi>i</mi> <mi>n</mi>
    <mi>u</mi> <mi>t</mi> <mi>e</mi> <mo>=</mo> <mn>0</mn> <mo>.</mo> <mn>022</mn>
    <mi>s</mi> <mi>e</mi> <mi>c</mi> <mi>o</mi> <mi>n</mi> <mi>d</mi> <mi>s</mi> <mo>/</mo>
    <mn>60</mn> <mi>s</mi> <mi>e</mi> <mi>c</mi> <mi>o</mi> <mi>n</mi> <mi>d</mi>
    <mi>s</mi> <mo>=</mo> <mn>0</mn> <mo>.</mo> <mn>00037</mn></mrow></math>
- en: The average per instance is the same as in the cumulative table because of the
    effect of the units canceling out.
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
  zh: 由于单位的抵消作用，每个实例的平均值与累计表中的平均值相同。
- en: For the purpose of average, it doesn’t matter what the interval is. If the interval
    were two minutes rather than one minute, our idea of throughput changes (i.e.,
    it’s exactly half), but the extra minute cancels out in the average calculation.
    In the case of Instance 1, the count in requests/seconds is [Equation 2-5](part0006_split_019.html#rate_avg_instance1_2min_1).
  id: totrans-283
  prefs: []
  type: TYPE_NORMAL
  zh: 对于平均值而言，间隔是什么并不重要。如果间隔是两分钟而不是一分钟，我们对吞吐量的理解会发生变化（即，它正好减半），但额外的一分钟在平均计算中会被抵消。在
    Instance 1 的情况下，请求/秒的计数是 [Equation 2-5](part0006_split_019.html#rate_avg_instance1_2min_1)。
- en: Equation 2-5\. The rate of throughput to Instance 1 over a two-minute interval
  id: totrans-284
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: Equation 2-5\. Instance 1 在两分钟间隔内的吞吐率
- en: <math alttext="2 r e q u e s t s slash 2 m i n u t e s equals 2 r e q u e s
    t s slash 120 s e c o n d s equals 0.01667 r e q u e s t s slash s e c o n d"
    display="block"><mrow><mn>2</mn> <mi>r</mi> <mi>e</mi> <mi>q</mi> <mi>u</mi> <mi>e</mi>
    <mi>s</mi> <mi>t</mi> <mi>s</mi> <mo>/</mo> <mn>2</mn> <mi>m</mi> <mi>i</mi> <mi>n</mi>
    <mi>u</mi> <mi>t</mi> <mi>e</mi> <mi>s</mi> <mo>=</mo> <mn>2</mn> <mi>r</mi> <mi>e</mi>
    <mi>q</mi> <mi>u</mi> <mi>e</mi> <mi>s</mi> <mi>t</mi> <mi>s</mi> <mo>/</mo> <mn>120</mn>
    <mi>s</mi> <mi>e</mi> <mi>c</mi> <mi>o</mi> <mi>n</mi> <mi>d</mi> <mi>s</mi> <mo>=</mo>
    <mn>0</mn> <mo>.</mo> <mn>01667</mn> <mi>r</mi> <mi>e</mi> <mi>q</mi> <mi>u</mi>
    <mi>e</mi> <mi>s</mi> <mi>t</mi> <mi>s</mi> <mo>/</mo> <mi>s</mi> <mi>e</mi> <mi>c</mi>
    <mi>o</mi> <mi>n</mi> <mi>d</mi></mrow></math>
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
  zh: <math alttext="2 r e q u e s t s slash 2 m i n u t e s equals 2 r e q u e s
    t s slash 120 s e c o n d s equals 0.01667 r e q u e s t s slash s e c o n d"
    display="block"><mrow><mn>2</mn> <mi>r</mi> <mi>e</mi> <mi>q</mi> <mi>u</mi> <mi>e</mi>
    <mi>s</mi> <mi>t</mi> <mi>s</mi> <mo>/</mo> <mn>2</mn> <mi>m</mi> <mi>i</mi> <mi>n</mi>
    <mi>u</mi> <mi>t</mi> <mi>e</mi> <mi>s</mi> <mo>=</mo> <mn>2</mn> <mi>r</mi> <mi>e</mi>
    <mi>q</mi> <mi>u</mi> <mi>e</mi> <mi>s</mi> <mi>t</mi> <mi>s</mi> <mo>/</mo> <mn>120</mn>
    <mi>s</mi> <mi>e</mi> <mi>c</mi> <mi>o</mi> <mi>n</mi> <mi>d</mi> <mi>s</mi> <mo>=</mo>
    <mn>0</mn> <mo>.</mo> <mn>01667</mn> <mi>r</mi> <mi>e</mi> <mi>q</mi> <mi>u</mi>
    <mi>e</mi> <mi>s</mi> <mi>t</mi> <mi>s</mi> <mo>/</mo> <mi>s</mi> <mi>e</mi> <mi>c</mi>
    <mi>o</mi> <mi>n</mi> <mi>d</mi></mrow></math>
- en: The sum is [Equation 2-6](part0006_split_019.html#rate_avg_instance1_2min_2).
    But when we divide these, the average is still the same. In this division, you
    can essentially factor out the *2* from both numerator and denominator.
  id: totrans-286
  prefs: []
  type: TYPE_NORMAL
  zh: 总和是 [Equation 2-6](part0006_split_019.html#rate_avg_instance1_2min_2)。但是当我们进行除法时，平均值仍然相同。在这个除法中，你可以从分子和分母中本质上因子出
    *2*。
- en: Equation 2-6\. The rate-normalized sum of Instance 1 over a two-minute interval
  id: totrans-287
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: Equation 2-6\. Instance 1 在两分钟间隔内的率标准化总和
- en: <math alttext="22 m i l l i s e c o n d s slash 2 m i n u t e s equals 0.022
    s e c o n d s slash 120 s e c o n d s equals 0.00018" display="block"><mrow><mn>22</mn>
    <mi>m</mi> <mi>i</mi> <mi>l</mi> <mi>l</mi> <mi>i</mi> <mi>s</mi> <mi>e</mi> <mi>c</mi>
    <mi>o</mi> <mi>n</mi> <mi>d</mi> <mi>s</mi> <mo>/</mo> <mn>2</mn> <mi>m</mi> <mi>i</mi>
    <mi>n</mi> <mi>u</mi> <mi>t</mi> <mi>e</mi> <mi>s</mi> <mo>=</mo> <mn>0</mn> <mo>.</mo>
    <mn>022</mn> <mi>s</mi> <mi>e</mi> <mi>c</mi> <mi>o</mi> <mi>n</mi> <mi>d</mi>
    <mi>s</mi> <mo>/</mo> <mn>120</mn> <mi>s</mi> <mi>e</mi> <mi>c</mi> <mi>o</mi>
    <mi>n</mi> <mi>d</mi> <mi>s</mi> <mo>=</mo> <mn>0</mn> <mo>.</mo> <mn>00018</mn></mrow></math>
  id: totrans-288
  prefs: []
  type: TYPE_NORMAL
  zh: <math alttext="22 m i l l i s e c o n d s slash 2 m i n u t e s equals 0.022
    s e c o n d s slash 120 s e c o n d s equals 0.00018" display="block"><mrow><mn>22</mn>
    <mi>m</mi> <mi>i</mi> <mi>l</mi> <mi>l</mi> <mi>i</mi> <mi>s</mi> <mi>e</mi> <mi>c</mi>
    <mi>o</mi> <mi>n</mi> <mi>d</mi> <mi>s</mi> <mo>/</mo> <mn>2</mn> <mi>m</mi> <mi>i</mi>
    <mi>n</mi> <mi>u</mi> <mi>t</mi> <mi>e</mi> <mi>s</mi> <mo>=</mo> <mn>0</mn> <mo>.</mo>
    <mn>022</mn> <mi>s</mi> <mi>e</mi> <mi>c</mi> <mi>o</mi> <mi>n</mi> <mi>d</mi>
    <mi>s</mi> <mo>/</mo> <mn>120</mn> <mi>s</mi> <mi>e</mi> <mi>c</mi> <mi>o</mi>
    <mi>n</mi> <mi>d</mi> <mi>s</mi> <mo>=</mo> <mn>0</mn> <mo>.</mo> <mn>00018</mn></mrow></math>
- en: Average is not ideal for monitoring availability. In general, you are better
    off accepting a slightly worse average and better worst-case (e.g., greater than
    99th percentile) performance since the worst case tends to happen much more frequently
    than our intuition leads us to believe. Still, the combination of sum divided
    by count is easy to compute and possible on almost all monitoring systems, even
    those without more sophisticated math operations. So average is at least some
    baseline to have across a range of wildly different monitoring systems. If at
    all possible, don’t use average at all.
  id: totrans-289
  prefs: []
  type: TYPE_NORMAL
  zh: 平均值对于监控可用性来说并不理想。一般而言，接受略差一些的平均值，而更好的最坏情况（例如，大于第99百分位数的性能）会更好，因为最坏情况通常发生的频率远远超过我们的直觉。尽管如此，通过总和除以计数来计算是简单的，并且几乎所有监控系统都可以实现，即使是没有更复杂数学运算的系统也能如此。因此，平均值至少是跨一系列截然不同的监控系统中的某种基线。如果可能的话，最好根本不要使用平均值。
- en: 'Average: a random number that falls somewhere between the maximum and 1/2 the
    median. Most often used to ignore reality.'
  id: totrans-290
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 平均值：一个随机数，落在最大值和中位数的1/2之间。最常用于忽略现实。
- en: ''
  id: totrans-291
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Gil Tene
  id: totrans-292
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: Gil Tene
- en: Instead, for availability it is more useful to look at maximum or a high-percentile
    statistic, as we’ll see in detail in [“Timers”](part0009_split_009.html#8ILKM-2d714b853a094e9a910510217e0e3d73).
  id: totrans-293
  prefs: []
  type: TYPE_NORMAL
  zh: 相反，对于可用性，查看最大值或高百分位数的统计数据更为有用，如我们将在 [“Timers”](part0009_split_009.html#8ILKM-2d714b853a094e9a910510217e0e3d73)
    中详细讨论的那样。
- en: Maximum Is a Decaying Signal That Isn’t Aligned to the Push Interval
  id: totrans-294
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 最大值是一个衰减信号，不与推送间隔对齐
- en: Micrometer decays the maximum rather than aligning it to the publishing interval
    like it does for sum and count. If we perfectly aligned the view of maximum time
    to the push interval, then a dropped metrics payload means we potentially miss
    out on seeing a particularly high maximum value (because in the next interval
    we’d only consider samples that occurred in that interval).
  id: totrans-295
  prefs: []
  type: TYPE_NORMAL
  zh: Micrometer 将最大值衰减而不是将其与发布间隔对齐，就像它对总和和计数所做的那样。如果我们完美地将最大时间的视图与推送间隔对齐，那么丢失的度量负载意味着我们可能错过看到特别高的最大值（因为在下一个间隔中，我们只会考虑发生在那个间隔内的样本）。
- en: For other statistics like count, missing a publishing interval is generally
    not problematic, because the counter continues to accumulate during a period where
    a metrics payload is dropped, and the next successful payload will surface it.
  id: totrans-296
  prefs: []
  type: TYPE_NORMAL
  zh: 对于像计数这样的其他统计数据，错过发布间隔通常不会有问题，因为在度量负载被丢弃的期间，计数器仍然会累积，并且下一个成功的负载将显示它。
- en: Practically, there are many reasons why a high maximum latency and a dropped
    metrics payload would be correlated. For example, if the application is under
    heavy resource pressure (like a saturated network interface), a response to the
    user for an API endpoint that is being timed (and for which a maximum value is
    being tracked) may be exceedingly high at the same time that a metrics post request
    to the monitoring system fails with a read timeout. But such conditions can be
    (and many times are) temporary.
  id: totrans-297
  prefs: []
  type: TYPE_NORMAL
  zh: 实际上，有很多原因可以解释为何高最大延迟和丢失的度量负载会相关联。例如，如果应用程序受到严重资源压力的影响（比如饱和的网络接口），在同一时间，对于正在计时的
    API 端点的用户响应（并且正在跟踪最大值）可能非常高，同时监控系统的度量值发送请求由于读取超时而失败。但这样的条件可能是（而且经常是）暂时的。
- en: Perhaps you have a client-side load-balancing strategy that recognizes that
    (from the client’s perspective) API latency has gone up sharply for this instance
    that is under resource pressure and begins preferring other instances. By relieving
    pressure on this instance it recovers.
  id: totrans-298
  prefs: []
  type: TYPE_NORMAL
  zh: 也许您有一个客户端负载均衡策略，该策略意识到（从客户端的角度）API 的延迟在承受资源压力的实例中急剧上升，并开始优先考虑其他实例。通过减轻该实例的压力，它得以恢复。
- en: In some subsequent interval, after the instance has recovered, it’s nice to
    be able to push a maximum latency seen during this time of trouble that would
    otherwise have been skipped. In fact, it’s precisely these times of duress that
    we care about the most, not the maximum latency under fair-weather conditions!
  id: totrans-299
  prefs: []
  type: TYPE_NORMAL
  zh: 在随后的某个时间段，实例恢复之后，能够推送在这段困难时期中看到的最大延迟是很好的，否则这些延迟会被跳过。事实上，正是这些困难时期我们最关心的，而不是在晴天条件下的最大延迟！
- en: The effect of this decaying though is that a maximum value will “linger” for
    a period of time after it actually occurred. In [Figure 2-5](part0006_split_020.html#max_decays),
    we see a maximum value of approximately 30 ms for a timed operation. This 30 ms
    operation occurred sometime in the metrics publishing interval immediately before
    when the line first spikes up from 0 (around 19:15).
  id: totrans-300
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然这种衰减的效应是最大值会在实际发生之后的一段时间内“持续存在”。在 [图 2-5](part0006_split_020.html#max_decays)
    中，我们可以看到定时操作的最大值约为 30 毫秒。这个 30 毫秒的操作发生在度量发布间隔之前的某个时刻，当线条从 0（大约在 19:15）首次上升时。
- en: '![srej 0205](../images/00039.png)'
  id: totrans-301
  prefs: []
  type: TYPE_IMG
  zh: '![srej 0205](../images/00039.png)'
- en: Figure 2-5\. The decaying maximum lingers on a chart for some time
  id: totrans-302
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 2-5\. 衰减的最大值在图表上持续存在一段时间
- en: This timer was configured to decay maximum values over a period of two minutes.
    So it lingers until about 19:17\. Since this timer didn’t see any operations after
    this initial interval in which the 30 ms timing was seen, the time series disappears
    after the maximum value decays.
  id: totrans-303
  prefs: []
  type: TYPE_NORMAL
  zh: 这个定时器被配置为在两分钟内衰减最大值。因此，它会持续到大约 19:17。由于这个定时器在看到 30 毫秒的时间后没有看到任何操作，最大值衰减后时间序列消失。
- en: Micrometer keeps track of maximums in a [ring buffer](https://oreil.ly/sHbIN)
    to achieve this decaying behavior. The ring buffer has configuration options `distributionStatisticsBufferLength`
    and `distributionStatisticExpiry` on `Timer.Builder` that you can use to decay
    for longer, as shown in [Example 2-20](part0006_split_024.html#timer_fluent_builder).
    By default, Micrometer builds timers with a ring buffer of length 3, and the pointer
    will be advanced every 2 minutes.
  id: totrans-304
  prefs: []
  type: TYPE_NORMAL
  zh: Micrometer 通过在 [环形缓冲区](https://oreil.ly/sHbIN) 中跟踪最大值来实现这种衰减行为。环形缓冲区在 `Timer.Builder`
    上有 `distributionStatisticsBufferLength` 和 `distributionStatisticExpiry` 的配置选项，您可以使用它们来进行更长时间的衰减，就像
    [示例 2-20](part0006_split_024.html#timer_fluent_builder) 中所示的那样。默认情况下，Micrometer
    使用长度为 3 的环形缓冲区构建定时器，并且指针将每 2 分钟前进一次。
- en: '[Figure 2-6](part0006_split_020.html#ring_buffer) is an illustration of a ring
    buffer of three elements. This ring buffer is just an array with a pointer to
    a particular element from which the maximum value will be polled whenever we publish
    metrics. Every `distributionStatisticExpiry`, the pointer is advanced to the next
    element in the ring buffer. The zeroth index element in this buffer has no samples
    in it. The first and second indexed elements are storing the state of the largest
    sample they have seen since their last reset, 10 ms. The darkened ring around
    the first index indicates that this index is the element that is currently being
    polled from.'
  id: totrans-305
  prefs: []
  type: TYPE_NORMAL
  zh: '[图 2-6](part0006_split_020.html#ring_buffer) 是一个包含三个元素的环形缓冲区的示意图。这个环形缓冲区只是一个带有指向特定元素的指针的数组，在我们发布指标时将从中轮询最大值。每经过
    `distributionStatisticExpiry`，指针就会前进到环形缓冲区中的下一个元素。在这个缓冲区中，索引为零的元素没有样本。第一个和第二个索引元素存储着它们自上次重置以来看到的最大样本的状态，为
    10 毫秒。第一个索引周围的阴影环表示正在从中轮询的元素。'
- en: '![srej 0206](../images/00004.png)'
  id: totrans-306
  prefs: []
  type: TYPE_IMG
  zh: '![srej 0206](../images/00004.png)'
- en: Figure 2-6\. A ring buffer of three elements
  id: totrans-307
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 2-6\. 一个包含三个元素的环形缓冲区
- en: '[Figure 2-7](part0006_split_020.html#ring_buffer_of_maxes) shows a timer ring
    buffer with three elements and a two-minute expiry as it evolves over an eight-minute
    period of time. Below the figure is a minute-by-minute description of how the
    values are changing where `t` is the wall time in minutes.'
  id: totrans-308
  prefs: []
  type: TYPE_NORMAL
  zh: '[图 2-7](part0006_split_020.html#ring_buffer_of_maxes) 展示了一个包含三个元素和两分钟过期时间的定时器环形缓冲区，在八分钟的时间段内发生变化。图下方是关于值如何变化的每分钟描述，其中
    `t` 是分钟数。'
- en: '![srej 0207](../images/00033.png)'
  id: totrans-309
  prefs: []
  type: TYPE_IMG
  zh: '![srej 0207](../images/00033.png)'
- en: Figure 2-7\. A timer max ring buffer of length 3 and two-minute expiry
  id: totrans-310
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 2-7\. 长度为 3 的定时器最大环形缓冲区
- en: t=0
  id: totrans-311
  prefs: []
  type: TYPE_NORMAL
  zh: t=0
- en: 'This is the initial state. Each ring buffer element is empty. No timer recordings
    have been observed. Between t=0 and t=1, two timer recordings are observed: one
    at 10 ms and one at 8 ms.'
  id: totrans-312
  prefs: []
  type: TYPE_NORMAL
  zh: 这   这是初始状态。每个环形缓冲区元素都为空。没有观察到计时器记录。在 t=0 和 t=1 之间，观察到两个计时器记录：一个在 10 毫秒，另一个在
    8 毫秒。
- en: t=1
  id: totrans-313
  prefs: []
  type: TYPE_NORMAL
  zh: t=1
- en: Since 10 ms is the greater of the two recordings seen and every ring buffer
    element was previously empty, all of them now are tracking 10 ms as the maximum.
    If we were to publish metrics at t=1, the max would be 10 ms. Between t=1 and
    t=2 we observe a 7 ms timing, but it is not greater than the samples in any of
    the ring buffer elements.
  id: totrans-314
  prefs: []
  type: TYPE_NORMAL
  zh: 由于看到的两个记录中 10 毫秒是较大的，并且每个环形缓冲区元素之前都为空，现在所有元素都在跟踪 10 毫秒作为最大值。如果我们在 t=1 时发布度量，最大值将为
    10 毫秒。在 t=1 和 t=2 之间，我们观察到了 7 毫秒的计时，但它没有超过任何环形缓冲区元素中的样本。
- en: t=2
  id: totrans-315
  prefs: []
  type: TYPE_NORMAL
  zh: t=2
- en: The zeroth ring buffer element is reset because the expiry has been reached
    and the pointer is moved to index 1\. Between t=2 and t=3 we see a timer recording
    of 6 ms. Since the zeroth element has been cleared, it now is tracking 6 ms as
    its view of the max. The polled max is 10 ms.
  id: totrans-316
  prefs: []
  type: TYPE_NORMAL
  zh: 第零个环形缓冲区元素被重置，因为已达到到期时间，并且指针移动到索引 1。在 t=2 和 t=3 之间，我们看到了一个 6 毫秒的计时记录。由于第零个元素已经被清除，它现在跟踪
    6 毫秒作为其最大值。轮询最大值为 10 毫秒。
- en: t=3
  id: totrans-317
  prefs: []
  type: TYPE_NORMAL
  zh: t=3
- en: The oldest two ring buffer elements are still seeing 10 ms as the max, and the
    zeroth element is tracking 6 ms. The polled max is still 10 ms since the pointer
    is on index 1.
  id: totrans-318
  prefs: []
  type: TYPE_NORMAL
  zh: 最旧的两个环形缓冲区元素仍然将 10 毫秒作为最大值，而第零个元素跟踪 6 毫秒。轮询最大值仍然为 10 毫秒，因为指针在索引 1 上。
- en: t=4
  id: totrans-319
  prefs: []
  type: TYPE_NORMAL
  zh: t=4
- en: Index 1 is reset and the pointer is advanced to index 2\. Index 2 is still tracking
    10 ms, so the polled max is 10 ms.
  id: totrans-320
  prefs: []
  type: TYPE_NORMAL
  zh: 索引 1 被重置，并且指针被移到索引 2。索引 2 仍然跟踪 10 毫秒，因此轮询最大值为 10 毫秒。
- en: t=5
  id: totrans-321
  prefs: []
  type: TYPE_NORMAL
  zh: t=5
- en: Nothing changes. The polled max is 10 ms. Note that the timer would have reported
    a count and sum of 0 at this time and a max of 10 ms! This is what is meant by
    max not being aligned to the publishing interval in the same way that count and
    sum are.
  id: totrans-322
  prefs: []
  type: TYPE_NORMAL
  zh: 没有任何变化。轮询最大值为 10 毫秒。请注意，在此时计时器将报告计数和总和为 0，最大为 10 毫秒！这就是所谓的最大值不像计数和总和那样与发布间隔对齐的含义。
- en: t=6
  id: totrans-323
  prefs: []
  type: TYPE_NORMAL
  zh: t=6
- en: Index 2 is reset and the pointer circles back to index 0, which is still hanging
    on to the 6 ms sample it observed between t=2 and t=3 as the max. The polled max
    is 6 ms. Between t=6 and t=7, a 12 ms sample is observed, which becomes the max
    across the ring buffer.
  id: totrans-324
  prefs: []
  type: TYPE_NORMAL
  zh: 索引 2 被重置，指针循环回到索引 0，它仍然将其在 t=2 和 t=3 之间观察到的 6 毫秒样本作为最大值。轮询最大值为 6 毫秒。在 t=6 和
    t=7 之间，观察到了一个 12 毫秒的样本，它成为环形缓冲区中的最大值。
- en: t=7
  id: totrans-325
  prefs: []
  type: TYPE_NORMAL
  zh: t=7
- en: The polled max is 12 ms, observed shortly before t=7.
  id: totrans-326
  prefs: []
  type: TYPE_NORMAL
  zh: 轮询最大值为 12 毫秒，观察到的时间在 t=7 之前不久。
- en: t=8
  id: totrans-327
  prefs: []
  type: TYPE_NORMAL
  zh: t=8
- en: The zeroth ring buffer element is reset and the pointer moves to index 1\. The
    polled max is 12 ms.
  id: totrans-328
  prefs: []
  type: TYPE_NORMAL
  zh: 第零个环形缓冲区元素被重置，并且指针移动到索引 1。
- en: The Sum of Sum Over an Interval
  id: totrans-329
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 在时间间隔内总和的总和
- en: There are few cases where the sum of sums is useful. In fact, I’ve only ever
    encountered one case of it, which we’ll see later in [“Proportion of time spent
    in garbage collection”](part0009_split_018.html#8IN04-2d714b853a094e9a910510217e0e3d73),
    where the sum of time spent in garbage collection (GC) is divided by the total
    amount of time in the interval in which garbage collection was happening (e.g.,
    how much time was spent in GC altogether). Even in this case, we probably could
    develop a better alert signal for garbage collection if the JVM provided us with
    discrete timings for every garbage collection event as it occurred. If it did,
    we might look at high-percentile GC times or max GC time by cause.
  id: totrans-330
  prefs: []
  type: TYPE_NORMAL
  zh: 没有几种情况下总和的总和是有用的。事实上，我只遇到过一种情况，在 [“垃圾收集占用时间的比例”](part0009_split_018.html#8IN04-2d714b853a094e9a910510217e0e3d73)
    中我们稍后将会看到，其中垃圾收集（GC）花费的时间总和被分为正在进行垃圾收集的时间间隔的总时间（例如，总共花了多少时间在 GC 中）。即使在这种情况下，如果
    JVM 在每次垃圾收集事件发生时为我们提供离散的时间，我们可能也可以开发出更好的垃圾收集警报信号。如果是这样，我们可能会查看高百分位数的 GC 时间或按原因查看最大
    GC 时间。
- en: The Base Unit of Time
  id: totrans-331
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 时间的基本单位
- en: The appropriate base unit for timers varies by monitoring system. For example,
    Prometheus expects floating point second-precision data because conceptually seconds
    are a base unit of time. Atlas expects nanosecond-precision data because it can
    then accept and store integral values. Since it isn’t possible to measure a subdivision
    of a nanosecond (and in many cases it isn’t even possible to measure in true nanosecond
    precision), the backend takes advantage of this optimization. Regardless, Micrometer
    automatically scales timings to the expected base unit for each monitoring system.
  id: totrans-332
  prefs: []
  type: TYPE_NORMAL
  zh: 计时器的适当基本单位因监控系统而异。例如，Prometheus 期望浮点秒精度数据，因为从概念上讲，秒是时间的基本单位。Atlas 期望纳秒精度数据，因为它可以接受并存储整数值。由于无法测量纳秒的一个子分区（在许多情况下甚至无法真正实现纳秒精度），后端利用此优化。无论如何，Micrometer
    会自动将定时器按照每个监控系统预期的基本单位进行缩放。
- en: Neither one of these base units is right or wrong, and neither less precise.
    It is simply a matter of convention in each. The base unit of time doesn’t affect
    the *precision* of charts. Even though Micrometer ships times in seconds to Prometheus,
    for example, the chart will often still be displayed, like in [Figure 2-8](part0006_split_022.html#timer_base_unit_of_time_scaling),
    in milliseconds for common timers like those used to monitor user-facing API endpoints.
  id: totrans-333
  prefs: []
  type: TYPE_NORMAL
  zh: 这些基本单位都没有对错之分，也没有更少精确的说法。这只是每个约定的问题。时间的基本单位不影响图表的*精度*。例如，尽管 Micrometer 将时间以秒为单位发送到
    Prometheus，但例如用于监视用户界面 API 端点的常见计时器，图表通常仍会以毫秒显示，如[图 2-8](part0006_split_022.html#timer_base_unit_of_time_scaling)。
- en: '![srej 0208](../images/00113.png)'
  id: totrans-334
  prefs: []
  type: TYPE_IMG
  zh: '![srej 0208](../images/00113.png)'
- en: Figure 2-8\. A timer shipped with *seconds* base units displayed in milliseconds
  id: totrans-335
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 2-8\. 一个计时器，以*秒*为基本单位显示为毫秒
- en: We’ll cover charting more in [Chapter 4](part0009_split_000.html#8IL24-2d714b853a094e9a910510217e0e3d73),
    but for now, just know that scaling in this way is often accomplished automatically
    by the charting interface. We just need to tell it how to interpret the statistic,
    i.e., to say that the time series being displayed is dimensioned in seconds, as
    in [Figure 2-9](part0006_split_022.html#grafana_yaxis_seconds).
  id: totrans-336
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在[第四章](part0009_split_000.html#8IL24-2d714b853a094e9a910510217e0e3d73)中更详细地讨论图表，但现在只需知道，这种方式的缩放通常由图表界面自动完成。我们只需要告诉它如何解释统计数据，即告诉它显示的时间序列是以秒为单位的，如[图
    2-9](part0006_split_022.html#grafana_yaxis_seconds)。
- en: '![srej 0209](../images/00008.png)'
  id: totrans-337
  prefs: []
  type: TYPE_IMG
  zh: '![srej 0209](../images/00008.png)'
- en: Figure 2-9\. Informing the charting library how to interpret timer base units
  id: totrans-338
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 2-9\. 告知图表库如何解释计时器基本单位
- en: In this case, Grafana is smart enough to know that it is easier for humans to
    read in milliseconds than small fractions of a second, so it scales the seconds
    data down to milliseconds. Similarly, if it is canonical to represent timings
    in nanoseconds to a particular monitoring system, the charting library would perform
    the opposite math to scale the values up to milliseconds.
  id: totrans-339
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，Grafana 聪明地知道人们更容易读取毫秒而不是秒的小分数，因此它将秒数据缩小到毫秒。类似地，如果在特定监控系统中以纳秒表示时间是规范的，图表库将执行相反的数学操作将值放大到毫秒。
- en: Common Base Units Don’t Limit How You View the Data
  id: totrans-340
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 常见基本单位不限制您查看数据的方式
- en: For common units like time and data size (e.g., bytes), you shouldn’t need to
    concern yourself with how you intend to *view* the data to decide what scale you
    *record* at. It’s generally preferable to be consistent with your base units everywhere
    and allow the charting library later to do this sort of automatic scaling to a
    human-readable format. Rather than recording the payload size of a response body
    in bytes (because it will generally be small) and the size of the heap in megabytes
    (because it will generally be large), record both in bytes. They will both be
    scaled to reasonable values later when you go to view them.
  id: totrans-341
  prefs: []
  type: TYPE_NORMAL
  zh: 对于像时间和数据大小（例如字节）这样的常见单位，您不应该关心您打算*查看*数据以决定记录的比例。通常最好在所有地方都使用一致的基本单位，并允许图表库以后将这种自动缩放到人类可读格式。与其将响应体的有效载荷大小记录为字节（因为它通常很小）和堆大小记录为兆字节（因为它通常很大），不如将它们都记录为字节。稍后在查看时，它们都将被缩放到合理的值。
- en: For monitoring systems that do not have a clear preference for base unit of
    time, Micrometer chooses one; and it is not generally configurable because consistency
    across all applications is more important than changing the base unit of time
    when precision is not sacrificed either way.
  id: totrans-342
  prefs: []
  type: TYPE_NORMAL
  zh: 对于没有明确时间基准偏好的监控系统，Micrometer 会选择一个；通常不可配置，因为在不牺牲精度的情况下，保持所有应用程序的一致性比更改时间基准更重要。
- en: Using Timers
  id: totrans-343
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用定时器
- en: The `MeterRegistry` interface contains convenience methods for creating timers,
    as shown in [Example 2-19](part0006_split_024.html#timer_create).
  id: totrans-344
  prefs: []
  type: TYPE_NORMAL
  zh: '`MeterRegistry` 接口包含方便的方法用于创建定时器，如 [示例 2-19](part0006_split_024.html#timer_create)
    所示。'
- en: Example 2-19\. Creating timers
  id: totrans-345
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 2-19\. 创建定时器
- en: '[PRE21]'
  id: totrans-346
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: The `Timer` fluent builder (see [Example 2-20](part0006_split_024.html#timer_fluent_builder))
    contains more options. Most of the time you won’t use all of these options.
  id: totrans-347
  prefs: []
  type: TYPE_NORMAL
  zh: '`Timer` 流畅构建器（参见 [示例 2-20](part0006_split_024.html#timer_fluent_builder)）包含更多选项。大多数情况下，您不会使用所有这些选项。'
- en: Example 2-20\. Fluent builder for timers
  id: totrans-348
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 2-20\. 定时器的流畅构建器
- en: '[PRE22]'
  id: totrans-349
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: The `Timer` interface exposes several convenience overloads for recording timings
    inline, such as in [Example 2-21](part0006_split_024.html#timer_record_execution).
    Additionally, a `Runnable` or `Callable` can be wrapped with instrumentation and
    returned for use later.
  id: totrans-350
  prefs: []
  type: TYPE_NORMAL
  zh: '`Timer` 接口提供了几个方便的重载以内联记录计时，例如在 [示例 2-21](part0006_split_024.html#timer_record_execution)
    中。此外，可以用仪表包装 `Runnable` 或 `Callable` 并返回以供以后使用。'
- en: Example 2-21\. Recording execution with a timer
  id: totrans-351
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 2-21\. 使用定时器记录执行
- en: '[PRE23]'
  id: totrans-352
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: Timers Versus Distribution Summaries
  id: totrans-353
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 定时器与分布摘要
- en: '`Timers` are really just a specialized form of distribution summaries (see
    [“Distribution Summaries”](part0007_split_009.html#distribution_summaries)) that
    are aware of how to scale durations to the base unit of time of each monitoring
    system and that have an automatically determined base unit. In almost every case
    where you want to measure time, you should use a `Timer` rather than a `DistributionSummary`.
    The rare exception to this is when recording many long-duration events in a short
    interval, such that the nanosecond-precision `Timer` would overflow ~290 years
    (since Java’s long can effectively store a maximum of 9.22e9 seconds) inside of
    a single interval.'
  id: totrans-354
  prefs: []
  type: TYPE_NORMAL
  zh: '`Timers` 实际上只是分布摘要的一种专门形式（参见 [“分布摘要”](part0007_split_009.html#distribution_summaries)）。它们知道如何将持续时间缩放到每个监控系统的基本时间单位，并具有自动确定的基本单位。几乎每种需要测量时间的情况下，都应使用
    `Timer` 而不是 `DistributionSummary`。唯一的例外是在短时间内记录许多长持续时间事件时，纳秒精度的 `Timer` 在单个间隔内会溢出约290年（因为Java的长整型最多可以有效存储9.22e9秒）。'
- en: You may also store start state in a sample instance that can be stopped later.
    The sample records a start time based on the registry’s clock. After starting
    a sample, execute the code to be timed, and finish the operation by calling `stop(Timer)`
    on the sample.
  id: totrans-355
  prefs: []
  type: TYPE_NORMAL
  zh: 您还可以在样本实例中存储起始状态，稍后可以停止。样本根据注册表的时钟记录开始时间。开始样本后，执行要计时的代码，并在样本上调用 `stop(Timer)`
    完成操作。
- en: Notice in [Example 2-22](part0006_split_025.html#timer_sample) how the timer
    that the sample is accumulating to is not determined until it is time to stop
    the sample. This allows some tags to be determined dynamically from the end state
    of the operation we are timing. The use of `Timer.Sample` is especially common
    when we are dealing with some event-driven interface with a listener pattern.
    This example is a simplified form of Micrometer’s JOOQ execution listener.
  id: totrans-356
  prefs: []
  type: TYPE_NORMAL
  zh: 注意在 [示例 2-22](part0006_split_025.html#timer_sample) 中，样本累积到的定时器直到停止样本时才确定。这允许从我们正在计时的操作的最终状态动态确定一些标签。当我们处理具有监听器模式的某些事件驱动接口时，使用
    `Timer.Sample` 特别常见。该示例是 Micrometer 的 JOOQ 执行监听器的简化形式。
- en: Example 2-22\. Use of timer samples for event-driven patterns
  id: totrans-357
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 2-22\. 用于事件驱动模式的定时器样本的使用
- en: '[PRE24]'
  id: totrans-358
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: '[![1](../images/00112.png)](part0006_split_025.html#co_application_metrics_CO4-1)'
  id: totrans-359
  prefs: []
  type: TYPE_NORMAL
  zh: '[![1](../images/00112.png)](part0006_split_025.html#co_application_metrics_CO4-1)'
- en: We would typically add some tags based on the result of the execution with data
    elements found in `ExecuteContext`.
  id: totrans-360
  prefs: []
  type: TYPE_NORMAL
  zh: 我们通常会基于在 `ExecuteContext` 中找到的数据元素结果添加一些标签。
- en: There is also an `AutoCloseable` form of timer sample that is useful when timing
    blocks of code that contain checked exception handling, as shown in [Example 2-23](part0006_split_025.html#timer_closeable_sample).
    The pattern does require nested `try` statements, which are a bit unusual. If
    you are uncomfortable with this pattern, you can absolutely stick to a simple
    `Timer.Sample`.
  id: totrans-361
  prefs: []
  type: TYPE_NORMAL
  zh: 还有一种`AutoCloseable`形式的计时器示例，用于计时包含已检查异常处理的代码块，如[示例 2-23](part0006_split_025.html#timer_closeable_sample)所示。该模式需要嵌套的`try`语句，这有点不寻常。如果您对此模式感到不舒服，完全可以坚持使用简单的`Timer.Sample`。
- en: Example 2-23\. Use of timer samples
  id: totrans-362
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 2-23\. 使用计时器示例
- en: '[PRE25]'
  id: totrans-363
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: '[![1](../images/00112.png)](part0006_split_025.html#co_application_metrics_CO5-1)'
  id: totrans-364
  prefs: []
  type: TYPE_NORMAL
  zh: '[![1](../images/00112.png)](part0006_split_025.html#co_application_metrics_CO5-1)'
- en: This tag will apply to both outcomes. Description text and percentile histograms
    will also apply to both outcomes.
  id: totrans-365
  prefs: []
  type: TYPE_NORMAL
  zh: 此标签将适用于两个结果。描述文本和百分位直方图也将适用于两个结果。
- en: '[![2](../images/00059.png)](part0006_split_025.html#co_application_metrics_CO5-2)'
  id: totrans-366
  prefs: []
  type: TYPE_NORMAL
  zh: '[![2](../images/00059.png)](part0006_split_025.html#co_application_metrics_CO5-2)'
- en: This nested try statement makes it possible to access the `Timer.ResourceSample`
    in the catch block for adding error tags.
  id: totrans-367
  prefs: []
  type: TYPE_NORMAL
  zh: 此嵌套的 try 语句使得可以在 catch 块中访问`Timer.ResourceSample`，以添加错误标签。
- en: '[![3](../images/00067.png)](part0006_split_025.html#co_application_metrics_CO5-3)'
  id: totrans-368
  prefs: []
  type: TYPE_NORMAL
  zh: '[![3](../images/00067.png)](part0006_split_025.html#co_application_metrics_CO5-3)'
- en: We can add tags at each branching point in the `try/catch` block to record information
    about the outcome.
  id: totrans-369
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以在`try/catch`块的每个分支点添加标签，记录有关结果的信息。
- en: Micrometer has built-in metrics that include several timers. Some examples are
    given in [Table 2-10](part0006_split_025.html#timer_examples).
  id: totrans-370
  prefs: []
  type: TYPE_NORMAL
  zh: Micrometer 具有包括多个计时器在内的内置度量指标。一些示例见[表 2-10](part0006_split_025.html#timer_examples)。
- en: Table 2-10\. Examples of timers in Micrometer built-in instrumentation
  id: totrans-371
  prefs: []
  type: TYPE_NORMAL
  zh: 表 2-10\. Micrometer 内置工具中计时器的示例
- en: '| Metric name | Description |'
  id: totrans-372
  prefs: []
  type: TYPE_TB
  zh: '| 指标名称 | 描述 |'
- en: '| --- | --- |'
  id: totrans-373
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| http.server.requests | Spring Boot records timings for executions of WebMVC
    and WebFlux request handlers. |'
  id: totrans-374
  prefs: []
  type: TYPE_TB
  zh: '| http.server.requests | Spring Boot 记录 WebMVC 和 WebFlux 请求处理程序执行的时间。 |'
- en: '| jvm.gc.pause | Time spent in GC pause. |'
  id: totrans-375
  prefs: []
  type: TYPE_TB
  zh: '| jvm.gc.pause | 花费在 GC 暂停上的时间。 |'
- en: '| mongodb.driver.commands | Time spent in MongoDB operations. |'
  id: totrans-376
  prefs: []
  type: TYPE_TB
  zh: '| mongodb.driver.commands | 花费在 MongoDB 操作上的时间。 |'
- en: Timers are the metrics corollary to distributed tracing (discussed in depth
    in [Chapter 3](part0008_split_000.html#7K4G4-2d714b853a094e9a910510217e0e3d73))
    in the sense that trace spans and timers can instrument the same code, as in [Example 2-24](part0007_split_000.html#trace_and_timing).
  id: totrans-377
  prefs: []
  type: TYPE_NORMAL
  zh: 计时器是分布式跟踪的度量补充（在[第 3 章](part0008_split_000.html#7K4G4-2d714b853a094e9a910510217e0e3d73)中深入讨论），因为跟踪跨度和计时器可以在相同的代码中进行工具化，如示例 2-24 中所示。
- en: The Intersection of Tracing and Metrics
  id: totrans-378
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 追踪和度量的交集
- en: The overlap between distributed tracing and metrics is strictly limited to timing.
  id: totrans-379
  prefs: []
  type: TYPE_NORMAL
  zh: 分布式跟踪和度量之间的重叠严格限于计时。
- en: The sample code uses Zipkin’s Brave instrumentation, which we’ll see again later.
  id: totrans-380
  prefs: []
  type: TYPE_NORMAL
  zh: 示例代码使用了 Zipkin 的 Brave 工具包，稍后我们会再次见到它。
- en: Example 2-24\. Tracing and timing the same block of code
  id: totrans-381
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 2-24\. 跟踪和计时同一段代码
- en: '[PRE26]'
  id: totrans-382
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: '[![1](../images/00112.png)](part0007_split_000.html#co_application_metrics_CO6-1)'
  id: totrans-383
  prefs: []
  type: TYPE_NORMAL
  zh: '[![1](../images/00112.png)](part0007_split_000.html#co_application_metrics_CO6-1)'
- en: Brave doesn’t have an AutoCloseable construct like Micrometer, so the instrumentation
    looks a little asymmetric.
  id: totrans-384
  prefs: []
  type: TYPE_NORMAL
  zh: Brave 没有像 Micrometer 那样的 AutoCloseable 结构，因此仪表化看起来有些不对称。
- en: It’s natural to assume that a particular block of code, given similar inputs,
    would execute in roughly the same amount of time. Our intuition about this can
    be misleading.
  id: totrans-385
  prefs: []
  type: TYPE_NORMAL
  zh: 假设一个特定的代码块，在类似的输入条件下执行的时间大致相同，这是很自然的。我们对此的直觉可能是误导性的。
- en: Common Features of Latency Distributions
  id: totrans-386
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 延迟分布的共同特征
- en: It is important to understand some common characteristics of timings in Java
    applications. The same block of code will not execute in the same amount of time
    on each execution due to variance in the input parameters, downstream systems,
    the state of the heap, and many other variables. Nevertheless, many requests with
    similar inputs will commonly be satisfied in a similar amount of time.
  id: totrans-387
  prefs: []
  type: TYPE_NORMAL
  zh: 了解 Java 应用程序中时间特性的一些常见特征是很重要的。由于输入参数的变化、下游系统、堆的状态以及许多其他变量的影响，同一段代码块在每次执行时不会以相同的时间执行。尽管如此，许多具有类似输入的请求通常会在相似的时间内得到满足。
- en: Intuition may lead to a belief that timings are roughly normally distributed,
    i.e., that there is a central hump around the average with lower-probability tails
    for both faster and slower response times, like in [Figure 2-10](part0007_split_001.html#normal_distribution).
  id: totrans-388
  prefs: []
  type: TYPE_NORMAL
  zh: 直觉可能会让人相信，时间大致上是正态分布的，即围绕着平均值有一个中央的峰，对于更快和更慢的响应时间有更低概率的尾部，就像[图`2-10`](part0007_split_001.html#normal_distribution)中所示的那样。
- en: '![srej 0210](../images/00050.png)'
  id: totrans-389
  prefs: []
  type: TYPE_IMG
  zh: '![srej 0210](../images/00050.png)'
- en: Figure 2-10\. The normal distribution
  id: totrans-390
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图`2-10`。正态分布
- en: In real-world cases, timings are almost always multimodal, meaning there is
    more than one “hump,” or grouping of timings, along the latency spectrum. Most
    commonly, Java timings are bimodal (two humps, as shown in [Figure 2-11](part0007_split_001.html#bimodal)),
    with the smaller, rightmost hump representing events like garbage collection and
    VM pauses. That second hump also includes a ripple effect of the multimodality
    in downstream services.
  id: totrans-391
  prefs: []
  type: TYPE_NORMAL
  zh: 在真实世界的案例中，时间几乎总是多峰的，意味着在延迟范围内有多个“峰”，或者时间的分组。最常见的情况是，Java的时间是双峰的（两个峰，如[图`2-11`](part0007_split_001.html#bimodal)所示），其中较小的、最右边的峰代表了诸如垃圾收集和VM暂停之类的事件。第二个峰也包括了下游服务中多峰性的涟漪效应。
- en: '![srej 0211](../images/00056.png)'
  id: totrans-392
  prefs: []
  type: TYPE_IMG
  zh: '![srej 0211](../images/00056.png)'
- en: Figure 2-11\. A typical bimodal distribution of Java latencies
  id: totrans-393
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图`2-11`。Java延迟的典型双峰分布
- en: Bizarrely, the bigger, leftmost hump is often (though not always, of course)
    quite narrow and contains more than 99% of the timings. As a result, the 99th
    percentile (see [“Percentiles/Quantiles”](part0007_split_003.html#6LK44-2d714b853a094e9a910510217e0e3d73))
    will in many cases be below the average, which is skewed higher by the second
    hump.
  id: totrans-394
  prefs: []
  type: TYPE_NORMAL
  zh: 奇怪的是，最大的、最左边的峰通常（当然不总是）非常窄，含有超过`99%`的时间。因此，在许多情况下，`99`分位数（参见[“百分位数/分位数”](part0007_split_003.html#6LK44-2d714b853a094e9a910510217e0e3d73)）会低于平均值，平均值被第二个峰的增高所偏移。
- en: Standard Deviation
  id: totrans-395
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 标准差
- en: Some metrics instrumentation libraries and systems ship and display standard
    deviation. This metric only makes sense in the context of a normal distribution,
    which we’ve seen is essentially never the case. Standard deviation is not a meaningful
    statistic for real-world timings of Java executions. Ignore it! Also, ignore average.
  id: totrans-396
  prefs: []
  type: TYPE_NORMAL
  zh: 一些度量仪器库和系统会出厂并显示标准差。这个指标只在正态分布的情况下有意义，但我们看到这基本上从未发生过。标准差对于Java执行的实际时间不是一个有意义的统计量。忽略它！同时也忽略平均值。
- en: Percentiles/Quantiles
  id: totrans-397
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 百分位数/分位数
- en: Did I mention not to use average latency? At this point, you can probably see
    that I won’t miss an opportunity to pounce on average latency.
  id: totrans-398
  prefs: []
  type: TYPE_NORMAL
  zh: 我提到过不要使用平均延迟吗？在这一点上，你可能已经看到，我不会错过抨击平均延迟的机会。
- en: 'Average: a random number that falls somewhere between the maximum and 1/2 the
    median. Most often used to ignore reality.'
  id: totrans-399
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 平均值：一个介于最大值和中位数的`1/2`之间的随机数。通常用于忽略现实。
- en: ''
  id: totrans-400
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Gil Tene
  id: totrans-401
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 吉尔·特纳
- en: Average latency is a poor metric to monitor to assess latency behavior, and
    max is a useful alert threshold but can be spiky. For comparative performance,
    we can look at high-percentile values, which are less spiky. High max spikes will
    certainly be more prevalent in less-performant code, but in any case *when* they
    occur is not under your control, making side-by-side comparisons even of identical
    blocks of code running on two different instances difficult.
  id: totrans-402
  prefs: []
  type: TYPE_NORMAL
  zh: 平均延迟是评估延迟行为的一个糟糕的度量标准，最大值是一个有用的警戒阈值，但可能会有尖峰。对于比较性能，我们可以看高百分位数的值，这些值不太尖锐。高最大值尖峰在性能较差的代码中肯定会更普遍，但在任何情况下，它们发生的*时间*都不在你的控制之下，这使得在两个不同实例上运行的相同代码块之间进行比较变得困难。
- en: Depending on the monitoring system, the term *percentile*, or *quantile*, is
    used to describe a point in a set of samples that relates to the rank order of
    its values. So the middle quantile, which is also called the median or the 50th
    percentile, is the middle value in a set of samples ranked from least to greatest.
  id: totrans-403
  prefs: []
  type: TYPE_NORMAL
  zh: 根据监控系统的不同，术语*百分位数*或*分位数*用于描述与值的排名顺序相关的样本集中的一点。因此，中间分位数，也称为中位数或第`50`百分位数，是一组样本中从最小到最大排列的中间值。
- en: Median Versus Average
  id: totrans-404
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 中位数与平均值
- en: Average is rarely useful for monitoring timings. Statistically, the average
    is the sum of all samples divided by the total number of samples. The average
    is just a different measure of centrality than the median, not better or worse
    in general at representing centrality. Even if it were a “perfect” measure of
    centrality, for the purpose of proving our system is reliable we care more about
    the *worst* half of the distribution, not the best half.
  id: totrans-405
  prefs: []
  type: TYPE_NORMAL
  zh: 平均值很少对监控时间有用。从统计学角度来看，平均值是所有样本之和除以总样本数。平均值只是与中位数不同的一个中心度量，一般而言没有更好或更差的代表中心性。即使它是一种“完美”的中心度量，为了证明我们的系统可靠，我们更关心分布的*最差*一半，而不是最好的一半。
- en: Percentiles are a special type of quantile, described relative to 100%. In a
    list of 100 samples ordered from least to greatest, the 99th percentile (P99)
    is the 99th sample in order. In a list of 1,000 samples, the 99.9th percentile
    is the 999th sample.
  id: totrans-406
  prefs: []
  type: TYPE_NORMAL
  zh: 百分位数是一种特殊类型的分位数，相对于100%描述。在从最小到最大排序的100个样本列表中，第99百分位数（P99）是排序中的第99个样本。在1,000个样本列表中，第99.9百分位数是第999个样本。
- en: By this definition, percentiles, particularly high percentiles, are useful for
    determining what *most* users are experiencing (i.e., P99 is the worst latency
    that 99 out of 100 users experienced). For timings, percentiles usefully cut out
    the spiky behavior of VM or garbage collection pauses while still preserving majority
    user experience.
  id: totrans-407
  prefs: []
  type: TYPE_NORMAL
  zh: 根据这个定义，百分位数，特别是高百分位数，对确定*大多数*用户正在经历的情况非常有用（即P99是99个用户中有一个经历的最差延迟）。对于时间，百分位数有效地削减了虚拟机或垃圾收集暂停的突发行为，同时仍保留了大多数用户的体验。
- en: It is tempting to monitor a high-percentile value like the 99th and feel at
    ease that your users are experiencing good response times. Unfortunately, our
    intuition leads us astray with these statistics. The top 1% typically hides latencies
    that are one or two orders of magnitude larger than P99.
  id: totrans-408
  prefs: []
  type: TYPE_NORMAL
  zh: 监控高百分位值（如第99百分位）并感到放心，你的用户体验响应时间良好，这种诱惑很大。不幸的是，这些统计数据让我们的直觉误入歧途。前1%通常隐藏着比P99大一到两个数量级的延迟。
- en: Any single request will avoid the top 1% exactly 99% of the time. When considering
    `N` requests, the chance that at least one of these requests is in the top 1%
    is <math alttext="left-parenthesis 1 minus 0.99 Superscript upper N Baseline right-parenthesis
    asterisk 100 percent-sign"><mrow><mo>(</mo> <mn>1</mn> <mo>-</mo> <mn>0</mn> <mo>.</mo>
    <msup><mn>99</mn> <mi>N</mi></msup> <mo>)</mo> <mo>*</mo> <mn>100</mn> <mo>%</mo></mrow></math>
    (assuming these probabilities are independent, of course). It takes surprisingly
    few requests for there to be a greater than majority chance that one request will
    hit the top 1%. For 100 individual requests, the chance is <math alttext="left-parenthesis
    1 minus 0.99 Superscript 100 Baseline right-parenthesis asterisk 100 percent-sign
    equals 63.3 percent-sign"><mrow><mo>(</mo> <mn>1</mn> <mo>-</mo> <mn>0</mn> <mo>.</mo>
    <msup><mn>99</mn> <mn>100</mn></msup> <mo>)</mo> <mo>*</mo> <mn>100</mn> <mo>%</mo>
    <mo>=</mo> <mn>63</mn> <mo>.</mo> <mn>3</mn> <mo>%</mo></mrow></math> !
  id: totrans-409
  prefs: []
  type: TYPE_NORMAL
  zh: 任何单个请求避开了前1%的情况恰好有99%的时间。在考虑`N`个请求时，至少有一个请求处于前1%的概率为<math alttext="left-parenthesis
    1 minus 0.99 Superscript upper N Baseline right-parenthesis asterisk 100 percent-sign"><mrow><mo>(</mo>
    <mn>1</mn> <mo>-</mo> <mn>0</mn> <mo>.</mo> <msup><mn>99</mn> <mi>N</mi></msup>
    <mo>)</mo> <mo>*</mo> <mn>100</mn> <mo>%</mo></mrow></math>（当然，假设这些概率是独立的）。惊人的是，只需很少的请求就有超过半数的概率其中一个请求将达到前1%。对于100个单独的请求，这种机会是<math
    alttext="left-parenthesis 1 minus 0.99 Superscript 100 Baseline right-parenthesis
    asterisk 100 percent-sign equals 63.3 percent-sign"><mrow><mo>(</mo> <mn>1</mn>
    <mo>-</mo> <mn>0</mn> <mo>.</mo> <msup><mn>99</mn> <mn>100</mn></msup> <mo>)</mo>
    <mo>*</mo> <mn>100</mn> <mo>%</mo> <mo>=</mo> <mn>63</mn> <mo>.</mo> <mn>3</mn>
    <mo>%</mo></mrow></math>！
- en: Consider the fact that a user interaction with your system likely involves many
    resource interactions (UI, API gateway, multiple microservice calls, some database
    interactions, etc.). The chance that any individual end-to-end *user interaction*
    experiences a top 1% latency on some resource in the chain of events satisfying
    their request is actually much higher than 1%. We can approximate this chance
    as <math alttext="left-parenthesis 1 minus 0.99 Superscript upper N Baseline right-parenthesis
    asterisk 100 percent-sign"><mrow><mo>(</mo> <mn>1</mn> <mo>-</mo> <mn>0</mn> <mo>.</mo>
    <msup><mn>99</mn> <mi>N</mi></msup> <mo>)</mo> <mo>*</mo> <mn>100</mn> <mo>%</mo></mrow></math>
    . If a single request in a chain of microservices experiences a top 1% latency,
    then the whole user experience suffers, especially given the fact that the top
    1% tends to be an order of magnitude or more worse in performance than requests
    under the 99th percentile.
  id: totrans-410
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑到用户与您的系统的交互很可能涉及许多资源交互（UI、API 网关、多个微服务调用、一些数据库交互等）。任何单个的端到端*用户交互*在满足其请求的事件链中体验到顶部
    1% 的延迟的机会实际上要高于 1%。我们可以将这个机会近似为<math alttext="left-parenthesis 1 minus 0.99 Superscript
    upper N Baseline right-parenthesis asterisk 100 percent-sign"><mrow><mo>(</mo>
    <mn>1</mn> <mo>-</mo> <mn>0</mn> <mo>.</mo> <msup><mn>99</mn> <mi>N</mi></msup>
    <mo>)</mo> <mo>*</mo> <mn>100</mn> <mo>%</mo></mrow></math>。如果微服务链中的单个请求体验到顶部
    1% 的延迟，那么整个用户体验都会受到影响，尤其是考虑到顶部 1% 的性能往往比第 99 百分位以下的请求差一个数量级或更多。
- en: Time (Anti-)Correlation of Samples
  id: totrans-411
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 样本的时间（反）相关性
- en: The formulas given to determine the chance of experiencing a top 1% latency
    are only approximations. In reality, time-correlation of high/low latency leads
    to a lower chance, and anti-correlation would lead to a higher chance. In other
    words, the probabilities for each request aren’t truly independent. We almost
    never have information about this correlation, so the approximations are useful
    guides for how you should reason about your system.
  id: totrans-412
  prefs: []
  type: TYPE_NORMAL
  zh: 给出用于确定体验顶部 1% 延迟的机会的公式只是近似值。实际上，高/低延迟的时间相关性会导致机会降低，而反相关性会导致机会增加。换句话说，每个请求的概率并不真正独立。我们几乎从不了解这种相关性的信息，因此这些近似值对于您如何推理您的系统非常有用。
- en: 'Micrometer supports two ways of computing percentiles for timers:'
  id: totrans-413
  prefs: []
  type: TYPE_NORMAL
  zh: Micrometer 支持两种计算计时器的百分位数的方式：
- en: Precompute the percentile value and ship it directly to the monitoring system.
  id: totrans-414
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 预先计算百分位数值，并直接发送到监控系统。
- en: Group timings into discrete sets of latency buckets, and ship the sets of buckets
    together to the monitoring system (see [“Histograms”](part0007_split_007.html#6LKA8-2d714b853a094e9a910510217e0e3d73)).
    The monitoring system is then responsible for computing the percentile from a
    histogram.
  id: totrans-415
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将计时分组到离散的延迟桶中，并将这些桶集合一起发送到监控系统（见[“直方图”](part0007_split_007.html#6LKA8-2d714b853a094e9a910510217e0e3d73)）。然后监控系统负责从直方图计算百分位数。
- en: Precomputing percentile values is the most portable approach since many monitoring
    systems don’t support histogram-based percentile approximation, but it’s useful
    only in a narrow set of circumstances (we’ll see why a little later in this section).
    Precomputed percentiles can be added to a timer in a few different ways.
  id: totrans-416
  prefs: []
  type: TYPE_NORMAL
  zh: 预先计算百分位数值是最具可移植性的方法，因为许多监控系统不支持基于直方图的百分位数近似，但它只在一组狭窄的情况下有用（稍后在本节中我们将看到为什么）。预先计算的百分位数可以通过几种不同的方式添加到计时器中。
- en: The `Timer` fluent builder supports adding percentiles directly as the `Timer`
    is being constructed, as shown in [Example 2-25](part0007_split_005.html#timer_percentile_fluent).
  id: totrans-417
  prefs: []
  type: TYPE_NORMAL
  zh: '`Timer`流式构建器支持在构建`Timer`时直接添加百分位数，如[示例 2-25](part0007_split_005.html#timer_percentile_fluent)所示。'
- en: Example 2-25\. Adding percentiles to a Timer via the builder
  id: totrans-418
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 例 2-25\. 通过构建器向计时器添加百分位数
- en: '[PRE27]'
  id: totrans-419
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: '[Example 2-26](part0007_split_005.html#timer_percentile_meter_filter) shows
    how to add percentiles with a `MeterFilter`.'
  id: totrans-420
  prefs: []
  type: TYPE_NORMAL
  zh: '[示例 2-26](part0007_split_005.html#timer_percentile_meter_filter)展示了如何使用`MeterFilter`添加百分位数。'
- en: Example 2-26\. Adding percentiles to a Timer via a MeterFilter
  id: totrans-421
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 例 2-26\. 通过 MeterFilter 向计时器添加百分位数
- en: '[PRE28]'
  id: totrans-422
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: Lastly, frameworks like Spring Boot offer property-driven `MeterFilter` equivalents
    that allow you to add percentiles to `Timers` declaratively. The configuration
    shown in [Example 2-27](part0007_split_005.html#property_driven_percentiles) adds
    percentiles to any timer prefixed with the name `requests`.
  id: totrans-423
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，像 Spring Boot 这样的框架提供了基于属性驱动的`MeterFilter`等效项，允许您声明性地向`Timers`添加百分位数。在[示例 2-27](part0007_split_005.html#property_driven_percentiles)中显示的配置将百分位数添加到任何以名称`requests`为前缀的计时器。
- en: Example 2-27\. Adding percentiles to metrics prefixed with “requests” in Spring
    Boot
  id: totrans-424
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 例 2-27\. 在 Spring Boot 中为以“请求”为前缀的度量添加百分位数
- en: '[PRE29]'
  id: totrans-425
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: Adding percentiles through a `MeterFilter` allows you to add percentile support
    to `Timers` that are created not just in your application code, but in other libraries
    you are including in your application that contain Micrometer instrumentation.
  id: totrans-426
  prefs: []
  type: TYPE_NORMAL
  zh: 通过`MeterFilter`添加百分位支持，允许您不仅在应用代码中创建`Timers`，还在您的应用中包含的其他库中包含Micrometer仪表化。
- en: Adding Timers to Library Code
  id: totrans-427
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 向库代码添加计时器
- en: If you are authoring a library and including timing code, do not preconfigure
    your timers with features like percentiles, histograms, and SLO boundaries. These
    features all have some performance cost, even if it is minimal. Allow the consumers
    of your library to determine if the timing is an important enough indicator to
    warrant the extra expense of these statistics. In particular, end users will want
    to turn on histograms when they intend to use the timing as part of a comparative
    measure, like in [“Automated Canary Analysis”](part0010_split_013.html#9H5VC-2d714b853a094e9a910510217e0e3d73).
    When needed, users can configure these statistics with a `MeterFilter`.
  id: totrans-428
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您正在编写一个包含计时代码的库，请不要预先配置计时器，例如百分位数、直方图和SLO边界。即使性能成本很低，这些功能也会有一定的性能成本。允许您的库的消费者确定计时是否足够重要以便于这些统计信息的额外开销。特别是，最终用户将希望在打算将计时用作比较措施的情况下打开直方图，如在[“自动金丝雀分析”](part0010_split_013.html#9H5VC-2d714b853a094e9a910510217e0e3d73)中所示。在需要时，用户可以使用`MeterFilter`配置这些统计信息。
- en: Wherever a timer metric has more than a few total unique combinations of tags,
    pre-computed percentiles are unusable because they cannot be combined or aggregated.
    On a cluster of two instances, if the 90th percentile latency for a request endpoint
    is 100 ms on one application instance and 200 ms on another, we can’t simply average
    these two values together to arrive at a cluster-wide 90th percentile latency
    of 150 ms.
  id: totrans-429
  prefs: []
  type: TYPE_NORMAL
  zh: 每当一个计时器指标具有多个标签的总唯一组合超过几个时，预先计算的百分位数就无法使用，因为它们无法进行组合或聚合。在两个实例的集群中，如果请求端点的第90百分位延迟在一个应用实例上是100毫秒，而在另一个实例上是200毫秒，我们无法简单地将这两个值平均，以得出集群范围的90百分位延迟为150毫秒。
- en: '[Table 2-11](part0007_split_006.html#percentiles_for_two_instances) shows why,
    using the median (50th percentile) as an example. Since the individual samples
    that went into this percentile calculation were thrown away, there is no way to
    reconstitute them to derive a cluster-wide percentile at the monitoring system.'
  id: totrans-430
  prefs: []
  type: TYPE_NORMAL
  zh: '[表 2-11](part0007_split_006.html#percentiles_for_two_instances)解释了为什么要使用中位数（50th百分位数）作为例子。由于参与计算此百分位数的单个样本已被丢弃，在监控系统中无法重建它们以推导出集群范围的百分位数。'
- en: Table 2-11\. P50 (median) request latency in a cluster of two instances
  id: totrans-431
  prefs: []
  type: TYPE_NORMAL
  zh: 表 2-11\. 两个实例集群中的P50（中位数）请求延迟
- en: '| Instance | Individual latencies (ms) | P50 latency (ms) |'
  id: totrans-432
  prefs: []
  type: TYPE_TB
  zh: '| 实例 | 单个延迟（ms） | P50延迟（ms） |'
- en: '| --- | --- | --- |'
  id: totrans-433
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| 1 | [100,110,125] | 110 |'
  id: totrans-434
  prefs: []
  type: TYPE_TB
  zh: '| 1 | [100,110,125] | 110 |'
- en: '| 2 | [125,130,140] | 130 |'
  id: totrans-435
  prefs: []
  type: TYPE_TB
  zh: '| 2 | [125,130,140] | 130 |'
- en: '| Whole cluster | [100,110,125,125,130,140] | 125 |'
  id: totrans-436
  prefs: []
  type: TYPE_TB
  zh: '| 整个集群 | [100,110,125,125,130,140] | 125 |'
- en: The best we can do with precomputed percentiles is to simply plot all of the
    values and look for outliers, as in [Figure 2-12](part0007_split_006.html#p99_not_aggregated),
    generated from the Prometheus query `requests_second{quantile=0.99}`.
  id: totrans-437
  prefs: []
  type: TYPE_NORMAL
  zh: 用预先计算的百分位数值，我们可以简单地绘制所有数值并查找异常值，如来自Prometheus查询`requests_second{quantile=0.99}`的[图 2-12](part0007_split_006.html#p99_not_aggregated)所示。
- en: '![srej 0212](../images/00103.png)'
  id: totrans-438
  prefs: []
  type: TYPE_IMG
  zh: '![srej 0212](../images/00103.png)'
- en: Figure 2-12\. 99th percentile of a single timer for individual application instances
  id: totrans-439
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 2-12\. 单个应用实例的第99百分位计时器
- en: This scales to a point; but as the number of instances grows (imagine we had
    a cluster of 100 instances!), the visualization quickly becomes crowded. Attempts
    to limit the number of lines displayed to select just the top *N* worst latencies
    can result in situations where the legend is still full of individual instance
    IDs. This is because, as we see in [Figure 2-13](part0007_split_006.html#p99_topk),
    where we are selecting the top three worst latencies with the Prometheus query
    `topk(3, requests_second{quantile=0.99})`, the third-worst instance changes virtually
    every interval.
  id: totrans-440
  prefs: []
  type: TYPE_NORMAL
  zh: 这个问题存在其局限性；例如，当实例数量增加（设想我们有一个包含100个实例的集群！）时，可视化很快就会变得拥挤。试图限制显示的行数以选择仅显示前 *N*
    个最差的延迟可能导致情况，其中图例仍然充满了各个实例的ID。这是因为，正如我们在[图 2-13](part0007_split_006.html#p99_topk)中看到的，我们使用Prometheus查询`topk(3,
    requests_second{quantile=0.99})`选择了前三个最差的延迟实例，第三最差的实例几乎每个间隔都会变化。
- en: '![srej 0213](../images/00090.png)'
  id: totrans-441
  prefs: []
  type: TYPE_IMG
  zh: '![srej 0213](../images/00090.png)'
- en: Figure 2-13\. Top three worst 99th percentile of a single timer for individual
    application instances
  id: totrans-442
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图2-13\. 单个应用实例的前三个最差的第99分位计时器
- en: Because of the limitations of precomputed percentiles, if you are working with
    a monitoring system that supports histograms, *always* use them instead, as described
    in the following section.
  id: totrans-443
  prefs: []
  type: TYPE_NORMAL
  zh: 由于预先计算分位数的限制，如果您使用支持直方图的监控系统，*永远*使用它们，如下一节所述。
- en: Histograms
  id: totrans-444
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 直方图
- en: Metrics are always presented in aggregated form to the monitoring system. The
    individual timings that together we represent as the latency of a block of code
    are not shipped to the monitoring system. If they were, metrics would no longer
    have a fixed cost irrespective of throughput.
  id: totrans-445
  prefs: []
  type: TYPE_NORMAL
  zh: 指标总是以聚合形式呈现给监控系统。我们表示为代码块延迟的个体计时不会传送到监控系统。如果这样做的话，指标成本就不再固定，无论吞吐量如何。
- en: We can send an approximation of what the individual timings looked like together
    in a histogram. In a histogram, the range of possible timings is divided into
    a series of buckets. For each bucket (also known as an *interval* or *bin*), the
    histogram maintains a count of how many individual timings fell into that bucket.
    The buckets are consecutive and nonoverlapping. They are not often of equal size,
    since there is generally some part of the range which we care about at a more
    fine-grained level than others. For example, for an API endpoint latency histogram,
    we care more about the distinction between 1, 10, and 100 ms latencies than we
    do about 40 s and 41 s latencies. The latency buckets will be more granular around
    the expected value than well outside the expected value.
  id: totrans-446
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以发送一个近似于个体计时的直方图。在直方图中，可能计时范围被划分为一系列桶。对于每个桶（也称为*间隔*或*区间*），直方图会记录有多少个体计时落入该桶中。这些桶是连续且不重叠的。它们通常不是等大小的，因为通常对于我们关心某些部分的粒度比其他部分更详细。例如，对于API端点延迟直方图，我们更关心1、10和100毫秒延迟之间的区别，而不太关心40秒和41秒的延迟。延迟桶会更加细分在期望值周围而不是远离期望值。
- en: Importantly, by accumulating all the individual timings into buckets, and controlling
    the number of buckets, we can retain the shape of the distribution while maintaining
    a fixed cost.
  id: totrans-447
  prefs: []
  type: TYPE_NORMAL
  zh: 重要的是，通过将所有个体计时累积到桶中，并控制桶的数量，我们可以保留分布的形状同时保持固定成本。
- en: Histograms are represented in the monitoring system’s storage as a series of
    counters. In the case of Prometheus, as in [Table 2-12](part0007_split_007.html#histogram_bucket_storage),
    these counters have a special tag `le` that indicates that the metric is a count
    of all samples less than or equal to the tag value (in seconds).
  id: totrans-448
  prefs: []
  type: TYPE_NORMAL
  zh: 监控系统的存储中，直方图被表示为一系列计数器。在Prometheus的情况下，正如[表 2-12](part0007_split_007.html#histogram_bucket_storage)中所示，这些计数器具有一个特殊的标记`le`，表示该指标是所有样本少于或等于该标记值（以秒计）的计数。
- en: Table 2-12\. How histogram buckets are stored in a time series database (Prometheus)
  id: totrans-449
  prefs: []
  type: TYPE_NORMAL
  zh: 表2-12\. 直方图桶在时间序列数据库（Prometheus）中的存储方式
- en: '| Metric name | Values |'
  id: totrans-450
  prefs: []
  type: TYPE_TB
  zh: 指标名称 | 值 |
- en: '| --- | --- |'
  id: totrans-451
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| http_server_requests_seconds_bucket{status=200,le=0.1} | [10,10,12,15] |'
  id: totrans-452
  prefs: []
  type: TYPE_TB
  zh: '| http_server_requests_seconds_bucket{status=200,le=0.1} | [10,10,12,15] |'
- en: '| http_server_requests_seconds_bucket{status=200,le=0.2} | [20,20,24,26] |'
  id: totrans-453
  prefs: []
  type: TYPE_TB
  zh: '| http_server_requests_seconds_bucket{status=200,le=0.2} | [20,20,24,26] |'
- en: '| http_server_requests_seconds_bucket{status=200,le=0.5} | [30,30,40,67] |'
  id: totrans-454
  prefs: []
  type: TYPE_TB
  zh: '| http_server_requests_seconds_bucket{status=200,le=0.5} | [30,30,40,67] |'
- en: '| http_server_requests_seconds_bucket{status=500,le=0.1} | [1,1,2,5] |'
  id: totrans-455
  prefs: []
  type: TYPE_TB
  zh: '| http_server_requests_seconds_bucket{status=500,le=0.1} | [1,1,2,5] |'
- en: '| http_server_requests_seconds_bucket{status=500,le=0.2} | [1,1,2,6] |'
  id: totrans-456
  prefs: []
  type: TYPE_TB
  zh: '| http_server_requests_seconds_bucket{status=500,le=0.2} | [1,1,2,6] |'
- en: '| http_server_requests_seconds_bucket{status=500,le=0.5} | [1,1,2,6] |'
  id: totrans-457
  prefs: []
  type: TYPE_TB
  zh: '| http_server_requests_seconds_bucket{status=500,le=0.5} | [1,1,2,6] |'
- en: Depending on the monitoring system, a histogram may appear as either a normal
    or a cumulative histogram. A visual distinction between these two types of histograms
    is shown in [Figure 2-14](part0007_split_007.html#cumulative_vs_normal_histogram).
    Cumulative histogram buckets represent the count of all timings less than or equal
    to their boundary. Note that the timer’s count is equal to the sum of all buckets
    in a normal histogram.
  id: totrans-458
  prefs: []
  type: TYPE_NORMAL
  zh: 根据监控系统的不同，直方图可能会显示为正常或累计直方图。这两种类型的直方图之间的视觉区别如[图 2-14](part0007_split_007.html#cumulative_vs_normal_histogram)所示。累计直方图桶表示所有小于或等于其边界的计时的计数。请注意，正常直方图中计时器的计数等于所有桶的总和。
- en: '![srej 0214](../images/00095.png)'
  id: totrans-459
  prefs: []
  type: TYPE_IMG
  zh: '![srej 0214](../images/00095.png)'
- en: Figure 2-14\. Cumulative versus normal histogram
  id: totrans-460
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图2-14\. 累计与正常直方图
- en: Like adding any other tag, adding histogram data to a timer increases the total
    required storage by a factor equal to the number of buckets that the range is
    subdivided into. In this example, since there are three buckets (0.1 s, 0.2 s,
    and 0.5 s) there will be three times the number of permutations of other tags’
    time series stored.
  id: totrans-461
  prefs: []
  type: TYPE_NORMAL
  zh: 与添加任何其他标记类似，向计时器添加直方图数据会将所需存储总量增加至分隔范围中桶数的倍数。在此示例中，由于有三个桶（0.1 秒、0.2 秒和 0.5 秒），将存储其他标记时间序列的排列组合的三倍。
- en: This histogram is published each interval to the monitoring system. The histograms
    for each interval can be assembled into a heatmap. [Figure 2-15](part0007_split_007.html#latency_heatmap)
    shows the heatmap for the latency of an API endpoint. Most requests are served
    in ~1 ms, but there is a long tail of latencies leading all the way up to >100
    ms in each interval.
  id: totrans-462
  prefs: []
  type: TYPE_NORMAL
  zh: 此直方图每个间隔都会发布到监控系统。每个间隔的直方图可以组合成热图。[图 2-15](part0007_split_007.html#latency_heatmap)
    展示了 API 端点延迟的热图。大多数请求在约 1 毫秒内完成，但每个间隔的延迟尾部延伸至超过 100 毫秒。
- en: '![A heatmap of request latency](../images/00078.png)'
  id: totrans-463
  prefs: []
  type: TYPE_IMG
  zh: '![请求延迟的热图](../images/00078.png)'
- en: Figure 2-15\. Latency heatmap
  id: totrans-464
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 2-15\. 延迟热图
- en: Histogram data can also be used to perform an approximation for a percentile,
    and this common use of histogram data is reflected in Micrometer’s option to enable
    histograms, `publishPercentileHistogram`. High percentiles are especially useful
    when performing comparative measurements of an application’s performance (such
    as the relative performance of two versions of an application in [“Automated Canary
    Analysis”](part0010_split_013.html#9H5VC-2d714b853a094e9a910510217e0e3d73)). Histograms
    are not enabled by default because of the additional storage cost on the monitoring
    system and heap usage in your application. Micrometer uses a bucketing function
    empirically determined at Netflix to generate reasonably low error bounds for
    these approximations.
  id: totrans-465
  prefs: []
  type: TYPE_NORMAL
  zh: 直方图数据还可用于执行百分位数的近似，并且直方图数据的这种常见用法反映在 Micrometer 的选项中，即启用直方图 `publishPercentileHistogram`。在执行应用程序性能的比较测量时（例如比较应用程序两个版本的性能在[“自动金丝雀分析”](part0010_split_013.html#9H5VC-2d714b853a094e9a910510217e0e3d73)中的相对性能），高百分位数特别有用。默认情况下不启用直方图，因为这会增加监控系统的额外存储成本和应用程序的堆使用量。Netflix
    在实践中使用了一种分桶函数，以生成这些近似的合理低误差边界。
- en: Histogram publishing can be enabled for timers in a few ways.
  id: totrans-466
  prefs: []
  type: TYPE_NORMAL
  zh: 直方图发布可以通过几种方式启用计时器。
- en: The `Timer` fluent builder supports adding histograms directly as the `Timer`
    is being constructed, as shown in [Example 2-28](part0007_split_007.html#timer_histogram_fluent).
  id: totrans-467
  prefs: []
  type: TYPE_NORMAL
  zh: '`Timer` 流畅构建器支持在构建 `Timer` 时直接添加直方图，如 [示例 2-28](part0007_split_007.html#timer_histogram_fluent)
    所示。'
- en: Example 2-28\. Adding histograms to a Timer via the builder
  id: totrans-468
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 2-28\. 通过构建器向计时器添加直方图
- en: '[PRE30]'
  id: totrans-469
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: Histogram support can be added after the fact via a `MeterFilter`, as shown
    in [Example 2-29](part0007_split_007.html#timer_histogram_meter_filter). This
    ability is crucial in layering your application with effective monitoring. In
    addition to their particular business logic, applications almost always contain
    a rich binary dependency hierarchy as well. It is reasonable for authors of common
    dependencies like HikariCP for connection pooling or the RabbitMQ Java client
    to want to include instrumentation involving timers in their code. But it is impossible
    for the authors of the RabbitMQ Java client to know whether RabbitMQ interactions
    are significant enough in your application to warrant the extra cost of shipping
    distribution statistics like percentile histograms (no matter how optimized they
    may be). Allowing application developers to turn on additional distribution statistics
    via `MeterFilter` allows the RabbitMQ Java client authors to use a minimal timer
    in their code.
  id: totrans-470
  prefs: []
  type: TYPE_NORMAL
  zh: 可以通过 `MeterFilter` 后期添加直方图支持，如 [示例 2-29](part0007_split_007.html#timer_histogram_meter_filter)
    所示。这种能力对于将应用程序层层堆叠以实现有效监控至关重要。除了特定的业务逻辑外，应用程序几乎总是包含丰富的二进制依赖层次结构。例如，像 HikariCP
    连接池或 RabbitMQ Java 客户端这样的常见依赖的作者可能希望在其代码中包含涉及计时器的仪表化。但是，对于 RabbitMQ Java 客户端的作者来说，他们无法知道
    RabbitMQ 交互在您的应用程序中是否足够重要，以至于要承担像百分位直方图这样的分布统计额外成本（无论其优化程度如何）。通过 `MeterFilter`
    允许应用程序开发人员打开额外的分布统计功能，使 RabbitMQ Java 客户端作者可以在其代码中使用最小的计时器。
- en: Example 2-29\. Adding histograms to a Timer via a MeterFilter
  id: totrans-471
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 2-29\. 通过 MeterFilter 向计时器添加直方图
- en: '[PRE31]'
  id: totrans-472
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: '[![1](../images/00112.png)](part0007_split_007.html#co_application_metrics_CO7-1)'
  id: totrans-473
  prefs: []
  type: TYPE_NORMAL
  zh: '[![1](../images/00112.png)](part0007_split_007.html#co_application_metrics_CO7-1)'
- en: Combines percentile histogram publishing with whatever other distribution statistics
    are configured by default (or by other `MeterFilter` configurations).
  id: totrans-474
  prefs: []
  type: TYPE_NORMAL
  zh: 将百分位直方图发布与默认情况下配置的任何其他分布统计数据（或其他`MeterFilter`配置）结合起来。
- en: Lastly, frameworks like Spring Boot offer property-driven `MeterFilter` equivalents
    that allow you to add histograms to `Timers` declaratively. The configuration
    shown in [Example 2-30](part0007_split_007.html#property_driven_histograms) adds
    histogram support to any timer prefixed with the name `requests`.
  id: totrans-475
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，像Spring Boot这样的框架提供了基于属性驱动的`MeterFilter`等效项，允许您以声明方式将直方图添加到任何以“requests”命名前缀的计时器中。在[Example 2-30](part0007_split_007.html#property_driven_histograms)中显示的配置为任何以“requests”命名前缀的计时器添加直方图支持。
- en: Example 2-30\. Adding percentile histograms to metrics prefixed with “requests”
    in Spring Boot
  id: totrans-476
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: Example 2-30\. 在Spring Boot中为以“requests”为前缀的指标添加百分位直方图
- en: '[PRE32]'
  id: totrans-477
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: Histograms are only shipped to monitoring systems that support percentile approximation
    based on histogram data.
  id: totrans-478
  prefs: []
  type: TYPE_NORMAL
  zh: 直方图仅被发送到支持基于直方图数据的百分位数近似的监控系统。
- en: For Atlas, use the `:percentiles` function, as in [Example 2-31](part0007_split_007.html#atlas_percentiles).
  id: totrans-479
  prefs: []
  type: TYPE_NORMAL
  zh: 对于Atlas，请使用`:percentiles`函数，例如[Example 2-31](part0007_split_007.html#atlas_percentiles)中所示。
- en: Example 2-31\. Atlas percentiles function
  id: totrans-480
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: Example 2-31\. Atlas百分位数函数
- en: '[PRE33]'
  id: totrans-481
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: For Prometheus, use the `histogram_quantile` function, as in [Example 2-32](part0007_split_007.html#prometheus_percentiles).
    Recall from [“Percentiles/Quantiles”](part0007_split_003.html#6LK44-2d714b853a094e9a910510217e0e3d73)
    that percentiles are just a particular type of quantile. Prometheus histograms
    contain a special bucket called `Inf` that captures all samples exceeding the
    greatest bucket that you (or Micrometer) defines. Note that the timer’s count
    is equal to the count in the `Inf` bucket.
  id: totrans-482
  prefs: []
  type: TYPE_NORMAL
  zh: 对于Prometheus，请使用`histogram_quantile`函数，例如[Example 2-32](part0007_split_007.html#prometheus_percentiles)中所示。请从[“百分位数/分位数”](part0007_split_003.html#6LK44-2d714b853a094e9a910510217e0e3d73)中回忆起，百分位数只是分位数的一种特殊类型。Prometheus直方图包含一个称为`Inf`的特殊存储桶，用于捕获超过您（或Micrometer）定义的最大存储桶的所有样本。请注意，计时器的计数等于`Inf`存储桶中的计数。
- en: Example 2-32\. Prometheus histogram quantile function
  id: totrans-483
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: Example 2-32\. Prometheus直方图分位数函数
- en: '[PRE34]'
  id: totrans-484
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: Service Level Objective Boundaries
  id: totrans-485
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 服务水平目标边界
- en: Similar to percentiles and histograms, service level objective (SLO) boundaries
    can be added either through the `Timer` fluent builder or through a `MeterFilter`.
    You may notice I said “boundaries” and not “boundary” as you might expect. In
    many circumstances, it’s reasonable to layer your objectives. Gil Tene talks about
    establishing SLO requirements in his 2013 [talk](https://oreil.ly/-LNd6) on monitoring
    latency, which I’ll paraphrase here because this is such a useful framework for
    explaining the need to layer SLOs. The SLO requirements interview is captured
    in [Example 2-33](part0007_split_008.html#slo_requirements_interview).
  id: totrans-486
  prefs: []
  type: TYPE_NORMAL
  zh: 与百分位数和直方图类似，服务水平目标（SLO）边界可以通过`Timer`流畅构建器或`MeterFilter`添加。您可能会注意到我说的是“边界”而不是您可能期望的“边界”。在许多情况下，将您的目标层叠是合理的。Gil
    Tene在他2013年关于监控延迟的[演讲](https://oreil.ly/-LNd6)中谈到了建立SLO需求的内容，我在这里进行了paraphrase，因为这是解释层叠SLOs需求的一个非常有用的框架。SLO需求访谈内容记录在[Example 2-33](part0007_split_008.html#slo_requirements_interview)中。
- en: Example 2-33\. The SLO requirements interview
  id: totrans-487
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: Example 2-33\. SLO需求访谈
- en: '[PRE35]'
  id: totrans-488
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: '[![1](../images/00112.png)](part0007_split_008.html#co_application_metrics_CO8-1)'
  id: totrans-489
  prefs: []
  type: TYPE_NORMAL
  zh: '[![1](../images/00112.png)](part0007_split_008.html#co_application_metrics_CO8-1)'
- en: Oh no, you said the word “average"…we’re just going to pretend we didn’t hear
    this.
  id: totrans-490
  prefs: []
  type: TYPE_NORMAL
  zh: 哦不，您说了“平均”这个词……我们将假装我们没有听到这个。
- en: This interview eventually yields a set of SLOs.
  id: totrans-491
  prefs: []
  type: TYPE_NORMAL
  zh: 此访谈最终产生了一组SLOs。
- en: 90% better than 20 milliseconds
  id: totrans-492
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 90%优于20毫秒
- en: 99.99% better than 100 milliseconds
  id: totrans-493
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 99.99%优于100毫秒
- en: 100% better than 2 seconds
  id: totrans-494
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 100%优于2秒
- en: We will configure Micrometer then to publish SLO counts for 20 milliseconds,
    100 milliseconds, and 2 seconds. And we can simply compare, for example, the ratio
    of requests less than 20 milliseconds to the total number of requests; and if
    this ratio is less than 90%, then alert.
  id: totrans-495
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将配置Micrometer以发布20毫秒、100毫秒和2秒的SLO计数。例如，我们可以简单地比较小于20毫秒的请求占总请求数的比率；如果这个比率小于90%，则发出警报。
- en: Micrometer will ship a count for each of these boundaries that indicates how
    many requests did not exceed that boundary. A set of SLO boundaries together form
    a coarse histogram, as seen in [Figure 2-16](part0007_split_008.html#slo_histogram),
    where the latency domain is divided into buckets of zero to the lowest SLO and
    so on for consecutive SLO boundaries after that.
  id: totrans-496
  prefs: []
  type: TYPE_NORMAL
  zh: Micrometer将为每个边界发布一个计数，指示未超过该边界的请求数量。一组SLO边界共同形成一个粗略直方图，如[图 2-16](part0007_split_008.html#slo_histogram)所示，其中延迟域被划分为从零到最低SLO的各个桶，依此类推。
- en: '![srej 0216](../images/00034.png)'
  id: totrans-497
  prefs: []
  type: TYPE_IMG
  zh: '![srej 0216](../images/00034.png)'
- en: Figure 2-16\. Histogram of SLO boundaries
  id: totrans-498
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 2-16\. SLO边界直方图
- en: Shipping SLO boundaries does have an effect on total storage in the monitoring
    system and memory consumption in your application. However, because typically
    only a small set of boundaries is published, the cost is relatively low compared
    to percentile histograms.
  id: totrans-499
  prefs: []
  type: TYPE_NORMAL
  zh: 发布SLO边界确实会影响监控系统中的总存储和应用程序的内存消耗。然而，因为通常只发布一小组边界，与百分位直方图相比，成本相对较低。
- en: Percentile histograms and SLOs can be used together. Adding SLO boundaries simply
    adds more buckets than would be shipped with just a percentile histogram. When
    SLO boundaries are shipped in addition to percentile histograms, the histogram
    shipped contains the buckets Micrometer decides are necessary to yield reasonable
    error bounds on percentile approximations *plus* any SLO boundaries, as shown
    in [Figure 2-17](part0007_split_008.html#mixed_percentiles_slos).
  id: totrans-500
  prefs: []
  type: TYPE_NORMAL
  zh: 百分位直方图和SLO可以共同使用。添加SLO边界只是比仅使用百分位直方图增加更多的桶。当SLO边界除了百分位直方图外也被发布时，所发布的直方图包含Micrometer认为为了得到合理的百分位近似所必需的桶，*加上*任何SLO边界，如图 2-17所示（part0007_split_008.html#mixed_percentiles_slos）。
- en: '![srej 0217](../images/00015.png)'
  id: totrans-501
  prefs: []
  type: TYPE_IMG
  zh: '![srej 0217](../images/00015.png)'
- en: Figure 2-17\. Mixed histogram of service level objective boundaries and percentile
    histogram bucket boundaries
  id: totrans-502
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 2-17\. 服务水平目标边界和百分位直方图桶边界的混合直方图
- en: Publishing SLO boundaries is a far cheaper (and accurate) way of testing whether
    the *N*th percentile exceeds a certain value. For example, if you determine that
    an SLO is that 99% of requests are below 100 ms, then publish a 100 ms SLO boundary.
    To set an alert on violations of the SLO boundary, simply determine whether the
    ratio of requests below the boundary to total requests is less than 99%.
  id: totrans-503
  prefs: []
  type: TYPE_NORMAL
  zh: 发布SLO边界是测试第*N*个百分位是否超过特定值的一种更便宜（和准确）的方式。例如，如果确定SLO是99%的请求低于100毫秒，则发布100毫秒的SLO边界。要设置对SLO边界违规的警报，只需确定低于边界的请求与总请求的比率是否低于99%。
- en: This is a little inconvenient when the monitoring system expects normal histograms,
    like Atlas, because you have to select and sum all the buckets *less than* the
    SLO boundary. In [Example 2-34](part0007_split_008.html#slo_boundary_percentile_atlas),
    we want to test whether 99% of requests are less than 100 ms (0.1 seconds); but
    since it isn’t possible to treat tag values as numerical values, we can’t use
    operators like `:le` to select all time series with a tag less than 0.1 seconds.
    So we have to resort to performing numerical comparisons with a regular expression
    operator like `:re`.
  id: totrans-504
  prefs: []
  type: TYPE_NORMAL
  zh: 当监控系统期望普通的直方图（如Atlas）时，这有点不方便，因为你必须选择并求和所有小于SLO边界的桶。在[示例 2-34](part0007_split_008.html#slo_boundary_percentile_atlas)中，我们想测试是否有99%的请求少于100毫秒（0.1秒）；但由于无法将标签值视为数值，我们无法使用像`:le`这样的操作符选择所有小于0.1秒的时间序列。因此，我们必须使用像`:re`这样的正则表达式运算符执行数值比较。
- en: Example 2-34\. Atlas alert criteria using an SLO boundary
  id: totrans-505
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 2-34\. 使用SLO边界的Atlas警报条件
- en: '[PRE36]'
  id: totrans-506
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: Prometheus has the advantage here, given that its histograms are expressed cumulatively.
    That is, all the samples below 100 ms are accumulated to every boundary less than
    100 ms, including this boundary.
  id: totrans-507
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，Prometheus具有优势，因为其直方图是累积表达的。也就是说，所有低于100毫秒的样本都累积到所有低于100毫秒的边界，包括这个边界。
- en: The alert criteria is shown in [Example 2-35](part0007_split_008.html#slo_boundary_percentile_prometheus).
  id: totrans-508
  prefs: []
  type: TYPE_NORMAL
  zh: 警报条件显示在[示例 2-35](part0007_split_008.html#slo_boundary_percentile_prometheus)中。
- en: Example 2-35\. Prometheus alert criteria using an SLO boundary
  id: totrans-509
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 2-35\. 使用SLO边界的Prometheus警报条件
- en: '[PRE37]'
  id: totrans-510
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: '[![1](../images/00112.png)](part0007_split_008.html#co_application_metrics_CO9-1)'
  id: totrans-511
  prefs: []
  type: TYPE_NORMAL
  zh: '[![1](../images/00112.png)](part0007_split_008.html#co_application_metrics_CO9-1)'
- en: Division symbol
  id: totrans-512
  prefs: []
  type: TYPE_NORMAL
  zh: 除法符号
- en: Visually, the effect of these two queries can be seen in [Figure 2-18](part0007_split_008.html#slo_percentile_atlas_vs_prometheus).
  id: totrans-513
  prefs: []
  type: TYPE_NORMAL
  zh: 这两个查询的视觉效果可以在[图 2-18](part0007_split_008.html#slo_percentile_atlas_vs_prometheus)中看到。
- en: '![srej 0218](../images/00023.png)'
  id: totrans-514
  prefs: []
  type: TYPE_IMG
  zh: '![srej 0218](../images/00023.png)'
- en: 'Figure 2-18\. SLO boundary alert queries: Atlas versus Prometheus'
  id: totrans-515
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 2-18\. SLO 边界警报查询：Atlas vs Prometheus
- en: SLO publishing can be enabled for timers in a few ways.
  id: totrans-516
  prefs: []
  type: TYPE_NORMAL
  zh: 可以通过几种方式为计时器启用 SLO 发布。
- en: The `Timer` fluent builder supports adding SLOs directly as the `Timer` is being
    constructed, as shown in [Example 2-36](part0007_split_008.html#timer_slo_fluent).
  id: totrans-517
  prefs: []
  type: TYPE_NORMAL
  zh: '`Timer` 流畅构建器支持在创建 `Timer` 时直接添加 SLO，如 [示例 2-36](part0007_split_008.html#timer_slo_fluent)
    所示。'
- en: Example 2-36\. Adding SLO boundaries to a Timer via the builder
  id: totrans-518
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 2-36\. 通过构建器向计时器添加 SLO 边界
- en: '[PRE38]'
  id: totrans-519
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: '[Example 2-37](part0007_split_008.html#timer_slo_meter_filter) shows how to
    add SLO boundaries with a `MeterFilter`.'
  id: totrans-520
  prefs: []
  type: TYPE_NORMAL
  zh: '[示例 2-37](part0007_split_008.html#timer_slo_meter_filter) 展示了如何通过 `MeterFilter`
    添加 SLO 边界。'
- en: Example 2-37\. Adding SLO boundaries to a Timer via a MeterFilter
  id: totrans-521
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 2-37\. 通过 MeterFilter 向计时器添加 SLO 边界
- en: '[PRE39]'
  id: totrans-522
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: '[![1](../images/00112.png)](part0007_split_008.html#co_application_metrics_CO10-1)'
  id: totrans-523
  prefs: []
  type: TYPE_NORMAL
  zh: '[![1](../images/00112.png)](part0007_split_008.html#co_application_metrics_CO10-1)'
- en: The filter will apply to this timer as it is created.
  id: totrans-524
  prefs: []
  type: TYPE_NORMAL
  zh: 创建时此计时器将应用过滤器。
- en: The next meter type is very similar to a timer.
  id: totrans-525
  prefs: []
  type: TYPE_NORMAL
  zh: 下一个计量器类型与计时器非常相似。
- en: Distribution Summaries
  id: totrans-526
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 分布摘要
- en: A distribution summary, shown in [Example 2-38](part0007_split_009.html#distribution_summary_create),
    is used to track the distribution of events. It is similar to a timer structurally,
    but it records values that do not represent a unit of time. For example, a distribution
    summary could be used to measure the payload sizes of requests hitting a server.
  id: totrans-527
  prefs: []
  type: TYPE_NORMAL
  zh: '[示例 2-38](part0007_split_009.html#distribution_summary_create) 展示了分布摘要的使用来追踪事件的分布。在结构上类似于计时器，但记录的值并不代表时间单位。例如，可以使用分布摘要来测量命中服务器的请求的有效载荷大小。'
- en: Example 2-38\. Creating a distribution summary
  id: totrans-528
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 2-38\. 创建分布摘要
- en: '[PRE40]'
  id: totrans-529
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: Micrometer also provides a fluent builder, shown in [Example 2-39](part0007_split_009.html#distribution_summary_fluent_builder)
    for distribution summaries. For maximum portability, add base units, as they are
    part of the naming convention for some monitoring systems. Optionally, you may
    provide a scaling factor that each recorded sample will be multiplied by as it
    is recorded.
  id: totrans-530
  prefs: []
  type: TYPE_NORMAL
  zh: Micrometer 还提供了一个流畅构建器，如 [示例 2-39](part0007_split_009.html#distribution_summary_fluent_builder)
    所示，用于分布摘要。为了最大可移植性，添加基本单位，因为它们是某些监控系统命名约定的一部分。可选地，您可以提供一个倍增因子，每个记录的样本将在记录时乘以该因子。
- en: Example 2-39\. The distribution summary fluent builder
  id: totrans-531
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 2-39\. 分布摘要流畅构建器
- en: '[PRE41]'
  id: totrans-532
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: Distribution summaries have all the same percentile, histogram, and SLO options
    that timers do. Timers are just a specialized distribution summary for measuring
    time. SLOs are defined as fixed values instead of durations (i.e., `1000` instead
    of `Duration.ofMillis(1000)`, where 1,000 means something, depending on what base
    unit is assigned to the distribution summary) and provide convenience methods
    for timing blocks of code. That is the only difference in the available options.
  id: totrans-533
  prefs: []
  type: TYPE_NORMAL
  zh: 分布摘要具有与计时器相同的百分位数、直方图和 SLO 选项。计时器只是专用于测量时间的特殊分布摘要。SLO 是定义为固定值而不是持续时间（例如，`1000`
    而不是 `Duration.ofMillis(1000)`，其中 1000 根据为分布摘要分配的基本单位而有所不同），并为代码块计时提供方便的方法。这是可用选项的唯一差异。
- en: A common example of a distribution summary is payload size measured in bytes.
  id: totrans-534
  prefs: []
  type: TYPE_NORMAL
  zh: 一个常见的分布摘要示例是以字节为单位测量的有效载荷大小。
- en: Much like with timers, in many real-world cases the distribution is rarely normal.
    At one point I measured payload size in bytes, which was largely normal except
    there was a sharp drop-off on the left side of the distribution, because I was
    including request headers in the payload size. So there were zero occurrences
    of request payloads less than the size of having a certain set of request headers
    present.
  id: totrans-535
  prefs: []
  type: TYPE_NORMAL
  zh: 与计时器类似，在许多实际情况下，分布很少是正态的。曾经我测量过字节的有效载荷大小，这在很大程度上是正态的，但左侧分布有明显的降低，因为包括请求头在内的请求有效载荷大小。因此，在具有一定请求头集合的情况下，请求有效载荷小于某个大小的情况是零。
- en: 'Because distribution summaries can track any unit of measure, and the distribution
    of the measured values cannot be generally known as it can be for timers, the
    best way to alert on a distribution summary has some nuance:'
  id: totrans-536
  prefs: []
  type: TYPE_NORMAL
  zh: 因为分布摘要可以追踪任何计量单位，并且测量值的分布通常不像计时器那样普遍为所知，因此警报分布摘要的最佳方式具有一些微妙之处：
- en: When the distribution is multimodal, as it is for timers, it is likely best
    to set alerts on maximum value so that you can keep track of where the “worst
    case” is.
  id: totrans-537
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当分布是多模式时，就像计时器一样，最好设置在最大值上的警报，以便可以跟踪“最坏情况”所在。
- en: In most cases, it still makes sense to use high percentiles like the 99th percentile
    for comparative analysis (see [“Automated Canary Analysis”](part0010_split_013.html#9H5VC-2d714b853a094e9a910510217e0e3d73)).
  id: totrans-538
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在大多数情况下，使用高百分位数如第 99 百分位数进行比较分析仍然是有意义的（参见[“自动金丝雀分析”](part0010_split_013.html#9H5VC-2d714b853a094e9a910510217e0e3d73)）。
- en: Long Task Timers
  id: totrans-539
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 长任务计时器
- en: 'The long task timer is a special type of timer that lets you measure time while
    an event being measured is *still running*. A timer does not record the duration
    until the task is complete. Long task timers ship several statistics:'
  id: totrans-540
  prefs: []
  type: TYPE_NORMAL
  zh: 长任务计时器是一种特殊类型的计时器，允许您在事件正在运行时测量时间。计时器直到任务完成后才记录持续时间。长任务计时器提供了几个统计信息：
- en: Active
  id: totrans-541
  prefs: []
  type: TYPE_NORMAL
  zh: 活动中
- en: The number of executions that are currently in progress.
  id: totrans-542
  prefs: []
  type: TYPE_NORMAL
  zh: 当前正在进行的执行次数。
- en: Total duration
  id: totrans-543
  prefs: []
  type: TYPE_NORMAL
  zh: 总持续时间
- en: The sum of all in-progress execution times of the block of code being measured.
  id: totrans-544
  prefs: []
  type: TYPE_NORMAL
  zh: 正在测量的代码块的所有正在进行的执行时间总和。
- en: Max
  id: totrans-545
  prefs: []
  type: TYPE_NORMAL
  zh: 最大
- en: The longest in-progress timing. The max represents the total execution time
    of the oldest still-running execution time.
  id: totrans-546
  prefs: []
  type: TYPE_NORMAL
  zh: 最长的进行中计时。最大值表示最老的仍在运行中的执行时间的总计执行时间。
- en: Histograms
  id: totrans-547
  prefs: []
  type: TYPE_NORMAL
  zh: 直方图
- en: A set of discretized buckets of in-progress tasks.
  id: totrans-548
  prefs: []
  type: TYPE_NORMAL
  zh: 用于正在进行的任务的一组离散化桶。
- en: Percentiles
  id: totrans-549
  prefs: []
  type: TYPE_NORMAL
  zh: 百分位数
- en: Precomputed percentiles of in-progress execution times.
  id: totrans-550
  prefs: []
  type: TYPE_NORMAL
  zh: 预计算的正在进行的执行时间的百分位数。
- en: '[Figure 2-19](part0007_split_010.html#long_task_timer_active_duration) shows
    how a long task timer fundamentally differs from a timer. As soon as an operation
    is complete, it no longer contributes to the total duration. In contrast, an operation
    instrumented with a timer isn’t reported *until* it is complete. Notice how at
    time t=3, total duration increases by 2 rather than just 1\. This is because we
    have two tasks that were executing beginning at t=2, so they each contribute 1
    to the total at each interval while they continue to run. At t=4, both tasks stop,
    and so total duration drops to zero, along with active count.'
  id: totrans-551
  prefs: []
  type: TYPE_NORMAL
  zh: '[图 2-19](part0007_split_010.html#long_task_timer_active_duration)展示了长任务计时器与普通计时器的根本区别。一旦操作完成，它就不再对总持续时间做出贡献。相比之下，使用计时器进行操作直到完成时才会报告。请注意，在时间
    t=3 时，总持续时间增加了 2 而不仅仅是 1。这是因为我们有两个任务在 t=2 开始执行，所以它们在继续运行时每个时间间隔都贡献了 1。在 t=4 时，两个任务都停止了，因此总持续时间降至零，同时活动计数也降至零。'
- en: Long task timer average has a different meaning than a timer average. It is
    the average of the time active operations that have been running *to this point*.
    Similarly, maximum represents the longest running task to this point, decayed
    in a similar way that timer maximum is.
  id: totrans-552
  prefs: []
  type: TYPE_NORMAL
  zh: 长任务计时器的平均值与计时器的平均值有不同的含义。它是截至目前为止正在运行的活动操作的平均时间。类似地，最大值表示到目前为止运行时间最长的任务，以类似计时器最大值的方式衰减。
- en: '![srej 0219](../images/00005.png)'
  id: totrans-553
  prefs: []
  type: TYPE_IMG
  zh: '![srej 0219](../images/00005.png)'
- en: Figure 2-19\. Long task timer active and total duration for two tasks
  id: totrans-554
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 2-19\. 两个任务的长任务计时器活动和总持续时间
- en: The `MeterRegistry` interface contains convenience methods for creating long
    task timers, as shown in [Example 2-40](part0007_split_010.html#long_task_timer_create).
  id: totrans-555
  prefs: []
  type: TYPE_NORMAL
  zh: '`MeterRegistry`接口包含用于创建长任务计时器的便捷方法，如[示例 2-40](part0007_split_010.html#long_task_timer_create)所示。'
- en: Example 2-40\. Creating long task timers
  id: totrans-556
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 2-40\. 创建长任务计时器
- en: '[PRE42]'
  id: totrans-557
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: The `LongTaskTimer` fluent builder contains more options, shown in [Example 2-41](part0007_split_010.html#long_task_timer_fluent_builder).
  id: totrans-558
  prefs: []
  type: TYPE_NORMAL
  zh: '`LongTaskTimer`流畅构建器包含更多选项，如[示例 2-41](part0007_split_010.html#long_task_timer_fluent_builder)所示。'
- en: Example 2-41\. Fluent builder for long task timers
  id: totrans-559
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 2-41\. 长任务计时器的流畅构建器
- en: '[PRE43]'
  id: totrans-560
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
- en: Long task timers have a record method that returns a `Sample` that can later
    be stopped and convenience methods for recording a body of code wrapped in a lambda,
    as shown in [Example 2-42](part0007_split_010.html#long_task_timer_record_execution).
  id: totrans-561
  prefs: []
  type: TYPE_NORMAL
  zh: 长任务计时器具有一个记录方法，返回一个`Sample`，稍后可以停止，并提供了方便的方法来记录用 Lambda 包装的代码块，如[示例 2-42](part0007_split_010.html#long_task_timer_record_execution)所示。
- en: Example 2-42\. Recording execution with a long task timer
  id: totrans-562
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 2-42\. 使用长任务计时器记录执行
- en: '[PRE44]'
  id: totrans-563
  prefs: []
  type: TYPE_PRE
  zh: '[PRE44]'
- en: A good example of a long task timer is in [Edda](https://oreil.ly/qXUkv), which
    caches AWS resources such as instances, volumes, and autoscaling groups. Normally
    all data can be refreshed in a few minutes. If the AWS services are performing
    more slowly than usual, it can take much longer. A long task timer can be used
    to track the overall time for refreshing the metadata.
  id: totrans-564
  prefs: []
  type: TYPE_NORMAL
  zh: 一个好的长任务计时器示例在[Edda](https://oreil.ly/qXUkv)中，它缓存 AWS 资源，如实例、卷和自动缩放组。通常，所有数据可以在几分钟内刷新。如果
    AWS 服务的执行速度比平时慢，可能需要更长时间。可以使用长任务计时器来跟踪刷新元数据的总时间。
- en: In application code, it is common for such long-running processes to be implemented
    with something like Spring Boot’s `@Scheduled`, as shown in [Example 2-43](part0007_split_010.html#explicit_ltt).
  id: totrans-565
  prefs: []
  type: TYPE_NORMAL
  zh: 在应用程序代码中，通常会使用类似Spring Boot的`@Scheduled`来实现此类长时间运行的进程，如[示例 2-43](part0007_split_010.html#explicit_ltt)所示。
- en: Example 2-43\. An explicitly recorded long task timer for a scheduled operation
  id: totrans-566
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 2-43\. 明确记录的长任务定时器用于计划操作
- en: '[PRE45]'
  id: totrans-567
  prefs: []
  type: TYPE_PRE
  zh: '[PRE45]'
- en: Some frameworks like Spring Boot also respond to the `@Timed` annotation to
    create long task timers when the `longTask` attribute is set to `true`, as in
    [Example 2-44](part0007_split_010.html#annotation_ltt).
  id: totrans-568
  prefs: []
  type: TYPE_NORMAL
  zh: 一些框架如Spring Boot还会响应`@Timed`注解，当设置`longTask`属性为`true`时创建长任务计时器，如[示例 2-44](part0007_split_010.html#annotation_ltt)所示。
- en: Example 2-44\. An annotation-based long task timer for a scheduled operation
  id: totrans-569
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 2-44\. 基于注解的长任务定时器用于计划操作
- en: '[PRE46]'
  id: totrans-570
  prefs: []
  type: TYPE_PRE
  zh: '[PRE46]'
- en: If we wanted to alert when this process exceeds our threshold, with a long task
    timer we will receive that alert at the first reporting interval after we have
    exceeded the threshold. With a regular timer, we wouldn’t receive the alert until
    the first reporting interval after the process completed, over an hour later!
  id: totrans-571
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们想在此过程超过阈值时发出警报，使用长任务计时器，我们将在超过阈值后的第一个报告间隔收到警报。使用常规计时器，我们要等到进程完成后的第一个报告间隔，这可能需要一个小时后！
- en: Choosing the Right Meter Type
  id: totrans-572
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 选择正确的计量器类型
- en: In the instrumentation libraries for hierarchical metrics systems (see [“Hierarchical
    Metrics”](part0006_split_003.html#hierarchical_metrics)), typically only gauges
    and counters were supported. This led to a habit of precalculating statistics
    (most commonly rates like request throughput) and presenting them to the monitoring
    system as a gauge that could fluctuate up or down. Since Micrometer always exposes
    counters in a way that lets you derive a rate at query time, there is no need
    to perform this calculation manually in your application code.
  id: totrans-573
  prefs: []
  type: TYPE_NORMAL
  zh: 在分层指标系统的仪表化库中（参见[“分层指标”](part0006_split_003.html#hierarchical_metrics)），通常仅支持量规和计数器。这导致预先计算统计数据（最常见的是请求吞吐量等比率）并将其呈现给监控系统作为可以上下波动的量规的习惯。由于Micrometer始终以一种让您可以在查询时推导出速率的方式公开计数器，因此在应用程序代码中没有必要手动执行此计算。
- en: Both `Timer` and `DistributionSummary` always publish a count of events in addition
    to other measurements. There should never be a reason to count the number of executions
    of a block of code. They should be timed instead.
  id: totrans-574
  prefs: []
  type: TYPE_NORMAL
  zh: '`Timer`和`DistributionSummary`始终发布事件计数，除其他测量外。永远不应该统计代码块的执行次数，而应该计时。'
- en: Which Meter Type to Choose?
  id: totrans-575
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 选择哪种计量器类型？
- en: Never gauge something you can count, and never count something you can time.
  id: totrans-576
  prefs: []
  type: TYPE_NORMAL
  zh: 永远不要度量您可以计数的东西，也不要计数您可以计时的东西。
- en: As a general rule, select a `LongTaskTimer` whenever timings exceed two minutes,
    when you need to monitor in-flight requests, and especially when an operation’s
    failure may inflate the expected time from a few minutes to many minutes or hours.
  id: totrans-577
  prefs: []
  type: TYPE_NORMAL
  zh: 一般来说，当计时超过两分钟、需要监视飞行请求时，尤其是当操作的失败可能使预期时间从几分钟增加到几分钟或几小时时，应选择`LongTaskTimer`。
- en: Controlling Cost
  id: totrans-578
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 控制成本
- en: The cost of metrics grows as you instrument more and more pieces of your application.
    Perhaps at the beginning you only start with shipping basic statistics like memory
    and processor utilization, and grow to additional areas like HTTP request monitoring,
    cache performance, database interactions, and connection pool saturation,. In
    fact, many of these basic use cases are going to be increasingly automatically
    instrumented by frameworks like Spring Boot.
  id: totrans-579
  prefs: []
  type: TYPE_NORMAL
  zh: 随着您为应用程序的更多部分进行仪表化，指标的成本会增加。也许最初您只是开始传输基本的统计数据，比如内存和处理器利用率，并逐渐扩展到额外的领域，如HTTP请求监控、缓存性能、数据库交互和连接池饱和度。实际上，许多这些基本用例将会越来越多地由Spring
    Boot等框架自动进行仪表化。
- en: Expanding instrumentation to additional components isn’t the likely source of
    high cost in telemetry, however. To examine the cost of an individual metric,
    think about the unique permutations of a metric name and all of its key-value
    tag combinations. These form a set of time series on the backend, and we refer
    to the size of this set as the *cardinality* of the metric.
  id: totrans-580
  prefs: []
  type: TYPE_NORMAL
  zh: 扩展仪表化到额外的组件并非遥测成本高昂的主要来源。要检查单个指标的成本，请考虑指标名称及其所有键-值标签组合的唯一排列。这些形成后端的时间序列集合，我们将其称为指标的*基数*。
- en: It is essential that you carefully bound a metric’s cardinality by considering
    all the possible key-value tags combinations that could result in a high number
    of unique values and limit them in some way. The cardinality of a metric is the
    product of the unique tag values for each tag key. The reasonable limit you place
    on tag cardinality varies from monitoring system to monitoring system, but in
    general keeping it in the thousands is a reasonable upper bound. At Netflix, the
    general advice was to keep metric cardinality under one million time series. This
    is probably at the outside edge of what most organizations would find responsible.
  id: totrans-581
  prefs: []
  type: TYPE_NORMAL
  zh: 通过考虑可能导致大量唯一值的所有可能的键-值标签组合，仔细地界定度量的基数是至关重要的。度量的基数是每个标签键的唯一标签值的乘积。你在标签基数上设置的合理限制因监控系统而异，但通常保持在数千个是一个合理的上限。在Netflix，一般建议将度量的基数保持在一百万时间序列以下。这可能是大多数组织认为负责任的极限。
- en: Remember, metrics are intended to present an aggregate view of an indicator,
    and they shouldn’t be used to try to examine event-level or request-level performance.
    Other forms of telemetry like distributed tracing or logging are more appropriate
    for individual event-level telemetry.
  id: totrans-582
  prefs: []
  type: TYPE_NORMAL
  zh: 记住，度量旨在呈现指标的汇总视图，不应用于尝试检查事件级或请求级性能。其他形式的遥测，如分布式跟踪或日志记录，更适合个体事件级的遥测。
- en: 'Framework-provided telemetry is generally carefully crafted to limit tag cardinality.
    For example, Spring Boot’s timing of Spring WebMVC and WebFlux adds a handful
    of tags but carefully limits how each contributes to the cardinality of the metric.
    The following list bexplains what each tag key means:'
  id: totrans-583
  prefs: []
  type: TYPE_NORMAL
  zh: 框架提供的遥测通常会精心设计以限制标签基数。例如，Spring Boot对Spring WebMVC和WebFlux的时间测量会添加少量标签，但会精确地限制每个标签如何对度量的基数做出贡献。下面的列表解释了每个标签键的含义：
- en: Method
  id: totrans-584
  prefs: []
  type: TYPE_NORMAL
  zh: 方法
- en: There are a small number of possible values for HTTP method, based on the HTTP
    specification, e.g., `GET` or `POST`.
  id: totrans-585
  prefs: []
  type: TYPE_NORMAL
  zh: 基于HTTP规范，HTTP方法有少量可能的取值，例如，`GET`或`POST`。
- en: Status
  id: totrans-586
  prefs: []
  type: TYPE_NORMAL
  zh: 状态
- en: 'HTTP status codes come from the HTTP specification, so are naturally limited
    in the possible values. Also, most API endpoints are going to realistically only
    return one of a few values: 200–202 success/created/accepted, 304 not modified,
    400 bad request, 500 internal server error, and maybe 403 forbiddden. Most won’t
    return even this amount of variation.'
  id: totrans-587
  prefs: []
  type: TYPE_NORMAL
  zh: HTTP状态码来自HTTP规范，因此在可能的取值方面自然是有限的。此外，大多数API端点实际上只会返回少数几个值：200–202 成功/创建/已接受，304
    未修改，400 错误请求，500 服务器内部错误，也许还有403 禁止。大多数情况下，不会返回这么多的变化。
- en: Outcome
  id: totrans-588
  prefs: []
  type: TYPE_NORMAL
  zh: 结果
- en: A summarization of status code, e.g., `SUCCESS`, `CLIENT_ERROR`, or `SERVER_ERROR`.
  id: totrans-589
  prefs: []
  type: TYPE_NORMAL
  zh: 状态码的总结，例如，`SUCCESS`，`CLIENT_ERROR`或`SERVER_ERROR`。
- en: URI
  id: totrans-590
  prefs: []
  type: TYPE_NORMAL
  zh: 统一资源标识符（URI）
- en: This tag is a good demonstration of how tag cardinality could quickly get out
    of hand. For 200–400 status codes, the URI is going to be the path that the request
    was mapped to. But when the endpoint contains a path variable or request parameters,
    the framework is careful to use the *unsubstituted* path here rather than the
    raw path of the request, e.g., `/api/customer/{id}` instead of `/api/customer/123`
    and `/api/customer/456`. Not only does this help limit the metric’s cardinality,
    but it is also more useful to reason about the performance of all requests to
    `/api/customer/{id}` in the aggregate as opposed to groups of requests that retrieved
    the particular customer with ID `123` or `456`. In addition to path substitution,
    the URI should be further constrained in cases where the server is ultimately
    going to return a 404\. Otherwise, every mistyped URI `/api/doesntexist/1`, `/api/doesntexistagain`,
    etc., results in a new tag. So Spring Boot uses a URI tag value of `NOT_FOUND`
    whenever the status code is 404\. Similarly, it uses a `REDIRECT` value when the
    status code is 403 because the server may always redirect unauthenticated requests
    to the authentication mechanism, even when the requested path doesn’t exist.
  id: totrans-591
  prefs: []
  type: TYPE_NORMAL
  zh: 此标签很好地演示了标签基数可能迅速失控的情况。对于状态码为200至400的情况，URI 将是请求映射到的路径。但是当端点包含路径变量或请求参数时，框架会小心地在此处使用*未替换*路径，而不是请求的原始路径，例如，`/api/customer/{id}`
    而不是 `/api/customer/123` 和 `/api/customer/456`。这不仅有助于限制指标的基数，而且对于总体上关于`/api/customer/{id}`所有请求的性能进行推理也更为有用，而不是针对检索特定客户ID
    `123` 或 `456` 的请求组。除了路径替换之外，在服务器最终将返回404的情况下，还应进一步约束URI。否则，每个打错的URI `/api/doesntexist/1`，`/api/doesntexistagain`
    等都会导致一个新的标签。因此，Spring Boot 在状态码为404时使用了URI标签值`NOT_FOUND`。类似地，当状态码为403时，它使用`REDIRECT`值，因为服务器可能总是将未经身份验证的请求重定向到身份验证机制，即使请求的路径不存在。
- en: Exception
  id: totrans-592
  prefs: []
  type: TYPE_NORMAL
  zh: 异常
- en: When the request results in a 500 internal server error, this tag contains the
    exception class name, which is just a simple way of grouping the general classes
    of failures—for example, null pointer exceptions versus a connection timeout on
    a downstream service request. Again, there are generally only a few possible classes
    of failures based on the implementation of the endpoint, so this is naturally
    bounded.
  id: totrans-593
  prefs: []
  type: TYPE_NORMAL
  zh: 当请求导致500内部服务器错误时，此标签包含异常类名，这只是一种简单的方法来对失败的一般类进行分组，例如，空指针异常与下游服务请求的连接超时。同样，基于端点实现，通常只有几种可能的失败类别，因此这是自然而然地受到限制的。
- en: For HTTP server request metrics then, the total cardinality might be something
    like [Equation 2-7](part0007_split_013.html#http_server_request_cardinality).
  id: totrans-594
  prefs: []
  type: TYPE_NORMAL
  zh: 对于HTTP服务器请求指标，总基数可能类似于[Equation 2-7](part0007_split_013.html#http_server_request_cardinality)。
- en: Equation 2-7\. Cardinality of HTTP server request metric for a single endpoint
  id: totrans-595
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 方程式 2-7. 单个端点的HTTP服务器请求指标的基数
- en: <math alttext="2 m e t h o d s times 4 s t a t u s e s times 2 o u t c o m e
    s times 1 upper U upper R upper I times 3 e x c e p t i o n s equals 48 t a g
    v a l u e s" display="block"><mrow><mn>2</mn> <mi>m</mi> <mi>e</mi> <mi>t</mi>
    <mi>h</mi> <mi>o</mi> <mi>d</mi> <mi>s</mi> <mo>×</mo> <mn>4</mn> <mi>s</mi> <mi>t</mi>
    <mi>a</mi> <mi>t</mi> <mi>u</mi> <mi>s</mi> <mi>e</mi> <mi>s</mi> <mo>×</mo> <mn>2</mn>
    <mi>o</mi> <mi>u</mi> <mi>t</mi> <mi>c</mi> <mi>o</mi> <mi>m</mi> <mi>e</mi> <mi>s</mi>
    <mo>×</mo> <mn>1</mn> <mi>U</mi> <mi>R</mi> <mi>I</mi> <mo>×</mo> <mn>3</mn> <mi>e</mi>
    <mi>x</mi> <mi>c</mi> <mi>e</mi> <mi>p</mi> <mi>t</mi> <mi>i</mi> <mi>o</mi> <mi>n</mi>
    <mi>s</mi> <mo>=</mo> <mn>48</mn> <mi>t</mi> <mi>a</mi> <mi>g</mi> <mi>v</mi>
    <mi>a</mi> <mi>l</mi> <mi>u</mi> <mi>e</mi> <mi>s</mi></mrow></math>
  id: totrans-596
  prefs: []
  type: TYPE_NORMAL
  zh: <math alttext="2 m e t h o d s times 4 s t a t u s e s times 2 o u t c o m e
    s times 1 upper U upper R upper I times 3 e x c e p t i o n s equals 48 t a g
    v a l u e s" display="block"><mrow><mn>2</mn> <mi>m</mi> <mi>e</mi> <mi>t</mi>
    <mi>h</mi> <mi>o</mi> <mi>d</mi> <mi>s</mi> <mo>×</mo> <mn>4</mn> <mi>s</mi> <mi>t</mi>
    <mi>a</mi> <mi>t</mi> <mi>u</mi> <mi>s</mi> <mi>e</mi> <mi>s</mi> <mo>×</mo> <mn>2</mn>
    <mi>o</mi> <mi>u</mi> <mi>t</mi> <mi>c</mi> <mi>o</mi> <mi>m</mi> <mi>e</mi> <mi>s</mi>
    <mo>×</mo> <mn>1</mn> <mi>U</mi> <mi>R</mi> <mi>I</mi> <mo>×</mo> <mn>3</mn> <mi>e</mi>
    <mi>x</mi> <mi>c</mi> <mi>e</mi> <mi>p</mi> <mi>t</mi> <mi>i</mi> <mi>o</mi> <mi>n</mi>
    <mi>s</mi> <mo>=</mo> <mn>48</mn> <mi>t</mi> <mi>a</mi> <mi>g</mi> <mi>v</mi>
    <mi>a</mi> <mi>l</mi> <mi>u</mi> <mi>e</mi> <mi>s</mi></mrow></math>
- en: Resist the urge to overoptimize for cost. In particular, there is no need to
    try to limit the publication of zero values, because in some application states
    in theory all metrics could be nonzero for a particular publishing interval. It
    is at that moment of greatest saturation where you would be publishing the most
    nonzero metrics that will govern the cost of metrics to you, not the low points
    where you could publish some lesser set of metrics by excluding zero values. Also,
    reporting a zero value is a useful signal that something is just not happening
    as opposed to the service not reporting at all.
  id: totrans-597
  prefs: []
  type: TYPE_NORMAL
  zh: 不要为了成本而过度优化。特别是，没有必要试图限制零值的发布，因为在理论上的某些应用状态下，特定发布间隔内的所有指标都可能是非零的。正是在这种饱和度最高的时刻，您将发布最多的非零指标，这些指标将主导您的成本，而不是在低点，您可以通过排除零值来发布一些较少的指标。此外，报告零值是一个有用的信号，表明某些事情并未发生，而不是服务根本未报告。
- en: In some cases, where tag cardinality cannot be limited easily by out-of-the-box
    instrumentation, you will find the configuration of a set of metrics makes you
    define how to limit the tags responsibly. A good example is Micrometer’s instrumentation
    for the Jetty `HttpClient`. A typical request using the Jetty `HttpClient` looks
    like [Example 2-45](part0007_split_013.html#jetty_http_client_call). The `HttpClient`
    API doesn’t provide a mechanism for providing a path variable to the `POST` call
    and a collection of variable values to substitute later, so by the time Micrometer’s
    Jetty `Request.Listener` intercepts the request, path variables have already been
    substituted irreversibly.
  id: totrans-598
  prefs: []
  type: TYPE_NORMAL
  zh: 在某些情况下，如果标签的基数不能轻松地通过开箱即用的仪器来限制，你会发现一组指标的配置会让你负责定义如何负责任地限制标签。一个很好的例子是 Micrometer
    为 Jetty `HttpClient` 进行仪器化。使用 Jetty `HttpClient` 进行典型请求看起来像 [例子 2-45](part0007_split_013.html#jetty_http_client_call)。`HttpClient`
    API 不提供向 `POST` 调用提供路径变量和稍后替换的变量值的机制，因此当 Micrometer 的 Jetty `Request.Listener`
    拦截请求时，路径变量已经被不可逆转地替换了。
- en: Example 2-45\. Jersey HTTP client call with path variable string concatenation
  id: totrans-599
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: '[例子 2-45](part0007_split_013.html#jetty_http_client_call)。Jersey HTTP 客户端调用带有路径变量字符串连接'
- en: '[PRE47]'
  id: totrans-600
  prefs: []
  type: TYPE_PRE
  zh: '[PRE47]'
- en: Jetty client metrics should use the unsubstituted path for the `uri` tag for
    the same reason the URI tag on Spring Boot’s instrumentation of WebMVC and WebFlux
    was based on an unsubstituted value. It becomes the responsibility of the engineer
    using Jetty `HttpClient` to specify how to `unsubstitute` path variables for the
    purpose of tagging, as shown in [Example 2-46](part0007_split_013.html#jetty_http_client_metrics_config).
  id: totrans-601
  prefs: []
  type: TYPE_NORMAL
  zh: Jetty 客户端指标应该使用未替换的路径来标记 `uri` 标签，原因与 Spring Boot 对 WebMVC 和 WebFlux 进行仪表化时
    URI 标签基于未替换的值相同。将如何为 Jetty `HttpClient` 标记变量路径的责任交给了使用 Jetty `HttpClient` 的工程师，如
    [例子 2-46](part0007_split_013.html#jetty_http_client_metrics_config) 所示。
- en: Example 2-46\. Jersey HTTP client metrics configuration
  id: totrans-602
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: '[例子 2-46](part0007_split_013.html#jetty_http_client_metrics_config)。Jersey
    HTTP 客户端指标配置'
- en: '[PRE48]'
  id: totrans-603
  prefs: []
  type: TYPE_PRE
  zh: '[PRE48]'
- en: Coordinated Omission
  id: totrans-604
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 协调遗漏
- en: My first job in high school was as a fast-food worker. Running the drive-through
    window gave me some early firsthand experience about how to lie with statistics.
  id: totrans-605
  prefs: []
  type: TYPE_NORMAL
  zh: 我高中的第一份工作是做快餐店的快餐工人。驶入式快餐窗口为我提供了一些早期的第一手经验，了解如何用统计数据撒谎。
- en: Our performance as a store was evaluated on the basis of the *average* duration
    from the time a customer placed an order at the menu to when they departed with
    their order. Our store was fairly understaffed typically, so at times the average
    time exceeded our goal. We simply waited until a lull in activity and did laps
    around the building with one of our cars. A couple dozen three-to-four-second
    service times will lower the average quickly (again, average is a problem statistic
    more often than not)! We could make our service time look arbitrarily good. At
    some point, the corporate headquarters added minimum service time to the average
    statistic they were evaluating, and our cheating was over.
  id: totrans-606
  prefs: []
  type: TYPE_NORMAL
  zh: 我们作为一家商店的表现是根据客户在菜单上下订单到离开店铺的*平均*持续时间来评估的。我们店通常人手不足，所以有时平均时间会超过我们的目标。我们只需等到活动停顿，然后用我们的一辆车在建筑周围绕圈。几十个三到四秒的服务时间将迅速降低平均值（再次强调，平均值往往是一个有问题的统计指标）！我们可以让我们的服务时间看起来任意好。在某个时候，总部将最短服务时间添加到他们评估的平均统计数据中，我们的作弊就结束了。
- en: In one bizarre case, a bus came through the drive-through and each window of
    the bus ordered. Our service time was only driven by a pressure plate near the
    menu and after the service window, so it was unaware of service time per order,
    only per vehicle. Clearly we didn’t serve the bus order as quickly as we would
    serve a typical car, and the ripple effect of the bus on other service times illustrates
    a concept called *coordinated omission*, in which if we aren’t careful, we monitor
    some definition of service time but exclude wait time. There are two examples
    of coordinated omission with this bus incident, illustrated in [Figure 2-20](part0007_split_014.html#coordinated_omission_bus).
  id: totrans-607
  prefs: []
  type: TYPE_NORMAL
  zh: 在一个奇怪的案例中，一辆公共汽车开进了驶入式快餐窗口，车上每个窗口都点了餐。我们的服务时间仅由菜单附近的压力板控制，服务窗口后，我们无法感知每个订单的服务时间，只能感知每辆车的服务时间。显然，我们没有像对待一辆普通轿车那样快速为公共汽车提供订单，公共汽车对其他服务时间的连锁反应说明了一个称为*协调遗漏*的概念，即如果我们不小心，我们会监视某种定义的服务时间，但排除等待时间。在这个公交事件中，有两个协调遗漏的例子，如
    [图 2-20](part0007_split_014.html#coordinated_omission_bus) 所示。
- en: '![srej 0220](../images/00011.png)'
  id: totrans-608
  prefs: []
  type: TYPE_IMG
  zh: '![srej 0220](../images/00011.png)'
- en: Figure 2-20\. Coordinated omission caused by a bus in the drive-through
  id: totrans-609
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 2-20\. 在驶入式快餐窗口中由一辆公共汽车引起的协调遗漏
- en: At the point where the bus is at the window receiving its orders, there are
    only three other cars whose service time is being recorded (the three that have
    activated the pressure plate at the menu). The two cars behind the menu aren’t
    being observed by the system. The actual impact of the bus’s obstruction was on
    five other customers, but we will only see a service time impact on three.
  id: totrans-610
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在公交车在窗口接收订单时，只有其他三辆车的服务时间正在记录（已激活菜单上的压力板的三辆车）。菜单后面的两辆车并未被系统观察到。公交车阻塞的实际影响是对其他五名顾客，但我们只会看到三个顾客的服务时间影响。
- en: Suppose instead of service time being determined from the menu through leaving
    the order window, we instead monitored service time as just the time spent at
    the order window. The average service time then was only affected by how long
    it took to serve the bus alone, and not the compounding effect it had on the cars
    behind it.
  id: totrans-611
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 假设服务时间不是通过菜单到离开订单窗口来决定，而是通过仅监控在订单窗口处所用的时间作为服务时间。那么，平均服务时间只受仅仅为公交车服务所需的时间影响，而不受其对后面车辆的复合效应影响。
- en: These effects are similar to the effect that thread pools have on request timing.
    If a response time is calculated based on when a request handler begins processing
    a request and ends when the response is committed, there is no accounting for
    the time that a request sat in a queue waiting for an available request handler
    thread to begin processing it.
  id: totrans-612
  prefs: []
  type: TYPE_NORMAL
  zh: 这些效果类似于线程池对请求时间的影响。如果响应时间是基于请求处理程序开始处理请求时计算的，并在响应提交时结束，那么没有计算请求在队列中等待可用请求处理程序线程开始处理它的时间。
- en: 'The other consequence of coordinated omission illustrated by this example is
    that blocking the drive-through lane prevents the restaurant from being totally
    overwhelmed by a steady state of customer orders. In fact, the appearance of a
    long line at the drive-through may have discouraged would-be customers from even
    attempting an order. Thread pools can have this effect as well. Coordinated omission
    arises from several sources:'
  id: totrans-613
  prefs: []
  type: TYPE_NORMAL
  zh: 此示例所示的协调省略的另一个后果是，阻塞驶入通道会阻止餐厅被稳定的顾客订单完全压倒。事实上，驶入通道处长队可能已经阻止潜在顾客尝试下单。线程池也可能产生这种效果。协调省略源于几个方面：
- en: Serverless functions
  id: totrans-614
  prefs: []
  type: TYPE_NORMAL
  zh: 无服务器函数
- en: Measuring the execution of a serverless function from the perspective of that
    function of course doesn’t record the time required to launch the function.
  id: totrans-615
  prefs: []
  type: TYPE_NORMAL
  zh: 从服务器无服务器函数的执行角度来衡量其执行时间，当然不会记录启动函数所需的时间。
- en: Pauses
  id: totrans-616
  prefs: []
  type: TYPE_NORMAL
  zh: 暂停
- en: Pauses come in many forms—for example, the JVM pauses due to garbage collection,
    a reindexing database becomes momentarily unresponsive, and cache buffers flush
    to disk. Execution pauses are reported as higher latencies on in-flight timings,
    but operations for which timings haven’t yet started will report unrealistically
    low latencies.
  id: totrans-617
  prefs: []
  type: TYPE_NORMAL
  zh: 暂停有很多形式，例如，由于垃圾收集而导致的JVM暂停，重新索引的数据库短暂地失去响应性，以及缓存缓冲区刷新到磁盘。执行暂停被报告为飞行时间的较高延迟，但尚未开始计时的操作将报告不现实的低延迟。
- en: Load testers
  id: totrans-618
  prefs: []
  type: TYPE_NORMAL
  zh: 负载测试人员
- en: Conventional load testers back up in their own thread pools before truly saturating
    a service.
  id: totrans-619
  prefs: []
  type: TYPE_NORMAL
  zh: 传统的负载测试工具在真正使服务饱和之前会在它们自己的线程池中备份。
- en: The need for accurate load tests is so common that we’ll go into a little more
    detail about them.
  id: totrans-620
  prefs: []
  type: TYPE_NORMAL
  zh: 对准确的负载测试的需求是如此普遍，以至于我们将会稍微详细地讨论它们。
- en: Load Testing
  id: totrans-621
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 负载测试
- en: Some conventional load testers like Apache Bench generate requests at a particular
    rate. Aggregated statistics are generated from the set of all response times.
    When responses don’t fit inside the collection bucket interval, the next request
    will be delayed.
  id: totrans-622
  prefs: []
  type: TYPE_NORMAL
  zh: 一些传统的负载测试工具如Apache Bench以特定速率生成请求。从所有响应时间集合生成聚合统计信息。当响应不符合收集桶间隔时，下一个请求将延迟。
- en: In this way, a service that is becoming oversaturated doesn’t get pushed over
    the edge because the unintentional coordination of a longer response time causes
    the load test to back off. This coordination comes from the fact that these types
    of tests use a blocking request model that effectively limits concurrency to less
    than or equal to the number of cores on the machine running the test.
  id: totrans-623
  prefs: []
  type: TYPE_NORMAL
  zh: 这种方式，一个变得过度饱和的服务不会因为无意间协调长时间响应而被推到边缘，导致负载测试退却。这种协调来自于这些类型的测试使用的阻塞请求模型，有效地限制并发量小于或等于运行测试的机器上的核心数。
- en: Real users don’t have this kind of coordination. They interact with your service
    independently of one another, and so can saturate the service to a far greater
    degree. One effective way to simulate user behavior is to saturate your service
    with a nonblocking load test. Gatling and JMeter each act this way (but Apache
    Bench does not). But to illustrate how an effective load test should work, we
    can use Spring’s nonblocking `WebClient` and Project Reactor to create a simple
    nonblocking load test. The result is shown in [Example 2-47](part0007_split_015.html#6LLAA-2d714b853a094e9a910510217e0e3d73).
    It’s in fact so easy to build these nonblocking load tests now that maybe it’s
    not worth the extra cognitive overhead of dedicated tools like JMeter and Gatling.
    You’ll have to decide this for yourself and your team.
  id: totrans-624
  prefs: []
  type: TYPE_NORMAL
  zh: 真正的用户没有这种协调能力。 他们独立于彼此与您的服务进行交互，因此可以更大程度地使服务饱和。 模拟用户行为的一种有效方法是使用非阻塞负载测试使您的服务饱和。
    Gatling 和 JMeter 都是这样操作的（但 Apache Bench 不是）。 但是，为了说明有效的负载测试应该如何工作，我们可以使用 Spring
    的非阻塞`WebClient`和 Project Reactor 创建一个简单的非阻塞负载测试。 结果如 [示例 2-47](part0007_split_015.html#6LLAA-2d714b853a094e9a910510217e0e3d73)
    所示。 实际上，现在构建这些非阻塞负载测试是如此容易，以至于也许不值得使用专用工具如 JMeter 和 Gatling 的额外认知负担。 您将不得不为自己和您的团队决定这一点。
- en: Example 2-47\. A nonblocking load test with WebClient and Project Reactor
  id: totrans-625
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 2-47\. 使用 WebClient 和 Project Reactor 的非阻塞负载测试
- en: '[PRE49]'
  id: totrans-626
  prefs: []
  type: TYPE_PRE
  zh: '[PRE49]'
- en: '[![1](../images/00112.png)](part0007_split_015.html#co_application_metrics_CO11-1)'
  id: totrans-627
  prefs: []
  type: TYPE_NORMAL
  zh: '[![1](../images/00112.png)](part0007_split_015.html#co_application_metrics_CO11-1)'
- en: Configure a registry to ship metrics from the load test’s perspective to a monitoring
    system of choice.
  id: totrans-628
  prefs: []
  type: TYPE_NORMAL
  zh: 配置一个注册表，将负载测试的视角的度量发送到所选择的监控系统。
- en: '[![2](../images/00059.png)](part0007_split_015.html#co_application_metrics_CO11-2)'
  id: totrans-629
  prefs: []
  type: TYPE_NORMAL
  zh: '[![2](../images/00059.png)](part0007_split_015.html#co_application_metrics_CO11-2)'
- en: Generate an infinite flux, or if you want to run this for a particular number
    of requests, you can use `Flux.range(0, MAX_REQUESTS)` instead.
  id: totrans-630
  prefs: []
  type: TYPE_NORMAL
  zh: 生成一个无限流，或者如果您想要为特定数量的请求运行此操作，可以使用 `Flux.range(0, MAX_REQUESTS)`。
- en: '[![3](../images/00067.png)](part0007_split_015.html#co_application_metrics_CO11-3)'
  id: totrans-631
  prefs: []
  type: TYPE_NORMAL
  zh: '[![3](../images/00067.png)](part0007_split_015.html#co_application_metrics_CO11-3)'
- en: Clamp the rate at which you want the test to send requests to the service.
  id: totrans-632
  prefs: []
  type: TYPE_NORMAL
  zh: 限制您希望测试发送请求到服务的速率。
- en: The difference between a reactive load test like this and a conventional load
    test is significant, as seen in [Figure 2-21](part0007_split_015.html#non_blocking_vs_conventional_load_test).
    Conventional load tests (because they are blocking, and therefore can only have
    a concurrency level equal to or less than the number of cores on the machine running
    the test) show a max latency less than 10 ms. A nonblocking reactive load test
    shows a tower of latencies all the way up to greater than 200 ms, with a strong
    band greater than 200 ms as the application becomes saturated.
  id: totrans-633
  prefs: []
  type: TYPE_NORMAL
  zh: 这样的反应式负载测试与传统负载测试之间的差异是显著的，如 [图 2-21](part0007_split_015.html#non_blocking_vs_conventional_load_test)
    所示。 传统负载测试（因为它们是阻塞的，因此并发级别只能等于或小于运行测试的机器上的核心数）显示的最大延迟小于 10 毫秒。 非阻塞的反应式负载测试显示了一堆延迟，直到大于
    200 毫秒，以及一个强大的大于 200 毫秒的频带，当应用程序变得饱和时。
- en: '![srej 0221](../images/00069.png)'
  id: totrans-634
  prefs: []
  type: TYPE_IMG
  zh: '![srej 0221](../images/00069.png)'
- en: Figure 2-21\. Blocking load test versus a nonblocking (reactive) load test
  id: totrans-635
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 2-21\. 阻塞负载测试与非阻塞（反应式）负载测试之间的效果
- en: The effect (shown in [Figure 2-22](part0007_split_015.html#non_blocking_vs_conventional_load_test_max))
    on the alert criteria suggested in [“Latency”](part0009_split_017.html#8ILV9-2d714b853a094e9a910510217e0e3d73)
    is noticeable, as expected.
  id: totrans-636
  prefs: []
  type: TYPE_NORMAL
  zh: 如预期的那样，对[“延迟”](part0009_split_017.html#8ILV9-2d714b853a094e9a910510217e0e3d73)建议的警报条件的影响（如
    [图 2-22](part0007_split_015.html#non_blocking_vs_conventional_load_test_max) 所示）是明显的。
- en: '![srej 0222](../images/00068.png)'
  id: totrans-637
  prefs: []
  type: TYPE_IMG
  zh: '![srej 0222](../images/00068.png)'
- en: Figure 2-22\. Difference in max latency
  id: totrans-638
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 2-22\. 最大延迟的差异
- en: The effect is also noticeable on the 99th percentile latency indicator, shown
    in [Figure 2-23](part0007_split_015.html#non_blocking_vs_conventional_load_test_p99),
    so it would show up on the key indicator we use to *compare* the response-time
    performance of two versions of the same microservice (see [“Automated Canary Analysis”](part0010_split_013.html#9H5VC-2d714b853a094e9a910510217e0e3d73)).
  id: totrans-639
  prefs: []
  type: TYPE_NORMAL
  zh: 这种效果也会在 [图 2-23](part0007_split_015.html#non_blocking_vs_conventional_load_test_p99)
    中显示出 99 百分位延迟指标上，因此它将出现在我们用于*比较*同一微服务两个版本的响应时间性能的关键指标上（参见[“自动金丝雀分析”](part0010_split_013.html#9H5VC-2d714b853a094e9a910510217e0e3d73)）。
- en: '![srej 0223](../images/00025.png)'
  id: totrans-640
  prefs: []
  type: TYPE_IMG
  zh: '![srej 0223](../images/00025.png)'
- en: Figure 2-23\. Difference in 99th percentile
  id: totrans-641
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 2-23\. 99 百分位延迟的差异
- en: This example also shows why a server’s view of its own throughput can be misleading.
    Throughput, shown in [Figure 2-24](part0007_split_015.html#non_blocking_vs_conventional_load_test_throughput),
    only increased from approximately 1 ops/second to 3 ops/second between the two
    tests, but this represents how many requests are being *completed*. In fact, during
    the period of the reactive load test where the service was oversaturated, many
    more requests were being queued up on the service’s Tomcat thread pool and not
    being handled in a timely fashion.
  id: totrans-642
  prefs: []
  type: TYPE_NORMAL
  zh: 该示例还说明了为什么服务器对自身吞吐量的视图可能具有误导性。吞吐量显示在[图 2-24](part0007_split_015.html#non_blocking_vs_conventional_load_test_throughput)中，仅在两个测试之间从大约每秒1次操作增加到每秒3次操作，但这代表有多少请求被*完成*。事实上，在反应式负载测试期间，服务超负荷的情况下，更多的请求被排队在服务的Tomcat线程池上，并没有及时处理。
- en: If monitoring throughput (and latency) for the sake of alert criteria in production,
    it would be better to monitor both from the perspective of the client when possible,
    as discussed in [“Latency”](part0009_split_017.html#8ILV9-2d714b853a094e9a910510217e0e3d73).
  id: totrans-643
  prefs: []
  type: TYPE_NORMAL
  zh: 如果出于生产警报标准而监控吞吐量（和延迟），最好在可能的情况下从客户端的角度监控，正如[“延迟”](part0009_split_017.html#8ILV9-2d714b853a094e9a910510217e0e3d73)中讨论的那样。
- en: '![srej 0224](../images/00036.png)'
  id: totrans-644
  prefs: []
  type: TYPE_IMG
  zh: '![srej 0224](../images/00036.png)'
- en: Figure 2-24\. Difference in throughput
  id: totrans-645
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 2-24\. 吞吐量差异
- en: Lastly, average latency is shown in [Figure 2-25](part0007_split_015.html#non_blocking_vs_conventional_load_test_average).
    Even though the average has gone up by an order of magnitude between the two tests,
    average is still around 60 ms, which probably doesn’t seem all that bad. Average
    hides so much of what is really happening that it simply isn’t a useful measure.
  id: totrans-646
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，平均延迟显示在[图 2-25](part0007_split_015.html#non_blocking_vs_conventional_load_test_average)中。尽管两个测试之间的平均值提高了一个数量级，但平均值仍然在约60毫秒左右，这可能看起来并不那么糟糕。平均值隐藏了很多实际发生的情况，因此并不是一个有用的度量标准。
- en: '![srej 0225](../images/00096.png)'
  id: totrans-647
  prefs: []
  type: TYPE_IMG
  zh: '![srej 0225](../images/00096.png)'
- en: Figure 2-25\. Difference in average latency
  id: totrans-648
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 2-25\. 平均延迟差异
- en: Now that we’ve seen many of the meter building blocks and some of the ways they
    are used, let’s turn our focus to application-wide customization of how metrics
    are shipped.
  id: totrans-649
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经看到了许多计量器构建模块以及它们的一些使用方式，让我们把注意力转向应用程序范围内的度量标准如何进行自定义。
- en: Meter Filters
  id: totrans-650
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Meter Filters
- en: The more instrumentation that is added to various parts of the Java stack, the
    greater the necessity of somehow controlling which metrics are published and at
    what fidelity. I first became aware of this need chatting with one one of the
    engineers on the Netflix rating team (the ones that control the thumbs up/star
    rating system on the Netflix UI). He showed me how a particular metric instrumented
    in a core platform library included by most user-facing microservices was recording
    roughly 70,000 time series per API endpoint! This was absurdly wasteful, since
    the vast majority of these time series were not used for many product teams in
    dashboards and alerts. Instrumentation had been developed for the highest-possible-fidelity
    use case. This underscores how little choice core library producers really have.
    They need to instrument for the high fidelity case and rely on somebody downstream
    of them to tune down this fidelity to something useful for them. From this experience,
    Micrometer meter filters were born.
  id: totrans-651
  prefs: []
  type: TYPE_NORMAL
  zh: 随着在Java堆栈的各个部分添加更多的仪表，有必要在某种程度上控制发布哪些指标以及以何种精度。我首次意识到这一需求是在与Netflix评分团队中的一名工程师聊天时（这些工程师控制Netflix
    UI上的点赞/星级评分系统）。他向我展示了一个特定指标的情况，该指标被核心平台库中的大多数用户面向微服务所记录，每个API端点大约产生了大约70,000个时间序列！这是非常浪费的，因为这些时间序列中绝大多数对于许多产品团队在仪表板和警报中并不实用。仪表化已经为最高可能的精度用例开发。这突显了核心库生产者实际上有多么少的选择权。他们需要为高精度案例进行仪表化，并依赖于他们之后的某些人来调整这种精度，使其对他们有用。正是基于这种经验，Micrometer计量器过滤器诞生了。
- en: 'Each registry can be configured with meter filters, which allow a great degree
    of control over how and when meters are registered and what kinds of statistics
    they emit. Meter filters serve three basic functions:'
  id: totrans-652
  prefs: []
  type: TYPE_NORMAL
  zh: 每个注册表都可以配置计量器过滤器，这些过滤器允许对注册和统计信息的时间和方式进行高度控制。计量器过滤器具有三个基本功能：
- en: '*Deny* (or accept) meters from being registered.'
  id: totrans-653
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*Deny*（或接受）注册的计量器。'
- en: '*Transform* meter IDs (e.g., changing the name, adding or removing tags, changing
    description or base units).'
  id: totrans-654
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*Transform* 计量器ID（例如，更改名称、添加或删除标签、更改描述或基本单位）。'
- en: '*Configure* distribution statistics for some meter types.'
  id: totrans-655
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*Configure* 为某些计量器类型配置分布统计信息。'
- en: Implementations of `MeterFilter` are added to the registry programmatically,
    as in [Example 2-48](part0007_split_016.html#meter_filter_apply).
  id: totrans-656
  prefs: []
  type: TYPE_NORMAL
  zh: '`MeterFilter`的实现以编程方式添加到注册表中，例如在[示例 2-48](part0007_split_016.html#meter_filter_apply)中。'
- en: Example 2-48\. Applying meter filters
  id: totrans-657
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 2-48\. 应用计量器过滤器
- en: '[PRE50]'
  id: totrans-658
  prefs: []
  type: TYPE_PRE
  zh: '[PRE50]'
- en: Meter filters are applied in order, and the results of transforming or configuring
    a meter are chained.
  id: totrans-659
  prefs: []
  type: TYPE_NORMAL
  zh: 计量器过滤器按顺序应用，并且变换或配置计量器的结果会被链接。
- en: Apply Meter Filters Early in the Application Life Cycle
  id: totrans-660
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在应用程序生命周期的早期应用计量器过滤器
- en: For performance reasons, meter filters only influence meters registered *after*
    the filter.
  id: totrans-661
  prefs: []
  type: TYPE_NORMAL
  zh: 出于性能原因，计量器过滤器仅影响在过滤器之后注册的计量器。
- en: Deny/Accept Meters
  id: totrans-662
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 拒绝/接受计量器
- en: The verbose form of an accept/deny filter is shown in [Example 2-49](part0007_split_018.html#verbose_meter_filter).
  id: totrans-663
  prefs: []
  type: TYPE_NORMAL
  zh: 接受/拒绝过滤器的冗长形式显示在[示例 2-49](part0007_split_018.html#verbose_meter_filter)中。
- en: Example 2-49\. Most verbose form of an accept/deny filter
  id: totrans-664
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 2-49\. 接受/拒绝过滤器的最冗长形式
- en: '[PRE51]'
  id: totrans-665
  prefs: []
  type: TYPE_PRE
  zh: '[PRE51]'
- en: '`MeterFilterReply` has three possible states:'
  id: totrans-666
  prefs: []
  type: TYPE_NORMAL
  zh: '`MeterFilterReply`有三种可能的状态：'
- en: '`DENY`'
  id: totrans-667
  prefs: []
  type: TYPE_NORMAL
  zh: '`DENY`'
- en: Do not allow this meter to be registered. When you attempt to register a meter
    against a registry and the filter returns `DENY`, the registry will return a NOOP
    version of that meter (e.g., `NoopCounter`, `NoopTimer`). Your code can continue
    to interact with the NOOP meter, but anything recorded to it is discarded immediately
    with minimal overhead.
  id: totrans-668
  prefs: []
  type: TYPE_NORMAL
  zh: 不允许注册此计量器。当您尝试将计量器注册到注册表并且过滤器返回`DENY`时，注册表将返回该计量器的NOOP版本（例如`NoopCounter`、`NoopTimer`）。您的代码可以继续与NOOP计量器交互，但其中记录的任何内容都将立即丢弃，且开销最小。
- en: '`NEUTRAL`'
  id: totrans-669
  prefs: []
  type: TYPE_NORMAL
  zh: '`NEUTRAL`'
- en: If no other meter filter has returned `DENY`, then registration of meters proceeds
    as normal.
  id: totrans-670
  prefs: []
  type: TYPE_NORMAL
  zh: 如果没有其他计量器过滤器返回`DENY`，则计量器的注册将正常进行。
- en: '`ACCEPT`'
  id: totrans-671
  prefs: []
  type: TYPE_NORMAL
  zh: '`ACCEPT`'
- en: If a filter returns `ACCEPT`, the meter is immediately registered without interrogating
    any further filters’ accept methods.
  id: totrans-672
  prefs: []
  type: TYPE_NORMAL
  zh: 如果过滤器返回`ACCEPT`，则计量器将立即注册，而不会进一步查询任何其他过滤器的接受方法。
- en: '`MeterFilter` provides several convenience static builders for deny/accept
    type filters:'
  id: totrans-673
  prefs: []
  type: TYPE_NORMAL
  zh: '`MeterFilter`提供了几个方便的静态构建器用于拒绝/接受类型的过滤器：'
- en: '`accept()`'
  id: totrans-674
  prefs: []
  type: TYPE_NORMAL
  zh: '`accept()`'
- en: Accept every meter, overriding the decisions of any filters that follow.
  id: totrans-675
  prefs: []
  type: TYPE_NORMAL
  zh: 接受每个计量器，覆盖随后任何过滤器的决策。
- en: '`accept(Predicate<Meter.Id>)`'
  id: totrans-676
  prefs: []
  type: TYPE_NORMAL
  zh: '`accept(Predicate<Meter.Id>)`'
- en: Accept any meter matching the predicate.
  id: totrans-677
  prefs: []
  type: TYPE_NORMAL
  zh: 接受与谓词匹配的任何计量器。
- en: '`acceptNameStartsWith(String)`'
  id: totrans-678
  prefs: []
  type: TYPE_NORMAL
  zh: '`acceptNameStartsWith(String)`'
- en: Accept every meter with a matching prefix.
  id: totrans-679
  prefs: []
  type: TYPE_NORMAL
  zh: 接受与特定前缀匹配的每个计量器。
- en: '`deny()`'
  id: totrans-680
  prefs: []
  type: TYPE_NORMAL
  zh: '`deny()`'
- en: Deny every meter, overriding the decisions of any filters that follow.
  id: totrans-681
  prefs: []
  type: TYPE_NORMAL
  zh: 拒绝每个计量器，覆盖随后任何过滤器的决策。
- en: '`denyNameStartsWith(String)`'
  id: totrans-682
  prefs: []
  type: TYPE_NORMAL
  zh: '`denyNameStartsWith(String)`'
- en: Deny every meter with a matching prefix. All out-of-the-box `MeterBinder` implementations
    provided by Micrometer have names with common prefixes to allow for easy grouping
    visualization in UIs, but also to make them easy to disable/enable as a group
    with a prefix. For example, you can deny all JVM metrics with `MeterFilter.denyNameStartsWith("jvm")`.
  id: totrans-683
  prefs: []
  type: TYPE_NORMAL
  zh: 拒绝所有名称以匹配前缀开头的计量器。Micrometer提供的所有开箱即用的`MeterBinder`实现都具有通用前缀的名称，以便在用户界面中轻松进行分组可视化，同时也可以通过前缀轻松禁用/启用它们。例如，您可以使用`MeterFilter.denyNameStartsWith("jvm")`来拒绝所有JVM指标。
- en: '`deny(Predicate<Meter.Id>)`'
  id: totrans-684
  prefs: []
  type: TYPE_NORMAL
  zh: '`deny(Predicate<Meter.Id>)`'
- en: Deny any meter matching the predicate.
  id: totrans-685
  prefs: []
  type: TYPE_NORMAL
  zh: 拒绝任何与谓词匹配的计量器。
- en: '`maximumAllowableMetrics(int)`'
  id: totrans-686
  prefs: []
  type: TYPE_NORMAL
  zh: '`maximumAllowableMetrics(int)`'
- en: Deny any meter after the registry has reached a certain number of meters.
  id: totrans-687
  prefs: []
  type: TYPE_NORMAL
  zh: 在注册表达到一定数量的计量器后拒绝任何计量器。
- en: '`maximumAllowableTags(String meterNamePrefix, String tagKey, int maximumTagValues,
    MeterFilter onMaxReached)`'
  id: totrans-688
  prefs: []
  type: TYPE_NORMAL
  zh: '`maximumAllowableTags(String meterNamePrefix, String tagKey, int maximumTagValues,
    MeterFilter onMaxReached)`'
- en: Place an upper bound on the number of tags produced by matching series.
  id: totrans-689
  prefs: []
  type: TYPE_NORMAL
  zh: 对匹配系列产生的标签数量设置上限。
- en: '*Allowlisting* only a certain group of metrics is a particularly common case
    for monitoring systems that are *expensive*. This can be achieved with the static:'
  id: totrans-690
  prefs: []
  type: TYPE_NORMAL
  zh: '*Allowlisting*只有一组特定的指标是监控系统中的一种常见情况，这些系统可能会很昂贵。可以通过静态方法实现这一点：'
- en: '`denyUnless(Predicate<Meter.Id>)`'
  id: totrans-691
  prefs: []
  type: TYPE_NORMAL
  zh: '`denyUnless(Predicate<Meter.Id>)`'
- en: Deny all meters that *don’t* match the predicate.
  id: totrans-692
  prefs: []
  type: TYPE_NORMAL
  zh: 拒绝所有不符合谓词的计量器。
- en: Meter filters are applied in the order in which they are configured on the registry,
    so it is possible to stack deny/accept filters to achieve more complex rules.
    In [Example 2-50](part0007_split_018.html#accept_only_http), we’re explicitly
    accepting any metric prefixed with `http`, and denying everything else. Because
    the first filter gives an accept decision on a meter like `http.server.requests`,
    the universal deny filter is never asked to provide an opinion.
  id: totrans-693
  prefs: []
  type: TYPE_NORMAL
  zh: 米特过滤器按照它们在注册表上配置的顺序应用，因此可以堆叠拒绝/接受过滤器以实现更复杂的规则。在[示例 2-50](part0007_split_018.html#accept_only_http)中，我们明确地接受任何以
    `http` 开头的度量标准，并拒绝一切其他情况。因为第一个过滤器对于像 `http.server.requests` 这样的米特给出了接受决策，通用的拒绝过滤器就不再需要提供意见。
- en: Example 2-50\. Accept only HTTP metrics and deny everything else
  id: totrans-694
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 2-50\. 仅接受 HTTP 指标，拒绝一切其他情况
- en: '[PRE52]'
  id: totrans-695
  prefs: []
  type: TYPE_PRE
  zh: '[PRE52]'
- en: Transforming Metrics
  id: totrans-696
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 转换度量标准
- en: Meter filters can also transform a meter’s name, tags, description, and base
    units. One of the most common applications of transforming metrics is to add common
    tags. The author of a common Java library like the RabbitMQ Java client cannot
    possibly guess how you wish to identify RabbitMQ metrics arriving at your monitoring
    system by application, the deployed environment, the instance that the code is
    running on, the version of the application, etc. The possibility of applying common
    tags to all metrics streaming out of an application means that low-level-library
    authors can keep their instrumentation simple, adding only tags related to the
    piece they are instrumenting, e.g., the queue name for RabbitMQ metrics. The application
    developer can then enrich this instrumentation with other identifying information.
  id: totrans-697
  prefs: []
  type: TYPE_NORMAL
  zh: 米特过滤器还可以转换米特的名称、标签、描述和基本单位。转换度量标准最常见的应用之一是添加通用标签。像 RabbitMQ Java 客户端这样的常见 Java
    库的作者不可能猜测到您希望通过应用程序、部署环境、代码运行的实例、应用程序版本等标识 RabbitMQ 指标到达监控系统。将通用标签应用于从应用程序流出的所有度量意味着低级库作者可以保持他们的仪器简单，仅添加与他们正在仪器化的部分相关的标签，例如
    RabbitMQ 指标的队列名称。然后，应用程序开发人员可以使用其他识别信息丰富此仪器化。
- en: A transform filter is shown in [Example 2-51](part0007_split_019.html#transform_meter_filter).
    This filter adds a name prefix and an additional tag conditionally to meters starting
    with the name “test.”
  id: totrans-698
  prefs: []
  type: TYPE_NORMAL
  zh: 在[示例 2-51](part0007_split_019.html#transform_meter_filter)中显示了一个转换过滤器。此过滤器为以名称“test”开头的米特添加名称前缀和额外标签。
- en: Example 2-51\. Transform meter filter
  id: totrans-699
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 2-51\. 转换米特过滤器
- en: '[PRE53]'
  id: totrans-700
  prefs: []
  type: TYPE_PRE
  zh: '[PRE53]'
- en: '`MeterFilter` provides convenience builders for many common transformation
    cases:'
  id: totrans-701
  prefs: []
  type: TYPE_NORMAL
  zh: '`MeterFilter` 为许多常见转换情况提供了方便的构建器：'
- en: '`commonTags(Iterable<Tag>)`'
  id: totrans-702
  prefs: []
  type: TYPE_NORMAL
  zh: '`commonTags(Iterable<Tag>)`'
- en: Add a set of tags to all metrics. Adding common tags for app name, host, region,
    etc., is a highly recommended practice.
  id: totrans-703
  prefs: []
  type: TYPE_NORMAL
  zh: 为所有米特添加一组标签。添加应用名称、主机、区域等常见标签是一种强烈推荐的做法。
- en: '`ignoreTags(String...)`'
  id: totrans-704
  prefs: []
  type: TYPE_NORMAL
  zh: '`ignoreTags(String...)`'
- en: Drop matching tag keys from every meter. This is particularly useful when a
    tag’s cardinality probably becomes too high and starts stressing your monitoring
    system or costing too much, but you can’t change all the instrumentation points
    quickly.
  id: totrans-705
  prefs: []
  type: TYPE_NORMAL
  zh: 从每个米特中删除匹配的标签键。当标签的基数可能变得过高并开始对监控系统造成压力或成本过高时，这是特别有用的。但您无法快速更改所有仪器点时，可以使用此方法。
- en: '`replaceTagValues(String tagKey, Function<String, String> replacement, String...
    exceptions)`'
  id: totrans-706
  prefs: []
  type: TYPE_NORMAL
  zh: '`replaceTagValues(String tagKey, Function<String, String> replacement, String...
    exceptions)`'
- en: Replace tag values according to the provided mapping for all matching tag keys.
    This can be used to reduce the total cardinality of a tag by mapping some portion
    of tag values to something else.
  id: totrans-707
  prefs: []
  type: TYPE_NORMAL
  zh: 根据提供的映射替换所有匹配标签键的标签值。这可用于通过将某些标签值映射到其他值来减少标签的总基数。
- en: '`renameTag(String meterNamePrefix, String fromTagKey, String toTagKey)`'
  id: totrans-708
  prefs: []
  type: TYPE_NORMAL
  zh: '`renameTag(String meterNamePrefix, String fromTagKey, String toTagKey)`'
- en: Rename a tag key for every metric beginning with a given prefix.
  id: totrans-709
  prefs: []
  type: TYPE_NORMAL
  zh: 为以给定前缀开头的每个米特重命名标签键。
- en: Ignoring one or more of the tags mentioned at the beginning of this section
    on Netflix core platform instrumentation, which yielded tens of thousands of tags
    per API endpoint, could have significantly cut down on cost.
  id: totrans-710
  prefs: []
  type: TYPE_NORMAL
  zh: 在 Netflix 核心平台仪器化的开始部分提到忽略这些标签中的一个或多个，这导致每个 API 端点生成数万个标签，可以显著降低成本。
- en: Configuring Distribution Statistics
  id: totrans-711
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 配置分布统计
- en: '`Timer`, `LongTaskTimer`, and `DistributionSummary` contain a set of optional
    distribution statistics in addition to the basics of count, total, and max that
    can be configured through filters. These distribution statistics include precomputed
    [“Percentiles/Quantiles”](part0007_split_003.html#6LK44-2d714b853a094e9a910510217e0e3d73),
    [“Service Level Objective Boundaries”](part0007_split_008.html#6LKH9-2d714b853a094e9a910510217e0e3d73),
    and [“Histograms”](part0007_split_007.html#6LKA8-2d714b853a094e9a910510217e0e3d73).
    Distribution statistics can be configured through a `MeterFilter`, as shown in
    [Example 2-52](part0007_split_020.html#distribution_statistics).'
  id: totrans-712
  prefs: []
  type: TYPE_NORMAL
  zh: '`Timer`、`LongTaskTimer`和`DistributionSummary`除了基本的计数、总数和最大值外，还包含一组可选的分布统计，可以通过过滤器进行配置。这些分布统计包括预先计算的[“百分位数/分位数”](part0007_split_003.html#6LK44-2d714b853a094e9a910510217e0e3d73)、[“服务水平目标边界”](part0007_split_008.html#6LKH9-2d714b853a094e9a910510217e0e3d73)和[“直方图”](part0007_split_007.html#6LKA8-2d714b853a094e9a910510217e0e3d73)。可以通过`MeterFilter`进行分布统计的配置，如[示例 2-52](part0007_split_020.html#distribution_statistics)所示。'
- en: Example 2-52\. Configuring distribution statistics
  id: totrans-713
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 2-52\. 配置分布统计
- en: '[PRE54]'
  id: totrans-714
  prefs: []
  type: TYPE_PRE
  zh: '[PRE54]'
- en: Generally, you should create a new `DistributionStatisticConfig` with just the
    pieces you wish to configure and then `merge` it with the input configuration.
    This allows you to drop-down on registry-provided defaults for distribution statistics
    and to chain multiple filters together, each of which configures some part of
    the distribution statistics (e.g., maybe you want a 100 ms SLO for all HTTP requests
    but only percentile histograms on a few critical endpoints).
  id: totrans-715
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，您应创建一个仅包含您希望配置的部分的新`DistributionStatisticConfig`，然后与输入配置进行`merge`。这允许您降低注册表提供的分布统计的默认值，并将多个过滤器链在一起，每个过滤器配置分布统计的一部分（例如，您可能希望为所有HTTP请求设置100毫秒的SLO，但仅在几个关键端点上设置百分位直方图）。
- en: '`MeterFilter` provides convenience builders for the following:'
  id: totrans-716
  prefs: []
  type: TYPE_NORMAL
  zh: '`MeterFilter`为以下提供了方便的构建器：'
- en: '`maxExpected(Duration/long)`'
  id: totrans-717
  prefs: []
  type: TYPE_NORMAL
  zh: '`maxExpected(Duration/long)`'
- en: Governs the upper bound of percentile histogram buckets shipped from a timer
    or summary.
  id: totrans-718
  prefs: []
  type: TYPE_NORMAL
  zh: 管理从计时器或摘要发送的百分位直方图桶的上限。
- en: '`minExpected(Duration/long)`'
  id: totrans-719
  prefs: []
  type: TYPE_NORMAL
  zh: '`minExpected(Duration/long)`'
- en: Governs the lower bound of percentile histogram buckets shipped from a timer
    or summary.
  id: totrans-720
  prefs: []
  type: TYPE_NORMAL
  zh: 管理从计时器或摘要发送的百分位直方图桶的下限。
- en: 'Spring Boot offers property-based filters for configuring SLOs, percentiles,
    and percentile histograms by name prefix, as shown in the following list:'
  id: totrans-721
  prefs: []
  type: TYPE_NORMAL
  zh: Spring Boot提供了基于属性的过滤器，用于按名称前缀配置SLO、百分位数和百分位直方图，如下列表所示：
- en: '`management.metrics.distribution.percentiles-histogram`'
  id: totrans-722
  prefs: []
  type: TYPE_NORMAL
  zh: '`management.metrics.distribution.percentiles-histogram`'
- en: Whether to publish a histogram suitable for computing aggregable (across dimension)
    percentile approximations.
  id: totrans-723
  prefs: []
  type: TYPE_NORMAL
  zh: 是否发布适合计算可聚合（跨维度）百分位数近似的直方图。
- en: '`management.metrics.distribution.minimum-expected-value`'
  id: totrans-724
  prefs: []
  type: TYPE_NORMAL
  zh: '`management.metrics.distribution.minimum-expected-value`'
- en: Publish less histogram buckets by clamping the range of expected values.
  id: totrans-725
  prefs: []
  type: TYPE_NORMAL
  zh: 通过夹紧期望值的范围来发布较少的直方图桶。
- en: '`management.metrics.distribution.maximum-expected-value`'
  id: totrans-726
  prefs: []
  type: TYPE_NORMAL
  zh: '`management.metrics.distribution.maximum-expected-value`'
- en: Publish less histogram buckets by clamping the range of expected values.
  id: totrans-727
  prefs: []
  type: TYPE_NORMAL
  zh: 通过夹紧期望值的范围来发布较少的直方图桶。
- en: '`management.metrics.distribution.percentiles`'
  id: totrans-728
  prefs: []
  type: TYPE_NORMAL
  zh: '`management.metrics.distribution.percentiles`'
- en: Publish percentile values computed in your application.
  id: totrans-729
  prefs: []
  type: TYPE_NORMAL
  zh: 发布在您的应用程序中计算的百分位值。
- en: '`management.metrics.distribution.sla`'
  id: totrans-730
  prefs: []
  type: TYPE_NORMAL
  zh: '`management.metrics.distribution.sla`'
- en: Publish a cumulative histogram with buckets defined by your SLAs.
  id: totrans-731
  prefs: []
  type: TYPE_NORMAL
  zh: 发布一个累积直方图，其桶由您的SLA定义。
- en: Meter filters show up in ways that demonstrate how organizational culture can
    drive even the lowest level of software configurtion. Several organizations use
    them to separate platform and application metrics, for example.
  id: totrans-732
  prefs: []
  type: TYPE_NORMAL
  zh: 计量器过滤器显示了组织文化如何推动甚至是软件配置的最低层次。例如，几个组织使用它们来分离平台和应用程序指标。
- en: Separating Platform and Application Metrics
  id: totrans-733
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 分离平台和应用指标
- en: Conway’s Law suggests that “you ship your org chart.” This means roughly that
    the way in which your system is written, deployed, and works bears some resemblance
    to your organization.
  id: totrans-734
  prefs: []
  type: TYPE_NORMAL
  zh: 康威定律表明“您发布您的组织结构”。这大致意味着您的系统编写、部署和运行的方式与您的组织有些相似。
- en: I’ve found a common pattern that I think is a good positive illustration of
    this principle. At Netflix, the operations engineering organization (what we are
    calling platform engineering in this book) built tools that solved problems otherwise
    undifferentiated among individual microservices. This organization was very much
    customer-engineer-focused, but it exercised no oversight or control over what
    individual teams did because of the overarching “freedom and responsibility” culture.
    But at many organizations (and I don’t think this is necessarily worse or better),
    platform teams do act centrally on behalf of product teams. So while the monitoring
    of an individual microservice at Netflix was wholly the responsibility of the
    product team (with as much advice and assistance as requested from the central
    team), at many organizations the responsibility for monitoring applications may
    reside wholly with a central platform team.
  id: totrans-735
  prefs: []
  type: TYPE_NORMAL
  zh: 我发现了一个常见的模式，我认为这是对这一原则的一个良好的积极说明。在Netflix，运维工程组织（本书中我们称之为平台工程）构建了解决个体微服务中否则不同的问题的工具。这个组织非常关注客户工程，但它对个体团队的做法没有任何监督或控制，这是因为全面的“自由和责任”文化。但在许多组织中（我不认为这种情况是更好或更差的），平台团队确实代表产品团队集中行事。因此，在Netflix，单个微服务的监控完全是产品团队的责任（中央团队提供根据需要的建议和协助），而在许多组织中，监控应用程序的责任可能完全由中央平台团队承担。
- en: In other cases, the responsibility is split, with a central platform team responsible
    for monitoring certain types of signals (usually resource metrics like processor,
    memory, and maybe closer-to-business metrics like API error ratio) and application
    teams responsible for any custom indicators. You may notice how the responsibilities
    in this case roughly break down along the lines of what black box and white box
    instrumentation each excel at (with platform teams monitoring black box signals
    and product teams monitoring white box signals). This is a good illustration of
    how agent-based instrumentation shipped to some particular SaaS product may serve
    the needs of the platform team while product teams use an entirely different monitoring
    system for other signals—i.e., how these types of instrumentation can be complementary
    rather than competitive.
  id: totrans-736
  prefs: []
  type: TYPE_NORMAL
  zh: 在其他情况下，责任被分割开来，中央平台团队负责监控某些类型的信号（通常是资源指标，如处理器、内存，以及可能更接近业务的指标，如API错误比率），而应用程序团队则负责任何自定义指标。您可能会注意到，在这种情况下，责任基本上按照黑盒和白盒仪器的优点分配（平台团队监控黑盒信号，产品团队监控白盒信号）。这很好地说明了基于代理的仪器装置如何为特定的SaaS产品服务平台团队的需求，而产品团队则使用完全不同的监控系统来处理其他信号——即这些类型的仪器装置如何是互补而不是竞争关系的好例子。
- en: 'Let’s consider an organization like this, and the impact it has on how metrics
    telemetry is configured in the application. To make this concrete, assume this
    organization is using Prometheus as its monitoring system. A platform engineer
    and a product engineer have different goals in this case:'
  id: totrans-737
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们考虑这样一个组织，并看看这对应用程序中的度量遥测配置产生的影响。为了使这个概念具体化，假设这个组织正在使用Prometheus作为其监控系统。在这种情况下，平台工程师和产品工程师有不同的目标：
- en: Platform engineer
  id: totrans-738
  prefs: []
  type: TYPE_NORMAL
  zh: 平台工程师
- en: A platform engineer wants to monitor all microservices across the organization
    in the same way. This means that every microservice should publish a set of metrics
    the platform team intends to monitor. These metrics should have a consistent way
    of determining common tags (e.g., for the stack like test/dev/prod, region, cluster,
    server group name, application version, and an instance identifier). There is
    no value to the platform team in shipping anything more than the set of metrics
    the platform team intends to monitor. This set of metrics is unlikely to change
    significantly over time, because by the nature of the responsibility of the platform
    team, they represent general indicators that are useful to all applications and
    aren’t tied to specific business functions or features.
  id: totrans-739
  prefs: []
  type: TYPE_NORMAL
  zh: 平台工程师希望以同样的方式监控组织中的所有微服务。这意味着每个微服务都应该发布一组度量标准，以供平台团队监控。这些度量标准应该有一种一致的方式来确定公共标签（例如，用于堆栈的测试/dev/prod、区域、集群、服务器组名称、应用程序版本和实例标识符）。对于平台团队来说，超出他们打算监控的度量标准集的任何内容都没有价值。这组度量标准随着时间的推移不太可能发生显著变化，因为按照平台团队的责任性质，它们代表了对所有应用程序有用而不与特定业务功能或特性相关联的一般指标。
- en: Product engineer
  id: totrans-740
  prefs: []
  type: TYPE_NORMAL
  zh: 产品工程师
- en: A product engineer wants to monitor their microservice(s) alone. The same set
    of common tags applicable to the platform engineer are likely beneficial to the
    product engineer as well, but there may be additional common tags that further
    differentiate individual instances at a level that isn’t relevant to the platform
    team. For example, the application team may deploy several clusters of its microservice
    that could contain the same application code but serve different segments of its
    end users (e.g., internal users versus external users). They will likely want
    to add a common tag for this distinction to their metrics as well, as there may
    be different SLOs for different end-user populations. The metrics that a product
    engineer should focus most on will be more specific to end-user experience. They
    are also likely to be feature-focused. As new features change, the set of metrics
    changes as well.
  id: totrans-741
  prefs: []
  type: TYPE_NORMAL
  zh: 产品工程师希望仅监视他们自己的微服务。适用于平台工程师的相同一组常用标签对产品工程师也可能有利，但可能有额外的常用标签，进一步区分个体实例的层次，这对平台团队并不重要。例如，应用团队可能部署其微服务的几个集群，这些集群可能包含相同的应用代码，但为其终端用户服务的段不同（例如，内部用户与外部用户）。他们可能也希望将用于区分这种差异的常用标签添加到他们的度量中，因为不同的终端用户群体可能有不同的
    SLO。产品工程师应该关注的度量应该更具体于用户体验。它们也可能是以功能为重点的。随着新功能的变化，度量集合也会发生变化。
- en: If metrics for a microservice were published through a single `MeterRegistry`,
    there is a chance that product engineer customizations to the registry would impact
    the observability of the microservice for the platform team. And, depending on
    how metrics tags are being aggregated for display by the product team, platform
    engineers adding additional common tags could impact the alerts and dashboards
    of product engineers.
  id: totrans-742
  prefs: []
  type: TYPE_NORMAL
  zh: 如果微服务的度量通过单个 `MeterRegistry` 发布，产品工程师对注册表的自定义可能会影响平台团队的微服务可观察性。根据产品团队如何聚合度量标签以供平台团队显示，平台工程师添加额外的常用标签可能会影响产品工程师的警报和仪表板。
- en: Because the engineering organization is structured in this way with this division
    of responsibilities across team boundaries, it should come up with a way to split
    the publishing of metrics into distinct meter registries that best serve the individual
    responsibilities of platform and product teams. “You ship your org chart.”
  id: totrans-743
  prefs: []
  type: TYPE_NORMAL
  zh: 因为工程组织是按这种方式结构化的，跨团队边界分工，所以应该想出一种方法，将度量的发布分成不同的仪表注册表，以最好地服务于平台和产品团队的个别职责。“你出货你的组织图。”
- en: Since this sort of division of responsibility is fairly common, let’s consider
    how this would be achieved. First, the platform team becomes responsible for shipping
    a common library, a JAR binary dependency that every microservice can include
    that contains this common configuration. Because presumably microservice teams
    will be on different release cycles, the platform team will naturally have to
    evolve this common configuration slowly, relative to the pace of change of any
    individual microservice. In this common platform JAR, we’d expect to see autoconfiguration
    like in [Example 2-53](part0007_split_021.html#6LM0R-2d714b853a094e9a910510217e0e3d73).
  id: totrans-744
  prefs: []
  type: TYPE_NORMAL
  zh: 由于这种责任划分相当普遍，让我们考虑如何实现这一点。首先，平台团队负责发布一个通用库，一个 JAR 二进制依赖项，每个微服务都可以包含，其中包含这个通用配置。因为微服务团队可能处于不同的发布周期，相对于任何单个微服务的变化速度，平台团队自然需要慢慢发展这个通用配置。在这个通用平台
    JAR 中，我们期望看到像在 [示例 2-53](part0007_split_021.html#6LM0R-2d714b853a094e9a910510217e0e3d73)
    中的自动配置。
- en: Example 2-53\. Platform team’s autoconfiguration of metrics shared with product
    teams
  id: totrans-745
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 2-53\. 平台团队自动配置与产品团队共享的度量
- en: '[PRE55]'
  id: totrans-746
  prefs: []
  type: TYPE_PRE
  zh: '[PRE55]'
- en: '[![1](../images/00112.png)](part0007_split_021.html#co_application_metrics_CO12-1)'
  id: totrans-747
  prefs: []
  type: TYPE_NORMAL
  zh: '[![1](../images/00112.png)](part0007_split_021.html#co_application_metrics_CO12-1)'
- en: In the platform team’s configuration, a Prometheus meter registry can be created
    privately, without adding it to the Spring application context, so it is not subject
    to `MeterFilter`, `MeterBinder`, and other customizations that the product team
    might configure via the application context.
  id: totrans-748
  prefs: []
  type: TYPE_NORMAL
  zh: 在平台团队的配置中，可以私下创建一个 Prometheus 仪表注册表，而不将其添加到 Spring 应用程序上下文中，因此不受 `MeterFilter`、`MeterBinder`
    和产品团队可能通过应用程序上下文配置的其他自定义影响。
- en: '[![2](../images/00059.png)](part0007_split_021.html#co_application_metrics_CO12-2)'
  id: totrans-749
  prefs: []
  type: TYPE_NORMAL
  zh: '[![2](../images/00059.png)](part0007_split_021.html#co_application_metrics_CO12-2)'
- en: The metrics that the platform team cares about are added directly to the privately
    configured registry.
  id: totrans-750
  prefs: []
  type: TYPE_NORMAL
  zh: 平台团队关心的度量直接添加到配置的私有注册表中。
- en: '[![3](../images/00067.png)](part0007_split_021.html#co_application_metrics_CO12-3)'
  id: totrans-751
  prefs: []
  type: TYPE_NORMAL
  zh: '[![3](../images/00067.png)](part0007_split_021.html#co_application_metrics_CO12-3)'
- en: The platform team provides a common tag meter filter that works for every microservice
    running in Kubernetes. This practice is a concern cutting all microservice teams,
    and they all benefit from the same set of common tags (though they may add their
    own additionally). The meter filter is also applied right after construction to
    the private platform meter registry. A fallback set of common tags is provided
    for when the application isn’t running in Kubernetes.
  id: totrans-752
  prefs: []
  type: TYPE_NORMAL
  zh: 平台团队为在Kubernetes中运行的每个微服务提供了一个通用标签计量过滤器。这种做法关注所有微服务团队，并且他们都从相同的一组通用标签中受益（尽管他们可能额外添加自己的）。计量过滤器在构建后立即应用于私有平台计量注册表。提供了一组备用的通用标签，以处理应用程序不在Kubernetes中运行的情况。
- en: '[![4](../images/00016.png)](part0007_split_021.html#co_application_metrics_CO12-4)'
  id: totrans-753
  prefs: []
  type: TYPE_NORMAL
  zh: '[![4](../images/00016.png)](part0007_split_021.html#co_application_metrics_CO12-4)'
- en: The platform team sets up an API endpoint for itself, common to every application
    and distinct from the typical `/actuator/prometheus` endpoint that Spring would
    autoconfigure, leaving the actuator endpoint to be under the full control of the
    product team for its own purposes.
  id: totrans-754
  prefs: []
  type: TYPE_NORMAL
  zh: 平台团队为自身设置了一个API端点，对每个应用程序都是通用的，与Spring自动配置的典型 `/actuator/prometheus` 端点不同，后者完全由产品团队控制以满足其自身需求。
- en: The implementation of Kubernetes common tags, shown in [Example 2-54](part0007_split_021.html#6LMD0-2d714b853a094e9a910510217e0e3d73),
    is applicable to the kinds of annotations that Spinnaker’s Kubernetes implementation
    configures to be placed on pods. Spinnaker will be discussed in greater detail
    in [Chapter 5](part0010_split_000.html#9H5K4-2d714b853a094e9a910510217e0e3d73).
  id: totrans-755
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes通用标签的实现，显示在[例2-54](part0007_split_021.html#6LMD0-2d714b853a094e9a910510217e0e3d73)，适用于Spinnaker的Kubernetes实现配置要放置在Pod上的注释类型。Spinnaker将在[第5章](part0010_split_000.html#9H5K4-2d714b853a094e9a910510217e0e3d73)中详细讨论。
- en: Example 2-54\. Kubernetes common tags, assuming the service was deployed by
    Spinnaker
  id: totrans-756
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 例2-54 Kubernetes通用标签，假设服务由Spinnaker部署。
- en: '[PRE56]'
  id: totrans-757
  prefs: []
  type: TYPE_PRE
  zh: '[PRE56]'
- en: Another use case of meter filters involves adding a layer of resiliency to your
    publication of metrics themselves.
  id: totrans-758
  prefs: []
  type: TYPE_NORMAL
  zh: 计量过滤器的另一个用例涉及向发布的指标本身添加一层弹性。
- en: Partitioning Metrics by Monitoring System
  id: totrans-759
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 按监控系统划分指标
- en: Suppose your organization has selected Prometheus as its primary monitoring
    system, and a dedicated platform engineering team is operating a series of Prometheus
    instances which should be pulling metrics from every application in the company’s
    inventory. Perhaps this platform team even contributes to monitoring some set
    of common indicators, on behalf of product teams, known to be broadly applicable
    to every Java microservice running in the organization.
  id: totrans-760
  prefs: []
  type: TYPE_NORMAL
  zh: 假设您的组织选择了Prometheus作为其主要监控系统，并且专门的平台工程团队正在操作一系列Prometheus实例，这些实例应该从公司库存中的每个应用程序中拉取指标。也许这个平台团队甚至为监控某些通用指标做出贡献，代表产品团队，这些指标被广泛应用于组织中运行的每个Java微服务。
- en: How do these engineers prove that the Prometheus instances they think they are
    operating effectively are in fact scraping all the deployed assets successfully?
    There are different failure modes. In one case, Prometheus could simply time out
    attempting to pull metrics from a given application. This would be visible from
    Prometheus’s monitoring of itself. But another failure mode might be that we have
    misconfigured Prometheus so that it isn’t even *attempting* to scrape this application.
    In this case, Prometheus dutifully scrapes all the applications it knows about
    and reports nothing about the applications it doesn’t.
  id: totrans-761
  prefs: []
  type: TYPE_NORMAL
  zh: 这些工程师如何证明他们认为自己有效操作的Prometheus实例实际上确实成功地从所有部署的资产中获取指标？存在不同的失败模式。在某些情况下，Prometheus可能会在尝试从特定应用程序获取指标时超时。这可以从Prometheus对自身的监控中看到。但另一种失败模式可能是，我们配置了Prometheus，以至于它甚至不会尝试从此应用程序获取指标。在这种情况下，Prometheus会尽职地从所有它知道的应用程序中获取指标，并且对于它不知道的应用程序不报告任何内容。
- en: Suppose also your organization is running its infrastructure on AWS. We could
    choose to dual-publish metrics, both to our primary monitoring system Prometheus
    and to AWS Cloudwatch. A little investigation shows that Cloudwatch (like other
    public cloud-provider-hosted monitoring solutions) is fairly expensive, billed
    by the number of time series sent. But we really only want to use Cloudwatch to
    verify that Prometheus is doing what it should.
  id: totrans-762
  prefs: []
  type: TYPE_NORMAL
  zh: 假设你的组织也在AWS上运行其基础架构。我们可以选择将度量指标双重发布，既发送到我们的主要监控系统Prometheus，也发送到AWS Cloudwatch。一些调查显示，Cloudwatch（像其他公共云提供商托管的监控解决方案一样）是非常昂贵的，按发送的时间序列数量计费。但我们实际上只想使用Cloudwatch来验证Prometheus是否按预期工作。
- en: The overall process looks like [Figure 2-26](part0007_split_022.html#prom_and_cloudwatch).
    The Prometheus team routinely queries the state of the deployed asset inventory
    (maybe through a stateful delivery automation solution as described in [Chapter 5](part0010_split_000.html#9H5K4-2d714b853a094e9a910510217e0e3d73)).
    For each application listed, the team can check for the counter that Micrometer
    maintains of Prometheus’s scrape attempts for the application. An application
    that isn’t being scraped will have a zero or empty counter.
  id: totrans-763
  prefs: []
  type: TYPE_NORMAL
  zh: 整个过程看起来像[图2-26](part0007_split_022.html#prom_and_cloudwatch)所示。Prometheus团队定期查询部署资产清单的状态（可能通过像[第5章](part0010_split_000.html#9H5K4-2d714b853a094e9a910510217e0e3d73)描述的有状态交付自动化解决方案）。对于列出的每个应用程序，团队可以检查Micrometer维护的Prometheus抓取尝试的计数器。未被抓取的应用程序将具有零或空计数器。
- en: '![srej 0226](../images/00117.png)'
  id: totrans-764
  prefs: []
  type: TYPE_IMG
  zh: '![srej 0226](../images/00117.png)'
- en: Figure 2-26\. Shipping metrics to both Prometheus and Cloudwatch
  id: totrans-765
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图2-26\. 向Prometheus和Cloudwatch发送度量指标的过程
- en: '[Example 2-55](part0007_split_022.html#cloud_watch_meter_registry_customizer)
    shows how we can use an accept and deny `MeterFilter` pair to cost-effectively
    ship to Cloudwatch only the Prometheus metrics that are relevant in helping the
    platform team determine that the Prometheus scrape configuration is working as
    expected. It uses a Spring Boot feature called `MeterRegistryCustomizer` that
    allows us to add filter and other registry customization to specific registry
    types rather than to all of them.'
  id: totrans-766
  prefs: []
  type: TYPE_NORMAL
  zh: '[示例 2-55](part0007_split_022.html#cloud_watch_meter_registry_customizer)展示了如何使用接受和拒绝的
    `MeterFilter` 对来成本有效地仅将对帮助平台团队确定Prometheus抓取配置是否按预期工作有用的Prometheus度量指标发布到Cloudwatch。它使用了Spring
    Boot的一个特性称为 `MeterRegistryCustomizer`，允许我们将过滤器和其他注册自定义添加到特定的注册类型，而不是添加到所有注册类型中。'
- en: Example 2-55\. Using Cloudwatch MeterRegistryCustomizer
  id: totrans-767
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 2-55\. 使用Cloudwatch MeterRegistryCustomizer
- en: '[PRE57]'
  id: totrans-768
  prefs: []
  type: TYPE_PRE
  zh: '[PRE57]'
- en: There is one last concept related to the organization of metrics.
  id: totrans-769
  prefs: []
  type: TYPE_NORMAL
  zh: 与度量指标组织相关的最后一个概念是有关的。
- en: Meter Binders
  id: totrans-770
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 仪表绑定器
- en: In many cases monitoring some subsystem or library involves more than one meter.
    Micrometer provides a simple functional interface called a `MeterBinder` that
    is designed for encapsulating a set of meters together. Spring Boot automatically
    registers the metrics from any `MeterBinder` bean that is configured to the application
    context (i.e., `@Bean MeterBinder ...`). [Example 2-56](part0007_split_023.html#meter_binder)
    illustrates a simple meter binder that encapsulates some metrics around a vehicle
    type.
  id: totrans-771
  prefs: []
  type: TYPE_NORMAL
  zh: 在许多情况下，监控某些子系统或库涉及不止一个仪表。Micrometer 提供了一个简单的功能接口称为 `MeterBinder`，旨在将一组仪表封装在一起。Spring
    Boot 自动将任何配置为应用上下文的 `MeterBinder` bean 中的指标注册到度量指标中（即 `@Bean MeterBinder ...`）。[示例
    2-56](part0007_split_023.html#meter_binder)展示了一个简单的仪表绑定器，用于围绕车辆类型封装一些度量指标。
- en: Example 2-56\. Meter binder implementation
  id: totrans-772
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 2-56\. 仪表绑定器实现
- en: '[PRE58]'
  id: totrans-773
  prefs: []
  type: TYPE_PRE
  zh: '[PRE58]'
- en: It is best if all metrics registered in a meter binder share some common prefix
    (in this case “vehicle”), especially when the binder is packed up and shipped
    as default configuration across a wide array of applications. Some teams may not
    find the metrics to be useful in their specific case and filter them out to save
    on cost. Having a common prefix makes it easy to apply a deny meter filter by
    the common prefix, as in [Example 2-57](part0007_split_023.html#property_based_deny_filter).
    In this way, you can add and remove metrics from the meter binder over time, and
    the filter logic still has the effect of broadly including or excluding the metrics
    produced by this meter binder.
  id: totrans-774
  prefs: []
  type: TYPE_NORMAL
  zh: 当一个仪表绑定器中注册的所有度量指标共享一些公共前缀时最好（在本例中为“vehicle”），特别是当该绑定器被打包并作为广泛应用程序配置的默认配置时。一些团队可能认为这些度量指标在其特定情况下无用，并将其过滤掉以节省成本。具有公共前缀使得通过公共前缀应用拒绝仪表过滤器变得容易，如[示例
    2-57](part0007_split_023.html#property_based_deny_filter)所示。通过这种方式，您可以随时间添加和删除仪表绑定器中的度量指标，而过滤逻辑仍然能够广泛包括或排除此仪表绑定器产生的度量指标。
- en: Example 2-57\. A property-based deny filter for metrics coming from the vehicle
    meter binder
  id: totrans-775
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 2-57\. 用于来自车辆计量绑定器的度量的基于属性的拒绝过滤器
- en: '[PRE59]'
  id: totrans-776
  prefs: []
  type: TYPE_PRE
  zh: '[PRE59]'
- en: Summary
  id: totrans-777
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: In this chapter, you’ve learned how to measure various parts of your application
    with dimensional metrics. We haven’t yet discussed specifically how to *use* this
    data. We will eventually be coming back to metrics in [Chapter 4](part0009_split_000.html#8IL24-2d714b853a094e9a910510217e0e3d73),
    where effective indicators for every Java microservice are presented along with
    how to build effective charts and alerts.
  id: totrans-778
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，你已经学习了如何使用维度指标来衡量应用程序的各个部分。我们还没有具体讨论如何*使用*这些数据。在第[4章](part0009_split_000.html#8IL24-2d714b853a094e9a910510217e0e3d73)中，我们将会回到指标这个话题，介绍每个Java微服务的有效指标，以及如何构建有效的图表和警报。
- en: The organizational commitment you are signing up for to take advantage of all
    this dimensional metrics data involves the selection of one or more target dimensional
    monitoring systems, either picking a SaaS offering or standing up one of the available
    OSS systems on-prem. The impact on your code is limited. When using modern Java
    web frameworks like Spring Boot, prepackaged instrumentation will provide a great
    deal of detail without having to write any custom instrumentation code. All you
    need to do is add a dependency on the monitoring system implementation of your
    choice and then provide some configuration to ship metrics to it.
  id: totrans-779
  prefs: []
  type: TYPE_NORMAL
  zh: 您签署的组织承诺是为了利用所有这些维度指标数据，涉及选择一个或多个目标维度监控系统，可以选择一个SaaS提供或在本地搭建一个可用的开源系统。对您的代码的影响有限。当使用像Spring
    Boot这样的现代Java Web框架时，预打包的仪器将提供大量详细信息，而无需编写任何自定义仪器代码。您只需添加对您选择的监控系统实现的依赖，并提供一些配置以将指标发送到该系统。
- en: In the next chapter, we’ll see how metrics instrumentation compares to debuggability
    signals like distributed traces and logs. While reading it, keep in mind that
    the metrics instrumentation we’ve just discussed is designed to provide fixed-cost
    telemetry that helps you to understand what is happening to your system in the
    *aggregate*. These other telemetry sources will provide detailed information about
    what is happening at an individual event (or request) level.
  id: totrans-780
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将看到指标仪表化与分布式跟踪和日志等调试信号的比较。阅读时，请记住，我们刚刚讨论过的指标仪表化旨在提供固定成本的遥测，帮助您了解系统在*整体*上发生了什么。而这些其他遥测来源将提供关于每个单独事件（或请求）级别发生情况的详细信息。
