- en: Chapter 8\. Parallel Data Processing with Streams
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第8章\. 使用流进行并行数据处理
- en: Our world is overwhelmingly concurrent and parallel; we can almost always do
    more than one thing at once. Our programs need to solve more and more problems,
    that’s why data processing often benefits from being parallel, too.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的世界充满了并发和并行；我们几乎总是可以同时做更多事情。我们的程序需要解决越来越多的问题，这就是为什么数据处理通常也会从并行处理中受益的原因。
- en: In [Chapter 6](ch06.xhtml#_02-data-processing), you’ve learned about Streams
    as data processing pipelines built of functional operations. Now it’s time to
    go parallel!
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在[第六章](ch06.xhtml#_02-data-processing)中，您已经了解了作为数据处理管道的流和函数操作。现在是并行处理的时候了！
- en: In this chapter, you will learn about the importance of concurrency and parallelism,
    how and when to use parallel Streams, and when not to. Everything you learned
    in the previous two chapters about data processing with Streams so far also applies
    to using them for parallel processing. That’s why this chapter will concentrate
    on the differences and intricacies of parallel Streams.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，您将了解并发和并行性的重要性，以及何时以及如何使用并行流，以及何时不要使用。到目前为止，在前两章中学到的有关使用流进行数据处理的一切，也适用于使用它们进行并行处理。因此，本章将集中讨论并行流的差异和复杂性。
- en: Concurrency Versus Parallelism
  id: totrans-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 并发与并行
- en: 'The terms *parallelism* and *concurrency* often get mixed up because the concepts
    are closely related. Rob Pike, one of the co-designers of the programming language
    [*Go*](https://go.dev), defined the terms nicely:'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 术语*并行性* 和 *并发性* 经常被混淆，因为这些概念密切相关。罗布·派克，*Go* 语言的共同设计者之一，对这些术语进行了很好的定义：
- en: Concurrency is about **dealing** with a lot of things at once. Parallelism is
    about **doing** a lot of things at once. The ideas are, obviously, related, but
    one is inherently associated with structure, and the other is associated with
    execution. Concurrency is structuring things in a way that might allow parallelism
    to actually execute them simultaneously. But parallelism is not the goal of concurrency.
    The goal of concurrency is good structure and the possibility to implement execution
    modes like parallelism.
  id: totrans-6
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 并发是**同时处理**多件事情。并行是**同时执行**多件事情。显然，这些想法是相关的，但一个与结构紧密相关，另一个与执行相关。并发是以一种可能允许并行执行的方式组织事物。但并行不是并发的目标。并发的目标是良好的结构和实现并行执行等执行模式的可能性。
- en: ''
  id: totrans-7
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Rob Pike, [“Concurrency Is Not Parallelism” at Waza 2012](https://go.dev/blog/waza-talk)
  id: totrans-8
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 罗布·派克，在[Waza 2012年的“并发不等于并行”](https://go.dev/blog/waza-talk)
- en: '*Concurrency* is the general concept of multiple tasks running in overlapping
    time periods competing over the available resources. A single CPU core interleaves
    them by scheduling and switching between tasks as it sees fit. Switching between
    tasks is relatively easy and fast. This way, two tasks can *figuratively* run
    on a single CPU core simultaneously, even though they *literally* don’t. Think
    of it like a juggler using only one hand (single CPU core) with multiple balls
    (tasks). They can only hold a single ball at any time (doing the work), but which
    ball changes over time (interrupting and switching to another task). Even with
    only two balls, they have to juggle the workload.'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: '*并发性* 是多个任务在重叠时间段内运行并竞争可用资源的一般概念。单个CPU核心通过调度和切换任务来交错它们。任务之间的切换相对容易和快速。这样，即使它们*实际上*不能，两个任务也可以*象征性地*在单个CPU核心上同时运行。可以将其想象成一个只用一只手（单个CPU核心）抛接多个球（任务）的杂技演员。他们每次只能抓住一个球（执行工作），但随着时间的推移，球的类型会改变（中断并切换到另一个任务）。即使只有两个球，他们也必须完成工作。'
- en: '*Parallelism*, on the other hand, isn’t about managing interleaved tasks but
    their *simultaneous* execution. If more than one CPU core is available, the tasks
    can run *in-parallel* on different cores. The juggler now uses both hands (more
    than one CPU core) to hold two balls at once (doing the work simultaneously).'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 另一方面，*并行性* 不是管理交错任务，而是它们的*同时*执行。如果有多个CPU核心可用，任务可以在不同核心上*并行*运行。现在，杂技演员同时使用两只手（多个CPU核心），同时拿着两个球（同时执行工作）。
- en: See [Figure 8-1](#_01-parallel-concurrent-async_concurrent-vs-parallel) for
    a more visual representation of how thread scheduling differs between the two
    concepts.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 参见[图8-1](#_01-parallel-concurrent-async_concurrent-vs-parallel)，更直观地展示了线程调度在这两个概念之间的差异。
- en: '![Concurrent versus parallel thread execution](assets/afaj_0801.png)'
  id: totrans-12
  prefs: []
  type: TYPE_IMG
  zh: '![并行与并发线程执行](assets/afaj_0801.png)'
- en: Figure 8-1\. Concurrent versus parallel thread execution
  id: totrans-13
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图8-1\. 并发与并行线程执行
- en: '*Concurrency* and *parallelism* in Java share the same goal: taking care of
    *multiple* tasks with threads. Their difference lies in the difficulty to do it
    efficiently, with ease, and doing it right, and in a safe manner.'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: '*Java* 中的 *并发* 和 *并行* 共享同一个目标：使用线程处理 *多个* 任务。它们的区别在于如何高效、轻松地以及正确和安全地执行这些任务。'
- en: Both multi-tasking concepts aren’t mutually exclusive and are often used together.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 多任务概念既不是互斥的，也经常一起使用。
- en: One thing to consider when using multiple threads is that you can no longer
    easily follow or debug the actual flow of your application as you could do in
    a single-threaded one. To use data structures in concurrent environments, they
    have to be “thread-safe,” usually requiring coordination with locks, semaphores,
    etc., to work correctly and guarantee safe access to any shared state. Executing
    code in parallel usually lacks such coordination because it’s focused on the execution
    itself. This makes it safer, more natural, and easier to reason with.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 使用多线程时需要考虑的一件事是，与单线程环境相比，您无法轻松地跟踪或调试应用程序的实际流程。要在并发环境中使用数据结构，它们必须是“线程安全”的，通常需要与锁、信号量等协调以正确工作并确保安全访问任何共享状态。并行执行的代码通常缺乏这种协调，因为它专注于执行本身。这使得并行执行更安全、更自然且更易于理解。
- en: Streams as Parallel Functional Pipelines
  id: totrans-17
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 并行功能管道流
- en: 'Java provides an easy-to-use data processing pipeline with parallel processing
    capabilities: *Streams*. As I’ve discussed before in [Chapter 6](ch06.xhtml#_02-data-processing),
    they process their operations in *sequential* order by default. However, a single
    method call switches the pipeline into “parallel mode,” either the intermediate
    Stream operation `parallel`, or the `parallelStream` method available on `java.util.Collection`-based
    types. Going back to a sequentially processed Stream is possible, too, by calling
    the intermediate operation `sequential()`.'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: Java 提供了一个易于使用的数据处理管道，具有并行处理能力：*流*。如我之前在 [第 6 章](ch06.xhtml#_02-data-processing)
    中讨论的那样，默认情况下它们按 *顺序* 处理操作。但是，通过单个方法调用，可以将管道切换到“并行模式”，要么是中间的 Stream 操作 `parallel`，要么是
    `java.util.Collection` 类型上可用的 `parallelStream` 方法。也可以通过调用中间操作 `sequential()` 回到顺序处理的流。
- en: Warning
  id: totrans-19
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 警告
- en: Switching between execution modes with `parallel()` and `sequential()` affects
    the Stream pipeline as a whole regardless of the position in the pipeline. The
    last one called before the terminal operation dictates the mode for the whole
    pipeline. There’s no way to run a certain part of the Stream in a different execution
    mode from the rest.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 `parallel()` 和 `sequential()` 在执行模式之间切换影响整个 Stream 管道，无论在管道中的位置如何。在终端操作之前调用的最后一个方法决定整个管道的模式。无法使流的某个部分在与其余部分不同的执行模式下运行。
- en: Parallel Streams use the concept of *recursive decomposition*, meaning they
    *divide and conquer* the data source by splitting up the elements with the underlying
    `Spliterator` to process chunks of elements in parallel. Each chunk is processed
    by a dedicated thread and may even be split up again, recursively, until the Stream
    API is satisfied that the chunks and threads are a good match for the available
    resources.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 并行流使用 *递归分解* 的概念，意味着它们通过使用底层的 `Spliterator` 将数据源进行 *分治*，以便并行处理数据块。每个数据块由专用线程处理，甚至可以递归地再次分解，直到
    Stream API 认为这些数据块和线程与可用资源相匹配。
- en: You don’t have to create or manage these threads or use an explicit `ExecutorService`.
    Instead, the Stream API uses the *common* `ForkJoinPool` internally to spin-off
    and manage new threads.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 你不必创建或管理这些线程，也不需要使用显式的 `ExecutorService`。相反，Stream API 内部使用 *通用* 的 `ForkJoinPool`
    来衍生和管理新线程。
- en: These chunks of elements and their operations are forked into multiple threads.
    Finally, the sub-results of the threads are joined again to derive a final result,
    as shown in [Figure 8-2](#_02-data-processing_parallel-fork-join).
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 这些数据块和它们的操作被分叉成多个线程。最后，线程的子结果再次连接以得出最终结果，如 [图 8-2](#_02-data-processing_parallel-fork-join)
    所示。
- en: '![Parallel Stream Fork/Join](assets/afaj_0802.png)'
  id: totrans-24
  prefs: []
  type: TYPE_IMG
  zh: '![并行流 Fork/Join](assets/afaj_0802.png)'
- en: Figure 8-2\. Parallel Stream Fork/Join
  id: totrans-25
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 8-2\. 并行流 Fork/Join
- en: The size of the chunks varies, depending on the Stream’s data source underlying
    `Spliterator` characteristics. [“Choosing the Right Data Source”](#_02-parallel-streams_data-source)
    goes over the different characteristics and data sources and their affinity for
    proficiency in splitting elements into chunks.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 根据流的数据源底层`Spliterator`特性，块的大小会有所不同。["选择正确的数据源"](#_02-parallel-streams_data-source)讨论了不同的特性和数据源及其对元素分割效率的亲和性。
- en: Parallel Streams in Action
  id: totrans-27
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 并行流实例
- en: To illustrate how to process a Stream in parallel, we’re going to count the
    occurrences of distinct words in Tolstoy’s “War and Peace” again, ^([1](ch08.xhtml#idm45115231315840)),
    as was done in the previous chapter.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 为了说明如何并行处理流，我们将再次计算托尔斯泰的《战争与和平》中不同单词的出现次数 ^([1](ch08.xhtml#idm45115231315840))，就像前一章节所做的那样。
- en: 'First, a rough approach should be outlined as a blueprint for the necessary
    steps that need to be translated into Stream operations:'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，应概述一个粗略的方法作为将需要翻译为流操作的必要步骤的蓝图：
- en: Loading the content of “War and Peace”
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 载入《战争与和平》的内容
- en: Cleaning the content by removing punctuation, etc.
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过删除标点等来清理内容
- en: Splitting the content to create words
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将内容分割以创建单词
- en: Counting all distinct words
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 计算所有不同的单词
- en: Instead of using the `Files.lines` method, a more naïve sequential approach,
    as shown in <<[Example 8-1](#_01-parallel-concurrent-async_war-and-peace-seq)
    is chosen to better represent the improvements the right data source and parallel
    Streams can have.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 选择一个更为天真的顺序方法，而不是使用`Files.lines`方法，以更好地表现出正确数据源和并行流的改进，如第<<[示例 8-1](#_01-parallel-concurrent-async_war-and-peace-seq)章所示。
- en: Example 8-1\. Sequentially counting words in “War and Peace”
  id: totrans-35
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 8-1\. 逐步计算《战争与和平》中的单词
- en: '[PRE0]'
  id: totrans-36
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: '[![1](assets/1.png)](#co_parallel_data_processing_with_streams_CO1-1)'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: '[![1](assets/1.png)](#co_parallel_data_processing_with_streams_CO1-1)'
- en: Multiple pre-compiled `Pattern` instances are used to clean up the content.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 多个预编译的`Pattern`实例用于清理内容。
- en: '[![2](assets/2.png)](#co_parallel_data_processing_with_streams_CO1-2)'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: '[![2](assets/2.png)](#co_parallel_data_processing_with_streams_CO1-2)'
- en: The content is read in one swoop.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 内容一次性读取。
- en: '[![3](assets/3.png)](#co_parallel_data_processing_with_streams_CO1-3)'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: '[![3](assets/3.png)](#co_parallel_data_processing_with_streams_CO1-3)'
- en: The cleanup patterns remove all punctuation.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 清理模式移除所有标点。
- en: '[![4](assets/4.png)](#co_parallel_data_processing_with_streams_CO1-4)'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: '[![4](assets/4.png)](#co_parallel_data_processing_with_streams_CO1-4)'
- en: The lines are split on whitespace and the resulting `String[]` array is flat-mapped
    to a Stream of `String` elements, which are further filtered to be actually “words.”
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 行按空格分割，结果为`String[]`数组被平面映射为`String`元素的流，进一步过滤以实际为“单词”。
- en: '[![5](assets/5.png)](#co_parallel_data_processing_with_streams_CO1-5)'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: '[![5](assets/5.png)](#co_parallel_data_processing_with_streams_CO1-5)'
- en: Counting words in a case-insensitive fashion is simply done by converting all
    words to lowercase and letting a Collector do the actual work.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 以不区分大小写的方式计数单词只需将所有单词转换为小写，并让收集器完成实际工作。
- en: Counting is done with the help of `Collectors.toMap`, which takes the words
    as keys by calling `Function.identity()`, which is a shortcut to create a `Function<T,
    T>` that returns its input argument. If a key collision occurs, meaning a word
    is encountered more than once, the Collector merges the existing value with the
    new value, `1`, by evaluation `Integer::sum` with both values.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 使用`Collectors.toMap`进行计数，它通过调用`Function.identity()`以单词为键，这是一个创建返回其输入参数的`Function<T,
    T>`的快捷方式。如果发生键冲突，意味着遇到了多次出现的单词，收集器通过评估`Integer::sum`来合并现有值和新值`1`。
- en: On my computer with a 6-core / 12-thread CPU, the sequential version runs in
    ~140ms.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 在我计算机上，配备6核/12线程CPU，顺序版本运行时间约为~140ms。
- en: Note
  id: totrans-49
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: Threads, in the case of a CPU, refer to *simultanous multithreading* (SMT),
    not Java threads. It’s often referred to as *hyper-threading*, which is the proprietary
    implementation of SMT by Intel.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 在CPU的情况下，线程指的是*同时多线程*（SMT），而不是Java线程。它通常被称为*超线程*，这是Intel对SMT的专有实现。
- en: This initial Stream pipeline might solve the problem of counting words in “War
    and Peace” but it leaves quite some room for improvement. Making it parallel wouldn’t
    change much because the data source only provides a singular element, so only
    later operations can be forked off. So how can the pipeline be redesigned to gain
    performance from a parallel approach?
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 这个初始的 Stream 管道可能解决了在《战争与和平》中统计单词的问题，但还有很大的改进空间。将其并行化不会有太大改变，因为数据源只提供了一个单一元素，所以只有后续操作可以被分叉。那么如何重新设计管道以从并行方法中获得性能提升呢？
- en: If you think back to [Figure 8-2](#_02-data-processing_parallel-fork-join),
    parallel Streams fork pipelines of operations that are merged back together to
    create a result. Right now, the pipeline counts words for a singular `String`
    which is the whole book. A more the pipeline could easily count words in any `String`
    element flowing through the pipeline and let the terminal `collect` operation
    merge the results just as easily.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 如果回想一下 [图 8-2](#_02-data-processing_parallel-fork-join)，并行流分叉操作管道，这些操作会合并在一起创建一个结果。目前，该管道计算一个整本书作为一个单一的
    `String`。更好的方法可以轻松地在流经管道的任何 `String` 元素中计算单词，并让终端 `collect` 操作同样轻松地合并结果。
- en: 'For a good parallel performance of all operations, the Stream pipeline needs
    a data source with multiple elements. Instead of using `Files.readString`, the
    convenience type also has a `Stream`-creating method that reads a file line-by-line:
    `static Stream<String> lines(Path path) throws IOException`. Even though processing
    more elements will result in more clean-up operation calls in total, the tasks
    are distributed to multiple threads run in parallel to use the available resources
    most efficiently.'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 为了使所有操作都能有良好的并行性能，流管道需要具有多个元素的数据源。而不是使用 `Files.readString`，这个便捷类型还有一个创建 `Stream`
    的方法，它逐行读取文件：`static Stream<String> lines(Path path) throws IOException`。尽管处理更多元素会导致总体上更多的清理操作调用，但任务被分布到多个线程并行运行，以最有效地利用可用资源。
- en: Another important change must be done to the `collect` operation. To ensure
    no `ConcurrentModificationException` occurs, the thread-safe variant `Collectors.toConcurrentMap`
    is used with the same arguments as before.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个重要的变化必须对 `collect` 操作进行。为了确保不会发生 `ConcurrentModificationException`，使用线程安全的变体
    `Collectors.toConcurrentMap` 与之前相同的参数。
- en: Using Collectors in parallel environments
  id: totrans-55
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在并行环境中使用 Collectors
- en: As Collectors share a mutable intermediate results container, they’re susceptible
    to concurrent modifications from multiple threads during the `combiner` step.
    That’s why you should always check the documentation of the Collector used in
    a parallel pipeline for thread-safety, and choose an appropriate alternative if
    necessary.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 由于 Collectors 共享一个可变的中间结果容器，它们容易受到多线程在 `combiner` 步骤期间的并发修改的影响。这就是为什么在并行管道中使用的
    Collector 的文档总是应该检查其线程安全性，并在必要时选择合适的替代方法。
- en: All these small adaptions to switch to a parallel approach accumulates in the
    code shown in [Example 8-2](#_01-parallel-concurrent-async_war-and-peace-parallel).
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 所有这些小的调整切换到并行方法在 [示例 8-2](#_01-parallel-concurrent-async_war-and-peace-parallel)
    中的代码中累积起来。
- en: Example 8-2\. Parallel counting words in “War and Peace”
  id: totrans-58
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 8-2\. 在《战争与和平》中并行计算单词
- en: '[PRE1]'
  id: totrans-59
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: '[![1](assets/1.png)](#co_parallel_data_processing_with_streams_CO2-1)'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: '[![1](assets/1.png)](#co_parallel_data_processing_with_streams_CO2-1)'
- en: The `Files.lines` call requires you to close the `Stream`. Using it in a `try-with-resources`-block
    delegates the work to the runtime, so you don’t have to close it manually.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: '`Files.lines` 调用要求你关闭 `Stream`。在 `try-with-resources` 块中使用它将工作委托给运行时，因此你不必手动关闭它。'
- en: '[![2](assets/2.png)](#co_parallel_data_processing_with_streams_CO2-2)'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: '[![2](assets/2.png)](#co_parallel_data_processing_with_streams_CO2-2)'
- en: All previous steps — cleaning and splitting the lines — are unchanged.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 所有先前的步骤 - 清理和拆分行 - 都没有改变。
- en: '[![3](assets/3.png)](#co_parallel_data_processing_with_streams_CO2-4)'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: '[![3](assets/3.png)](#co_parallel_data_processing_with_streams_CO2-4)'
- en: Counting is done the same way but with a thread-safe Collector variant instead.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 计数方式相同，但使用了线程安全的 Collector 变体。
- en: By using an optimized data source and adding a `parallel()` call into the pipeline,
    the required time decreases to ~25ms.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 通过使用优化的数据源并在管道中添加一个 `parallel()` 调用，所需时间减少到约 25 毫秒。
- en: That’s a performance increase of over 5x! So why don’t we always use parallel
    Streams?
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 这导致性能提升超过 5 倍！那么为什么我们不总是使用并行流呢？
- en: When to Use and When to Avoid Parallel Streams
  id: totrans-68
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 何时使用并避免并行流
- en: 'Why use a sequential Stream if a parallel Stream can provide a performance
    boost with a single method call and a few considerations to the data source and
    terminal operation? The simple answer: any performance gains aren’t guaranteed
    and are affected by many factors. Using parallel Streams is primarily a performance
    optimization and should always be a conscious and informed decision, not just
    because it’s *easy* thanks to a single method call.'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 如果并行流能通过单一方法调用和对数据源以及终端操作的一些考虑来提升性能，那么为什么还要使用顺序流呢？简单来说：任何性能增益都不是保证的，并且受到许多因素的影响。使用并行流主要是性能优化，应始终是有意识和明智的决定，而不仅仅因为它通过一个方法调用就变得*简单*。
- en: There are no *absolute* rules about choosing parallel over sequential data processing.
    The criteria depend on many different factors, like your requirements, the task
    at hand, available resources, etc., and all influence each other. That’s why there
    is no easy answer to the question “when to use parallel Streams?”, neither *quantitative*
    nor *qualitative*. Still, there are certain *informal* guidelines that provide
    a good starting point to decide.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 选择并行还是顺序数据处理没有*绝对*规则。选择的标准取决于许多不同因素，如您的需求、当前任务、可用资源等等，所有这些因素都相互影响。因此，“何时使用并行流？”没有*定量*也没有*定性*的简单答案。尽管如此，有一些*非正式*的指导方针可以提供一个很好的起点来决定。
- en: Let’s take a look at them in order of how a Stream pipeline is built, from creating
    a Stream to adding intermediate operation and finishing the pipeline by adding
    the terminal operation.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们按照流管道的构建顺序来看看它们，从创建流开始，添加中间操作，然后通过添加终端操作完成流管道。
- en: Choosing the Right Data Source
  id: totrans-72
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 选择正确的数据源
- en: Every Stream — sequential and parallel — begins with a data source handled by
    a `Spliterator`.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 每个流（包括顺序和并行流）都始于由`Spliterator`处理的数据源。
- en: In a sequential Stream, the `Spliterator` behaves like a simple `Iterator`,
    supplying the Stream with one element after another. For parallel Streams, however,
    the data source gets split up into multiple chunks. Ideally, these chunks are
    of roughly equivalent size, so the work is distributed evenly, but that isn’t
    always possible, depending on the data source itself. This splitting process is
    called *decomposing the data source*. It can be cheap or favorable for parallel
    processing; or complicated and costly.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 在顺序流中，`Spliterator`的行为类似于简单的`Iterator`，一个接一个地向流提供元素。然而，对于并行流，数据源被分割成多个块。理想情况下，这些块的大小大致相等，因此工作可以均匀分布，但这并不总是可能的，这取决于数据源本身。这个分割过程称为*分解数据源*。这可以是廉价或有利于并行处理；也可以是复杂和昂贵的。
- en: For example, an array-based data source, like `ArrayList`, knows its exact size
    and easily decomposes because the location of all elements is known, so equally
    large chunks are easily obtainable.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，基于数组的数据源，如 `ArrayList`，知道其确切大小，并且容易分解，因为所有元素的位置都是已知的，所以可以轻松获取同等大小的块。
- en: A linked list, on the other hand, is a fundamentally sequential data source,
    with each of its elements only effectively knowing their direct neighbors. Finding
    a specific position means you have to traverse all beforehand. Although Java’s
    implementation, `LinkedList`, *cheats* by keeping track of the size, which creates
    the more favorable `Spliterator` characteristics `SIZED` and `SUBSIZED`. Nevertheless,
    it’s not a preferred data source for parallel Streams.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 另一方面，链表是一种基本的顺序数据源，每个元素只知道它们直接的邻居。查找特定位置意味着您必须遍历所有元素之前的内容。虽然 Java 的实现，`LinkedList`，通过跟踪大小来*作弊*，从而创建更有利的`Spliterator`特征
    `SIZED` 和 `SUBSIZED`。尽管如此，它并不是并行流的首选数据源。
- en: '[Table 8-1](#_01-parallel-streams_decomposability) lists different common data
    sources and their proficiency of decomposability for parallel use.'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: '[表 8-1](#_01-parallel-streams_decomposability) 列出了不同常见数据源及其适合并行使用的可分解性能力。'
- en: Table 8-1\. Parallel decomposability
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 表 8-1\. 并行可分解性
- en: '| Data source | Parallel Decomposability |'
  id: totrans-79
  prefs: []
  type: TYPE_TB
  zh: '| 数据源 | 并行可分解性 |'
- en: '| --- | --- |'
  id: totrans-80
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| `IntStream.range / .rangeClosed` | `+++` |'
  id: totrans-81
  prefs: []
  type: TYPE_TB
  zh: '| `IntStream.range / .rangeClosed` | `+++` |'
- en: '| `Arrays.stream` (primitives) | `+++` |'
  id: totrans-82
  prefs: []
  type: TYPE_TB
  zh: '| `Arrays.stream`（原始类型） | `+++` |'
- en: '| `ArrayList` | `++` |'
  id: totrans-83
  prefs: []
  type: TYPE_TB
  zh: '| `ArrayList` | `++` |'
- en: '| `Arrays.stream` (objects) | `++` |'
  id: totrans-84
  prefs: []
  type: TYPE_TB
  zh: '| `Arrays.stream`（对象） | `++` |'
- en: '| `HashSet` | `+` |'
  id: totrans-85
  prefs: []
  type: TYPE_TB
  zh: '| `HashSet` | `+` |'
- en: '| `TreeSet` | `+` |'
  id: totrans-86
  prefs: []
  type: TYPE_TB
  zh: '| `TreeSet` | `+` |'
- en: '| `LinkedList` | `--` |'
  id: totrans-87
  prefs: []
  type: TYPE_TB
  zh: '| `LinkedList` | `--` |'
- en: '| `Stream.iterate` | `--` |'
  id: totrans-88
  prefs: []
  type: TYPE_TB
  zh: '| `Stream.iterate` | `--` |'
- en: The degree of efficient decomposability isn’t the only factor regarding data
    sources and their possible performance in parallel Streams. A more technical aspect
    that’s easy to overlook is *data locality*.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 高效分解的程度并非唯一关乎数据源及其在并行流中可能性能的因素。一个容易被忽视的更技术性方面是 *数据局部性*。
- en: Besides more cores, modern computers feature a myriad of caches to improve performance
    at a memory level. Where memory is stored depends on the decisions made by the
    runtime and the CPU itself. Reading from L1 cache is ~100 times faster than RAM,
    L2 cache ~25 times. The “closer” the data is to actual processing, the better
    performance can be achieved.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 现代计算机除了更多核心外，还拥有许多缓存，以提高内存级2缓存则快约25倍。数据越接近实际处理，性能就会越好。
- en: Usually, JDK implementations store object fields and arrays in adjacent memory
    locations. This design allows for prefetching “near” data and speeding up any
    task.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，JDK实现将对象字段和数组存储在相邻的内存位置。这种设计允许预取“接近”数据并加快任何任务的速度。
- en: Arrays and lists of reference types, a `List<Integer>` or an `Integer[]`, store
    a collection of pointers to the actual values, compared to an array of primitives — `int[]` — which
    stores its values next to each other. If there’s a cache miss because the required
    next value isn’t prefetched, the CPU has to wait for the actual data to be loaded,
    and therefore *wasting* resources. That doesn’t mean that only primitive arrays
    are a good match for parallel processing, though. *Data locality* is just one
    of many criteria that might affect your decision to choose the right data source
    for going parallel. Compared to the other criteria, though, it’s quite a minuscule
    one and slightly out of your direct control of how the runtime and JDK store data.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 引用类型的数组和列表，比如 `List<Integer>` 或 `Integer[]`，存储的是指向实际值的指针集合，与原始数据类型的数组 `int[]`
    相比，后者将其值存储在相邻位置。如果由于缓存未命中而需要等待加载实际数据，CPU 就必须等待，因此 *浪费* 资源。但这并不意味着只有原始数据类型的数组适合并行处理。*数据局部性*
    只是影响您选择正确数据源进行并行处理的众多标准之一。与其他标准相比，它是相当微小的一个，而且稍微超出了您直接控制运行时和 JDK 存储数据的范围。
- en: Number of Elements
  id: totrans-93
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 元素数量
- en: 'There’s no definitive number of elements that will give you the best parallel
    performance, but one thing is clear: the more elements a parallel Stream has to
    process, the better, so it can offset the overhead of coordinating multiple threads.'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 并不存在可以确切保证给出最佳并行性能的元素数量，但有一点是明确的：并行流处理的元素越多，其处理效率就越高，因此可以抵消协调多个线程的开销。
- en: To process elements in parallel, they must be partitioned, processed, and joined
    again for the final result. These operations are all related, and finding a sensible
    balance is a *must-have*. This balance is represented by the *NQ model*.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 要并行处理元素，必须对其进行分区、处理，然后再将它们连接以获得最终结果。这些操作都是相关的，找到合理的平衡是 *必不可少* 的。这种平衡由 *NQ 模型*
    表示。
- en: '*N* represents the number of elements, *Q* is the cost of a single task. Their
    product — *N * Q* — indicates the likeliness of getting a speedup from parallel
    processing. A general overview of weighing the different aspects can be seen in
    [Figure 8-3](#_01-parallel-concurrent-async_n-q).'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: '*N* 代表元素的数量，*Q* 是单个任务的成本。它们的乘积 — *N * Q* — 表示并行处理获得加速的可能性。可以在 [图 8-3](#_01-parallel-concurrent-async_n-q)
    中看到对不同方面进行权衡的概述。'
- en: '![Cost per task in relation to task count](assets/afaj_0803.png)'
  id: totrans-97
  prefs: []
  type: TYPE_IMG
  zh: '![任务成本与任务数量关系图](assets/afaj_0803.png)'
- en: Figure 8-3\. The NQ model
  id: totrans-98
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 8-3\. NQ 模型
- en: 'As you can see, a higher number of elements is always a good indicator for
    possible speedup by parallel processing compared to a lower number. Long-running
    tasks also profit from being run in parallel and might even outweigh the lack
    of enough elements. But the best-case scenario is having both: lots of elements
    *and* non-cheap tasks.'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 正如你所见，元素数量的增加总是可能通过并行处理获得加速的良好指标，与较少的元素相比。长时间运行的任务也会从并行运行中受益，甚至可能超过元素不足的影响。但最理想的情况是两者兼备：大量元素
    *和* 非廉价任务。
- en: Stream Operations
  id: totrans-100
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 流   流操作
- en: After choosing the right data source, the operations are the next puzzle piece.
    The main goal of designing your parallel operations is to achieve the same final
    result as with a sequential Stream. That’s why most of the design choices for
    intermediate operations are universal.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 在选择了正确的数据源之后，操作就是下一个难题。设计并行操作的主要目标是与顺序流获得相同的最终结果。这就是为什么大多数中间操作的设计选择都是通用的。
- en: In the case of parallel Streams, though, issues that aren’t a big deal in sequential
    Streams can accumulate quickly. So adhering to more functional principles and
    parallel-friendly operations is important.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，在并行流的情况下，那些在顺序流中并不重要的问题会迅速积累。因此，遵循更多的功能性原则和并行友好操作是很重要的。
- en: Pure Lambdas
  id: totrans-103
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 纯lambda表达式
- en: Lambda expressions used in Stream operations should always be *pure*, meaning
    they shouldn’t rely on *non-local* mutable state or emit any side effects. To
    mitigate the most apparent *non-local* state issues, any captured variables must
    be effectively `final`, as explained in [“Effectively final”](ch02.xhtml#_01-functions_lambdas_effectively-final),
    which only affects the reference itself.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 在流操作中使用的lambda表达式应始终是*纯*的，这意味着它们不应依赖于*非局部*的可变状态或产生任何副作用。为了减轻最明显的*非局部*状态问题，任何被捕获的变量必须是有效地`final`，如[“有效地final”](ch02.xhtml#_01-functions_lambdas_effectively-final)中所解释的，这仅影响引用本身。
- en: Reading immutable state isn’t an issue either. The real problem arises from
    a thread that changes *non-local* state, so any access requires synchronization
    between them, or you end up with non-deterministic behavior, like *race conditions*.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 读取不可变状态也不是问题。真正的问题是来自于改变*非局部*状态的线程，因此任何访问都需要在它们之间同步，否则就会出现非确定性行为，如*竞争条件*。
- en: The easiest way to prevent any non-deterministic behavior is to make sure that
    any *non-local* state is deeply immutable. This way, the lambda stays pure and
    can’t be affected by other threads running the same lambda.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 防止任何非确定性行为的最简单方法是确保任何*非局部*状态都是深度不可变的。这样，lambda函数保持纯净，并且不会受到其他线程运行相同lambda的影响。
- en: Parallel-friendly Operations
  id: totrans-107
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 并行友好操作
- en: Not all Stream operations are a good fit for parallel processing. The simplest
    way to judge an operation is its reliance on a specific encounter order for the
    Stream’s elements.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 并非所有的流操作都适合并行处理。判断一个操作是否适合并行处理的最简单方法是它是否依赖于流元素的特定遇到顺序。
- en: For example, the `limit`, `skip`, or `distinct` intermediate operations rely
    heavily on encounter order to provide a deterministic — or *stable* — behavior
    for ordered Streams, meaning they always choose or dismiss the same items.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，`limit`、`skip`或`distinct`中间操作严重依赖于遇到顺序，以提供有序流的确定性 — 或*稳定* — 行为，这意味着它们总是选择或忽略相同的项。
- en: 'This stability, however, comes at a price in parallel Streams: synchronization
    across all threads and increased memory needs. For example, to guarantee that
    the `limit` operation produces the same results in parallel use as in sequential
    Streams, it must wait for all preceding operations to finish in encounter order
    and buffer all elements until it’s known if they are needed.'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，这种稳定性在并行流中是有代价的：需要跨所有线程同步和增加内存需求。例如，为了保证`limit`操作在并行使用时产生与顺序流相同的结果，必须等待所有前序操作按照遇到顺序完成并缓冲所有元素，直到知道它们是否被需要。
- en: Luckily, not all pipelines require a fixed encounter order. Calling `unordered()`
    on a Stream pipeline changes the resulting Streams characteristics to `UNORDERED`,
    and therefore, *stable* operations become *unstable*. In many cases, it just doesn’t
    matter *which* distinct elements are picked, as long as the final result contains
    no duplicates. For `limit`, it’s a little trickier and depends on your requirements.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 幸运的是，并非所有的流水线都需要固定的遇到顺序。在流水线上调用`unordered()`会改变生成的流的特征为`UNORDERED`，因此*稳定*的操作会变为*不稳定*。在许多情况下，选取哪些不同的元素并不重要，只要最终的结果中不包含重复项即可。对于`limit`，情况则有些棘手，这取决于你的需求。
- en: There are also two *stable* terminal operations that depend on the encounter
    order of the data source, `findFirst` and `forEach`. Both of them provide an *unstable*
    variant, too, as listed in [Table 8-2](#_01-parallel-streams-stable-unstable-terminal-ops).
    They should be preferred for parallel Streams if your requirements allow it.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 还有两个*稳定*的终端操作依赖于数据源的遇到顺序，即`findFirst`和`forEach`。它们也有一个*不稳定*的变体，如在[表 8-2](#_01-parallel-streams-stable-unstable-terminal-ops)中所列。如果你的需求允许，应优先选择它们用于并行流。
- en: Table 8-2\. Stable versus unstable terminal operations
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 表 8-2\. 稳定与不稳定的终端操作
- en: '| Stable operations | Unstable operations |'
  id: totrans-114
  prefs: []
  type: TYPE_TB
  zh: '| 稳定操作 | 不稳定操作 |'
- en: '| --- | --- |'
  id: totrans-115
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| `findFirst()` | `findAny()` |'
  id: totrans-116
  prefs: []
  type: TYPE_TB
  zh: '| `findFirst()` | `findAny()` |'
- en: '| `forEachOrdered(Consumer<? super T> action)` | `forEach(Consumer<? super
    T> action)` |'
  id: totrans-117
  prefs: []
  type: TYPE_TB
  zh: '| `forEachOrdered(Consumer<? super T> action)` | `forEach(Consumer<? super
    T> action)` |'
- en: Even with fully parallelized intermediate operations, the final applicative
    terminal operation in a Stream pipeline is sequential to achieve a singular result
    or emit a side effect. Just like with unstable intermediate operations, the terminal
    operations `findAny()` and `forEach(…​)` can immensely profit from being unconstrained
    from encounter order and having to wait for other elements from other threads.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 即使在完全并行化的中间操作中，流管道中的最终适用终端操作是顺序的，以实现单一结果或发出副作用。就像不稳定的中间操作一样，终端操作`findAny()`和`forEach(…​)`可以极大地受益于不受限制地进行遇到顺序，并且无需等待来自其他线程的其他元素。
- en: Reduce Versus Collect
  id: totrans-119
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 减少与收集
- en: 'The terminal operations `reduce` and `collect` are two sides of the same coin:
    both are *reduction* — or *fold* — operations.'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 终端操作`reduce`和`collect`是同一个硬币的两面：两者都是*减少* — 或*折叠* — 操作。
- en: 'In functional programming, *fold* operations combine elements by applying a
    function to the elements and recombine the results recursively to build up a return
    value. The difference lies in the general approach on how to recombine the results:
    *immutable* versus *mutable* accumulation.'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 在函数式编程中，*fold*操作通过将函数应用于元素并递归地重新组合结果来结合元素以建立一个返回值。区别在于如何重新组合结果的一般方法：*不可变*与*可变*的累积。
- en: As I’ve discussed in [“Reducing Versus Collecting Elements”](ch06.xhtml#_02-data-processing_reduce-vs-collect),
    a *mutable* accumulation is more akin to how you would approach the problem in
    a `for`-loop, as seen in [Example 8-3](#_01-parallel-streams_mutable-acc-for-loop).
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我在[“减少与收集元素”](ch06.xhtml#_02-data-processing_reduce-vs-collect)中所讨论的那样，*可变*的累积更类似于你在`for`循环中处理问题的方式，就像在[示例 8-3](#_01-parallel-streams_mutable-acc-for-loop)中所见。
- en: Example 8-3\. Mutable accumulation with a for-loop
  id: totrans-123
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 8-3\. 使用for循环进行可变累积
- en: '[PRE2]'
  id: totrans-124
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: For a sequentially processed problem, this is a straightforward approach. Using
    non-local and mutable state, however, is a contra-indicator for parallel processing.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 对于顺序处理的问题，这是一种简单直接的方法。然而，使用非局部和可变状态却是并行处理的反指标。
- en: Functional programming favors *immutable* values, so the accumulation only depends
    on the previous result and current Stream element to produce a new and *immutable
    result*. This way, the operations can easily be run in parallel, as seen in [Figure 8-4](#_01-parallel-streams_immutable-reduction).
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 函数式编程偏爱*不可变*值，因此积累仅依赖于先前的结果和当前的流元素来生成一个新的和*不可变的结果*。这种方式使得操作可以很容易地并行运行，正如在[图 8-4](#_01-parallel-streams_immutable-reduction)中所示。
- en: '![Immutable accumulation of numbers](assets/afaj_0804.png)'
  id: totrans-127
  prefs: []
  type: TYPE_IMG
  zh: '![数字的不可变累积](assets/afaj_0804.png)'
- en: Figure 8-4\. Immutable accumulation of numbers
  id: totrans-128
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 8-4\. 数字的不可变累积
- en: 'The flow still has the same elements as before: an initial value `0` for each
    summation of values. Instead of accumulating the results in a single value, each
    step returns a new value as the left operand for the next summation. The simplest
    Stream form is shown in [Example 8-4](#_01-parallel-streams_immutable-reduction-stream).'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 流仍然具有与之前相同的元素：每个求和值的初始值`0`。与在单个值中累积结果不同，每一步返回一个新值作为下一个求和的左操作数。最简单的流形式在[示例 8-4](#_01-parallel-streams_immutable-reduction-stream)中显示。
- en: Example 8-4\. Immutable accumulation of numbers with a Stream
  id: totrans-130
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 8-4\. 使用流进行数字的不可变累积
- en: '[PRE3]'
  id: totrans-131
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: '[![1](assets/1.png)](#co_parallel_data_processing_with_streams_CO3-1)'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: '[![1](assets/1.png)](#co_parallel_data_processing_with_streams_CO3-1)'
- en: The initial value — or *identity* — is used for every parallel reduction operation.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 初始值 — 或*身份* — 用于每个并行减少操作。
- en: '[![2](assets/2.png)](#co_parallel_data_processing_with_streams_CO3-2)'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: '[![2](assets/2.png)](#co_parallel_data_processing_with_streams_CO3-2)'
- en: The method reference translates into a `BiFunction<Integer, Integer, Integer>`
    to accumulate the previous (or initial) value with the current Stream element.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 方法引用转换为一个`BiFunction<Integer, Integer, Integer>`，用于累积前一个（或初始）值与当前流元素。
- en: This more abstract form of reduction is easily parallelizable if it’s *associative*
    and without any shared state. A reduction is associative if the order or grouping
    of the accumulator arguments is irrelevant to the final result.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 如果它是*可关联的*且没有任何共享状态，则这种更抽象的减少形式很容易并行化。如果关联器参数的顺序或分组对最终结果无关紧要，则减少是可关联的。
- en: Even though *immutable* reduction is more amenable to parallel processing, it’s
    not the only reduction option in town. Depending on your requirements, a *mutable*
    reduction might be a more fitting solution because creating a new immutable result
    for every accumulation step could be costly. With enough elements, such costs
    accumulate over time affecting performance and memory requirements.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管*不可变*的规约更适合并行处理，但这并不是唯一的规约选项。根据你的要求，*可变*规约可能是更合适的解决方案，因为为每个累积步骤创建一个新的不可变结果可能会很昂贵。随着元素的增加，这些成本会随时间累积，影响性能和内存需求。
- en: A *mutable* reduction mitigates this overhead by using a mutable results container.
    The accumulation function receives this container instead of only the prior result,
    and it doesn’t return any value, unlike a `reduce` operator. To create the final
    result, the combiner merges all containers.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: '*可变*规约通过使用可变结果容器来减轻这种开销。累积函数接收这个容器而不是只有先前的结果，并且不像`reduce`运算符那样返回任何值。为了创建最终结果，组合器合并所有容器。'
- en: The factors that a decision between using `reduce` or `collect` in sequential
    and parallel Streams boil down to what kind of element you have and the usability
    and straightforwardness of the terminal *fold* operation. There are times when
    you might need every bit of performance available to you to improve your data
    processing, and a more complicated *fold* operation. Many other factors affect
    performance in general, so having an easier-to-understand and maintainable terminal
    operation might outweigh the downside of sacrificing a little bit more memory
    and CPU cycles.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 在顺序和并行流之间使用`reduce`或`collect`进行决策的因素归结为你拥有什么样的元素以及终端*fold*操作的可用性和直观性。有时，你可能需要利用所有可用的性能来改进数据处理，并且需要一个更复杂的*fold*操作。许多其他因素会影响性能，因此拥有一个更易于理解和可维护的终端操作可能会超过牺牲更多内存和CPU周期的缺点。
- en: Stream Overhead and Available Resources
  id: totrans-140
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 流的开销和可用资源
- en: Compared to traditional looping structures, a Stream always creates an unavoidable
    overhead, regardless of being sequential or parallel. Their advantage lies in
    providing a declarative way of defining data processing pipelines and utilizing
    many functional principles to maximize their ease of use and performance. In most
    real-world scenarios, though, the overhead is negligible compared to their conciseness
    and clarity.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 与传统的循环结构相比，无论是顺序还是并行流，都会产生不可避免的开销。它们的优势在于提供了一种声明性的方式来定义数据处理管道，并利用许多功能原理来最大化其易用性和性能。然而，在大多数实际情况下，与它们的简洁性和清晰性相比，开销都是可以忽略不计的。
- en: In the case of parallel Streams, though, you start with a more significant initial
    handicap compared to sequential Streams. Besides the overhead of the Stream scaffold
    itself, you have to think about data source decomposition costs, thread management
    by the `ForkJoinPool`, and recombining the final result, to get the full picture
    of all moving parts. And all those parts must have the resources — CPU cores and
    memory available to actually run them in parallel.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 在并行流的情况下，与顺序流相比，你将从更大的初始劣势开始。除了流脚手架本身的开销外，你还必须考虑数据源分解成本、`ForkJoinPool`的线程管理以及重新组合最终结果，以获得所有移动部件的全貌。并且所有这些部件都必须具有资源——CPU核心和内存可用以实际并行运行它们。
- en: Coined by the computer scientist Gene Amdahl in 1967, *Amdahl’s law*⁠^([2](ch08.xhtml#idm45115230447824))
    provides a way to calculate the theoretical latency speedup in parallel executions
    for constant workloads. The law takes the *parallel portion* of a single task
    and the *number of tasks* running in parallel into account, as shown in [Figure 8-5](#_01-parallel-concurrent-async_amdhals-law).
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 由计算机科学家Gene Amdahl在1967年创造，*阿姆达尔定律*⁠^([2](ch08.xhtml#idm45115230447824))提供了一种计算并行执行中理论延迟速度提升的方法，适用于恒定工作负载。该定律考虑了单个任务的*并行部分*和并行运行的*任务数量*，如[图8-5](#_01-parallel-concurrent-async_amdhals-law)所示。
- en: '![Amdahl''s law](assets/afaj_0805.png)'
  id: totrans-144
  prefs: []
  type: TYPE_IMG
  zh: '![阿姆达尔定律](assets/afaj_0805.png)'
- en: Figure 8-5\. Amdahl’s law
  id: totrans-145
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图8-5\. 阿姆达尔定律
- en: As you can see, the maximum performance gains have a ceiling depending on the
    count of parallel tasks that can be run simultaneously. There is no benefit in
    easily parallelizable tasks if the runtime can’t actually run them parallel due
    to the lack of adequate resources and is forced to interleave the tasks instead.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 正如你所看到的，最大的性能增益有一个上限，这取决于同时可以运行的并行任务的数量。如果运行时无法真正并行运行它们，因为缺乏足够的资源而被迫交替执行任务，那么容易并行化的任务就没有任何好处。
- en: 'Example: War and Peace (revisited)'
  id: totrans-147
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 示例：《战争与和平》（重访）
- en: With all these criteria for parallel Stream performance in mind, let’s analyze
    the previous example of counting the distinct words of Tolstoy’s “War and Peace”
    again to better understand why this particular Stream pipeline is a great match
    for parallel processing.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑到并行流性能的所有这些标准，让我们再次分析之前的“战争与和平”词汇统计示例，以更好地理解为何这个流管道非常适合并行处理。
- en: Data source characteristics
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 数据源特性
- en: The Stream is created from a UTF-8 plain text file with the help of the `Files.lines`
    method, which has quite good parallel characteristics according to its documentation^([3](ch08.xhtml#idm45115230437904)).
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 流是通过`Files.lines`方法从UTF-8纯文本文件创建的，根据文档，这个方法具有相当好的并行特性^([3](ch08.xhtml#idm45115230437904))。
- en: Number of elements
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 元素数量
- en: The text file contains over 60.000 lines, therefore, 60.000 elements flow through
    the pipeline. That’s not much for modern computers, but it’s also not a negligible
    number of elements.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 文本文件包含超过60,000行，因此通过管道流动的元素数量为60,000。对于现代计算机来说并不多，但元素数量也不可忽视。
- en: Intermediate operations
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 中间操作
- en: Each Stream operation works on a single line, completely independent from another,
    without any shared or outside state that requires coordination. The regular expressions
    are pre-compiled and read-only.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 每个流操作在单独的一行上工作，完全独立于其他操作，没有任何需要协调的共享或外部状态。正则表达式是预编译的且只读的。
- en: Terminal operation
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 终端操作
- en: The `Collector` can gather the results independently and merges them with a
    simple arithmetic operation.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: '`Collector`可以独立地收集结果，并通过简单的算术操作合并它们。'
- en: Available resources
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 可用资源
- en: My computer has 12 CPU threads available at most and therefore ~5.000 lines
    per thread if all of them are utilized.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 我的计算机最多有12个CPU线程可用，因此如果全部利用，每个线程约处理5,000行。
- en: It looks like the example hit the *parallelism jackpot*, even if not all criteria
    were matched perfectly. That’s why the performance gain for even such a simple
    task was quite high and near the expected speedup of *Amdahl’s law* for highly
    parallelizable operations. Looking back at [Figure 8-5](#_01-parallel-concurrent-async_amdhals-law),
    the 5x improvement on my setup with 6 cores / 12 threads suggests a parallelizability
    of ~90%.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 看起来这个例子中使用了*并行化的奖池*，即使并没有完全符合所有标准。这就是为什么即使对于这样一个简单的任务，性能提升也相当高，接近于高度可并行化操作的*Amdahl定律*预期加速。回顾[图 8-5](#_01-parallel-concurrent-async_amdhals-law)，在我设置的6核/12线程上，5倍的提升表明其可并行性约为~90%。
- en: 'Example: Random Numbers'
  id: totrans-160
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 示例：随机数
- en: This simplistic but deliberately chosen example of counting words in “War and
    Peace” showed that parallel Streams could provide enormous performance gains that
    scale with the available resources. But that’s not always the case for every workload,
    especially for a more complex one.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 这个简单但故意选择的“战争与和平”词频统计的例子表明，并行流可以显著提升性能，其提升程度与可用资源成比例。但对于每种工作负载来说，并不总是如此。
- en: Let’s look at another example, working with random numbers, and how `IntStream` — sequential
    and parallel — compares to a simple `for`-loop, as shown in [Example 8-5](#_01-parallel-concurrent-async_for-seq-para).
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看另一个例子，处理随机数以及如何使用`IntStream` — 顺序和并行 — 与简单的`for`循环进行比较，如[示例 8-5](#_01-parallel-concurrent-async_for-seq-para)所示。
- en: Example 8-5\. Random number statistics
  id: totrans-163
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 8-5\. 随机数统计
- en: '[PRE4]'
  id: totrans-164
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: '[![1](assets/1.png)](#co_parallel_data_processing_with_streams_CO4-1)'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: '[![1](assets/1.png)](#co_parallel_data_processing_with_streams_CO4-1)'
- en: 100 million elements should be enough elements to reach the (non-definite) threshold
    to gain a performance boost from parallel processing.
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 1亿个元素应该足够达到（非确定性的）阈值，从而获得并行处理的性能提升。
- en: '[![2](assets/2.png)](#co_parallel_data_processing_with_streams_CO4-2)'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: '[![2](assets/2.png)](#co_parallel_data_processing_with_streams_CO4-2)'
- en: To do at least some work, the elements will be multiplied by `2` twice with
    the help of a shared lambda.
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 为了至少完成一些工作，元素将通过共享的lambda表达式被乘以`2`两次。
- en: '[![3](assets/3.png)](#co_parallel_data_processing_with_streams_CO4-3)'
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: '[![3](assets/3.png)](#co_parallel_data_processing_with_streams_CO4-3)'
- en: 'The default source for pseudo-random numbers is used: `java.util.Random`.'
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 默认的伪随机数源是：`java.util.Random`。
- en: '[![4](assets/4.png)](#co_parallel_data_processing_with_streams_CO4-4)'
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: '[![4](assets/4.png)](#co_parallel_data_processing_with_streams_CO4-4)'
- en: The `for`-loop version tries to mimic a Stream as well as possible, including
    using the same logic for *collecting* the results.
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: '`for`循环版本尝试尽可能模仿流的行为，包括使用相同的逻辑来*收集*结果。'
- en: '[![5](assets/5.png)](#co_parallel_data_processing_with_streams_CO4-5)'
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: '[![5](assets/5.png)](#co_parallel_data_processing_with_streams_CO4-5)'
- en: 'The sequential Stream is as straightforward as possible: Stream creation, two
    mapping functions, and then the collection of the results in the form of summary
    statistics.'
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 顺序流尽可能直截了当：流的创建，两个映射函数，然后将结果收集为汇总统计数据。
- en: '[![6](assets/6.png)](#co_parallel_data_processing_with_streams_CO4-6)'
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: '[![6](assets/6.png)](#co_parallel_data_processing_with_streams_CO4-6)'
- en: The parallel variant only adds a `parallel()` call to the previous sequential
    one.
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 并行变体只是在之前的顺序流上添加了一个`parallel()`调用。
- en: Is the summarizing of random numbers a good match for the criteria of parallel
    processing? Let’s analyze!
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 随机数的总结是否符合并行处理的标准？让我们来分析一下！
- en: Data source characteristics
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 数据源特性
- en: Even though `Random` is thread-safe, it’s explicitly mentioned in its documentation^([4](ch08.xhtml#idm45115230117168))
    that repeated use from different threads will impact performance negatively. Instead,
    the `ThreadLocalRandom` type is recommended.
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 即使`Random`是线程安全的，它在文档中明确提到^([4](ch08.xhtml#idm45115230117168))，从不同线程重复使用会对性能产生负面影响。相反，建议使用`ThreadLocalRandom`类型。
- en: Number of elements
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 元素数量
- en: 100 million elements should be enough to get a performance gain from parallel
    processing, no worries there.
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 1亿个元素应该足够从并行处理中获得性能提升，不用担心。
- en: Intermediate operations
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 中间操作
- en: No local or shared state. Another plus point for possible parallel performance.
    But the example might be too simplistic to offset the parallel overhead.
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 没有本地或共享状态。这对于可能的并行性能是一个正面因素。但是这个例子可能过于简单，无法抵消并行的开销。
- en: Terminal operation
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 终端操作
- en: The `IntSummaryStatistics` collector only holds four integers and can combine
    sub-results with simple arithmetics. It shouldn’t impact parallel performance
    negatively.
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: '`IntSummaryStatistics`收集器只保存四个整数，并且可以通过简单的算术组合子结果。它不应该对并行性能产生负面影响。'
- en: The scorecard for parallel processing doesn’t look too bad. The most obvious
    problem is the data source itself. A more fitting data source might increase performance
    compared to the *default* `Random` number generator.
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 并行处理的成绩单看起来还不错。最明显的问题是数据源本身。一个更合适的数据源可能会提高性能，相比于*默认*的`Random`数生成器。
- en: Besides `Random` and `ThreadLocalRandom`, there’s also `SplittableRandom`, which
    is specially designed for Streams. After measuring the elapsed time of the `for`-loop
    as the baseline compared to the other options, the necessity of choosing a favorable
    data source and measuring the Stream’s performance is quite obvious The factor
    of increased time between the different data sources is listed in [Table 8-3](#_01-parallel-concurrent-async_randoms).
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 除了`Random`和`ThreadLocalRandom`之外，还有专门为流设计的`SplittableRandom`。在将`for`循环的经过时间作为基准与其他选项比较后，选择一个有利的数据源并测量流的性能的必要性就显而易见了。不同数据源之间增加的时间因素列在[表 8-3](#_01-parallel-concurrent-async_randoms)中。
- en: Table 8-3\. Elapsed time for different random number generators
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 表 8-3\. 不同随机数生成器的经过时间
- en: '| Data source | for-loop | Sequential Stream | Parallel Stream |'
  id: totrans-189
  prefs: []
  type: TYPE_TB
  zh: '| 数据源 | for循环 | 顺序流 | 并行流 |'
- en: '| --- | --- | --- | --- |'
  id: totrans-190
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- |'
- en: '| `Random` | 1.0x | 1.05x | 27.4x |'
  id: totrans-191
  prefs: []
  type: TYPE_TB
  zh: '| `Random` | 1.0x | 1.05x | 27.4x |'
- en: '| `SplittableRandom` | 1.0x | 2.1x | 4.1x |'
  id: totrans-192
  prefs: []
  type: TYPE_TB
  zh: '| `SplittableRandom` | 1.0x | 2.1x | 4.1x |'
- en: '| `ThreadLocalRandom` | 1.0x | 2.3x | 0.6x |'
  id: totrans-193
  prefs: []
  type: TYPE_TB
  zh: '| `ThreadLocalRandom` | 1.0x | 2.3x | 0.6x |'
- en: Even though there should be enough elements in the pipeline, enabling parallel
    processing can be counter-productive and decrease the performance manifold. That’s
    why making Stream’s parallel must be a conscious and informed decision.
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 即使在流水线中应该有足够的元素，启用并行处理可能会事与愿违，使性能大幅降低。这就是为什么将流设为并行必须是一个审慎和知情的决定。
- en: Better performance is a worthwhile goal, but it depends on the context and your
    requirements if a parallel Stream is preferable to sequential data processing.
    You should always start with a sequential Stream and only go parallel if the requirements
    dictate it and you’ve measured the performance gain. Sometimes, a “good old” `for`-loop
    might do the job just as well, or even better.
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 更好的性能是一个值得追求的目标，但是如果一个并行流是否比顺序数据处理更可取，这取决于上下文和你的需求。你应该始终从顺序流开始，只有在需求规定并且你已经测量了性能增益时才选择并行流。有时，“老式”的`for`循环可能效果同样好，甚至更好。
- en: Parallel Streams Checklist
  id: totrans-196
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 并行流检查表
- en: '[Example 8-5](#_01-parallel-concurrent-async_for-seq-para) exposed the problem
    of unfavorable data sources for parallel processing. But it’s not the only indicator
    for non-parallelizable workflows. Based on the criteria in [“When to Use and When
    to Avoid Parallel Streams”](#_01-parallel-concurrent-async_when-to-use-parallelism),
    a checklist can be established as a quick indicator to favor a parallel Stream,
    or not, as seen in [Table 8-4](#_01-parallel-streams_checklist).'
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: '[示例 8-5](#_01-parallel-concurrent-async_for-seq-para) 揭示了并行处理中不利数据源的问题。但这并不是非并行化工作流的唯一指标。根据
    [“何时使用并避免使用并行流”](#_01-parallel-concurrent-async_when-to-use-parallelism) 中的标准，可以建立一个检查表作为快速指标，以支持并行流或不支持，如
    [表 8-4](#_01-parallel-streams_checklist) 所示。'
- en: Table 8-4\. Parallel Stream checklist
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 表 8-4\. 并行流检查表
- en: '| Criteria | Considerations |'
  id: totrans-199
  prefs: []
  type: TYPE_TB
  zh: '| 标准 | 考虑因素 |'
- en: '| --- | --- |'
  id: totrans-200
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| Data source |'
  id: totrans-201
  prefs: []
  type: TYPE_TB
  zh: '| 数据源 |'
- en: Cost of Decomposability
  id: totrans-202
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 可分解性的成本
- en: Evenness/predictability of split chunks
  id: totrans-203
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 分割块的均匀性/可预测性
- en: Data locality of elements
  id: totrans-204
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 元素的数据局部性
- en: '|'
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '| Number of elements |'
  id: totrans-206
  prefs: []
  type: TYPE_TB
  zh: '| 元素数量 |'
- en: Total number of elements
  id: totrans-207
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 元素的总数
- en: '*NQ* model'
  id: totrans-208
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*NQ* 模型'
- en: '|'
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '| Intermediate operations |'
  id: totrans-210
  prefs: []
  type: TYPE_TB
  zh: '| 中间操作 |'
- en: Interdependence between operations
  id: totrans-211
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 操作之间的相互依赖性
- en: Necessity of shared state
  id: totrans-212
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 共享状态的必要性
- en: Parallel-friendly operations
  id: totrans-213
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 并行友好的操作
- en: Encounter order
  id: totrans-214
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 遭遇顺序
- en: '|'
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '| Terminal operation |'
  id: totrans-216
  prefs: []
  type: TYPE_TB
  zh: '| 终端操作 |'
- en: Cost of merging the final result
  id: totrans-217
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 合并最终结果的成本
- en: Mutable or immutable reduction
  id: totrans-218
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 可变或不可变的减少
- en: '|'
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '| Available resources |'
  id: totrans-220
  prefs: []
  type: TYPE_TB
  zh: '| 可用资源 |'
- en: CPU count
  id: totrans-221
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: CPU 数量
- en: Memory
  id: totrans-222
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 内存
- en: Common `ForkJoinPool` or customized
  id: totrans-223
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 常见的 `ForkJoinPool` 或定制的
- en: '|'
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: Any of these criteria affect parallel Stream performance and should influence
    your decision. No single one of them is an absolute deal-breaker, though.
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: 这些标准中的任何一个都会影响并行流的性能，并应影响您的决策。然而，没有一个是绝对的破坏者。
- en: Your code could *always* be more performant. Running Streams in parallel adds
    the complexity and overhead of coordinating multiple threads with possibly little
    gain or even decreased performance if not used correctly or in unfavorable environments.
    However, if used for fitting data sources and parallelizable tasks, using parallel
    Streams is an easy-to-use optimization technique for introducing a more efficient
    way of data processing into your pipelines.
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 您的代码总是可以更高效。在并行流中运行流添加了协调多个线程的复杂性和开销，可能会因不正确使用或在不利环境中使用而导致性能甚至下降。然而，如果用于适合的数据源和可并行化任务，则使用并行流是一种简单易用的优化技术，可以在流水线中引入更高效的数据处理方式。
- en: Takeaways
  id: totrans-227
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 要点
- en: Hardware evolves in the direction of more cores, not necessarily faster ones.
    Concurrency and parallelism play an important role in utilizing all available
    resources.
  id: totrans-228
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 硬件朝着更多核心的方向发展，而不一定是更快的核心。并发性和并行性在利用所有可用资源方面起着重要作用。
- en: Sequential processing is defined by its textual order in the code. Parallel
    code execution may overlap, making it harder to follow, analyze, and debug.
  id: totrans-229
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 顺序处理是由代码中的文本顺序定义的。并行代码执行可能重叠，使其更难以跟踪、分析和调试。
- en: Going parallel with Streams is easy, but their inherent complexity is hidden.
  id: totrans-230
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用流进行并行操作很容易，但它们固有的复杂性是隐藏的。
- en: 'Concurrent and parallel code introduces a whole new set of requirements and
    possible problems and caveats. Parallel processing is an optimization technique
    and should be treated as such: if you don’t need it, don’t do it; it’s a hard
    problem.'
  id: totrans-231
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 并发和并行代码引入了一整套新的要求和可能的问题和注意事项。并行处理是一种优化技术，应该像这样对待：如果不需要，就不要使用；这是一个难题。
- en: Most functionally preferred techniques, like *pure functions* and *immutability*,
    are beneficial, if not a requirement, for error-free and performant parallelized
    code. Adhering to these techniques early on, even in sequential code, allows an
    easier transition to parallel processing, if needed.
  id: totrans-232
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 大多数功能上首选的技术，如 *纯函数* 和 *不可变性*，对于无错误和高性能的并行化代码是有利的，如果不是必须的话。从早期遵循这些技术，即使在顺序代码中，也可以更轻松地过渡到并行处理。
- en: 'Kent Beck’s famous quote applies to parallel Streams, too: “first make it work,
    then make it right, and, finally, make it fast."⁠^([5](ch08.xhtml#idm45115230052720))
    Start with a sequential Stream to fulfill your data processing needs. Improve
    it by optimizing its operations. Only if necessary and proven beneficial, make
    it fast by going parallel.'
  id: totrans-233
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kent Beck 的著名语录也适用于并行流：“先让它运行起来，然后把它做对，最后使它快。”⁠^([5](ch08.xhtml#idm45115230052720))
    从顺序流开始满足您的数据处理需求。通过优化其操作来改进它。只有在必要且被证明有益的情况下，才通过并行方式使其快速。
- en: Read the documentation of your data source, operations, etc., to see if they
    are a good fit for parallel execution. It often provides the reasoning behind
    implementation details, performance indications, examples, and sometimes even
    alternative approaches.
  id: totrans-234
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 阅读您的数据源、操作等的文档，以查看它们是否适合并行执行。它通常提供了实现细节背后的推理、性能指示、示例，有时甚至还提供了替代方法。
- en: ^([1](ch08.xhtml#idm45115231315840-marker)) Project Gutenberg provides multiple
    versions of Tolstoy’s [“War and Peace”](https://www.gutenberg.org/ebooks/2600)
    for free. The plain-text version is used so no additional formatting affects the
    process of counting words.
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: ^([1](ch08.xhtml#idm45115231315840-marker)) 古腾堡计划免费提供多个版本的托尔斯泰的[《战争与和平》](https://www.gutenberg.org/ebooks/2600)。使用纯文本版本，以确保不会因额外的格式化而影响计数单词的过程。
- en: ^([2](ch08.xhtml#idm45115230447824-marker)) The Wikipedia entry on [Amdahl’s
    law](https://en.wikipedia.org/wiki/Amdahl%27s_law) describes the actual formula
    in detail.
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: ^([2](ch08.xhtml#idm45115230447824-marker)) 维基百科关于[Amdahl定律](https://en.wikipedia.org/wiki/Amdahl%27s_law)详细描述了实际公式。
- en: ^([3](ch08.xhtml#idm45115230437904-marker)) The call if delegated to `Files.lines(Path
    path, CharSet cs)` which [documentation](https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/nio/file/Files.xhtml#lines(java.nio.file.Path,java.nio.charset.Charset))
    lists possibly good parallel performance due to its `Spliterator` splitting in
    an optimal ratio under normal circumstances.
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: ^([3](ch08.xhtml#idm45115230437904-marker)) 调用委托给`Files.lines(Path path, CharSet
    cs)`，其[文档](https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/nio/file/Files.xhtml#lines(java.nio.file.Path,java.nio.charset.Charset))列出由于其`Spliterator`在正常情况下以最佳比例分割而可能获得良好的并行性能。
- en: ^([4](ch08.xhtml#idm45115230117168-marker)) Ususally, the documentation of a
    type, like for [`java.util.Random`](https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/util/Random.xhtml)
    gives indications about their use in multi-threaded environments.
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: ^([4](ch08.xhtml#idm45115230117168-marker)) 通常，类型的文档，如[`java.util.Random`](https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/util/Random.xhtml)，提供了在多线程环境中使用它们的指示。
- en: ^([5](ch08.xhtml#idm45115230052720-marker)) Kent Beck is an American software
    engineer and the creator of *extreme programming*. The quote is usually attributed
    to him, even though the gist of it exists for a long time like described in B.
    W. Lampson, “Hints for Computer System Design,” in [*IEEE Software*, Vol. 1, No.
    1, 11-28, Jan. 1984](https://doi.org/10.1109/MS.1984.233391).
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: ^([5](ch08.xhtml#idm45115230052720-marker)) 肯特·贝克是美国软件工程师，也是*极限编程*的创始人。尽管这句引述通常被归因于他，但其实这个思想早在
    B·W·兰普森的《计算机系统设计提示》中就有描述，见[*IEEE Software*, Vol. 1, No. 1, 11-28, Jan. 1984](https://doi.org/10.1109/MS.1984.233391)。
