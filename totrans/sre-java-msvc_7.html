<html><head></head><body>
<div id="sbo-rt-content" class="calibre2"><section data-type="chapter" type="chapter" data-pdf-bookmark="Chapter 7. Traffic Management" class="calibre3"><div class="preface" id="ch_traffic_management">
<h1 class="calibre17" id="BE6O4-2d714b853a094e9a910510217e0e3d73"><span class="keep-together">Chapter 7. </span>Traffic Management</h1>


<p class="author1"><a data-type="indexterm" data-primary="traffic management" id="ix_ch07-asciidoc0" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre"/>Cloud native applications expect failure and low availability from the other services and resources they interact with. In this chapter, we introduce important mitigation strategies involving load balancing (platform, gateway, and client-side) and call resilience patterns (retrying, rate limiters, bulkheads, and circuit breakers) that work together to ensure your microservices continue to perform.</p>

<p class="author1">These patterns won’t be applicable for every organization. Often introducing more complex traffic management trades off operational complexity for more predictable user experience or a lower overall failure rate. In other words, it’s easy to make a REST call to a downstream service with your HTTP client of choice; it’s a little more complicated to wrap that call in a retry. And a little more complicated still to provide a circuit breaker and fallback. But with greater complexity comes greater reliability.</p>

<p class="author1">Organizations should evaluate their need here based on the types of applications they have (for example, where circuit breaking is applicable) and which application frameworks microservices are primarily written in. Java has first-class library support for these patterns and integration into popular frameworks like Spring, but the lack of support in some other languages would make it preferable to use sidecars or service meshes, even if there is some loss of flexibility as a result.</p>






</div></section></div>



  

<div id="sbo-rt-content" class="calibre2">
<section data-type="chapter" type="chapter" data-pdf-bookmark="Chapter 7. Traffic Management" class="calibre3">
<div class="preface" id="ch_traffic_management">
<section data-type="sect1" data-pdf-bookmark="Microservices Offer More Potential Failure Points" class="calibre3"><div class="preface" id="idm45139261429016">
<h1 class="calibre19" id="calibre_pb_1">Microservices Offer More Potential Failure Points</h1>

<p class="author1"><a data-type="indexterm" data-primary="failure" data-secondary="potential failure points from microservices" id="idm45139261427848" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre"/><a data-type="indexterm" data-primary="traffic management" data-secondary="potential failure points from microservices" id="idm45139261426840" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre"/>As the number of microservices involved in a user interaction grows, the likelihood of encountering a service instance (in any given user interaction) that is in a low availability state increases. A service can put load on a downstream service that it cannot sustain and cause it to fail. Call resiliency patterns protect a service from failures in the downstream services, as well as negatively impact downstream services. They alter the call sequence with a goal of providing a reduced service to end users, but a service nevertheless. For example, a personalized list of Netflix movie recommendations can be replaced with generic movie recommendations if the personalization service is suffering from low availability.</p>

<p class="author1">Microservices are usually deployed in a horizontally scaled way across different availability zones to increase resiliency of the distributed system. Microservices are not static. At any given time several of them can be released (new versions are being deployed or canaried), scaled, moved, or failed over. Some instances may experience failures, but not all. They may be temporarily down or experiencing reduced performance. This dynamic, frequently changed system requires adopting a set of practices for dynamically routing traffic: from discovering where the services are in the first place to picking which instance to send the traffic to. This is covered by different load-balancing approaches.</p>

<p class="author1">Two approaches exist for implementing these patterns: the application framework (code) and the supporting infrastructure (platform or gateway load balancers, service mesh). A combination can also be used. Generally, implementing these in application frameworks allows more flexibility and customization that’s specialized to the business domain. For example, replacing personalized movie recommendations with generic ones is acceptable, but there is no obvious fallback response to a request to a payment or billing service—an understanding of the business domain matters.</p>
</div></section>













</div></section></div>



  

<div id="sbo-rt-content" class="calibre2">
<section data-type="chapter" type="chapter" data-pdf-bookmark="Chapter 7. Traffic Management" class="calibre3">
<div class="preface" id="ch_traffic_management">
<section data-type="sect1" data-pdf-bookmark="Concurrency of Systems" class="calibre3"><div class="preface" id="idm45139261422632">
<h1 class="calibre19" id="calibre_pb_2">Concurrency of Systems</h1>

<p class="author1"><a data-type="indexterm" data-primary="concurrency" data-secondary="traffic management and" id="idm45139261421432" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre"/><a data-type="indexterm" data-primary="traffic management" data-secondary="concurrency of systems" id="idm45139261420456" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre"/>By “concurrency” I am referring to the number of requests a microservice can service at once. There is a natural bound to concurrency in any system, usually driven by a resource like CPU or memory or the performance of a downstream service when requests are satisfied in a blocking manner. Any attempted requests exceeding this bound cannot be satisfied immediately and must be queued or rejected. In the case of a typical Java microservice running on Tomcat, the number of threads in Tomcat’s thread pool represents an upper bound on its concurrency limit (though system resources may very well be exhausted by a number of concurrent requests less than the Tomcat thread pool). The accept queue maintained by the operating system effectively queues up requests in excess of that concurrency limit.</p>

<p class="author1">Services fail when during prolonged periods of time the request rate exceeds the response rate. As the queue grows, so will the latency (since requests don’t even begin getting serviced until they are removed from the queue). Eventually queued requests will start timing out.</p>

<p class="author1">In this chapter, we will cover strategies to prevent a cascading failure from occurring because a concurrency limit has been reached. The discussion on load balancing, viewed from this perspective, is really a proactive approach to directing traffic in such a way as to prevent load-related failure in the first place.</p>
</div></section>













</div></section></div>



  

<div id="sbo-rt-content" class="calibre2">
<section data-type="chapter" type="chapter" data-pdf-bookmark="Chapter 7. Traffic Management" class="calibre3">
<div class="preface" id="ch_traffic_management">
<section data-type="sect1" data-pdf-bookmark="Platform Load Balancing" class="calibre3"><div class="preface" id="idm45139261416888">
<h1 class="calibre19" id="calibre_pb_3">Platform Load Balancing</h1>

<p class="author1"><a data-type="indexterm" data-primary="load balancing" data-secondary="platform" id="idm45139261415688" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre"/><a data-type="indexterm" data-primary="platform load balancing" id="idm45139261394328" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre"/><a data-type="indexterm" data-primary="traffic management" data-secondary="platform load balancing" id="idm45139261393656" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre"/>Every modern runtime platform (e.g., IaaS offerings like AWS/GCP/Azure, a CaaS offering such as any Kubernetes distribution, or a PaaS offering like Cloud Foundry) has at least some basic cluster load balancer. These load balancers serve to distribute traffic across the instances in a cluster one way or another (often round-robin), but also have a wide range of other responsibilities. For example, AWS Elastic Load Balancers also serve the interests of TLS termination, content-based routing, sticky sessions, etc.</p>

<p class="author1">In on-premises environments, even simpler configurations are still prevalent with IIS, Nginx, Apache, etc., serving as statically configured load balancers in front of a fixed set of named virtual machines or physical machines.</p>

<p class="author1">Before discussing more complex options, it’s worth noting that there is nothing wrong with this setup for a particular level of scale. One regional casualty/property insurer primarily serves a web application for its captive agents, so capacity requirements for this user pool is incredibly stable. While such an organization can benefit from an active-active deployment for greater resiliency to failure in an individual datacenter, its traffic pattern doesn’t warrant the more complex load balancing at a gateway or on the client side.</p>
</div></section>













</div></section></div>



  

<div id="sbo-rt-content" class="calibre2">
<section data-type="chapter" type="chapter" data-pdf-bookmark="Chapter 7. Traffic Management" class="calibre3">
<div class="preface" id="ch_traffic_management">
<section data-type="sect1" data-pdf-bookmark="Gateway Load Balancing" class="calibre3"><div class="preface" id="idm45139261390200">
<h1 class="calibre19" id="BE6P5-2d714b853a094e9a910510217e0e3d73">Gateway Load Balancing</h1>

<p class="author1"><a data-type="indexterm" data-primary="gateway load balancing" id="ix_ch07-asciidoc1" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre"/><a data-type="indexterm" data-primary="load balancing" data-secondary="gateway" id="ix_ch07-asciidoc2" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre"/><a data-type="indexterm" data-primary="traffic management" data-secondary="gateway load balancing" id="ix_ch07-asciidoc3" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre"/>Software-based gateways are readily available in open source. <a href="https://oreil.ly/yTMx-" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre">Spring Cloud Gateway</a> is a reasonably modern incarnation of such a gateway, influenced by experience learned from working with <a href="https://oreil.ly/fNqHm" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre">Zuul</a>.</p>

<p class="author1">The ability of a runtime platform to load balance traffic to optimize availability is limited. For some availability signals like latency, the caller is the best source of information. The load balancer and calling application are similarly positioned to observe and react to latency as an availability signal. But for other signals, especially those involving utilization, the server itself is the best (and often only) source of this information. Combining these two sources of availability signals yields the most effective load-balancing strategy.</p>

<p class="author1">From the perspective of reliability, the goal of load balancing is to direct traffic away from servers that have high error rates. The goal should <em class="calibre12">not</em> be to optimize for the fastest response time. Optimizing for response time tends to result in strategies that can <em class="calibre12">herd</em> traffic to a healthy instance or group of instances, causing them to become overloaded and unavailable. Avoiding instances with high error rates still allows traffic to be distributed to instances that are not optimally performant, but available enough. If all instances in a cluster are overloaded, choosing one instance over another offers no benefit no matter how smart the load-balancing strategy. However, in many cases a subset of instances are overloaded because of temporary conditions.</p>

<p class="author1">A temporarily overloaded subset is found wherever there is a process whose execution is likely to be staggered across the cluster. For example, not all instances are likely to undergo GC or VM pauses, data updates, or cache swapping at the same time. This staggering tends to be present whenever there is no cluster-wide coordination of these processes. If all instances perform some sort of data update based on a synchronized clock, cluster coordination exists. For an example of a lack of coordination, consider what causes a GC pause to occur. Allocations incurred satisfying any given request eventually lead to a GC event. Since traffic will almost certainly be distributed nonuniformly across the cluster regardless of the load-balancing strategy, allocations will be staggered, leading to staggered GC events.</p>

<p class="author1">Another example of a subset of low-availability instances is the set of cold instances post-startup, such as instances brought into service by an autoscaling event or a zero-downtime deployment. With the rising popularity of serverless technologies, focus has been directed at application start time up to the point where health checks pass (effectively when the application instance is placed in service). But it’s important to note a second phase of cold start ill performance that begins on the first request, as in <a data-type="xref" href="part0012_split_004.html#first_five_minutes_latency" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre">Figure 7-1</a>, and ends when runtime optimizations have taken effect (i.e., the JVM’s JIT optimization, or application-specific behaviors like memory mapping a working set of data into memory). It’s this second phase that is so important to mitigate.</p>

<figure class="calibre32"><div id="first_five_minutes_latency" class="figure">
<img src="../images/00070.png" alt="The max will be much higher in the first few requests" class="calibre165"/>
<h6 class="calibre34"><span class="keep-together">Figure 7-1. </span>The max is more than an order of magnitude worse than P99 in the first few requests</h6>
</div></figure>

<p class="author1">The chart plots the two Prometheus queries shown in <a data-type="xref" href="part0012_split_004.html#first_five_minutes_latency_prometheus" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre">Example 7-1</a>.</p>
<div id="first_five_minutes_latency_prometheus" data-type="example" class="calibre61">
<h5 class="calibre62"><span class="keep-together">Example 7-1. </span>Prometheus queries plotting max and P99 latency for a REST endpoint/persons</h5>

<pre data-type="programlisting" class="calibre63">http_server_requests_seconds_max{uri="/persons"}
histogram_quantile(
  0.99,
  sum(
    rate(
      http_server_requests_seconds_bucket{uri="/persons"}[5m]
    )
  ) by (le)
)</pre></div>

<p class="author1">Some instances will run slower than others more or less permanently because of either bad underlying hardware or, increasingly, a noisy neighbor.</p>

<p class="author1">Clearly, round-robin load balancing can be improved upon. Architecturally, the logic for this load balancer resides in the edge gateway, as shown in <a data-type="xref" href="part0012_split_004.html#gateway_load_balancer" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre">Figure 7-2</a>.</p>

<figure class="calibre32"><div id="gateway_load_balancer" class="figure">
<img src="../images/00064.png" alt="srej 0702" class="calibre166"/>
<h6 class="calibre34"><span class="keep-together">Figure 7-2. </span>Using an API gateway as a smarter load balancer</h6>
</div></figure>

<p class="author1">User-facing traffic comes in through a platform load balancer, which distributes the traffic in a round-robin fashion to a cluster of gateway instances. In this case, we’ve shown one gateway serving requests to multiple microservices behind the edge. Gateway instances communicate directly with service instances by fetching an instance list from a discovery service like Netflix Eureka or HashiCorp Consul. There is no need for a platform load balancer in front of individual microservices that are load balanced by the gateway.</p>

<p class="author1">With this general setup in mind, we can progressively come up with a load-balancing strategy that takes into account application instances’ notion of their own availability. Then we’ll consider its unintended side effects. The goal is for you to be exposed to techniques that can be used in combination with domain-specific knowledge to craft a load-balancing strategy that works well for you while learning to think through and anticipate side effects.</p>








</div></section>













</div></section></div>



  

<div id="sbo-rt-content" class="calibre2">
<section data-type="chapter" type="chapter" data-pdf-bookmark="Chapter 7. Traffic Management" class="calibre3">
<div class="preface" id="ch_traffic_management">
<section data-type="sect1" data-pdf-bookmark="Gateway Load Balancing" class="calibre3">
<div class="preface" id="idm45139261390200">
<section data-type="sect2" data-pdf-bookmark="Join the Shortest Queue" class="calibre3"><div class="preface" id="idm45139261365560">
<h2 class="calibre37" id="calibre_pb_5">Join the Shortest Queue</h2>

<p class="author1"><a data-type="indexterm" data-primary="gateway load balancing" data-secondary="join the shortest queue" id="ix_ch07-asciidoc4" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre"/><a data-type="indexterm" data-primary="join the shortest queue load balancer" id="ix_ch07-asciidoc5" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre"/><a data-type="indexterm" data-primary="load balancing" data-secondary="join the shortest queue load balancer" id="ix_ch07-asciidoc6" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre"/>Perhaps the simplest “adaptive” load balancer that goes beyond simple round-robin is “join the shortest queue.”</p>

<p class="author1">Join the shortest queue is implemented by comparing some instance availability signal visible to the load balancer. A good example of this is in-flight requests to each instance that the load balancer is aware of. Suppose the load balancer is directing traffic to three application instances, two of which have an in-flight request. When the load balancer receives a new request, it will direct the request to the one instance that has no in-flight requests, as shown in <a data-type="xref" href="part0012_split_005.html#jsq_load_balancer" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre">Figure 7-3</a>. This is computationally cheap (just minimizing/maximizing some statistic) and easy to implement.</p>

<figure class="calibre32"><div id="jsq_load_balancer" class="figure">
<img src="../images/00058.png" alt="The load balancer knows which instance to direct traffic to" class="calibre167"/>
<h6 class="calibre34"><span class="keep-together">Figure 7-3. </span>Join the shortest queue with one load balancer node</h6>
</div></figure>

<p class="author1">It starts to break down when there is more than one load balancer instance. To this point, the algorithm described makes decisions based on in-flight requests known to any one load balancer instance (those requests that passed through it). In other words, in a pool of load balancers, each load balancer is making its own independent decision, unaware of in-flight requests occurring on the others.</p>

<p class="author1"><a data-type="xref" href="part0012_split_005.html#jsq_many_load_balancers" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre">Figure 7-4</a> shows how Load Balancer 1 will make a bad decision to send an incoming request to Server 3 on the basis of incomplete information it has about in-flight requests managed by other load balancer nodes. The arrows indicate in-flight requests. So before a new request comes in, Load Balancer 1 has an in-flight request to Service 1 and 2. Load Balancer 2 has an in-flight request to Service 2 and 3. Load Balancer 3 has three in-flight requests to Service 3. As a new request comes in to Load Balancer 1, since it only knows about its own in-flight requests, it will decide to send the new request to Service 3, even though it is the busiest service instance, with four in-flight requests coming from the other load balancers in the cluster.</p>

<figure class="calibre32"><div id="jsq_many_load_balancers" class="figure">
<img src="../images/00024.png" alt="The load balancer will make a bad decision based on incomplete information" class="calibre168"/>
<h6 class="calibre34"><span class="keep-together">Figure 7-4. </span>Join the shortest queue with several load balancer nodes</h6>
</div></figure>

<p class="author1">Join the shortest queue is an example of load balancing based on only the load balancer’s view of the situation. One consequence of this for low-throughput applications is that a load balancer is managing only a few in-flight requests to a subset of the instances in a cluster. The choice of which instance in the cluster is least utilized can lead to a choice between two instances with zero in-flight requests, a random choice since no other information is available.</p>
</div></section>













</div></section>













</div></section></div>



  

<div id="sbo-rt-content" class="calibre2">
<section data-type="chapter" type="chapter" data-pdf-bookmark="Chapter 7. Traffic Management" class="calibre3">
<div class="preface" id="ch_traffic_management">
<section data-type="sect1" data-pdf-bookmark="Gateway Load Balancing" class="calibre3">
<div class="preface" id="idm45139261390200">
<section data-type="sect2" data-pdf-bookmark="Join the Shortest Queue" class="calibre3">
<div class="preface" id="idm45139261365560">
<div data-type="warning" type="warning" class="calibre30"><h1 class="calibre69" id="calibre_pb_6">Avoid the Temptation to Coordinate!</h1>
<p class="author1">It may be tempting to consider sharing the state of each load balancer’s in-flight requests with other load balancers, but distributed coordination like this is difficult and should be avoided whenever possible. You wind up facing an engineering choice between rigging a peer-based distributed state system or choosing a shared datastore with the typical consistency, availability, and partitionability trade-offs.<a data-type="indexterm" data-startref="ix_ch07-asciidoc6" id="idm45139261349336" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre"/><a data-type="indexterm" data-startref="ix_ch07-asciidoc5" id="idm45139261348632" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre"/><a data-type="indexterm" data-startref="ix_ch07-asciidoc4" id="idm45139261347960" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre"/></p>
</div>

<p class="author1">The next pattern uses information from the instances being load balanced.</p>
</div></section>













</div></section>













</div></section></div>



  

<div id="sbo-rt-content" class="calibre2">
<section data-type="chapter" type="chapter" data-pdf-bookmark="Chapter 7. Traffic Management" class="calibre3">
<div class="preface" id="ch_traffic_management">
<section data-type="sect1" data-pdf-bookmark="Gateway Load Balancing" class="calibre3">
<div class="preface" id="idm45139261390200">
<section data-type="sect2" class="calibre3" data-pdf-bookmark="Instance-Reported Availability and Utilization"><div class="preface" id="idm45139261364936">
<h2 class="calibre37" id="BE6R4-2d714b853a094e9a910510217e0e3d73">Instance-Reported Availability and Utilization</h2>

<p class="author1"><a data-type="indexterm" data-primary="availability" data-secondary="instance-reported" id="ix_ch07-asciidoc7" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre"/><a data-type="indexterm" data-primary="gateway load balancing" data-secondary="instance-reported availability/utilization" id="ix_ch07-asciidoc8" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre"/><a data-type="indexterm" data-primary="instance-reported availability/utilization" id="ix_ch07-asciidoc9" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre"/>If instead we can inform each load balancer of the instance’s perspective on its own availability and utilization, then two load balancers using the same instance have the same information regarding its availability. There are two available solutions:</p>
<dl class="calibre20">
<dt class="calibre21">Poll</dt>
<dd class="calibre22">
<p class="calibre23">Poll each instance’s utilization, sampling data from health check endpoint detail.</p>
</dd>
<dt class="calibre21">Passively track</dt>
<dd class="calibre22">
<p class="calibre23">Passively track a header on the responses coming from the server annotated with current utilization data.</p>
</dd>
</dl>

<p class="author1">Both approaches are equally simple to implement, and each has trade-offs.</p>

<p class="author1"><a data-type="indexterm" data-primary="HealthMeterRegistry" id="ix_ch07-asciidoc10" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre"/>Micrometer has a <code class="calibre24">MeterRegistry</code> implementation called <code class="calibre24">HealthMeterRegistry</code> (available in the <code class="calibre24">io.micrometer:micrometer-registry-health</code> module) specifically to convert metrics data into availability signals that can be mapped to health indicators watched by load balancers.</p>

<p class="author1">A <code class="calibre24">HealthMeterRegistry</code> is configured with a set of service level objectives that are then mapped to framework health indicators and sampled each time the load balancer queries the health check endpoint.</p>

<p class="author1">Micrometer provides out-of-the-box service level objectives that are known to be applicable to a broad range of Java applications. These can be manually configured, as in <a data-type="xref" href="part0012_split_007.html#oob_slos" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre">Example 7-2</a>. Spring Boot Actuator also autoconfigures these objectives when <code class="calibre24">micrometer-registry-health</code> is present.</p>
<div id="oob_slos" data-type="example" class="calibre61">
<h5 class="calibre62"><span class="keep-together">Example 7-2. </span>Creating a HealthMeterRegistry with recommended service level objectives</h5>

<pre data-type="programlisting" data-code-language="java" class="calibre63"><code class="n">HealthMeterRegistry</code> <code class="n">registry</code> <code class="o">=</code> <code class="n">HealthMeterRegistry</code>
  <code class="o">.</code><code class="na">builder</code><code class="o">(</code><code class="n">HealthConfig</code><code class="o">.</code><code class="na">DEFAULT</code><code class="o">)</code>
  <code class="o">.</code><code class="na">serviceLevelObjectives</code><code class="o">(</code><code class="n">JvmServiceLevelObjectives</code><code class="o">.</code><code class="na">MEMORY</code><code class="o">)</code>
  <code class="o">.</code><code class="na">serviceLevelObjectives</code><code class="o">(</code><code class="n">JvmServiceLevelObjectives</code><code class="o">.</code><code class="na">ALLOCATIONS</code><code class="o">)</code>
  <code class="o">.</code><code class="na">serviceLevelObjectives</code><code class="o">(</code><code class="n">OperatingSystemServiceLevelObjectives</code><code class="o">.</code><code class="na">DISK</code><code class="o">)</code>
  <code class="o">.</code><code class="na">build</code><code class="o">();</code></pre></div>

<p class="author1">When this is bound to framework-level health indicators, these objectives are incorporated into the overall determination of an application’s health. Spring Boot Actuator’s health endpoint is shown configured with this default set of SLOs in <a data-type="xref" href="part0012_split_007.html#slo_actuator_health" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre">Figure 7-5</a>.</p>

<figure class="calibre32"><div id="slo_actuator_health" class="figure">
<img src="../images/00085.png" alt="srej 0705" class="calibre169"/>
<h6 class="calibre34"><span class="keep-together">Figure 7-5. </span>Spring Boot Actuator health endpoint with service level objectives</h6>
</div></figure>

<p class="author1">You can define your own service level objectives as well, and in <a data-type="xref" href="part0012_split_007.html#poll_instance_utilization_server" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre">Example 7-3</a> we define an <code class="calibre24">api.utilization</code> service level objective to support sampling utilization data from health check endpoint detail on the server. Spring Boot Actuator adds this objective to the <code class="calibre24">HealthMeterRegistry</code> that it will automatically create; or if you are wiring your own <code class="calibre24">HealthMeterRegistry</code>, you can add it directly at construction time.</p>
<div id="poll_instance_utilization_server" data-type="example" class="calibre61">
<h5 class="calibre62"><span class="keep-together">Example 7-3. </span>A custom ServiceLevelObjective to report server utilization</h5>

<pre data-type="programlisting" data-code-language="java" class="calibre63"><code class="nd">@Configuration</code><code class="calibre24">
</code><code class="k">class</code><code class="calibre24"> </code><code class="nc">UtilizationServiceLevelObjective</code><code class="calibre24"> </code><code class="o">{</code><code class="calibre24">
</code><code class="calibre24">  </code><code class="nd">@Bean</code><code class="calibre24">
</code><code class="calibre24">  </code><code class="n">ServiceLevelObjective</code><code class="calibre24"> </code><code class="nf">apiUtilization</code><code class="o">(</code><code class="o">)</code><code class="calibre24"> </code><code class="o">{</code><code class="calibre24">
</code><code class="calibre24">      </code><code class="k">return</code><code class="calibre24"> </code><code class="n">ServiceLevelObjective</code><code class="calibre24">
</code><code class="calibre24">        </code><code class="o">.</code><code class="na">build</code><code class="o">(</code><code class="s">"api.utilization"</code><code class="o">)</code><code class="calibre24"> </code><a class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre" id="co_traffic_management_CO1-1" href="part0012_split_007.html#callout_traffic_management_CO1-1"><img src="../images/00112.png" alt="1" class="calibre66"/></a><code class="calibre24">
</code><code class="calibre24">        </code><code class="o">.</code><code class="na">baseUnit</code><code class="o">(</code><code class="s">"requests"</code><code class="o">)</code><code class="calibre24"> </code><a class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre" id="co_traffic_management_CO1-2" href="part0012_split_007.html#callout_traffic_management_CO1-2"><img src="../images/00059.png" alt="2" class="calibre66"/></a><code class="calibre24">
</code><code class="calibre24">        </code><code class="o">.</code><code class="na">failedMessage</code><code class="o">(</code><code class="s">"Rate limit to 10,000 requests/second."</code><code class="o">)</code><code class="calibre24"> </code><a class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre" id="co_traffic_management_CO1-3" href="part0012_split_007.html#callout_traffic_management_CO1-3"><img src="../images/00067.png" alt="3" class="calibre66"/></a><code class="calibre24">
</code><code class="calibre24">        </code><code class="o">.</code><code class="na">count</code><code class="o">(</code><code class="n">s</code><code class="calibre24"> </code><code class="o">-</code><code class="o">&gt;</code><code class="calibre24"> </code><code class="n">s</code><code class="o">.</code><code class="na">name</code><code class="o">(</code><code class="s">"http.server.requests"</code><code class="o">)</code><code class="calibre24"> </code><a class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre" id="co_traffic_management_CO1-4" href="part0012_split_007.html#callout_traffic_management_CO1-4"><img src="../images/00016.png" alt="4" class="calibre66"/></a><code class="calibre24">
</code><code class="calibre24">          </code><code class="o">.</code><code class="na">tag</code><code class="o">(</code><code class="s">"uri"</code><code class="o">,</code><code class="calibre24"> </code><code class="s">"/persons"</code><code class="o">)</code><code class="calibre24">
</code><code class="calibre24">          </code><code class="o">.</code><code class="na">tag</code><code class="o">(</code><code class="s">"outcome"</code><code class="o">,</code><code class="calibre24"> </code><code class="s">"SUCCESS"</code><code class="o">)</code><code class="calibre24">
</code><code class="calibre24">        </code><code class="o">)</code><code class="calibre24">
</code><code class="calibre24">        </code><code class="o">.</code><code class="na">isLessThan</code><code class="o">(</code><code class="mi">10_000</code><code class="o">)</code><code class="o">;</code><code class="calibre24"> </code><a class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre" id="co_traffic_management_CO1-5" href="part0012_split_007.html#callout_traffic_management_CO1-5"><img src="../images/00100.png" alt="5" class="calibre66"/></a><code class="calibre24">
</code><code class="calibre24">  </code><code class="o">}</code><code class="calibre24">
</code><code class="o">}</code></pre></div>
<dl class="calibre20">
<dt class="calibre21"><a class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre" id="callout_traffic_management_CO1-1" href="part0012_split_007.html#co_traffic_management_CO1-1"><img src="../images/00112.png" alt="1" class="calibre66"/></a></dt>
<dd class="calibre67"><p class="calibre68">A name for the service level objective. This can be naming convention normalized just like a meter name when exposing it as the name of a health indicator component. Spring Boot would show this as a health component named <code class="calibre24">apiUtilization</code> (camel-cased) based on its convention.</p></dd>
<dt class="calibre21"><a class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre" id="callout_traffic_management_CO1-2" href="part0012_split_007.html#co_traffic_management_CO1-2"><img src="../images/00059.png" alt="2" class="calibre66"/></a></dt>
<dd class="calibre67"><p class="calibre68">The unit of measure of utilization, which makes the output a little more human readable.</p></dd>
<dt class="calibre21"><a class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre" id="callout_traffic_management_CO1-3" href="part0012_split_007.html#co_traffic_management_CO1-3"><img src="../images/00067.png" alt="3" class="calibre66"/></a></dt>
<dd class="calibre67"><p class="calibre68">What it means for this objective to not be met, in plain language.</p></dd>
<dt class="calibre21"><a class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre" id="callout_traffic_management_CO1-4" href="part0012_split_007.html#co_traffic_management_CO1-4"><img src="../images/00016.png" alt="4" class="calibre66"/></a></dt>
<dd class="calibre67"><p class="calibre68">We are retrieving a measure of throughput (<code class="calibre24">count</code>) here. Also available are <code class="calibre24">value</code> to retrieve a gauge value, <code class="calibre24">total</code> to retrieve timer total time, distribution summary total amount, long task timer active tasks, and <code class="calibre24">percentile</code>.</p></dd>
<dt class="calibre21"><a class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre" id="callout_traffic_management_CO1-5" href="part0012_split_007.html#co_traffic_management_CO1-5"><img src="../images/00100.png" alt="5" class="calibre66"/></a></dt>
<dd class="calibre67"><p class="calibre68">A threshold that we are testing the measure against. When this service is receiving more than 10,000 requests/second, it reports itself as out of service to anything monitoring its health endpoint.</p></dd>
</dl>

<p class="author1">When this health indicator is being consumed by a gateway that can contain custom code to respond to different conditions, it’s best to always report <code class="calibre24">UP</code> as the status for this health indicator. We could hardcode some fixed threshold in the application and report a different status like <code class="calibre24">OVERLOADED</code> when the utilization exceeds the threshold. Better would be to fetch the threshold from a dynamic configuration server such that the value can be changed on running instances in one stroke by changing the config server. Best is to leave the determination of what utilization is too much to the load balancer, which could be folding this decision into more complex criteria<a data-type="indexterm" data-startref="ix_ch07-asciidoc10" id="idm45139261118040" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre"/>.<a data-type="indexterm" data-startref="ix_ch07-asciidoc9" id="idm45139261117208" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre"/><a data-type="indexterm" data-startref="ix_ch07-asciidoc8" id="idm45139261116504" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre"/><a data-type="indexterm" data-startref="ix_ch07-asciidoc7" id="idm45139261115832" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre"/></p>
</div></section>













</div></section>













</div></section></div>



  

<div id="sbo-rt-content" class="calibre2">
<section data-type="chapter" type="chapter" data-pdf-bookmark="Chapter 7. Traffic Management" class="calibre3">
<div class="preface" id="ch_traffic_management">
<section data-type="sect1" data-pdf-bookmark="Gateway Load Balancing" class="calibre3">
<div class="preface" id="idm45139261390200">
<section data-type="sect2" data-pdf-bookmark="Health Checks" class="calibre3"><div class="preface" id="idm45139261346184">
<h2 class="calibre37" id="BE71V-2d714b853a094e9a910510217e0e3d73">Health Checks</h2>

<p class="author1"><a data-type="indexterm" data-primary="gateway load balancing" data-secondary="health checks" id="ix_ch07-asciidoc11" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre"/><a data-type="indexterm" data-primary="health checks" id="ix_ch07-asciidoc12" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre"/>Sometimes, though, our “gateway” is something like a platform load balancer (by platform load balancer I mean something like an AWS Application Load Balancer) that can respond to coarser measures of availability for its decisions. For example, many platform load balancers offer a means to configure a health check path and port. This could easily be configured to <code class="calibre24">/actuator/health</code>, but the platform load balancer will be responding only to whether the HTTP status of the response is successful. There isn’t enough configurability to peek at the utilization detail and make a decision relative to a threshold. In this case, it really is up to the application code to set a threshold and return <code class="calibre24">Health.up()</code> or <code class="calibre24">Health.outOfService()</code>. While there is nothing really inherently wrong with leaving this decision up to the app, it does require some a priori knowledge of performance at the time the app is being written, and of course is less flexible in the deployed environment. As an example of a platform load balancer that looks at health checks, DigitalOcean provides a “health check” <a href="https://oreil.ly/yYBzh" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre">configuration</a> for Kubernetes load balancers, as shown in <a data-type="xref" href="part0012_split_008.html#k8s_health_check_lb" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre">Example 7-4</a>. Health check configurations are also available for AWS Auto Scaling Groups and Google Cloud load balancers. Azure load balancers offer a similar configuration that is called a “health probe.”</p>
<div id="k8s_health_check_lb" data-type="example" class="calibre61">
<h5 class="calibre62"><span class="keep-together">Example 7-4. </span>A Kubernetes load balancer configured to look at instance-reported utilization</h5>

<pre data-type="programlisting" data-code-language="yaml" class="calibre63"><code class="nt">metadata</code><code class="p">:</code>
 <code class="nt">name</code><code class="p">:</code> <code class="calibre24">instance-reported-utilization</code>
  <code class="calibre24">annotations</code><code class="calibre24">:</code>
   <code class="calibre24">service.beta.kubernetes.io/do-loadbalancer-healthcheck-port:80</code>
   <code class="calibre24">service.beta.kubernetes.io/do-loadbalancer-healthcheck-protocol:http</code>
   <code class="calibre24">service.beta.kubernetes.io/do-loadbalancer-healthcheck-path:/actuator/health</code>
   <code class="calibre24">service.beta.kubernetes.io/do-loadbalancer-healthcheck-check-interval-seconds:3</code>
   <code class="calibre24">service.beta.kubernetes.io/do-loadbalancer-healthcheck-response-timeout-seconds:5</code>
   <code class="calibre24">service.beta.kubernetes.io/do-loadbalancer-healthcheck-unhealthy-threshold:3</code>
   <code class="calibre24">service.beta.kubernetes.io/do-loadbalancer-healthcheck-healthy-threshold:5</code></pre></div>

<p class="author1">When setting up a health indicator like this, the task is to find some key performance indicator that best summarizes the application’s availability. This performance indicator should monitor whatever the weak spot is in the application where an overabundance of traffic will eventually cause trouble. We are choosing to consider the <code class="calibre24">/persons</code> API endpoint the key performance indicator of utilization availability in this example. We could have selected more than one endpoint, multiple HTTP response outcomes, or any other combination of factors for HTTP endpoint throughput. Also, there are other measures of utilization that we could have used. If this was an <span class="keep-together">event-driven</span> application, then the rate of messages consumed from a message queue or Kafka topic would be reasonable. If multiple execution paths in the application all led to an interaction with some utilization-constrained resources like a datasource or the file system, as in <a data-type="xref" href="part0012_split_008.html#utilization_of_datasource" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre">Figure 7-6</a>, then measuring the utilization on that resource would also seem reasonable.</p>

<figure class="calibre32"><div id="utilization_of_datasource" class="figure">
<img src="../images/00052.png" alt="srej 0706" class="calibre170"/>
<h6 class="calibre34"><span class="keep-together">Figure 7-6. </span>Measure throughput on a datasource when multiple execution paths lead it to be a bottleneck</h6>
</div></figure>

<p class="author1">This health indicator can be added to a new Spring Boot application generated from <a href="https://start.spring.io" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre">start.spring.io</a> that includes a runtime dependency on <code class="calibre24">io.micrometer:micrometer-core</code> and the configuration found in <a data-type="xref" href="part0012_split_008.html#poll_instance_utilization_server_config" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre">Example 7-5</a>.</p>
<div id="poll_instance_utilization_server_config" data-type="example" class="calibre61">
<h5 class="calibre62"><span class="keep-together">Example 7-5. </span>Required application.yml configuration</h5>

<pre data-type="programlisting" data-code-language="yaml" class="calibre63"><code class="nt">management</code><code class="p">:</code>
  <code class="nt">endpoints.web.exposure.include</code><code class="p">:</code> <code class="calibre24">health</code>
  <code class="nt">endpoint.health.show-details</code><code class="p">:</code> <code class="calibre24">always</code></pre></div>

<p class="author1">The response from <code class="calibre24">http://APP_HOST/actuator/health</code> includes the instance’s view of its own utilization. Whether or not this utilization represents near full capacity is not important from the perspective of the “choice of two” algorithm. It is the algorithm’s choice to weight higher the lower of two such figures. It is only when the gateway/load balancer needs to prefilter the list of instances presented to the “choice of two” algorithm that it needs some domain-specific knowledge of a reasonable cutoff threshold to use, being at that point imbued with some understanding of whether a particular utilization level represents <em class="calibre12">too much</em> utilization or not.</p>

<p class="author1">By actively polling each instance, we are adding additional load on each instance proportional to the number of load balancer nodes. But for a service with low throughput, specifically when the utilization polling rate <em class="calibre12">exceeds</em> the request rate through a particular load balancer, polling provides a more accurate picture of utilization.</p>

<p class="author1">The passive strategy provides as up-to-date a view of utilization as the last request to arrive at a particular instance. The higher the throughput to an instance, the more accurate the utilization measure is.</p>

<p class="author1">We can use instance-reported utilization or health as an input to a more randomizing heuristic, as described next.<a data-type="indexterm" data-startref="ix_ch07-asciidoc12" id="idm45139261071672" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre"/><a data-type="indexterm" data-startref="ix_ch07-asciidoc11" id="idm45139261070968" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre"/></p>
</div></section>













</div></section>













</div></section></div>



  

<div id="sbo-rt-content" class="calibre2">
<section data-type="chapter" type="chapter" data-pdf-bookmark="Chapter 7. Traffic Management" class="calibre3">
<div class="preface" id="ch_traffic_management">
<section data-type="sect1" data-pdf-bookmark="Gateway Load Balancing" class="calibre3">
<div class="preface" id="idm45139261390200">
<section data-type="sect2" data-pdf-bookmark="Choice of Two" class="calibre3"><div class="preface" id="idm45139261114568">
<h2 class="calibre37" id="calibre_pb_9">Choice of Two</h2>

<p class="author1"><a data-type="indexterm" data-primary="“choice of two” load balancing" data-primary-sortas="choice of two" id="idm45139261031768" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre"/><a data-type="indexterm" data-primary="gateway load balancing" data-secondary="choice of two" id="idm45139261030824" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre"/>“Choice of two” selects two servers randomly and selects one based on the maximization of some criteria.</p>

<p class="author1">Defining the criteria with multiple factors limits bias that could unintentionally lead to herding. For example, suppose one server is failing on every request and that (as is often the case) the failure mode is such that failed responses have a lower response time than a successful response. The instance’s utilization will appear lower. If utilization was the only factor used, then load balancers would start sending <em class="calibre12">more</em> requests to the unhealthy instance!</p>

<p class="author1">Compute an aggregate of these three factors and maximize on the aggregate for the choice of two selection:</p>
<dl class="calibre20">
<dt class="calibre21">Client health</dt>
<dd class="calibre22">
<p class="calibre23">A measure of connection-related errors for that instance</p>
</dd>
<dt class="calibre21">Server utilization</dt>
<dd class="calibre22">
<p class="calibre23">The most recent utilization measure provided by the instance</p>
</dd>
<dt class="calibre21">Client utilization</dt>
<dd class="calibre22">
<p class="calibre23">Count of in-flight requests to the instance from this load balancer</p>
</dd>
</dl>

<p class="author1">To make this even more robust, consider prefiltering the list of servers from which the two are chosen and compared. Make sure to bound the filtering in some way to avoid high CPU cost in searching for relatively healthy instances in a cluster with a large pool of instances that are unhealthy (e.g., by only attempting so many times to select a relatively healthy instance). By filtering, we can present the choice of two algorithm with a choice between relatively healthy instances even when some portion of the cluster is persistently unavailable.</p>

<p class="author1">We can add one last tweak to our selection algorithm to accommodate cold starts.</p>
</div></section>













</div></section>













</div></section></div>



  

<div id="sbo-rt-content" class="calibre2">
<section data-type="chapter" type="chapter" data-pdf-bookmark="Chapter 7. Traffic Management" class="calibre3">
<div class="preface" id="ch_traffic_management">
<section data-type="sect1" data-pdf-bookmark="Gateway Load Balancing" class="calibre3">
<div class="preface" id="idm45139261390200">
<section data-type="sect2" data-pdf-bookmark="Instance Probation" class="calibre3"><div class="preface" id="idm45139261062872">
<h2 class="calibre37" id="calibre_pb_10">Instance Probation</h2>

<p class="author1"><a data-type="indexterm" data-primary="gateway load balancing" data-secondary="instance probation" id="idm45139261061784" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre"/><a data-type="indexterm" data-primary="instance probation" id="idm45139261060920" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre"/><a data-type="indexterm" data-primary="probation (instance probation)" id="idm45139261060248" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre"/>To avoid overloading new instances while they are still undergoing their second-phase warmup, we can simply place a static limit on the number of requests that are allowed to go to that new instance. The probationary period ends when the load balancer receives one or more utilization responses from the new instance.</p>

<p class="author1">The concept of statically rate limiting new instances can be extended to include a gradually ramping-up rate limit based on the instance’s age. Micrometer includes a <code class="calibre24">process.uptime</code> metric out of the box that can be used to calculate instance age.</p>

<p class="author1">Now that we have a toolbox of load-balancing strategies, let’s think about some of the unintended side effects they can have.</p>
</div></section>













</div></section>













</div></section></div>



  

<div id="sbo-rt-content" class="calibre2">
<section data-type="chapter" type="chapter" data-pdf-bookmark="Chapter 7. Traffic Management" class="calibre3">
<div class="preface" id="ch_traffic_management">
<section data-type="sect1" data-pdf-bookmark="Gateway Load Balancing" class="calibre3">
<div class="preface" id="idm45139261390200">
<section data-type="sect2" data-pdf-bookmark="Knock-On Effects of Smarter Load Balancing" class="calibre3"><div class="preface" id="idm45139261057288">
<h2 class="calibre37" id="calibre_pb_11">Knock-On Effects of Smarter Load Balancing</h2>

<p class="author1"><a data-type="indexterm" data-primary="gateway load balancing" data-secondary="knock-on effects of smarter load balancing" id="idm45139261007384" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre"/>The goal of developing the choice of two load balancers was to divert traffic away from instances suffering from availability problems. This has some interesting effects:</p>

<ul class="printings">
<li class="calibre15">
<p class="calibre18">When load balancing across two clusters in a blue/green deployment (or rolling blue/green), if one of the clusters has relatively worse performance, then it will receive less than an equal share of traffic.</p>
</li>
<li class="calibre15">
<p class="calibre18">In an automated canary analysis setup, the baseline and canary may receive different proportions of traffic for the same reason.</p>
</li>
<li class="calibre15">
<p class="calibre18">Anomaly detection may not pick up on outliers as quickly, as early signals of low reliability mean that fewer attempts are made against that instance.</p>
</li>
<li class="calibre15">
<p class="calibre18">The request distribution will not be as uniform as a round-robin load balancer.</p>
</li>
</ul>

<p class="author1">Availability signals are always decayed over time. In the instance-reported utilization examples (<a data-type="xref" href="part0012_split_007.html#poll_instance_utilization_server" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre">Example 7-3</a>), this is why we used a rate-per-interval measure of utilization. As soon as the interval rolls over, a period of instability is no longer reflected in utilization data. The end result is if an instance recovers from a period of low availability, it can win a choice-of-two comparison again and receive traffic from the load balancer.</p>

<p class="author1">Not every microservice architecture is designed such that inter-microservice requests always pass through a gateway (nor should they be).<a data-type="indexterm" data-startref="ix_ch07-asciidoc3" id="idm45139260999384" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre"/><a data-type="indexterm" data-startref="ix_ch07-asciidoc2" id="idm45139260998680" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre"/><a data-type="indexterm" data-startref="ix_ch07-asciidoc1" id="idm45139260998008" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre"/></p>
</div></section>





</div></section>













</div></section></div>



  

<div id="sbo-rt-content" class="calibre2">
<section data-type="chapter" type="chapter" data-pdf-bookmark="Chapter 7. Traffic Management" class="calibre3">
<div class="preface" id="ch_traffic_management">
<section data-type="sect1" data-pdf-bookmark="Client-Side Load Balancing" class="calibre3"><div class="preface" id="idm45139261389256">
<h1 class="calibre19" id="BE75G-2d714b853a094e9a910510217e0e3d73">Client-Side Load Balancing</h1>

<p class="author1"><a data-type="indexterm" data-primary="client-side load balancing" id="ix_ch07-asciidoc13" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre"/><a data-type="indexterm" data-primary="load balancing" data-secondary="client-side" id="ix_ch07-asciidoc14" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre"/><a data-type="indexterm" data-primary="traffic management" data-secondary="client-side load balancing" id="ix_ch07-asciidoc15" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre"/>A third option is to implement a client-side load balancer. This leaves load-balancing decisions to the caller. Historically, client-side load balancing has been used for novel load-balancing strategies like cloud platform zone avoidance or zone affinity, preference for lowest weighted response times, etc. When these strategies work well in general, they tend to reemerge as features of platform load balancers.</p>

<p class="author1"><a data-type="xref" href="part0012_split_012.html#client_side_load_balancer" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre">Figure 7-7</a> shows an interaction between Service A and Service B where Service A is using a client-side load balancer to distribute traffic to Service B. The client-side load balancer is part of Service A’s application code. Typically, an instance list will be fetched from a discovery service like Eureka or Consul, and because the client-side load balancer directs traffic to Service B instances picked from the instance list fetched from discovery, there is no need for a platform load balancer in front of <span class="keep-together">Service B.</span></p>

<figure class="calibre32"><div id="client_side_load_balancer" class="figure">
<img src="../images/00087.png" alt="srej 0707" class="calibre171"/>
<h6 class="calibre34"><span class="keep-together">Figure 7-7. </span>Client-side load balancing</h6>
</div></figure>

<p class="author1">Client-side load balancing can be used for different purposes. One of the original purposes was to dynamically source a list of server IPs or host names from a central service discovery mechanism like Eureka or Consul.</p>
</div></section>













</div></section></div>



  

<div id="sbo-rt-content" class="calibre2">
<section data-type="chapter" type="chapter" data-pdf-bookmark="Chapter 7. Traffic Management" class="calibre3">
<div class="preface" id="ch_traffic_management">
<section data-type="sect1" data-pdf-bookmark="Client-Side Load Balancing" class="calibre3">
<div class="preface" id="idm45139261389256">
<div data-type="note" type="note" class="calibre28"><h1 class="calibre54" id="calibre_pb_13">Why Service Discovery Instead of a Cloud Load Balancer?</h1>
<p class="author1"><a data-type="indexterm" data-primary="cloud load balancer, service discovery versus" id="idm45139260986440" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre"/><a data-type="indexterm" data-primary="service discovery, cloud load balancer versus" id="idm45139260985704" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre"/>When Netflix first developed Eureka, AWS VPC did not yet exist, and Elastic Load Balancers always had public, internet-facing host names. Not desiring to expose internal microservices to the public internet, Netflix built Eureka to achieve centrally what a private Application Load Balancer (ALBs being a replacement for what is now considered a legacy ELB construct in AWS) can achieve on a per-microservice basis. Perhaps if VPC was around when Netflix first migrated to AWS, Eureka would never have come about. Nevertheless, its use has extended beyond just load balancing to available instances in a cluster. <a data-type="xref" href="part0010_split_011.html#eureka_api_availability" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre">Table 5-1</a> showed how it is also used in blue/green deployments of event-driven microservices to take the instances in a disabled cluster out of service. Not every enterprise will take advantage of this kind of tooling, and if not, private cloud load balancers are probably simpler to manage.</p>
</div>

<p class="author1">Spring Cloud Commons has a client-side load-balancing abstraction that makes the configuration of these typical concerns fairly straightforward, as in <a data-type="xref" href="part0012_split_013.html#load_balancing_zone_health_checks" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre">Example 7-6</a>. Any use of the <code class="calibre24">WebClient</code> generated from such a configuration will cache the service listing for a period of time, preferring instances in the same zone, and using the configured <code class="calibre24">DiscoveryClient</code> to fetch the list of available names.</p>
<div id="load_balancing_zone_health_checks" data-type="example" class="calibre61">
<h5 class="calibre62"><span class="keep-together">Example 7-6. </span>Load balancing health checks</h5>

<pre data-type="programlisting" data-code-language="java" class="calibre63"><code class="nd">@Configuration</code>
<code class="nd">@LoadBalancerClient</code><code class="o">(</code>
  <code class="n">name</code> <code class="o">=</code> <code class="s">"discovery-load-balancer"</code><code class="o">,</code>
  <code class="n">configuration</code> <code class="o">=</code> <code class="n">DiscoveryLoadBalancerConfiguration</code><code class="o">.</code><code class="na">class</code>
<code class="o">)</code>
<code class="k">class</code> <code class="nc">WebClientConfig</code> <code class="o">{</code>
  <code class="nd">@LoadBalanced</code>
  <code class="nd">@Bean</code>
  <code class="n">WebClient</code><code class="o">.</code><code class="na">Builder</code> <code class="nf">webClientBuilder</code><code class="o">()</code> <code class="o">{</code>
    <code class="k">return</code> <code class="n">WebClient</code><code class="o">.</code><code class="na">builder</code><code class="o">();</code>
  <code class="o">}</code>
<code class="o">}</code>

<code class="nd">@Configuration</code>
<code class="k">class</code> <code class="nc">DiscoveryLoadBalancerConfiguration</code> <code class="o">{</code>
	<code class="nd">@Bean</code>
	<code class="k">public</code> <code class="n">ServiceInstanceListSupplier</code> <code class="nf">discoveryClientServiceInstances</code><code class="o">(</code>
    <code class="n">ConfigurableApplicationContext</code> <code class="n">context</code><code class="o">)</code> <code class="o">{</code>

    <code class="k">return</code> <code class="n">ServiceInstanceListSuppliers</code><code class="o">.</code><code class="na">builder</code><code class="o">()</code>
      <code class="o">.</code><code class="na">withDiscoveryClient</code><code class="o">()</code>
      <code class="o">.</code><code class="na">withZonePreference</code><code class="o">()</code>
      <code class="o">.</code><code class="na">withHealthChecks</code><code class="o">()</code>
      <code class="o">.</code><code class="na">withCaching</code><code class="o">()</code>
      <code class="o">.</code><code class="na">build</code><code class="o">(</code><code class="n">context</code><code class="o">);</code>
	<code class="o">}</code>
<code class="o">}</code></pre></div>

<p class="author1">Not all load balancing is about server selection, however. There is one particular client-side load-balancing strategy used to cut off tail latencies above the 99th <span class="keep-together">percentile.</span><a data-type="indexterm" data-startref="ix_ch07-asciidoc15" id="idm45139260976072" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre"/><a data-type="indexterm" data-startref="ix_ch07-asciidoc14" id="idm45139260909944" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre"/><a data-type="indexterm" data-startref="ix_ch07-asciidoc13" id="idm45139260909304" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre"/></p>
</div></section>













</div></section></div>



  

<div id="sbo-rt-content" class="calibre2">
<section data-type="chapter" type="chapter" data-pdf-bookmark="Chapter 7. Traffic Management" class="calibre3">
<div class="preface" id="ch_traffic_management">
<section data-type="sect1" data-pdf-bookmark="Hedge Requests" class="calibre3"><div class="preface" id="hedge_requests">
<h1 class="calibre19" id="calibre_pb_14">Hedge Requests</h1>

<p class="author1"><a data-type="indexterm" data-primary="hedge requests" id="idm45139260906824" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre"/><a data-type="indexterm" data-primary="latency" data-secondary="hedge requests to mitigate" id="idm45139260905896" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre"/><a data-type="indexterm" data-primary="traffic management" data-secondary="hedge requests" id="idm45139260904984" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre"/><a data-type="xref" href="part0006_split_000.html#5N3C4-2d714b853a094e9a910510217e0e3d73" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre">Chapter 2</a> showed that for <em class="calibre12">N</em> requests, the chance that at least one of these requests is in the top 1% of the latency distribution is <math alttext="left-parenthesis 1 minus 0.99 Superscript upper N Baseline right-parenthesis asterisk 100 percent-sign">
  <mrow>
    <mo>(</mo>
    <mn>1</mn>
    <mo>-</mo>
    <mn>0</mn>
    <mo>.</mo>
    <msup><mn>99</mn> <mi>N</mi> </msup>
    <mo>)</mo>
    <mo>*</mo>
    <mn>100</mn>
    <mo>%</mo>
  </mrow>
</math>. Furthermore, we saw how latency distributions are almost always multimodal, with the top 1% generally one to two orders of magnitude worse than the 99th percentile. For even 100 individual resource interactions, the chance of encountering one of these top 1% latencies is <math alttext="left-parenthesis 1 minus 0.99 Superscript 100 Baseline right-parenthesis asterisk 100 percent-sign equals 63.3 percent-sign">
  <mrow>
    <mo>(</mo>
    <mn>1</mn>
    <mo>-</mo>
    <mn>0</mn>
    <mo>.</mo>
    <msup><mn>99</mn> <mn>100</mn> </msup>
    <mo>)</mo>
    <mo>*</mo>
    <mn>100</mn>
    <mo>%</mo>
    <mo>=</mo>
    <mn>63</mn>
    <mo>.</mo>
    <mn>3</mn>
    <mo>%</mo>
  </mrow>
</math>.</p>

<p class="author1">One well-tested strategy to mitigate the effects of the top 1% latency when calling a downstream service or resource is to simply ship multiple requests downstream and accept whichever response comes back first, discarding the others.</p>

<p class="author1">This approach may seem surprising because obviously it increases the load on the downstream linearly according to the additional number of requests you include in your hedge (and potentially this fans out more than linearly beyond the direct downstream, as it in turn makes requests to <em class="calibre12">its</em> downstreams and so on). In many enterprises, services experience a throughput that doesn’t come close to their total capacity, and the most resilient services are scaled horizontally in some sort of active-active capacity to limit the impact of an outage in any one region. This has the effect of increasing capacity (generally unused) to improve resiliency. At its best, hedge requesting can serve to simply use this excess capacity while improving end-user response times by significantly reducing the frequency of the worst latencies.</p>

<p class="author1">Obviously, the decision to employ hedge requesting requires some domain-specific knowledge about the downstream service being called. It wouldn’t be appropriate to ship three requests to a third-party payment system to charge a customer’s credit card three times! For this reason, hedge requesting is typically performed in application code.</p>
</div></section>













</div></section></div>



  

<div id="sbo-rt-content" class="calibre2">
<section data-type="chapter" type="chapter" data-pdf-bookmark="Chapter 7. Traffic Management" class="calibre3">
<div class="preface" id="ch_traffic_management">
<section data-type="sect1" data-pdf-bookmark="Hedge Requests" class="calibre3">
<div class="preface" id="hedge_requests">
<div data-type="warning" type="warning" class="calibre30"><h1 class="calibre69" id="calibre_pb_15">Hedge Requests Can’t Be Implemented by Service Mesh Client-Side Load Balancers (!!)</h1>
<p class="author1"><a data-type="indexterm" data-primary="service mesh" data-secondary="hedge requests and" id="idm45139260882744" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre"/>Since domain-specific knowledge essentially requires that the load-balancing decision is made in the calling application, notice that shifting the responsibility for client-side load balancing to a service mesh is unworkable for hedge requesting. Given that hedge requesting is one of the simplest and most effective means of compensating for long-tail latencies above the 99th percentile, the inability of service mesh to replace application code for this purpose should be a trigger to consider whether the service mesh pattern is really appropriate more generally.</p>
</div>

<p class="author1">We now turn the discussion to patterns that compensate for failure in downstream microservices or lessen the likelihood of such services being overwhelmed in the first place.</p>
</div></section>













</div></section></div>



  

<div id="sbo-rt-content" class="calibre2">
<section data-type="chapter" type="chapter" data-pdf-bookmark="Chapter 7. Traffic Management" class="calibre3">
<div class="preface" id="ch_traffic_management">
<section data-type="sect1" data-pdf-bookmark="Call Resiliency Patterns" class="calibre3"><div class="preface" id="idm45139260880232">
<h1 class="calibre19" id="BE798-2d714b853a094e9a910510217e0e3d73">Call Resiliency Patterns</h1>

<p class="author1"><a data-type="indexterm" data-primary="call resiliency patterns" id="ix_ch07-asciidoc16" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre"/><a data-type="indexterm" data-primary="traffic management" data-secondary="call resiliency patterns" id="ix_ch07-asciidoc17" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre"/>Regardless of how well a load balancer makes a predictive decision about which instance <em class="calibre12">should</em> handle traffic best, any prediction is based on a projection of past performance. Past performance is never a guarantee of future results, so there still is a need for another level of resiliency to handle failure. Additionally, even a microservice cluster behind a load balancer that perfectly allocates traffic to the most available instances at any given time has a limit for what it can handle. The layers of a microservice architecture need to be guarded against overloading that could lead to complete failure.</p>

<p class="author1">These mechanisms together form different basic “backpressure” schemes.</p>
<blockquote class="pcalibre8 pcalibre9 pcalibre7">
<p class="calibre16"><a data-type="indexterm" data-primary="backpressure" id="idm45139260874312" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre"/>Backpressure is the signaling of failure from a serving system to the requesting system and how the requesting system handles those failures to prevent overloading itself and the serving system. Designing for backpressure means bounding resource use during times of overload and times of system failure. This is one of the basic building blocks of creating a robust distributed system. Implementations of backpressure usually involve either dropping new messages on the floor, or shipping errors back to users (and incrementing a metric in both cases) when a resource becomes limited or failures occur. Timeouts and exponential backoffs on connections and requests to other systems are also essential. Without backpressure mechanisms in place, cascading failure or unintentional message loss become likely. When a system is not able to handle the failures of another, it tends to emit failures to another system that depends on it.</p>
<p data-type="attribution" class="pcalibre10 pcalibre11">Jeff Hodges</p>
</blockquote>

<p class="author1">The caller can combine four patterns to improve resiliency:</p>

<ul class="printings">
<li class="calibre15">
<p class="calibre18">Retries</p>
</li>
<li class="calibre15">
<p class="calibre18">Rate limiters</p>
</li>
<li class="calibre15">
<p class="calibre18">Bulkheads</p>
</li>
<li class="calibre15">
<p class="calibre18">Circuit breakers</p>
</li>
</ul>

<p class="author1">Retries are an obvious first step to overcoming intermittent failure, but we need to be cautious of creating “retry storms,” i.e., overwhelming parts of the system that are already under duress with retries when the original requests begin to fail. The other patterns will help compensate. Still, let’s start with retries.</p>








</div></section>













</div></section></div>



  

<div id="sbo-rt-content" class="calibre2">
<section data-type="chapter" type="chapter" data-pdf-bookmark="Chapter 7. Traffic Management" class="calibre3">
<div class="preface" id="ch_traffic_management">
<section data-type="sect1" data-pdf-bookmark="Call Resiliency Patterns" class="calibre3">
<div class="preface" id="idm45139260880232">
<section data-type="sect2" data-pdf-bookmark="Retries" class="calibre3"><div class="preface" id="idm45139260866376">
<h2 class="calibre37" id="BE79V-2d714b853a094e9a910510217e0e3d73">Retries</h2>

<p class="author1"><a data-type="indexterm" data-primary="call resiliency patterns" data-secondary="retries" id="ix_ch07-asciidoc18" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre"/><a data-type="indexterm" data-primary="retries" id="ix_ch07-asciidoc19" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre"/>Expect transient failure in downstream services, caused by temporarily full thread pools, slow network connections resulting in timeouts, or other temporary conditions that lead to unavailability. This class of faults typically self-correct after a short period of time. Callers should be prepared to handle transient failure by wrapping calls to downstreams in retry logic. Consider three factors when adding retries:</p>

<ul class="printings">
<li class="calibre15">
<p class="calibre18">Whether retries are appropriate. This often requires domain-specific knowledge of the called service. For example, should we retry a payment attempt on a downstream service that returned a timeout? Will the timed-out operation eventually be processed, making a retry a potential double charge?</p>
</li>
<li class="calibre15">
<p class="calibre18">The maximum number of retry attempts, and the duration (including backoffs, as shown in <a data-type="xref" href="part0012_split_017.html#retry_resilience4j" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre">Example 7-7</a>) to use between attempts.</p>
</li>
<li class="calibre15">
<p class="calibre18">Which responses (and exception types) warrant a retry. For example, if a downstream returns a 400 because the inputs are malformed for some reason, we cannot expect a different result by retrying the same inputs.</p>
</li>
</ul>
<div id="retry_resilience4j" data-type="example" class="calibre61">
<h5 class="calibre62"><span class="keep-together">Example 7-7. </span>Setting up an exponential backoff retry with Resilience4J</h5>

<pre data-type="programlisting" data-code-language="java" class="calibre63"><code class="n">RetryConfig</code> <code class="n">config</code> <code class="o">=</code> <code class="n">RetryConfig</code><code class="o">.</code><code class="na">custom</code><code class="o">()</code>
  <code class="o">.</code><code class="na">intervalFunction</code><code class="o">(</code><code class="n">IntervalFunction</code><code class="o">.</code><code class="na">ofExponentialBackoff</code><code class="o">(</code>
    <code class="n">Duration</code><code class="o">.</code><code class="na">ofSeconds</code><code class="o">(</code><code class="mi">10</code><code class="o">),</code> <code class="mi">3</code><code class="o">))</code>
  <code class="o">.</code><code class="na">maxAttempts</code><code class="o">(</code><code class="mi">3</code><code class="o">)</code>
  <code class="o">.</code><code class="na">retryExceptions</code><code class="o">(</code><code class="n">RetryableApiException</code><code class="o">.</code><code class="na">class</code><code class="o">)</code>
  <code class="o">.</code><code class="na">build</code><code class="o">();</code>

<code class="n">RetryRegistry</code> <code class="n">retryRegistry</code> <code class="o">=</code> <code class="n">RetryRegistry</code><code class="o">.</code><code class="na">of</code><code class="o">(</code><code class="n">config</code><code class="o">);</code>

<code class="n">Retry</code> <code class="n">retry</code> <code class="o">=</code> <code class="n">retryRegistry</code><code class="o">.</code><code class="na">retry</code><code class="o">(</code><code class="s">"persons.api"</code><code class="o">);</code>

<code class="n">retry</code><code class="o">.</code><code class="na">executeCallable</code><code class="o">(()</code> <code class="o">-&gt;</code> <code class="o">{</code>
  <code class="n">Response</code> <code class="n">response</code> <code class="o">=</code> <code class="o">...</code>
  <code class="k">switch</code><code class="o">(</code><code class="n">response</code><code class="o">.</code><code class="na">code</code><code class="o">())</code> <code class="o">{</code>
    <code class="k">case</code> <code class="mi">401</code><code class="o">:</code>
      <code class="c">// Authentication flow</code>
    <code class="k">case</code> <code class="mi">502</code><code class="o">:</code>
    <code class="k">case</code> <code class="mi">503</code><code class="o">:</code>
    <code class="k">case</code> <code class="mi">504</code><code class="o">:</code>
      <code class="k">throw</code> <code class="k">new</code> <code class="nf">RetryableApiException</code><code class="o">();</code>
  <code class="o">}</code>

  <code class="k">return</code> <code class="n">response</code><code class="o">;</code>
<code class="o">});</code></pre></div>

<p class="author1">Resilience4J has a built-in metric for retry logic, enabled by binding your retry to a Micrometer meter registry, as in <a data-type="xref" href="part0012_split_017.html#retry_metrics_bind" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre">Example 7-8</a>.</p>
<div id="retry_metrics_bind" data-type="example" class="calibre61">
<h5 class="calibre62"><span class="keep-together">Example 7-8. </span>Publishing metrics about retries via Micrometer</h5>

<pre data-type="programlisting" data-code-language="java" class="calibre63"><code class="n">TaggedRetryMetrics</code>
  <code class="o">.</code><code class="na">ofRetryRegistry</code><code class="o">(</code><code class="n">retryRegistry</code><code class="o">)</code>
  <code class="o">.</code><code class="na">bindTo</code><code class="o">(</code><code class="n">meterRegistry</code><code class="o">);</code></pre></div>

<p class="author1">This exports a single gauge <code class="calibre24">resilience4j.retry.calls</code> with a <code class="calibre24">kind</code> tag segregating successful (with and without retry) and failed (with and without retry) calls. If you were to set an alert, it would be on a fixed threshold of calls where <code class="calibre24">kind</code> equals <code class="calibre24">failed.with.retry</code>. In many cases, the code where the call is being made is itself going to be timed. For example, a REST endpoint that, when invoked, does some work, including making downstream service calls with retry logic, is itself going to be timed with <code class="calibre24">http.server.requests</code>, and you should already be alerting on failures of that endpoint.</p>

<p class="author1">Nevertheless, if your application contains a common component guarding access to a resource or downstream service with retry logic, then alerting on a high failure rate to that resource can be a good signal that several pieces of your application will be <span class="keep-together">failing.</span><a data-type="indexterm" data-startref="ix_ch07-asciidoc19" id="idm45139260685544" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre"/><a data-type="indexterm" data-startref="ix_ch07-asciidoc18" id="idm45139260684840" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre"/></p>
</div></section>













</div></section>













</div></section></div>



  

<div id="sbo-rt-content" class="calibre2">
<section data-type="chapter" type="chapter" data-pdf-bookmark="Chapter 7. Traffic Management" class="calibre3">
<div class="preface" id="ch_traffic_management">
<section data-type="sect1" data-pdf-bookmark="Call Resiliency Patterns" class="calibre3">
<div class="preface" id="idm45139260880232">
<section data-type="sect2" data-pdf-bookmark="Rate Limiters" class="calibre3"><div class="preface" id="idm45139260684040">
<h2 class="calibre37" id="BE7EA-2d714b853a094e9a910510217e0e3d73">Rate Limiters</h2>

<p class="author1"><a data-type="indexterm" data-primary="call resiliency patterns" data-secondary="rate limiters" id="ix_ch07-asciidoc20" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre"/><a data-type="indexterm" data-primary="rate limiters" id="ix_ch07-asciidoc21" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre"/>The load on a microservice naturally varies over time based on user activity patterns, scheduled batch processes, etc. An atypical event could result in sudden and overwhelming bursts in activity. If increased load, maybe even for a particular business function served by a microservice, causes a strain on resources that could result in availability levels falling below an established SLO, rate limiting (also known as throttling) can keep the service up and serving requests, albeit at a defined rate of <span class="keep-together">throughput.</span></p>

<p class="author1">Resilience4J implements the rate limiter pattern with several options. In <a data-type="xref" href="part0012_split_018.html#BE7EN-2d714b853a094e9a910510217e0e3d73" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre">Example 7-9</a>, a rate limiter is used in a microservice that needs to make calls against downstream billing history and payment services. A diagram of the service interaction is shown in <a data-type="xref" href="part0012_split_018.html#call_resiliency_sample_services" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre">Figure 7-8</a>.</p>

<figure class="calibre32"><div id="call_resiliency_sample_services" class="figure">
<img src="../images/00107.png" alt="srej 0708" class="calibre172"/>
<h6 class="calibre34"><span class="keep-together">Figure 7-8. </span>Call resiliency example service interaction</h6>
</div></figure>
<div id="rate_limiter_resilience4j" data-type="example" class="calibre61">
<h5 class="calibre62" id="BE7EN-2d714b853a094e9a910510217e0e3d73"><span class="keep-together">Example 7-9. </span>Implementing a rate limiter with Resilience4J</h5>

<pre data-type="programlisting" data-code-language="java" class="calibre63"><code class="n">RateLimiterConfig</code><code class="calibre24"> </code><code class="n">config</code><code class="calibre24"> </code><code class="o">=</code><code class="calibre24"> </code><code class="n">RateLimiterConfig</code><code class="o">.</code><code class="na">custom</code><code class="o">(</code><code class="o">)</code><code class="calibre24">
</code><code class="calibre24">  </code><code class="o">.</code><code class="na">limitRefreshPeriod</code><code class="o">(</code><code class="n">Duration</code><code class="o">.</code><code class="na">ofMillis</code><code class="o">(</code><code class="mi">1</code><code class="o">)</code><code class="o">)</code><code class="calibre24">
</code><code class="calibre24">  </code><code class="o">.</code><code class="na">limitForPeriod</code><code class="o">(</code><code class="mi">10</code><code class="o">)</code><code class="calibre24"> </code><a class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre" id="co_traffic_management_CO2-1" href="part0012_split_018.html#callout_traffic_management_CO2-1"><img src="../images/00112.png" alt="1" class="calibre66"/></a><code class="calibre24">
</code><code class="calibre24">  </code><code class="o">.</code><code class="na">timeoutDuration</code><code class="o">(</code><code class="n">Duration</code><code class="o">.</code><code class="na">ofMillis</code><code class="o">(</code><code class="mi">25</code><code class="o">)</code><code class="o">)</code><code class="calibre24"> </code><a class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre" id="co_traffic_management_CO2-2" href="part0012_split_018.html#callout_traffic_management_CO2-2"><img src="../images/00059.png" alt="2" class="calibre66"/></a><code class="calibre24">
</code><code class="calibre24">  </code><code class="o">.</code><code class="na">build</code><code class="o">(</code><code class="o">)</code><code class="o">;</code><code class="calibre24">
</code><code class="calibre24">
</code><code class="n">RateLimiterRegistry</code><code class="calibre24"> </code><code class="n">rateLimiterRegistry</code><code class="calibre24"> </code><code class="o">=</code><code class="calibre24"> </code><code class="n">RateLimiterRegistry</code><code class="o">.</code><code class="na">of</code><code class="o">(</code><code class="n">config</code><code class="o">)</code><code class="o">;</code><code class="calibre24">
</code><code class="calibre24">
</code><code class="n">RateLimiter</code><code class="calibre24"> </code><code class="n">billingHistoryRateLimiter</code><code class="calibre24"> </code><code class="o">=</code><code class="calibre24"> </code><code class="n">rateLimiterRegistry</code><code class="calibre24">
</code><code class="calibre24">  </code><code class="o">.</code><code class="na">rateLimiter</code><code class="o">(</code><code class="s">"billingHistory"</code><code class="o">)</code><code class="o">;</code><code class="calibre24">
</code><code class="n">RateLimiter</code><code class="calibre24"> </code><code class="n">paymentRateLimiter</code><code class="calibre24"> </code><code class="o">=</code><code class="calibre24"> </code><code class="n">rateLimiterRegistry</code><code class="calibre24">
</code><code class="calibre24">  </code><code class="o">.</code><code class="na">rateLimiter</code><code class="o">(</code><code class="s">"payment"</code><code class="o">,</code><code class="calibre24"> </code><code class="n">config</code><code class="o">)</code><code class="o">;</code><code class="calibre24"> </code><a class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre" id="co_traffic_management_CO2-3" href="part0012_split_018.html#callout_traffic_management_CO2-3"><img src="../images/00067.png" alt="3" class="calibre66"/></a><code class="calibre24">
</code><code class="calibre24">
</code><code class="c">// Components that would, as part of their implementations,
</code><code class="c">// execute HTTP requests to downstream services
</code><code class="n">BillingHistory</code><code class="calibre24"> </code><code class="n">billingHistory</code><code class="calibre24"> </code><code class="o">=</code><code class="calibre24"> </code><code class="o">.</code><code class="o">.</code><code class="o">.</code><code class="calibre24">
</code><code class="n">Payments</code><code class="calibre24"> </code><code class="n">payments</code><code class="calibre24"> </code><code class="o">=</code><code class="calibre24"> </code><code class="o">.</code><code class="o">.</code><code class="o">.</code><code class="calibre24">
</code><code class="calibre24">
</code><code class="c">// Spring WebFlux Functional route specification
</code><code class="n">RouterFunction</code><code class="o">&lt;</code><code class="n">ServerResponse</code><code class="o">&gt;</code><code class="calibre24"> </code><code class="n">route</code><code class="calibre24"> </code><code class="o">=</code><code class="calibre24"> </code><code class="n">route</code><code class="o">(</code><code class="o">)</code><code class="calibre24">
</code><code class="calibre24">	</code><code class="o">.</code><code class="na">GET</code><code class="o">(</code><code class="s">"/billing/{id}"</code><code class="o">,</code><code class="calibre24"> </code><code class="n">accept</code><code class="o">(</code><code class="n">APPLICATION_JSON</code><code class="o">)</code><code class="o">,</code><code class="calibre24">
</code><code class="calibre24">    </code><code class="n">RateLimiter</code><code class="o">.</code><code class="na">decorateFunction</code><code class="o">(</code><code class="calibre24">
</code><code class="calibre24">      </code><code class="n">billingHistoryRateLimiter</code><code class="o">,</code><code class="calibre24">
</code><code class="calibre24">      </code><code class="nd">BillingHistory:</code><code class="o">:</code><code class="n">getHistory</code><code class="calibre24">
</code><code class="calibre24">    </code><code class="o">)</code><code class="calibre24">
</code><code class="calibre24">  </code><code class="o">)</code><code class="calibre24">
</code><code class="calibre24">	</code><code class="o">.</code><code class="na">POST</code><code class="o">(</code><code class="s">"/payment"</code><code class="o">,</code><code class="calibre24">
</code><code class="calibre24">    </code><code class="n">RateLimiter</code><code class="o">.</code><code class="na">decorateFunction</code><code class="o">(</code><code class="calibre24">
</code><code class="calibre24">      </code><code class="n">paymentRateLimiter</code><code class="o">,</code><code class="calibre24">
</code><code class="calibre24">      </code><code class="nd">Payments:</code><code class="o">:</code><code class="n">sendPayment</code><code class="calibre24">
</code><code class="calibre24">    </code><code class="o">)</code><code class="calibre24">
</code><code class="calibre24">  </code><code class="o">)</code><code class="calibre24">
</code><code class="calibre24">	</code><code class="o">.</code><code class="na">build</code><code class="o">(</code><code class="o">)</code><code class="o">;</code></pre></div>
<dl class="calibre20">
<dt class="calibre21"><a class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre" id="callout_traffic_management_CO2-1" href="part0012_split_018.html#co_traffic_management_CO2-1"><img src="../images/00112.png" alt="1" class="calibre66"/></a></dt>
<dd class="calibre67"><p class="calibre68">Concurrency limit allowed by the rate limiter.</p></dd>
<dt class="calibre21"><a class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre" id="callout_traffic_management_CO2-2" href="part0012_split_018.html#co_traffic_management_CO2-2"><img src="../images/00059.png" alt="2" class="calibre66"/></a></dt>
<dd class="calibre67"><p class="calibre68">Timeout for a blocked thread attempting to enter a saturated rate limiter.</p></dd>
<dt class="calibre21"><a class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre" id="callout_traffic_management_CO2-3" href="part0012_split_018.html#co_traffic_management_CO2-3"><img src="../images/00067.png" alt="3" class="calibre66"/></a></dt>
<dd class="calibre67"><p class="calibre68">A rate limiter for some service can be created with a configuration different from the global one (e.g., because this service is capable of a higher concurrency level than others).</p></dd>
</dl>

<p class="author1">Resilience4J has built-in metrics for rate limiters. Bind your rate limiter registry to a Micrometer meter registry, as in <a data-type="xref" href="part0012_split_018.html#rate_limiter_metrics_bind" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre">Example 7-10</a>.</p>
<div id="rate_limiter_metrics_bind" data-type="example" class="calibre61">
<h5 class="calibre62"><span class="keep-together">Example 7-10. </span>Publishing metrics about rate limiting via Micrometer</h5>

<pre data-type="programlisting" data-code-language="java" class="calibre63"><code class="n">TaggedRateLimiterMetrics</code>
  <code class="o">.</code><code class="na">ofRateLimiterRegistry</code><code class="o">(</code><code class="n">rateLimiterRegistry</code><code class="o">)</code>
  <code class="o">.</code><code class="na">bindTo</code><code class="o">(</code><code class="n">meterRegistry</code><code class="o">);</code></pre></div>

<p class="author1">The metrics in <a data-type="xref" href="part0012_split_018.html#rate_limiter_metrics" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre">Table 7-1</a> are then published.</p>

<p class="author1">The two metrics have different benefits. Available permissions is an interesting <em class="calibre12">predictive</em> indicator. If permissions are reaching zero or near zero (where maybe they previously did not), but waiting threads is low, then end-user experience has not yet been degraded. A high number of waiting threads is a more <em class="calibre12">reactive</em> measure that the downstream service may need to be scaled up because end-user experience is being degraded (if response time is important and there are often waiting threads).</p>
<table id="rate_limiter_metrics" class="calibre40">
<caption class="calibre41"><span class="keep-together">Table 7-1. </span>Rate limiter metrics exposed by Resilience4J</caption>
<thead class="calibre42">
<tr class="calibre43">
<th class="calibre44">Metric name</th>
<th class="calibre44">Type</th>
<th class="calibre44">Description</th>
</tr>
</thead>
<tbody class="calibre45">
<tr class="calibre46">
<td class="calibre47"><p class="calibre48">resilience4j.ratelimiter.available.permissions</p></td>
<td class="calibre47"><p class="calibre48">Gauge</p></td>
<td class="calibre47"><p class="calibre48">The number of available permissions, or unused concurrency capacity</p></td>
</tr>
<tr class="calibre50">
<td class="calibre47"><p class="calibre48">resilience4j.ratelimiter.waiting.threads</p></td>
<td class="calibre47"><p class="calibre48">Gauge</p></td>
<td class="calibre47"><p class="calibre48">The number of waiting threads</p></td>
</tr>
</tbody>
</table>

<p class="author1">In Atlas, the alert condition for waiting threads tests against a fixed threshold, as shown in <a data-type="xref" href="part0012_split_018.html#atlas_ratelimit" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre">Example 7-11</a>.</p>
<div id="atlas_ratelimit" data-type="example" class="calibre61">
<h5 class="calibre62"><span class="keep-together">Example 7-11. </span>Atlas rate limiter alert threshold</h5>

<pre data-type="programlisting" class="calibre63">name,resilience4j.ratelimiter.waiting.threads,:eq,
$THRESHOLD,
:gt</pre></div>

<p class="author1">In Prometheus, the idea is similar, as shown in <a data-type="xref" href="part0012_split_018.html#prometheus_ratelimit" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre">Example 7-12</a>.<a data-type="indexterm" data-startref="ix_ch07-asciidoc21" id="idm45139260442472" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre"/><a data-type="indexterm" data-startref="ix_ch07-asciidoc20" id="idm45139260441768" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre"/></p>
<div id="prometheus_ratelimit" data-type="example" class="calibre61">
<h5 class="calibre62"><span class="keep-together">Example 7-12. </span>Prometheus rate limiter alert threshold</h5>

<pre data-type="programlisting" class="calibre63">resilience4j_ratelimiter_waiting_threads &gt; $THRESHOLD</pre></div>
</div></section>













</div></section>













</div></section></div>



  

<div id="sbo-rt-content" class="calibre2">
<section data-type="chapter" type="chapter" data-pdf-bookmark="Chapter 7. Traffic Management" class="calibre3">
<div class="preface" id="ch_traffic_management">
<section data-type="sect1" data-pdf-bookmark="Call Resiliency Patterns" class="calibre3">
<div class="preface" id="idm45139260880232">
<section data-type="sect2" data-pdf-bookmark="Bulkheads" class="calibre3"><div class="preface" id="idm45139260683448">
<h2 class="calibre37" id="BE7N2-2d714b853a094e9a910510217e0e3d73">Bulkheads</h2>

<p class="author1"><a data-type="indexterm" data-primary="bulkheads" id="ix_ch07-asciidoc22" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre"/><a data-type="indexterm" data-primary="call resiliency patterns" data-secondary="bulkheads" id="ix_ch07-asciidoc23" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre"/>Microservices commonly execute requests on multiple downstream services. When a service suffers from low availability, it can cause dependent services to become unresponsive as well. This is particularly true when the dependent service is blocking and using a thread pool to make requests. For a microservice <em class="calibre12">A</em> with multiple downstream services, it could be that only a small portion of the traffic (requests of a certain type) cause a request to microservice <em class="calibre12">B</em>. If <em class="calibre12">A</em> is using a common thread pool to execute requests not only against <em class="calibre12">B</em> but against all of its other downstream services as well, then unavailability in <em class="calibre12">B</em> can gradually block requests, saturating threads in the common thread pool to the point where little or no work can happen.</p>

<p class="author1">The bulkhead pattern isolates downstream services from one another, specifying different concurrency limits for each downstream service. In this way, only requests that require a service call to <em class="calibre12">B</em> become unresponsive, and the rest of the <em class="calibre12">A</em> service continues to be responsive.</p>

<p class="author1">Resilience4J implements the bulkhead pattern with several options, shown in <a data-type="xref" href="part0012_split_019.html#BE7NH-2d714b853a094e9a910510217e0e3d73" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre">Example 7-13</a>.</p>
<div id="bulkhead_resilience4j" data-type="example" class="calibre61">
<h5 class="calibre62" id="BE7NH-2d714b853a094e9a910510217e0e3d73"><span class="keep-together">Example 7-13. </span>Implementing the bulkhead pattern with Resilience4J</h5>

<pre data-type="programlisting" data-code-language="java" class="calibre63"><code class="n">BulkheadConfig</code><code class="calibre24"> </code><code class="n">config</code><code class="calibre24"> </code><code class="o">=</code><code class="calibre24"> </code><code class="n">BulkheadConfig</code><code class="o">.</code><code class="na">custom</code><code class="o">(</code><code class="o">)</code><code class="calibre24">
</code><code class="calibre24">  	</code><code class="o">.</code><code class="na">maxConcurrentCalls</code><code class="o">(</code><code class="mi">150</code><code class="o">)</code><code class="calibre24"> </code><a class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre" id="co_traffic_management_CO3-1" href="part0012_split_019.html#callout_traffic_management_CO3-1"><img src="../images/00112.png" alt="1" class="calibre66"/></a><code class="calibre24">
</code><code class="calibre24">  	</code><code class="o">.</code><code class="na">maxWaitDuration</code><code class="o">(</code><code class="n">Duration</code><code class="o">.</code><code class="na">ofMillis</code><code class="o">(</code><code class="mi">500</code><code class="o">)</code><code class="o">)</code><code class="calibre24"> </code><a class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre" id="co_traffic_management_CO3-2" href="part0012_split_019.html#callout_traffic_management_CO3-2"><img src="../images/00059.png" alt="2" class="calibre66"/></a><code class="calibre24">
</code><code class="calibre24">  	</code><code class="o">.</code><code class="na">build</code><code class="o">(</code><code class="o">)</code><code class="o">;</code><code class="calibre24">
</code><code class="calibre24">
</code><code class="n">BulkheadRegistry</code><code class="calibre24"> </code><code class="n">registry</code><code class="calibre24"> </code><code class="o">=</code><code class="calibre24"> </code><code class="n">BulkheadRegistry</code><code class="o">.</code><code class="na">of</code><code class="o">(</code><code class="n">config</code><code class="o">)</code><code class="o">;</code><code class="calibre24">
</code><code class="calibre24">
</code><code class="n">Bulkhead</code><code class="calibre24"> </code><code class="n">billingHistoryBulkhead</code><code class="calibre24"> </code><code class="o">=</code><code class="calibre24"> </code><code class="n">registry</code><code class="o">.</code><code class="na">bulkhead</code><code class="o">(</code><code class="s">"billingHistory"</code><code class="o">)</code><code class="o">;</code><code class="calibre24">
</code><code class="n">Bulkhead</code><code class="calibre24"> </code><code class="n">paymentBulkhead</code><code class="calibre24"> </code><code class="o">=</code><code class="calibre24"> </code><code class="n">registry</code><code class="o">.</code><code class="na">bulkhead</code><code class="o">(</code><code class="s">"payment"</code><code class="o">,</code><code class="calibre24"> </code><code class="n">custom</code><code class="o">)</code><code class="o">;</code><code class="calibre24"> </code><a class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre" id="co_traffic_management_CO3-3" href="part0012_split_019.html#callout_traffic_management_CO3-3"><img src="../images/00067.png" alt="3" class="calibre66"/></a><code class="calibre24">
</code><code class="calibre24">
</code><code class="c">// Components that would, as part of their implementations, execute HTTP requests
</code><code class="c">// to downstream services
</code><code class="n">BillingHistory</code><code class="calibre24"> </code><code class="n">billingHistory</code><code class="calibre24"> </code><code class="o">=</code><code class="calibre24"> </code><code class="o">.</code><code class="o">.</code><code class="o">.</code><code class="calibre24">
</code><code class="n">Payments</code><code class="calibre24"> </code><code class="n">payments</code><code class="calibre24"> </code><code class="o">=</code><code class="calibre24"> </code><code class="o">.</code><code class="o">.</code><code class="o">.</code><code class="calibre24">
</code><code class="calibre24">
</code><code class="c">// Spring WebFlux Functional route specification
</code><code class="n">RouterFunction</code><code class="o">&lt;</code><code class="n">ServerResponse</code><code class="o">&gt;</code><code class="calibre24"> </code><code class="n">route</code><code class="calibre24"> </code><code class="o">=</code><code class="calibre24"> </code><code class="n">route</code><code class="o">(</code><code class="o">)</code><code class="calibre24">
</code><code class="calibre24">	</code><code class="o">.</code><code class="na">GET</code><code class="o">(</code><code class="s">"/billing/{id}"</code><code class="o">,</code><code class="calibre24"> </code><code class="n">accept</code><code class="o">(</code><code class="n">APPLICATION_JSON</code><code class="o">)</code><code class="o">,</code><code class="calibre24">
</code><code class="calibre24">    </code><code class="n">Bulkhead</code><code class="o">.</code><code class="na">decorateFunction</code><code class="o">(</code><code class="calibre24">
</code><code class="calibre24">      </code><code class="n">billingHistoryBulkhead</code><code class="o">,</code><code class="calibre24">
</code><code class="calibre24">      </code><code class="nd">BillingHistory:</code><code class="o">:</code><code class="n">getHistory</code><code class="calibre24">
</code><code class="calibre24">    </code><code class="o">)</code><code class="calibre24">
</code><code class="calibre24">  </code><code class="o">)</code><code class="calibre24">
</code><code class="calibre24">	</code><code class="o">.</code><code class="na">POST</code><code class="o">(</code><code class="s">"/payment"</code><code class="o">,</code><code class="calibre24">
</code><code class="calibre24">    </code><code class="n">Bulkhead</code><code class="o">.</code><code class="na">decorateFunction</code><code class="o">(</code><code class="calibre24">
</code><code class="calibre24">      </code><code class="n">paymentBulkhead</code><code class="o">,</code><code class="calibre24">
</code><code class="calibre24">      </code><code class="nd">Payments:</code><code class="o">:</code><code class="n">sendPayment</code><code class="calibre24">
</code><code class="calibre24">    </code><code class="o">)</code><code class="calibre24">
</code><code class="calibre24">  </code><code class="o">)</code><code class="calibre24">
</code><code class="calibre24">	</code><code class="o">.</code><code class="na">build</code><code class="o">(</code><code class="o">)</code><code class="o">;</code></pre></div>
<dl class="calibre20">
<dt class="calibre21"><a class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre" id="callout_traffic_management_CO3-1" href="part0012_split_019.html#co_traffic_management_CO3-1"><img src="../images/00112.png" alt="1" class="calibre66"/></a></dt>
<dd class="calibre67"><p class="calibre68">Concurrency limit allowed by the bulkhead.</p></dd>
<dt class="calibre21"><a class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre" id="callout_traffic_management_CO3-2" href="part0012_split_019.html#co_traffic_management_CO3-2"><img src="../images/00059.png" alt="2" class="calibre66"/></a></dt>
<dd class="calibre67"><p class="calibre68">Timeout for a blocked thread attempting to enter a saturated bulkhead.</p></dd>
<dt class="calibre21"><a class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre" id="callout_traffic_management_CO3-3" href="part0012_split_019.html#co_traffic_management_CO3-3"><img src="../images/00067.png" alt="3" class="calibre66"/></a></dt>
<dd class="calibre67"><p class="calibre68">A bulkhead for some service can be created with a configuration different from the global one (e.g., because this service is capable of a higher concurrency level than others).</p></dd>
</dl>

<p class="author1">Resilience4J has built-in metrics for bulkheads. Bind the bulkhead registry to a Micrometer meter registry, as in <a data-type="xref" href="part0012_split_019.html#bulkhead_metrics_bind" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre">Example 7-14</a>.</p>
<div id="bulkhead_metrics_bind" data-type="example" class="calibre61">
<h5 class="calibre62"><span class="keep-together">Example 7-14. </span>Publishing metrics about bulkheads via Micrometer</h5>

<pre data-type="programlisting" data-code-language="java" class="calibre63"><code class="n">TaggedBulkheadMetrics</code>
  <code class="o">.</code><code class="na">ofBulkheadRegistry</code><code class="o">(</code><code class="n">bulkheadRegistry</code><code class="o">)</code>
  <code class="o">.</code><code class="na">bindTo</code><code class="o">(</code><code class="n">meterRegistry</code><code class="o">);</code></pre></div>

<p class="author1"><a data-type="xref" href="part0012_split_019.html#bulkhead_metrics" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre">Table 7-2</a> shows the bulkhead metrics shipped by Resilience4J. Alert when available concurrent calls frequently reach zero or near zero.</p>
<table id="bulkhead_metrics" class="calibre40">
<caption class="calibre41"><span class="keep-together">Table 7-2. </span>Bulkhead metrics exposed by Resilience4J</caption>
<thead class="calibre42">
<tr class="calibre43">
<th class="calibre44">Metric name</th>
<th class="calibre44">Type</th>
<th class="calibre44">Description</th>
</tr>
</thead>
<tbody class="calibre45">
<tr class="calibre46">
<td class="calibre47"><p class="calibre48">resilience4j.bulkhead.available.concurrent.calls</p></td>
<td class="calibre47"><p class="calibre48">Gauge</p></td>
<td class="calibre47"><p class="calibre48">The number of available permissions, or unused capacity</p></td>
</tr>
<tr class="calibre50">
<td class="calibre47"><p class="calibre48">resilience4j.bulkhead.max.allowed.concurrent.calls</p></td>
<td class="calibre47"><p class="calibre48">Gauge</p></td>
<td class="calibre47"><p class="calibre48">The maximum number of available permissions</p></td>
</tr>
</tbody>
</table>

<p class="author1">In Atlas, the alert condition for waiting threads tests against a fixed threshold, as shown in <a data-type="xref" href="part0012_split_019.html#bulkhead_atlas" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre">Example 7-15</a>. This might also be a good place to use a <code class="calibre24">:roll-count</code> to limit alert chattiness.</p>
<div id="bulkhead_atlas" data-type="example" class="calibre61">
<h5 class="calibre62"><span class="keep-together">Example 7-15. </span>Atlas bulkhead alert criteria</h5>

<pre data-type="programlisting" class="calibre63">name,resilience4j.bulkhead.available.concurrent.calls,:eq,
$THRESHOLD,
:lt</pre></div>

<p class="author1">In Prometheus, the idea is similar, as shown in <a data-type="xref" href="part0012_split_019.html#bulkhead_prometheus" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre">Example 7-16</a>.<a data-type="indexterm" data-startref="ix_ch07-asciidoc23" id="idm45139260169240" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre"/><a data-type="indexterm" data-startref="ix_ch07-asciidoc22" id="idm45139260168536" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre"/></p>
<div id="bulkhead_prometheus" data-type="example" class="calibre61">
<h5 class="calibre62"><span class="keep-together">Example 7-16. </span>Prometheus bulkhead alert criteria</h5>

<pre data-type="programlisting" class="calibre63">resilience4j_bulkhead_available_concurrent_calls &lt; $THRESHOLD</pre></div>
</div></section>













</div></section>













</div></section></div>



  

<div id="sbo-rt-content" class="calibre2">
<section data-type="chapter" type="chapter" data-pdf-bookmark="Chapter 7. Traffic Management" class="calibre3">
<div class="preface" id="ch_traffic_management">
<section data-type="sect1" data-pdf-bookmark="Call Resiliency Patterns" class="calibre3">
<div class="preface" id="idm45139260880232">
<section data-type="sect2" data-pdf-bookmark="Circuit Breakers" class="calibre3"><div class="preface" id="circuit_breakers">
<h2 class="calibre37" id="BE7VA-2d714b853a094e9a910510217e0e3d73">Circuit Breakers</h2>

<p class="author1"><a data-type="indexterm" data-primary="call resiliency patterns" data-secondary="circuit breakers" id="ix_ch07-asciidoc24" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre"/><a data-type="indexterm" data-primary="circuit breakers" id="ix_ch07-asciidoc25" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre"/>Circuit breakers are a further extension of bulkheading with a twist. A circuit breaker maintains a finite state machine, as shown in <a data-type="xref" href="part0012_split_020.html#circuit_breaker_states" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre">Figure 7-9</a>, for an execution block that it guards with states of closed, half-open, and open. In the closed and half-open states, executions are allowed. In the open state, a fallback defined by the application is executed instead.</p>

<figure class="calibre32"><div id="circuit_breaker_states" class="figure">
<img src="../images/00099.png" alt="Closed, half-open, and open" class="calibre173"/>
<h6 class="calibre34"><span class="keep-together">Figure 7-9. </span>The states of a circuit breaker</h6>
</div></figure>

<p class="author1">One classic example of a circuit breaker is Netflix’s list of movie recommendations. This is generally personalized to the subscriber based on past viewing history, etc. A circuit breaker guarding a call to the personalization service might respond with a generic list of content as a fallback when the circuit breaker is in an open state.</p>

<p class="author1">For some classes of business problems, a fallback that doesn’t ultimately present the user with a failure is impossible. There is no reasonable fallback to accepting a payment from a user (assuming it couldn’t be stored somewhere for later processing).</p>

<p class="author1">Successful and unsuccessful executions are maintained in a ring buffer. When the ring buffer initially fills, the failure ratio is tested against a preconfigured threshold. The state of the circuit breaker changes from closed to open when the failure rate is above a configurable threshold. When the circuit breaker is tripped and opens, it will stop allowing executions for a defined period of time, after which the circuit half-opens, permits a small amount of traffic through, and tests the failure ratio of that small amount of traffic against the threshold. If the failure ratio falls below the threshold, the circuit is closed again.</p>

<p class="author1"><a href="https://oreil.ly/By0-M" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre">Netflix Hystrix</a> was the first major open source circuit breaker library, and while still well known, it has now been deprecated. Resilience4J implements the circuit breaker pattern with improvements to library hygiene and support for more threading models. An example is shown in <a data-type="xref" href="part0012_split_020.html#BE7VQ-2d714b853a094e9a910510217e0e3d73" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre">Example 7-17</a>.</p>
<div id="circuit_breaker_resilience4j" data-type="example" class="calibre61">
<h5 class="calibre62" id="BE7VQ-2d714b853a094e9a910510217e0e3d73"><span class="keep-together">Example 7-17. </span>Implementing the circuit breaker pattern with Resilience4J</h5>

<pre data-type="programlisting" data-code-language="java" class="calibre63"><code class="n">CircuitBreakerConfig</code><code class="calibre24"> </code><code class="n">circuitBreakerConfig</code><code class="calibre24"> </code><code class="o">=</code><code class="calibre24"> </code><code class="n">CircuitBreakerConfig</code><code class="o">.</code><code class="na">custom</code><code class="o">(</code><code class="o">)</code><code class="calibre24">
</code><code class="calibre24">  </code><code class="o">.</code><code class="na">failureRateThreshold</code><code class="o">(</code><code class="mi">50</code><code class="o">)</code><code class="calibre24">
</code><code class="calibre24">  </code><code class="o">.</code><code class="na">waitDurationInOpenState</code><code class="o">(</code><code class="n">Duration</code><code class="o">.</code><code class="na">ofMillis</code><code class="o">(</code><code class="mi">1000</code><code class="o">)</code><code class="o">)</code><code class="calibre24">
</code><code class="calibre24">  </code><code class="o">.</code><code class="na">ringBufferSizeInHalfOpenState</code><code class="o">(</code><code class="mi">2</code><code class="o">)</code><code class="calibre24">
</code><code class="calibre24">  </code><code class="o">.</code><code class="na">ringBufferSizeInClosedState</code><code class="o">(</code><code class="mi">2</code><code class="o">)</code><code class="calibre24">
</code><code class="calibre24">  </code><code class="o">.</code><code class="na">build</code><code class="o">(</code><code class="o">)</code><code class="o">;</code><code class="calibre24">
</code><code class="calibre24">
</code><code class="n">CircuitBreakerRegistry</code><code class="calibre24"> </code><code class="n">circuitBreakerRegistry</code><code class="calibre24"> </code><code class="o">=</code><code class="calibre24"> </code><code class="n">CircuitBreakerRegistry</code><code class="calibre24">
</code><code class="calibre24">  </code><code class="o">.</code><code class="na">of</code><code class="o">(</code><code class="n">circuitBreakerConfig</code><code class="o">)</code><code class="o">;</code><code class="calibre24">
</code><code class="calibre24">
</code><code class="n">CircuitBreaker</code><code class="calibre24"> </code><code class="n">billingHistoryCircuitBreaker</code><code class="calibre24"> </code><code class="o">=</code><code class="calibre24"> </code><code class="n">circuitBreakerRegistry</code><code class="calibre24">
</code><code class="calibre24">  </code><code class="o">.</code><code class="na">circuitBreaker</code><code class="o">(</code><code class="s">"billingHistoryCircuitBreaker"</code><code class="o">)</code><code class="o">;</code><code class="calibre24">
</code><code class="n">CircuitBreaker</code><code class="calibre24"> </code><code class="n">paymentCircuitBreaker</code><code class="calibre24"> </code><code class="o">=</code><code class="calibre24"> </code><code class="n">circuitBreakerRegistry</code><code class="calibre24">
</code><code class="calibre24">  </code><code class="o">.</code><code class="na">circuitBreaker</code><code class="o">(</code><code class="s">"payment"</code><code class="o">,</code><code class="calibre24"> </code><code class="n">circuitBreakerConfig</code><code class="o">)</code><code class="o">;</code><code class="calibre24"> </code><a class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre" id="co_traffic_management_CO4-1" href="part0012_split_020.html#callout_traffic_management_CO4-1"><img src="../images/00112.png" alt="1" class="calibre66"/></a><code class="calibre24">
</code><code class="calibre24">
</code><code class="c">// Components that would, as part of their implementations, execute HTTP requests
</code><code class="c">// to downstream services
</code><code class="n">BillingHistory</code><code class="calibre24"> </code><code class="n">billingHistory</code><code class="calibre24"> </code><code class="o">=</code><code class="calibre24"> </code><code class="o">.</code><code class="o">.</code><code class="o">.</code><code class="calibre24">
</code><code class="n">Payments</code><code class="calibre24"> </code><code class="n">payments</code><code class="calibre24"> </code><code class="o">=</code><code class="calibre24"> </code><code class="o">.</code><code class="o">.</code><code class="o">.</code><code class="calibre24">
</code><code class="calibre24">
</code><code class="c">// Spring WebFlux Functional route specification
</code><code class="n">RouterFunction</code><code class="o">&lt;</code><code class="n">ServerResponse</code><code class="o">&gt;</code><code class="calibre24"> </code><code class="n">route</code><code class="calibre24"> </code><code class="o">=</code><code class="calibre24"> </code><code class="n">route</code><code class="o">(</code><code class="o">)</code><code class="calibre24">
</code><code class="calibre24">	</code><code class="o">.</code><code class="na">GET</code><code class="o">(</code><code class="s">"/billing/{id}"</code><code class="o">,</code><code class="calibre24"> </code><code class="n">accept</code><code class="o">(</code><code class="n">APPLICATION_JSON</code><code class="o">)</code><code class="o">,</code><code class="calibre24">
</code><code class="calibre24">    </code><code class="n">CircuitBreaker</code><code class="o">.</code><code class="na">decorateFunction</code><code class="o">(</code><code class="calibre24">
</code><code class="calibre24">      </code><code class="n">billingHistoryCircuitBreaker</code><code class="o">,</code><code class="calibre24">
</code><code class="calibre24">      </code><code class="nd">BillingHistory:</code><code class="o">:</code><code class="n">getHistory</code><code class="calibre24">
</code><code class="calibre24">    </code><code class="o">)</code><code class="calibre24">
</code><code class="calibre24">  </code><code class="o">)</code><code class="calibre24">
</code><code class="calibre24">	</code><code class="o">.</code><code class="na">POST</code><code class="o">(</code><code class="s">"/payment"</code><code class="o">,</code><code class="calibre24">
</code><code class="calibre24">    </code><code class="n">CircuitBreaker</code><code class="o">.</code><code class="na">decorateFunction</code><code class="o">(</code><code class="calibre24">
</code><code class="calibre24">      </code><code class="n">paymentCircuitBreaker</code><code class="o">,</code><code class="calibre24">
</code><code class="calibre24">      </code><code class="nd">Payments:</code><code class="o">:</code><code class="n">sendPayment</code><code class="calibre24">
</code><code class="calibre24">    </code><code class="o">)</code><code class="calibre24">
</code><code class="calibre24">  </code><code class="o">)</code><code class="calibre24">
</code><code class="calibre24">	</code><code class="o">.</code><code class="na">build</code><code class="o">(</code><code class="o">)</code><code class="o">;</code></pre></div>
<dl class="calibre20">
<dt class="calibre21"><a class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre" id="callout_traffic_management_CO4-1" href="part0012_split_020.html#co_traffic_management_CO4-1"><img src="../images/00112.png" alt="1" class="calibre66"/></a></dt>
<dd class="calibre67"><p class="calibre68">A circuit breaker for some service can be created with a configuration different from the global one.</p></dd>
</dl>

<p class="author1">Resilience4J contains built-in metrics instrumentation for circuit breakers that you should monitor for open circuits. Enable it by binding your circuit breaker registry to a Micrometer meter registry, as in <a data-type="xref" href="part0012_split_020.html#circuit_breaker_metrics_bind" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre">Example 7-18</a>.</p>
<div id="circuit_breaker_metrics_bind" data-type="example" class="calibre61">
<h5 class="calibre62"><span class="keep-together">Example 7-18. </span>Bind circuit breaker metrics</h5>

<pre data-type="programlisting" data-code-language="java" class="calibre63"><code class="n">TaggedCircuitBreakerMetrics</code>
  <code class="o">.</code><code class="na">ofCircuitBreakerRegistry</code><code class="o">(</code><code class="n">circuitBreakerRegistry</code><code class="o">)</code>
  <code class="o">.</code><code class="na">bindTo</code><code class="o">(</code><code class="n">meterRegistry</code><code class="o">);</code></pre></div>

<p class="author1"><a data-type="xref" href="part0012_split_020.html#circuit_breaker_metrics" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre">Table 7-3</a> shows the two metrics exposed by Resilience4J for <em class="calibre12">each</em> circuit breaker.</p>
<table id="circuit_breaker_metrics" class="calibre40">
<caption class="calibre41"><span class="keep-together">Table 7-3. </span>Circuit breaker metrics exposed by Resilience4J</caption>
<thead class="calibre42">
<tr class="calibre43">
<th class="calibre44">Metric name</th>
<th class="calibre44">Type</th>
<th class="calibre44">Description</th>
</tr>
</thead>
<tbody class="calibre45">
<tr class="calibre46">
<td class="calibre47"><p class="calibre48">resilience4j.circuitbreaker.calls</p></td>
<td class="calibre47"><p class="calibre48">Timer</p></td>
<td class="calibre47"><p class="calibre48">Total number of successful and failed calls</p></td>
</tr>
<tr class="calibre49">
<td class="calibre47"><p class="calibre48">resilience4j.circuitbreaker.state</p></td>
<td class="calibre47"><p class="calibre48">Gauge</p></td>
<td class="calibre47"><p class="calibre48">Set to 0 or 1 depending on whether the state described by the state tag is active (open, closed, etc.)</p></td>
</tr>
<tr class="calibre59">
<td class="calibre47"><p class="calibre48">resilience4j.circuitbreaker.failure.rate</p></td>
<td class="calibre47"><p class="calibre48">Gauge</p></td>
<td class="calibre47"><p class="calibre48">The failure rate of the circuit breaker</p></td>
</tr>
</tbody>
</table>

<p class="author1">Since these are gauges, you can alert on whether <em class="calibre12">any</em> circuit breaker is currently open by performing a <code class="calibre24">max</code> aggregation. At this point, end users are already experiencing a degraded experience by receiving a fallback response or having the failure propagate to them directly.</p>

<p class="author1">In Atlas, the alert condition checks for the open state, as shown in <a data-type="xref" href="part0012_split_020.html#atlas_circuitbreaker" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre">Example 7-19</a>.</p>
<div id="atlas_circuitbreaker" data-type="example" class="calibre61">
<h5 class="calibre62"><span class="keep-together">Example 7-19. </span>Atlas circuit breaker alert threshold</h5>

<pre data-type="programlisting" class="calibre63">name,resilience4j.circuitbreaker.state,:eq,
state,open,:eq,
:and,
:max, <a class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre" id="co_traffic_management_CO5-1" href="part0012_split_020.html#callout_traffic_management_CO5-1"><img src="../images/00112.png" alt="1" class="calibre66"/></a>
1,
:eq</pre></div>
<dl class="calibre20">
<dt class="calibre21"><a class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre" id="callout_traffic_management_CO5-1" href="part0012_split_020.html#co_traffic_management_CO5-1"><img src="../images/00112.png" alt="1" class="calibre66"/></a></dt>
<dd class="calibre67"><p class="calibre68">If any circuit breaker is open, this alert will match on it.</p></dd>
</dl>

<p class="author1">In Prometheus, the idea is similar, as shown in <a data-type="xref" href="part0012_split_020.html#prometheus_circuitbreaker" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre">Example 7-20</a>. We can use <code class="calibre24">sum(..) &gt; 0</code> or <code class="calibre24">max(..) == 1</code> with the same effect.</p>
<div id="prometheus_circuitbreaker" data-type="example" class="calibre61">
<h5 class="calibre62"><span class="keep-together">Example 7-20. </span>Prometheus circuit breaker alert threshold</h5>

<pre data-type="programlisting" class="calibre63">sum(resilience4j_circuitbreaker_state{state="open"}) &gt; 0</pre></div>

<p class="author1">It’s probably OK if circuits briefly open and then close again though, so to limit alert chattiness, it may be better to instead set an error ratio indicator on <code class="calibre24">resilience4j.circuitbreaker.calls</code>, allowing for a certain number of failed requests going to the fallback before alerting.</p>

<p class="author1">Next we’ll discuss how we can improve the flexibility of the alert thresholds themselves by responding to changing conditions in the code and environment.<a data-type="indexterm" data-startref="ix_ch07-asciidoc25" id="idm45139259817608" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre"/><a data-type="indexterm" data-startref="ix_ch07-asciidoc24" id="idm45139259816904" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre"/></p>
</div></section>













</div></section>













</div></section></div>



  

<div id="sbo-rt-content" class="calibre2">
<section data-type="chapter" type="chapter" data-pdf-bookmark="Chapter 7. Traffic Management" class="calibre3">
<div class="preface" id="ch_traffic_management">
<section data-type="sect1" data-pdf-bookmark="Call Resiliency Patterns" class="calibre3">
<div class="preface" id="idm45139260880232">
<section data-type="sect2" data-pdf-bookmark="Adaptive Concurrency Limits" class="calibre3"><div class="preface" id="adaptive_concurrency_limits">
<h2 class="calibre37" id="calibre_pb_21">Adaptive Concurrency Limits</h2>

<p class="author1"><a data-type="indexterm" data-primary="adaptive concurrency limits" id="idm45139259814984" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre"/><a data-type="indexterm" data-primary="call resiliency patterns" data-secondary="adaptive concurrency limits" id="idm45139259814216" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre"/><a data-type="indexterm" data-primary="concurrency" data-secondary="adaptive concurrency limits" id="idm45139259801064" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre"/>Each of the call resiliency patterns presented so far (rate limiters, bulkheads, and circuit breakers) effectively serve to guard, either proactively or reactively, against load-related problems. They each have their own way of limiting concurrency.</p>

<p class="author1">In each case, the pattern was configured with a threshold value determined in advance of the microservice actually running in production. Rate limits are configured to constrain the number of requests that can be executed inside an interval, bulkheads limit instantaneous concurrency, and circuit breakers shed load away from instances that are experiencing failure (including load-related failure). These thresholds can be determined through careful performance testing, but their values tend to diverge from the true limit over time as code changes, the size of downstream clusters and their availability changes, etc.</p>

<p class="author1">A common theme throughout this book is to replace fixed thresholds or manual judgments with adaptive judgments. We saw this in <a data-type="xref" href="part0006_split_000.html#5N3C4-2d714b853a094e9a910510217e0e3d73" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre">Chapter 2</a> with thresholds set with forecasting algorithms, and in <a data-type="xref" href="part0010_split_000.html#9H5K4-2d714b853a094e9a910510217e0e3d73" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre">Chapter 5</a> with automated canary analysis. It is possible to adopt a similar adaptive approach to concurrency limits.</p>
</div></section>













</div></section>













</div></section></div>



  

<div id="sbo-rt-content" class="calibre2">
<section data-type="chapter" type="chapter" data-pdf-bookmark="Chapter 7. Traffic Management" class="calibre3">
<div class="preface" id="ch_traffic_management">
<section data-type="sect1" data-pdf-bookmark="Call Resiliency Patterns" class="calibre3">
<div class="preface" id="idm45139260880232">
<section data-type="sect2" data-pdf-bookmark="Choosing the Right Call Resiliency Pattern" class="calibre3"><div class="preface" id="idm45139259796232">
<h2 class="calibre37" id="calibre_pb_22">Choosing the Right Call Resiliency Pattern</h2>

<p class="author1"><a data-type="indexterm" data-primary="call resiliency patterns" data-secondary="choosing the right pattern" id="idm45139259825000" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre"/>In code, the patterns for bulkheads, rate limiters, and circuit breakers look remarkably similar. In fact, the three patterns have overlapping responsibilities, as shown in <a data-type="xref" href="part0012_split_022.html#call_resiliency_pattern_relationship" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre">Figure 7-10</a>.</p>

<figure class="calibre32"><div id="call_resiliency_pattern_relationship" class="figure">
<img src="../images/00081.png" alt="srej 0710" class="calibre174"/>
<h6 class="calibre34"><span class="keep-together">Figure 7-10. </span>Overlapping responsibilities of three call resiliency patterns</h6>
</div></figure>

<p class="author1">All <a data-type="indexterm" data-primary="bulkheads" id="idm45139259820168" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre"/><a data-type="indexterm" data-primary="circuit breakers" id="idm45139260003576" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre"/><a data-type="indexterm" data-primary="rate limiters" id="idm45139260002904" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre"/>three patterns accomplish rate limiting, but with varying mechanisms, summarized in <a data-type="xref" href="part0012_split_022.html#call_resiliency_pattern_rate_limiting_mechanisms" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre">Table 7-4</a>.</p>
<table id="call_resiliency_pattern_rate_limiting_mechanisms" class="calibre40">
<caption class="calibre41"><span class="keep-together">Table 7-4. </span>The rate-limiting mechanisms of different call resiliency patterns</caption>
<thead class="calibre42">
<tr class="calibre43">
<th class="calibre44">Pattern</th>
<th class="calibre44">Limiting mechanism</th>
<th class="calibre44">Notes</th>
</tr>
</thead>
<tbody class="calibre45">
<tr class="calibre46">
<td class="calibre47"><p class="calibre48">Rate limiter</p></td>
<td class="calibre47"><p class="calibre48">Limits rate per interval</p></td>
<td class="calibre47"><p class="calibre48">This does not limit instantaneous concurrency (e.g., a spike of traffic inside of the interval) unless that instantaneous concurrency exceeds the limit for the whole interval to be reached.</p></td>
</tr>
<tr class="calibre49">
<td class="calibre47"><p class="calibre48">Bulkhead</p></td>
<td class="calibre47"><p class="calibre48">Limits instantaneous concurrency level</p></td>
<td class="calibre47"><p class="calibre48">Limits the concurrency level at the time that a new request is attempted. This does not limit the number of requests to the downstream inside an interval except indirectly since the downstream service responds in a nonzero amount of time.</p></td>
</tr>
<tr class="calibre59">
<td class="calibre47"><p class="calibre48">Circuit breaker</p></td>
<td class="calibre47"><p class="calibre48">Responds to errors (some of which occur due to the natural limit in the downstream’s concurrency)</p></td>
<td class="calibre47"><p class="calibre48">Either the RPC request guarded by the circuit breaker will time out or the downstream service (or its load balancer) will respond with a failure, such as an HTTP 502 (unavailable). This does not limit either the instantaneous or per-interval rate except indirectly when the downstream begins to be saturated.</p></td>
</tr>
</tbody>
</table>

<p class="author1">For this reason, it isn’t common to see a single block of code guarded by more than one of the patterns of rate limiter, bulkhead, or circuit breaker.</p>

<p class="author1">The implementations of the call resiliency patterns shown to this point have all employed Resilience4J, making them an application development concern. Let’s compare keeping this as an application concern with externalizing the responsibility in service mesh.</p>
</div></section>













</div></section>













</div></section></div>



  

<div id="sbo-rt-content" class="calibre2">
<section data-type="chapter" type="chapter" data-pdf-bookmark="Chapter 7. Traffic Management" class="calibre3">
<div class="preface" id="ch_traffic_management">
<section data-type="sect1" data-pdf-bookmark="Call Resiliency Patterns" class="calibre3">
<div class="preface" id="idm45139260880232">
<section data-type="sect2" data-pdf-bookmark="Implementation in Service Mesh" class="calibre3"><div class="preface" id="service_mesh">
<h2 class="calibre37" id="BE895-2d714b853a094e9a910510217e0e3d73">Implementation in Service Mesh</h2>

<p class="author1"><a data-type="indexterm" data-primary="call resiliency patterns" data-secondary="implementation in service mesh" id="idm45139259831848" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre"/><a data-type="indexterm" data-primary="service mesh" data-secondary="call resiliency pattern implementation in" id="idm45139259830840" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre"/>Ultimately, the decision of whether to try to pry traffic management away from application concern has to be made in each organization based on the weight it places on several criteria shown in <a data-type="xref" href="part0012_split_023.html#traffic_management_decision_matrix" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre">Table 7-5</a>. “Application responsibility” here means that the functionality is achieved through application code or autoconfigured via a binary dependency on a shared library. The weights assigned to each criterion across the header row are just an example and will vary from organization to organization. For example, an organization that has a large number of programming languages in use may assign a much higher weight to language support. This should drive your <span class="keep-together">decision.</span></p>
<table id="traffic_management_decision_matrix" class="calibre40">
<caption class="calibre41"><span class="keep-together">Table 7-5. </span>The service mesh versus application responsibility decision matrix for traffic management (higher score = higher cost)</caption>
<thead class="calibre42">
<tr class="calibre43">
<th class="calibre44"/>
<th class="calibre44">Service mesh</th>
<th class="calibre44">Application responsibility</th>
</tr>
</thead>
<tbody class="calibre45">
<tr class="calibre46">
<td class="calibre47"><p class="calibre48">Language support = 5</p></td>
<td class="calibre47"><p class="calibre48">Low: only a thin client needed to connect to mesh (1 x 5 = 5)</p></td>
<td class="calibre47"><p class="calibre48">High: distinct implementation required for each language (5 x 5 = 25)</p></td>
</tr>
<tr class="calibre49">
<td class="calibre47"><p class="calibre48">Runtime support = 5</p></td>
<td class="calibre47"><p class="calibre48">High: for example, Istio is a Kubernetes CRD, so bound to a specific runtime (5 x 5 = 25)</p></td>
<td class="calibre47"><p class="calibre48">Low: only has an impact if the library wants to take advantage of some specific feature of the runtime (1 x 5 = 5)</p></td>
</tr>
<tr class="calibre46">
<td class="calibre47"><p class="calibre48">Deployment complexity = 4</p></td>
<td class="calibre47"><p class="calibre48">Medium: requires changes to deployment practices (3 x 4 = 12)</p></td>
<td class="calibre47"><p class="calibre48">Very low: doesn’t alter deployment at all (0 x 4 = 0)</p></td>
</tr>
<tr class="calibre49">
<td class="calibre47"><p class="calibre48">Anti-flexibility = 3</p></td>
<td class="calibre47"><p class="calibre48">Medium: as patterns become known, they are generalized in the mesh, but not immediately (3 x 3 = 9)</p></td>
<td class="calibre47"><p class="calibre48">Medium: introducing new patterns requires dependency updates across the stack (4 x 3 = 12)</p></td>
</tr>
<tr class="calibre46">
<td class="calibre47"><p class="calibre48">Operational cost = 2</p></td>
<td class="calibre47"><p class="calibre48">High: often much higher resource consumption (5 x 2 = 10) and operational experience upgrading the mesh independent of application footprint</p></td>
<td class="calibre47"><p class="calibre48">Low: no additional processes or containers allocated per application (1 x 2 = 2)</p></td>
</tr>
<tr class="calibre50">
<td class="calibre47"><p class="calibre48">Total cost</p></td>
<td class="calibre47"><p class="calibre48">5 + 25 + 12 + 9 + 10 = 61</p></td>
<td class="calibre47"><p class="calibre48">25 + 5 + 0 + 12 + 2 = 44 (best option with these weights)</p></td>
</tr>
</tbody>
</table>

<p class="author1">The choice-of-two load balancer described earlier is an example of a sophisticated load balancer that requires coordination with application code, so it could never be fully encapsulated by a service mesh technology.</p>

<p class="author1">There is one other complication of this lack of coordination with application code. Consider a task like <a href="https://oreil.ly/ZvOIn" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre">request timeouts</a>, handled by a sidecar proxy. While the proxy may hang up on a caller after the configured timeout, the application instance is still at work handling the request all the way to completion. If the application is using a conventional blocking thread-pool model like Tomcat, a thread continues to be consumed after the timeout.</p>

<p class="author1">Currently, Istio only supports a “circuit breaker” that more closely resembles a bulkhead as we’ve defined it, since it supports limiting instantaneous concurrency to a service by controlling maximum connections or requests. Rather than this being an application concern, with Istio the bulkhead would be applied with YAML configuration from the Istio Kubernetes custom resource definition, as in <a data-type="xref" href="part0012_split_023.html#istio_circuit_breaker" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre">Example 7-21</a>.</p>
<div id="istio_circuit_breaker" data-type="example" class="calibre61">
<h5 class="calibre62"><span class="keep-together">Example 7-21. </span>Istio circuit breaker</h5>

<pre data-type="programlisting" data-code-language="yaml" class="calibre63"><code class="nt">apiVersion</code><code class="p">:</code> <code class="calibre24">networking.istio.io/v1alpha3</code>
<code class="nt">kind</code><code class="p">:</code> <code class="calibre24">DestinationRule</code>
<code class="nt">metadata</code><code class="p">:</code>
  <code class="nt">name</code><code class="p">:</code> <code class="calibre24">billingHistory</code>
<code class="nt">spec</code><code class="p">:</code>
  <code class="nt">host</code><code class="p">:</code> <code class="calibre24">billingHistory</code>
  <code class="nt">subsets</code><code class="p">:</code>
  <code class="calibre24">-</code> <code class="nt">name</code><code class="p">:</code> <code class="calibre24">v1</code>
    <code class="nt">labels</code><code class="p">:</code>
      <code class="nt">version</code><code class="p">:</code> <code class="calibre24">v1</code>
    <code class="nt">trafficPolicy</code><code class="p">:</code>
      <code class="nt">connectionPool</code><code class="p">:</code>
        <code class="nt">tcp</code><code class="p">:</code>
          <code class="nt">maxConnections</code><code class="p">:</code> <code class="calibre24">150</code></pre></div>

<p class="author1">This also demonstrates the anti-flexibility of service mesh. The sophistication of your traffic management policy will be limited to what can be expressed in YAML. It’s important to consider how this limited expressiveness is a <em class="calibre12">necessary</em> condition of not being application code.</p>

<p class="author1">If, for example, Istio CRD YAML follows the typical evolution of markup that stretches to meet more diverse expectations, we would expect to see the imposition of boolean logic (appearing already in <a href="https://oreil.ly/vA0ng" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre">multi-match</a>) for assembling more complex rules together, etc. It feels like looping is inevitable.</p>

<p class="author1">Again, trends in software engineering are often cyclic. This desire to simplify application development through static configuration or markup has happened before with interesting consequences. Remember, way back in <a data-type="xref" href="part0005_split_013.html#configuration_as_code" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre">“Configuration as Code”</a>, the example of how XSLT wandered gradually into becoming a Turing complete language. This is significant, because the moment this happens, it becomes impossible to verify all sorts of characteristics of the configuration (now full-blown software) with static analysis. At that point, we’re far from the original stated goal of keeping functionality out of code.</p>
</div></section>













</div></section>













</div></section></div>



  

<div id="sbo-rt-content" class="calibre2">
<section data-type="chapter" type="chapter" data-pdf-bookmark="Chapter 7. Traffic Management" class="calibre3">
<div class="preface" id="ch_traffic_management">
<section data-type="sect1" data-pdf-bookmark="Call Resiliency Patterns" class="calibre3">
<div class="preface" id="idm45139260880232">
<section data-type="sect2" data-pdf-bookmark="Implementation in RSocket" class="calibre3"><div class="preface" id="idm45139259833064">
<h2 class="calibre37" id="calibre_pb_24">Implementation in RSocket</h2>

<p class="author1"><a data-type="indexterm" data-primary="call resiliency patterns" data-secondary="implementation in RSocket" id="idm45139259675064" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre"/><a data-type="indexterm" data-primary="Reactive Streams" id="idm45139259673960" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre"/><a data-type="indexterm" data-primary="RSocket" id="idm45139259673256" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre"/>Reactive Streams provides a standard for asynchronous stream processing with nonblocking backpressure. <a href="https://rsocket.io" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre">RSocket</a> is a persistent bidirectional remote procedure call protocol implementing Reactive Streams semantics. The goal of <a data-type="indexterm" data-primary="backpressure" id="idm45139259671560" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre"/><a data-type="indexterm" data-primary="Reactive Manifesto" id="idm45139259670856" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre"/>backpressure was described in 2014 in the <a href="https://oreil.ly/YLrAY" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre">Reactive Manifesto</a>:</p>
<blockquote class="pcalibre8 pcalibre9 pcalibre7">
<p class="calibre16">When one component is struggling to keep up, the system as a whole needs to respond in a sensible way. It is unacceptable for the component under stress to fail catastrophically or to drop messages in an uncontrolled fashion. Since it can’t cope and it can’t fail, it should communicate the fact that it is under stress to upstream components and so get them to reduce the load. This backpressure is an important feedback mechanism that allows systems to gracefully respond to load rather than collapse under it. The backpressure may cascade all the way up to the user, at which point responsiveness may degrade, but this mechanism will ensure that the system is resilient under load, and will provide information that may allow the system itself to apply other resources to help distribute the load…</p>
<p data-type="attribution" class="pcalibre10 pcalibre11">Reactive Manifesto</p>
</blockquote>

<p class="author1">The concept of backpressure across the network layer may very well eliminate the need for rate limiters, bulkheads, and circuit breakers in application code (or in a sidecar process). As an application instance observes its own decline in availability, it places backpressure on callers. Effectively, callers cannot make a call to an unavailable application instance.</p>

<p class="author1">Expect to see the further evolution of infrastructure, extending backpressure up and down the application stack. <a href="https://r2dbc.io" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre">R2DBC</a> has extended backpressure down even to database interactions. <a href="https://www.netifi.com" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre">Netifi</a> has built an entire control plane around this concept, a sort of alternative to service mesh without many of the disadvantages.<a data-type="indexterm" data-startref="ix_ch07-asciidoc17" id="idm45139259664232" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre"/><a data-type="indexterm" data-startref="ix_ch07-asciidoc16" id="idm45139259663528" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre"/></p>
</div></section>





</div></section>













</div></section></div>



  

<div id="sbo-rt-content" class="calibre2">
<section data-type="chapter" type="chapter" data-pdf-bookmark="Chapter 7. Traffic Management" class="calibre3">
<div class="preface" id="ch_traffic_management">
<section data-type="sect1" data-pdf-bookmark="Summary" class="calibre3"><div class="preface" id="idm45139260879608">
<h1 class="calibre19" id="calibre_pb_25">Summary</h1>

<p class="author1">Failure and degradation of performance should be expected and planned for in any production microservice architecture. In this chapter, we introduced a number of strategies for dealing with these conditions, from load balancing to call resilience <span class="keep-together">patterns.</span></p>

<p class="author1">Your organizational commitment to these patterns is almost entirely in application code. As with other crosscutting concerns that impact application code like metrics instrumentation and distributed tracing, there is an opportunity for an effective platform engineering team to step in and provide some of this cross-organizationally by shipping good default opinions in core libraries and configuration that are consumed by all of the organization’s microservices.</p>

<p class="author1">This book has described a journey toward more reliable systems. Go as far as you can on this journey, recognizing that at each step your business is better off. It starts with simply measuring the existing state of the system, building a greater degree of awareness about what your end users are experiencing day to day. Continue by adding debuggability signals that allow you to ask questions about why failure is occurring as you become aware of it. Improve your software delivery pipeline to limit the chances that you introduce more failure into the system as you continue to build out your software. Build the capability to observe the state of the deployed assets themselves so that you can begin to reason about how to make change cross-organizationally when needed. These compensations for expected failures are the last step in the journey toward building more reliable distributed systems.</p>

<p class="author1">At each step, build guardrails instead of gates!<a data-type="indexterm" data-startref="ix_ch07-asciidoc0" id="idm45139259657864" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre"/></p>
</div></section>







</div></section></div>



  </body></html>