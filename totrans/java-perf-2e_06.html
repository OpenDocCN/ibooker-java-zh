<html><head></head><body><section data-pdf-bookmark="Chapter 6. Garbage Collection Algorithms" data-type="chapter" epub:type="chapter"><div class="chapter" id="Collectors">&#13;
<h1><span class="label">Chapter 6. </span>Garbage Collection Algorithms</h1>&#13;
&#13;
&#13;
<p><a data-primary="garbage collection algorithms" data-type="indexterm" id="ix_ch06-asciidoc0"/><a data-type="xref" href="ch05.html#GC">Chapter 5</a> examined the general behavior of all garbage collectors, including&#13;
JVM flags that apply universally to all GC algorithms: how to select heap&#13;
sizes, generation sizes, logging, and so on. The basic tunings of garbage collection suffice for many circumstances.&#13;
When they do not, it is time to examine the specific operation of the&#13;
GC algorithm in use to determine how its parameters can be changed to minimize the impact of GC on the application.</p>&#13;
&#13;
<p>The key information needed to tune an individual collector is the data&#13;
from the GC log when that collector is enabled. This chapter starts, then,&#13;
by looking at each algorithm from the perspective of its log output, which allows us to understand how the GC algorithm works and how it can&#13;
be adjusted to work better. Each section then includes tuning information&#13;
to achieve that better performance.</p>&#13;
&#13;
<p>This chapter also covers the details of some new, experimental collectors.&#13;
Those collectors may not be 100% solid at the time of this writing but will&#13;
likely become full-fledged, production-worthy collectors by the time the next&#13;
LTS version of Java is released (just as G1 GC began as an experimental&#13;
collector and is now the default in JDK 11).</p>&#13;
&#13;
<p>A few unusual cases impact the performance of all GC algorithms: allocation of very large objects, objects that&#13;
are neither short- nor long-lived, and so on. Those cases are covered at the&#13;
end of this chapter.</p>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Understanding the Throughput Collector" data-type="sect1"><div class="sect1" id="idm45775554370776">&#13;
<h1>Understanding the Throughput Collector</h1>&#13;
&#13;
<p><a data-primary="garbage collection algorithms" data-secondary="throughput collector" data-type="indexterm" id="ix_ch06-asciidoc1"/><a data-primary="throughput garbage collector" data-type="indexterm" id="ix_ch06-asciidoc2"/>We’ll start by looking at the individual garbage collectors, beginning&#13;
with the throughput collector. Although we’ve seen that the G1 GC&#13;
collector is generally preferred, the details of the throughput collector&#13;
are easier and make a better foundation for understanding how things work.</p>&#13;
&#13;
<p>Recall from <a data-type="xref" href="ch05.html#GC">Chapter 5</a> that garbage collectors must do three basic operations:&#13;
find unused objects, free their memory, and compact the heap. The throughput&#13;
collector does all of those operations in the same GC cycle; <a data-primary="collection (term)" data-type="indexterm" id="idm45775554364728"/>together those&#13;
operations are referred to as a <em>collection</em>. These collectors can collect&#13;
either the young generation or the old generation during a single operation.</p>&#13;
&#13;
<p><a data-type="xref" href="#FigureParYoung">Figure 6-1</a> shows the heap before and after a young collection.</p>&#13;
&#13;
<figure><div class="figure" id="FigureParYoung">&#13;
<img alt="A diagram of the heap before and after a young collection." src="assets/jp2e_0601.png"/>&#13;
<h6><span class="label">Figure 6-1. </span>A throughput GC young collection</h6>&#13;
</div></figure>&#13;
&#13;
<p>A young collection occurs when eden has filled up. The young collection moves&#13;
all objects out of eden: some are moved to one of the survivor spaces (S0&#13;
in this diagram), and some are moved to the old generation, which now contains&#13;
more objects. Many objects, of course, are discarded because they are no&#13;
longer referenced.</p>&#13;
&#13;
<p>Because eden is usually empty after this operation, it may seem unusual to&#13;
consider that it has been compacted, but that’s the effect here.</p>&#13;
&#13;
<p>In the JDK 8 GC log with&#13;
<span class="keep-together"><code>PrintGCDetails</code>,</span>&#13;
a minor GC of the throughput collector appears like this:</p>&#13;
&#13;
<pre data-type="programlisting">17.806: [GC (Allocation Failure) [PSYoungGen: 227983K-&gt;14463K(264128K)]&#13;
             280122K-&gt;66610K(613696K), 0.0169320 secs]&#13;
	     [Times: user=0.05 sys=0.00, real=0.02 secs]</pre>&#13;
&#13;
<p>This GC occurred 17.806 seconds after the program began. Objects in the&#13;
young generation now occupy 14,463 KB (14 MB, in the survivor space); before the&#13;
GC, they occupied 227,983 KB (227 MB).<sup><a data-type="noteref" href="ch06.html#idm45775554356120" id="idm45775554356120-marker">1</a></sup>&#13;
The total size of the young generation&#13;
at this point is 264 MB.</p>&#13;
&#13;
<p>Meanwhile, the overall occupancy of the heap (both&#13;
young and old generations) decreased from 280 MB to 66 MB, and the&#13;
size of the entire heap at this point was <span class="keep-together">613 MB.</span> The operation took&#13;
less than 0.02 seconds (the 0.02 seconds of real time at the end of the output&#13;
is 0.0169320 seconds—the actual time—rounded). The program was&#13;
charged for more CPU time than real time because the&#13;
young collection was done by multiple threads (in this configuration, four&#13;
threads).</p>&#13;
&#13;
<p>The same log in JDK 11 would look something like this:</p>&#13;
&#13;
<pre data-type="programlisting">[17.805s][info][gc,start       ] GC(4) Pause Young (Allocation Failure)&#13;
[17.806s][info][gc,heap        ] GC(4) PSYoungGen: 227983K-&gt;14463K(264128K)&#13;
[17.806s][info][gc,heap        ] GC(4) ParOldGen: 280122K-&gt;66610K(613696K)&#13;
[17.806s][info][gc,metaspace   ] GC(4) Metaspace: 3743K-&gt;3743K(1056768K)&#13;
[17.806s][info][gc             ] GC(4) Pause Young (Allocation Failure)&#13;
                                          496M-&gt;79M(857M) 16.932ms&#13;
[17.086s][info][gc,cpu         ] GC(4) User=0.05s Sys=0.00s Real=0.02s</pre>&#13;
&#13;
<p>The information here is the same; it’s just a different format. And this&#13;
log entry has multiple lines; the previous log entry is actually a single&#13;
line (but that doesn’t reproduce in this format). This log also prints out&#13;
the metaspace sizes, but those will never change during a young collection.&#13;
The metaspace is also not included in the total heap size reported on the&#13;
fifth line of this sample.</p>&#13;
&#13;
<p><a data-type="xref" href="#FigureParOld">Figure 6-2</a> shows the heap before and after a full GC.</p>&#13;
&#13;
<figure><div class="figure" id="FigureParOld">&#13;
<img alt="A diagram of the heap before and after a full GC." src="assets/jp2e_0602.png"/>&#13;
<h6><span class="label">Figure 6-2. </span>A throughput full GC</h6>&#13;
</div></figure>&#13;
&#13;
<p>The old collection frees everything out of the young generation.&#13;
The only objects that remain in the old&#13;
generation are those that have active references, and all of those objects&#13;
have been compacted so that the beginning of the old generation is occupied,&#13;
and the remainder is free.</p>&#13;
&#13;
<p>The GC log reports that operation like this:</p>&#13;
&#13;
<pre data-type="programlisting">64.546: [Full GC (Ergonomics) [PSYoungGen: 15808K-&gt;0K(339456K)]&#13;
          [ParOldGen: 457753K-&gt;392528K(554432K)] 473561K-&gt;392528K(893888K)&#13;
	  [Metaspace: 56728K-&gt;56728K(115392K)], 1.3367080 secs]&#13;
	  [Times: user=4.44 sys=0.01, real=1.34 secs]</pre>&#13;
&#13;
<p>The young generation now occupies 0 bytes (and its size is 339 MB). Note&#13;
in the diagram that means the survivor spaces have been cleared as well.&#13;
The data in the old generation decreased&#13;
from 457 MB to 392 MB, and hence the entire heap usage has decreased from&#13;
473 MB to 392 MB. The size of the metaspace is unchanged;&#13;
it is not collected during most full GCs. (If the metaspace&#13;
runs out of room, the JVM will run a full GC to collect it, and&#13;
you will see the size of the metaspace change; I’ll show that a little further on.)&#13;
Because there is substantially more work to do&#13;
in a full GC, it has taken 1.3 seconds of real time, and 4.4 seconds of&#13;
CPU time (again for four parallel threads).</p>&#13;
&#13;
<p>The similar JDK 11 log is this:</p>&#13;
&#13;
<pre data-type="programlisting">[63.205s][info][gc,start       ] GC(13) Pause Full (Ergonomics)&#13;
[63.205s][info][gc,phases,start] GC(13) Marking Phase&#13;
[63.314s][info][gc,phases      ] GC(13) Marking Phase 109.273ms&#13;
[63.314s][info][gc,phases,start] GC(13) Summary Phase&#13;
[63.316s][info][gc,phases      ] GC(13) Summary Phase 1.470ms&#13;
[63.316s][info][gc,phases,start] GC(13) Adjust Roots&#13;
[63.331s][info][gc,phases      ] GC(13) Adjust Roots 14.642ms&#13;
[63.331s][info][gc,phases,start] GC(13) Compaction Phase&#13;
[63.482s][info][gc,phases      ] GC(13) Compaction Phase 1150.792ms&#13;
[64.482s][info][gc,phases,start] GC(13) Post Compact&#13;
[64.546s][info][gc,phases      ] GC(13) Post Compact 63.812ms&#13;
[64.546s][info][gc,heap        ] GC(13) PSYoungGen: 15808K-&gt;0K(339456K)&#13;
[64.546s][info][gc,heap        ] GC(13) ParOldGen: 457753K-&gt;392528K(554432K)&#13;
[64.546s][info][gc,metaspace   ] GC(13) Metaspace: 56728K-&gt;56728K(115392K)&#13;
[64.546s][info][gc             ] GC(13) Pause Full (Ergonomics)&#13;
                                            462M-&gt;383M(823M) 1336.708ms&#13;
[64.546s][info][gc,cpu         ] GC(13) User=4.446s Sys=0.01s Real=1.34s</pre>&#13;
<div data-type="tip"><h1>Quick Summary</h1>&#13;
<ul>&#13;
<li>&#13;
<p>The throughput collector has two operations: minor collections and full GCs, each of which marks, frees, and compacts the target generation.</p>&#13;
</li>&#13;
<li>&#13;
<p>Timings taken from the GC log are a quick way to determine the overall impact of GC on an application using these <span class="keep-together">collectors.</span></p>&#13;
</li>&#13;
</ul>&#13;
</div>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Adaptive and Static Heap Size Tuning" data-type="sect2"><div class="sect2" id="GCThroughput">&#13;
<h2>Adaptive and Static Heap Size Tuning</h2>&#13;
&#13;
<p><a data-primary="heap" data-secondary="advanced and static heap size tuning" data-type="indexterm" id="ix_ch06-asciidoc3"/><a data-primary="throughput garbage collector" data-secondary="advanced and static heap size tuning" data-type="indexterm" id="ix_ch06-asciidoc4"/><a data-primary="tuning (garbage collection algorithms)" data-secondary="advanced and static heap size tuning" data-type="indexterm" id="ix_ch06-asciidoc5"/>Tuning the throughput collector is all about pause times and striking a&#13;
balance between the overall heap size and the sizes of the old and young&#13;
generations.</p>&#13;
&#13;
<p>There are two trade-offs to consider here. First, we have the classic&#13;
programming trade-off of time versus space. A larger heap consumes more memory&#13;
on the machine, and the benefit of consuming that memory is (at least to&#13;
a certain extent) that the application will have a higher throughput.</p>&#13;
&#13;
<p>The second trade-off concerns the length of time it takes to perform&#13;
GC. The&#13;
number of full GC pauses can be reduced by increasing the heap size,&#13;
but that may have the perverse effect of increasing&#13;
average response times because of the longer GC times. Similarly,&#13;
full GC pauses can be shortened by allocating more of the heap to the young&#13;
generation than to the old generation, but that, in turn, increases the&#13;
frequency of the old GC collections.</p>&#13;
&#13;
<p>The effect of these trade-offs is shown in <a data-type="xref" href="#FigureGCPauses">Figure 6-3</a>. This graph&#13;
shows the maximum throughput of the stock REST server running&#13;
with different heap sizes. With a small 256 MB heap,&#13;
the server is spending a lot of time in GC (36% of total&#13;
time, in fact); the throughput is restricted as a result. As the heap size&#13;
is increased, the throughput rapidly increases—until the heap size is set&#13;
to 1,500 MB. After that, throughput increases less rapidly: the application&#13;
isn’t really GC-bound at that point (about 6% of time in GC). The law&#13;
of diminishing returns has crept in: the application can use additional&#13;
memory to gain throughput, but the gains become more limited.</p>&#13;
&#13;
<p>After a heap size of 4,500 MB, the throughput starts to decrease&#13;
slightly. At that point, the application has reached the second trade-off:&#13;
the additional memory has caused much longer GC cycles, and those longer&#13;
cycles—even though they are less <span class="keep-together">frequent—can</span> reduce the overall&#13;
throughput.</p>&#13;
&#13;
<p>The data in this graph was obtained by disabling adaptive sizing in the&#13;
JVM; the minimum and maximum heap sizes were set to the same value.&#13;
It is possible to run experiments on any application and determine the&#13;
best sizes for the heap and for the generations, but it is often easier to let the&#13;
JVM make those decisions (which is what usually happens, since adaptive&#13;
sizing is enabled by default).</p>&#13;
&#13;
<figure><div class="figure" id="FigureGCPauses">&#13;
<img alt="jp2e 0603" src="assets/jp2e_0603.png"/>&#13;
<h6><span class="label">Figure 6-3. </span>Throughput with various heap sizes</h6>&#13;
</div></figure>&#13;
&#13;
<p>Adaptive sizing in the throughput collector will resize the heap (and the generations) in order&#13;
to meet its pause-time goals. <a data-primary="-XX:GCTimeRatio=N" data-type="indexterm" id="ix_ch06-asciidoc6"/><a data-primary="-XX:MaxGCPauseMillis=N" data-type="indexterm" id="ix_ch06-asciidoc7"/>Those goals are set with these flags:&#13;
<span class="keep-together"><code>-XX:MaxGCPauseMillis=</code><em><code>N</code></em></span>&#13;
and&#13;
<span class="keep-together"><code>-XX:GCTimeRatio=</code><em><code>N</code></em></span>.</p>&#13;
&#13;
<p>The&#13;
<span class="keep-together"><code>MaxGCPauseMillis</code></span>&#13;
flag specifies the maximum pause&#13;
time that the application is willing to tolerate. It might be tempting to set this&#13;
to 0, or perhaps a small value like 50 ms. Be aware that this goal&#13;
applies to both minor and full GCs. If a very small value is used,&#13;
the application will end up with a very small old generation: for example, one that&#13;
can be cleaned in 50 ms. That will cause the JVM to perform very, very frequent&#13;
full GCs, and performance will be dismal. So be realistic: set the value to&#13;
something that can be achieved. By default, this flag is not set.</p>&#13;
&#13;
<p>The&#13;
<span class="keep-together"><code>GCTimeRatio</code></span>&#13;
flag specifies the amount of time you are willing for the application to&#13;
spend in GC (compared to the amount of time its application-level threads&#13;
should run). It is a ratio, so the value for <em><code>N</code></em> takes a little thought.&#13;
The value is used in the following equation to determine the percentage&#13;
of time the application threads should ideally run:</p>&#13;
<div data-type="equation">&#13;
<math alttext="upper T h r o u g h p u t upper G o a l equals 1 minus StartFraction 1 Over left-parenthesis 1 plus upper G upper C upper T i m e upper R a t i o right-parenthesis EndFraction" display="block">&#13;
  <mrow>&#13;
    <mi>T</mi>&#13;
    <mi>h</mi>&#13;
    <mi>r</mi>&#13;
    <mi>o</mi>&#13;
    <mi>u</mi>&#13;
    <mi>g</mi>&#13;
    <mi>h</mi>&#13;
    <mi>p</mi>&#13;
    <mi>u</mi>&#13;
    <mi>t</mi>&#13;
    <mi>G</mi>&#13;
    <mi>o</mi>&#13;
    <mi>a</mi>&#13;
    <mi>l</mi>&#13;
    <mo>=</mo>&#13;
    <mn>1</mn>&#13;
    <mo>-</mo>&#13;
    <mfrac><mn>1</mn> <mrow><mo>(</mo><mn>1</mn><mo>+</mo><mi>G</mi><mi>C</mi><mi>T</mi><mi>i</mi><mi>m</mi><mi>e</mi><mi>R</mi><mi>a</mi><mi>t</mi><mi>i</mi><mi>o</mi><mo>)</mo></mrow></mfrac>&#13;
  </mrow>&#13;
</math>&#13;
</div>&#13;
&#13;
<p>The default value for&#13;
<span class="keep-together"><code>GCTimeRatio</code></span>&#13;
is 99. Plugging that value into the equation yields 0.99, meaning that the&#13;
goal is to spend 99% of time in application processing, and&#13;
only 1% of time in GC. But don’t be confused by how those numbers line up&#13;
in the default case. A&#13;
<span class="keep-together"><code>GCTimeRatio</code></span>&#13;
of 95 does not mean that GC should run up to 5% of the time: it means&#13;
that GC should run up to 1.94% of the time.</p>&#13;
&#13;
<p>It’s easier to decide the minimum percentage of time you want the application&#13;
to perform work (say, 95%) and then calculate the value of the&#13;
<span class="keep-together"><code>GCTimeRatio</code></span>&#13;
from this <span class="keep-together">equation:</span></p>&#13;
<div data-type="equation">&#13;
<math alttext="upper G upper C upper T i m e upper R a t i o equals StartFraction upper T h r o u g h p u t Over left-parenthesis 1 minus upper T h r o u g h p u t right-parenthesis EndFraction" display="block">&#13;
  <mrow>&#13;
    <mi>G</mi>&#13;
    <mi>C</mi>&#13;
    <mi>T</mi>&#13;
    <mi>i</mi>&#13;
    <mi>m</mi>&#13;
    <mi>e</mi>&#13;
    <mi>R</mi>&#13;
    <mi>a</mi>&#13;
    <mi>t</mi>&#13;
    <mi>i</mi>&#13;
    <mi>o</mi>&#13;
    <mo>=</mo>&#13;
    <mfrac><mrow><mi>T</mi><mi>h</mi><mi>r</mi><mi>o</mi><mi>u</mi><mi>g</mi><mi>h</mi><mi>p</mi><mi>u</mi><mi>t</mi></mrow> <mrow><mo>(</mo><mn>1</mn><mo>-</mo><mi>T</mi><mi>h</mi><mi>r</mi><mi>o</mi><mi>u</mi><mi>g</mi><mi>h</mi><mi>p</mi><mi>u</mi><mi>t</mi><mo>)</mo></mrow></mfrac>&#13;
  </mrow>&#13;
</math>&#13;
</div>&#13;
&#13;
<p>For a throughput goal of 95% (0.95), this equation yields a&#13;
<span class="keep-together"><code>GCTimeRatio</code></span>&#13;
of 19.</p>&#13;
&#13;
<p><a data-primary="-Xms" data-type="indexterm" id="idm45775554278008"/><a data-primary="-Xmx" data-type="indexterm" id="idm45775554277304"/>The JVM uses these two flags to set the size of the heap within the&#13;
boundaries established by the initial (<code>-Xms</code>) and maximum (<code>-Xmx</code>) heap&#13;
sizes. The&#13;
<span class="keep-together"><code>MaxGCPauseMillis</code></span>&#13;
flag takes precedence: if it is set, the&#13;
sizes of the young and old generations are adjusted until the pause-time&#13;
goal is met. Once that happens, the overall size of the heap is increased&#13;
until the time-ratio goal is met. Once both goals are met, the JVM will&#13;
attempt to reduce the size of the heap so that it ends up with the&#13;
smallest possible heap that meets these two goals.</p>&#13;
&#13;
<p>Because the pause-time goal is not set by default, the usual effect of&#13;
automatic heap sizing is that the heap (and generation) sizes will increase until the&#13;
<span class="keep-together"><code>GCTimeRatio</code></span>&#13;
goal is met. In practice, though, the default setting of that&#13;
flag is optimistic. Your experience will vary,&#13;
of course, but I am much more used to seeing applications that spend 3% to 6%&#13;
of their time in GC and behave quite well. Sometimes I even work on applications in environments where memory is severely constrained; those applications end up spending 10% to 15% of their time in GC.&#13;
GC has a substantial impact on the performance of those applications, but the&#13;
overall performance goals are still met.</p>&#13;
&#13;
<p>So the best setting will vary depending on the application goals.&#13;
In the absence of other goals, I start with a time ratio of 19 (5% of time in GC).</p>&#13;
&#13;
<p><a data-type="xref" href="#TableGCAutoTuneDefault">Table 6-1</a> shows the effects of this dynamic tuning for&#13;
an application that needs a small heap and does little GC&#13;
(it is the stock REST server that has few long-lived objects).</p>&#13;
<table id="TableGCAutoTuneDefault">&#13;
<caption><span class="label">Table 6-1. </span>Effect of dynamic GC tuning</caption>&#13;
<thead>&#13;
<tr>&#13;
<th>GC settings</th>&#13;
<th>End heap size</th>&#13;
<th>Percent time in GC</th>&#13;
<th>OPS</th>&#13;
</tr>&#13;
</thead>&#13;
<tbody>&#13;
<tr>&#13;
<td><p>Default</p></td>&#13;
<td><p>649 MB</p></td>&#13;
<td><p>0.9%</p></td>&#13;
<td><p>9.2</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td><p><code>MaxGCPauseMillis=50ms</code></p></td>&#13;
<td><p>560 MB</p></td>&#13;
<td><p>1.0%</p></td>&#13;
<td><p>9.2</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td><p><code>Xms=Xmx=2048m</code></p></td>&#13;
<td><p>2 GB</p></td>&#13;
<td><p>0.04%</p></td>&#13;
<td><p>9.2</p></td>&#13;
</tr>&#13;
</tbody>&#13;
</table>&#13;
&#13;
<p>By default, the heap will have a 64 MB minimum size and a 2 GB maximum&#13;
size (since the machine has 8 GB of physical memory). In that case, the&#13;
<span class="keep-together"><code>GCTimeRatio</code></span>&#13;
works just as expected: the heap dynamically resized to 649 MB, at which&#13;
point the application was spending about 1% of total time in GC.</p>&#13;
&#13;
<p>Setting the&#13;
<span class="keep-together"><code>MaxGCPauseMillis</code></span>&#13;
flag in this case starts to reduce the size of the heap in order to meet that&#13;
pause-time goal. Because the garbage collector has so little work&#13;
to perform in this example, it succeeds and can still spend only 1% of&#13;
total time in GC, while maintaining the same throughput of 9.2 OPS.</p>&#13;
&#13;
<p>Finally, notice that more isn’t always better. A full 2 GB heap does mean&#13;
that the application can spend less time in GC, but GC isn’t the dominant&#13;
performance factor here, so the throughput doesn’t increase. As usual,&#13;
spending time optimizing the wrong area of the application has not&#13;
helped.</p>&#13;
&#13;
<p>If the same application is changed so that the previous 50 requests for each&#13;
user are saved in a global cache (e.g., as a JPA cache would do), the garbage&#13;
collector has to work&#13;
harder. <a data-type="xref" href="#TableGCAutoTune">Table 6-2</a> shows the trade-offs in that situation.</p>&#13;
<table class="less_space pagebreak-before" id="TableGCAutoTune">&#13;
<caption><span class="label">Table 6-2. </span>Effect of heap occupancy on dynamic GC tuning</caption>&#13;
<thead>&#13;
<tr>&#13;
<th>GC settings</th>&#13;
<th>End heap size</th>&#13;
<th>Percent time in GC</th>&#13;
<th>OPS</th>&#13;
</tr>&#13;
</thead>&#13;
<tbody>&#13;
<tr>&#13;
<td><p>Default</p></td>&#13;
<td><p>1.7 GB</p></td>&#13;
<td><p>9.3%</p></td>&#13;
<td><p>8.4</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td><p><code>MaxGCPauseMillis=50ms</code></p></td>&#13;
<td><p>588 MB</p></td>&#13;
<td><p>15.1%</p></td>&#13;
<td><p>7.9</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td><p><code>Xms=Xmx=2048m</code></p></td>&#13;
<td><p>2 GB</p></td>&#13;
<td><p>5.1%</p></td>&#13;
<td><p>9.0</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td><p><code>Xmx=3560M</code>; <code>MaxGCRatio=19</code></p></td>&#13;
<td><p>2.1 GB</p></td>&#13;
<td><p>8.8%</p></td>&#13;
<td><p>9.0</p></td>&#13;
</tr>&#13;
</tbody>&#13;
</table>&#13;
&#13;
<p>In a test that spends a significant amount of time in GC, the GC behavior is different.&#13;
The JVM will never be able to satisfy the 1% throughput goal in this test; it&#13;
tries its best to accommodate the default goal and does a reasonable job, using 1.7 GB of space.</p>&#13;
&#13;
<p>Application behavior is worse when an unrealistic&#13;
pause-time goal is given. To achieve a 50 ms collection time, the heap&#13;
is kept to 588 MB, but that means that GC now becomes excessively&#13;
frequent. Consequently, the throughput has decreased significantly.&#13;
In this scenario, the better performance comes from&#13;
instructing the JVM to utilize the entire heap by setting both&#13;
the initial and maximum sizes to 2 GB.</p>&#13;
&#13;
<p>Finally, the last line of the table shows what happens when the heap is&#13;
reasonably sized and we set a realistic time-ratio goal of 5%. The JVM itself determined&#13;
that approximately 2 GB was the optimal heap size, and it achieved the same&#13;
throughput as the hand-tuned case<a data-startref="ix_ch06-asciidoc7" data-type="indexterm" id="idm45775554233688"/><a data-startref="ix_ch06-asciidoc6" data-type="indexterm" id="idm45775554232984"/>.<a data-startref="ix_ch06-asciidoc5" data-type="indexterm" id="idm45775554232184"/><a data-startref="ix_ch06-asciidoc4" data-type="indexterm" id="idm45775554231480"/><a data-startref="ix_ch06-asciidoc3" data-type="indexterm" id="idm45775554230808"/></p>&#13;
<div data-type="tip"><h1>Quick Summary</h1>&#13;
<ul>&#13;
<li>&#13;
<p>Dynamic heap tuning is a good first step for heap sizing. For a wide set of applications, that will be all that is needed, and the dynamic settings will minimize the JVM’s memory use.</p>&#13;
</li>&#13;
<li>&#13;
<p>It is possible to statically size the heap to get the maximum possible performance. The sizes the JVM determines for a reasonable set of performance goals are a good first start for that tuning.<a data-startref="ix_ch06-asciidoc2" data-type="indexterm" id="idm45775554226952"/><a data-startref="ix_ch06-asciidoc1" data-type="indexterm" id="idm45775554226248"/></p>&#13;
</li>&#13;
</ul>&#13;
</div>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Understanding the G1 Garbage Collector" data-type="sect1"><div class="sect1" id="GCG1">&#13;
<h1>Understanding the G1 Garbage Collector</h1>&#13;
&#13;
<p><a data-primary="G1 GC (garbage first garbage collector)" data-type="indexterm" id="ix_ch06-asciidoc8"/><a data-primary="garbage collection algorithms" data-secondary="G1 GC" data-type="indexterm" id="ix_ch06-asciidoc9"/>G1 GC operates on discrete regions within the heap.&#13;
Each region (there are by default around 2,048) can belong to either the old&#13;
or new generation, and the generational regions need not be contiguous.&#13;
The idea behind having regions in the old generation is that when the&#13;
concurrent background threads look for unreferenced objects, some regions&#13;
will contain more garbage than other regions. The actual collection of a region still&#13;
requires that application threads be stopped, but G1 GC can focus on the&#13;
regions that are mostly garbage and spend only a little bit of time&#13;
emptying those regions. This approach—clearing out only the mostly&#13;
garbage regions—is what gives G1 GC its name: garbage first.</p>&#13;
&#13;
<p>That doesn’t apply to the regions in the young generation: during&#13;
a young GC, the entire young generation is either freed or promoted (to&#13;
a survivor space or to the old generation). Still, the young generation is&#13;
defined in terms of regions, in part because it makes resizing the generations&#13;
much easier if the regions are predefined.</p>&#13;
&#13;
<p><a data-primary="concurrent garbage collector" data-seealso="CMS garbage collector; G1 GC" data-type="indexterm" id="idm45775554219192"/>G1 GC is called a <em>concurrent collector</em> because the marking of free objects&#13;
within the old generation happens concurrently with the application threads&#13;
(i.e., they are left running). But it is not completely concurrent because&#13;
the marking and compacting of the young generation requires stopping all&#13;
application threads, and the compacting of the old generation also occurs&#13;
while the application threads are stopped.</p>&#13;
&#13;
<p>G1 GC has four logical operations:</p>&#13;
&#13;
<ul>&#13;
<li>&#13;
<p>A young collection</p>&#13;
</li>&#13;
<li>&#13;
<p>A background, concurrent marking cycle</p>&#13;
</li>&#13;
<li>&#13;
<p>A mixed collection</p>&#13;
</li>&#13;
<li>&#13;
<p>If necessary, a full GC</p>&#13;
</li>&#13;
</ul>&#13;
&#13;
<p>We’ll look at each of these in turn,&#13;
starting with the G1 GC young collection shown in <a data-type="xref" href="#FigureG1Young">Figure 6-4</a>.</p>&#13;
&#13;
<figure><div class="figure" id="FigureG1Young">&#13;
<img alt="A diagram of the heap before and after a G1 GC young collection." src="assets/jp2e_0604.png"/>&#13;
<h6><span class="label">Figure 6-4. </span>A G1 GC young collection</h6>&#13;
</div></figure>&#13;
&#13;
<p>Each small square in this figure represents a G1 GC region. The data in each&#13;
region is represented by the black area, and the letter in&#13;
each region identifies the generation to which the region belongs ([E]den,&#13;
[O]ld generation, [S]urvivor space). Empty&#13;
regions do not belong to a generation; G1 GC uses them arbitrarily for whichever&#13;
generation it deems necessary.</p>&#13;
&#13;
<p>The G1 GC young collection&#13;
is triggered when eden fills up (in this case, after filling four regions).&#13;
After the collection, eden is empty (though regions are assigned to it,&#13;
which will begin to fill up with data as the application proceeds).&#13;
At least one region is assigned to the survivor space (partially&#13;
filled in this example), and some data has moved into the old generation.</p>&#13;
&#13;
<p>The GC log illustrates this collection a little differently in G1 than in&#13;
other collectors. The JDK 8 example log was taken using&#13;
<span class="keep-together"><code>PrintGCDetails</code></span>,&#13;
but the details in the log for G1 GC are more verbose. The examples show&#13;
only a few of the important lines.</p>&#13;
&#13;
<p>Here is the standard collection of the young generation:</p>&#13;
&#13;
<pre data-type="programlisting">23.430: [GC pause (young), 0.23094400 secs]&#13;
...&#13;
   [Eden: 1286M(1286M)-&gt;0B(1212M)&#13;
   	Survivors: 78M-&gt;152M Heap: 1454M(4096M)-&gt;242M(4096M)]&#13;
   [Times: user=0.85 sys=0.05, real=0.23 secs]</pre>&#13;
&#13;
<p>Collection of the young generation took 0.23 seconds of real time, during which&#13;
the GC threads consumed 0.85 seconds of CPU time. 1,286 MB of objects were&#13;
moved out of eden (which was adaptively resized to 1,212 MB); 74 MB of that was moved to the&#13;
survivor space (it increased in size from 78 M to 152 MB), and the rest were freed.&#13;
We know they were freed by observing that the total heap occupancy decreased&#13;
by 1,212 MB. In the general case, some objects from&#13;
the survivor space might have been moved to the old generation, and if&#13;
the survivor space were full, some objects from eden would have been promoted&#13;
directly to the old generation—in those cases, the size of the old&#13;
generation would increase.</p>&#13;
&#13;
<p><a data-primary="G1 Evacuation Pause" data-type="indexterm" id="idm45775554203576"/>The similar log in JDK 11 looks like this:</p>&#13;
&#13;
<pre data-type="programlisting">[23.200s][info   ][gc,start     ] GC(10) Pause Young (Normal)&#13;
                                           (G1 Evacuation Pause)&#13;
[23.200s][info   ][gc,task      ] GC(10) Using 4 workers of 4 for evacuation&#13;
[23.430s][info   ][gc,phases    ] GC(10)   Pre Evacuate Collection Set: 0.0ms&#13;
[23.430s][info   ][gc,phases    ] GC(10)   Evacuate Collection Set: 230.3ms&#13;
[23.430s][info   ][gc,phases    ] GC(10)   Post Evacuate Collection Set: 0.5ms&#13;
[23.430s][info   ][gc,phases    ] GC(10)   Other: 0.1ms&#13;
[23.430s][info   ][gc,heap      ] GC(10) Eden regions: 643-&gt;606(606)&#13;
[23.430s][info   ][gc,heap      ] GC(10) Survivor regions: 39-&gt;76(76)&#13;
[23.430s][info   ][gc,heap      ] GC(10) Old regions: 67-&gt;75&#13;
[23.430s][info   ][gc,heap      ] GC(10) Humongous regions: 0-&gt;0&#13;
[23.430s][info   ][gc,metaspace ] GC(10) Metaspace: 18407K-&gt;18407K(1067008K)&#13;
[23.430s][info   ][gc           ] GC(10) Pause Young (Normal)&#13;
                                           (G1 Evacuation Pause)&#13;
                                           1454M(4096M)-&gt;242M(4096M) 230.104ms&#13;
[23.430s][info   ][gc,cpu       ] GC(10) User=0.85s Sys=0.05s Real=0.23s</pre>&#13;
&#13;
<p>A concurrent G1 GC cycle begins and ends as shown in <a data-type="xref" href="#FigureG1Concurrent">Figure 6-5</a>.</p>&#13;
&#13;
<figure><div class="figure" id="FigureG1Concurrent">&#13;
<img alt="A diagram of the heap before and after a G1 concurrent cycle." src="assets/jp2e_0605.png"/>&#13;
<h6><span class="label">Figure 6-5. </span>Concurrent collection performed by G1 GC</h6>&#13;
</div></figure>&#13;
&#13;
<p>This diagram presents three important things to observe. First, the young&#13;
generation has changed its occupancy: there will be at least one (and&#13;
possibly more) young collections during the concurrent cycle. Hence, the&#13;
eden regions before the marking cycle have been completely freed, and new&#13;
eden regions have started to be allocated.</p>&#13;
&#13;
<p>Second, some regions are now marked with an X. Those regions belong to the&#13;
old generation (and note that they still contain data)—they are regions&#13;
that the marking cycle has determined contain mostly garbage.</p>&#13;
&#13;
<p>Finally, notice that the&#13;
old generation (consisting of the regions marked with an O or an X) is&#13;
actually more occupied after the cycle has completed.&#13;
That’s because the young generation collections that occurred during the&#13;
marking cycle promoted data into the old generation. In addition,&#13;
the marking cycle doesn’t actually free any data in the old generation:&#13;
it merely identifies regions that are mostly garbage. Data from those&#13;
regions is freed in a later cycle.</p>&#13;
&#13;
<p>The G1 GC concurrent cycle has several phases, some of which stop all application&#13;
threads, and some of which do not. The first phase is called&#13;
<em>initial-mark</em> (in JDK 8) or <em>concurrent start</em> (in JDK 11). That phase stops&#13;
all application threads—partly because&#13;
it also executes a young collection, and it sets up the next phases of the&#13;
cycle.</p>&#13;
&#13;
<p>In JDK 8, that looks like this:</p>&#13;
&#13;
<pre data-type="programlisting">50.541: [GC pause (G1 Evacuation pause) (young) (initial-mark), 0.27767100 secs]&#13;
    ... lots of other data ...&#13;
    [Eden: 1220M(1220M)-&gt;0B(1220M)&#13;
    	Survivors: 144M-&gt;144M Heap: 3242M(4096M)-&gt;2093M(4096M)]&#13;
    [Times: user=1.02 sys=0.04, real=0.28 secs]</pre>&#13;
&#13;
<p>And in JDK 11:</p>&#13;
&#13;
<pre data-type="programlisting">[50.261s][info   ][gc,start      ] GC(11) Pause Young (Concurrent Start)&#13;
                                              (G1 Evacuation Pause)&#13;
[50.261s][info   ][gc,task       ] GC(11) Using 4 workers of 4 for evacuation&#13;
[50.541s][info   ][gc,phases     ] GC(11)   Pre Evacuate Collection Set: 0.1ms&#13;
[50.541s][info   ][gc,phases     ] GC(11)   Evacuate Collection Set: 25.9ms&#13;
[50.541s][info   ][gc,phases     ] GC(11)   Post Evacuate Collection Set: 1.7ms&#13;
[50.541s][info   ][gc,phases     ] GC(11)   Other: 0.2ms&#13;
[50.541s][info   ][gc,heap       ] GC(11) Eden regions: 1220-&gt;0(1220)&#13;
[50.541s][info   ][gc,heap       ] GC(11) Survivor regions: 144-&gt;144(144)&#13;
[50.541s][info   ][gc,heap       ] GC(11) Old regions: 1875-&gt;1946&#13;
[50.541s][info   ][gc,heap       ] GC(11) Humongous regions: 3-&gt;3&#13;
[50.541s][info   ][gc,metaspace  ] GC(11) Metaspace: 52261K-&gt;52261K(1099776K)&#13;
[50.541s][info   ][gc            ] GC(11) Pause Young (Concurrent Start)&#13;
                                              (G1 Evacuation Pause)&#13;
                                              1220M-&gt;0B(1220M) 280.055ms&#13;
[50.541s][info   ][gc,cpu        ] GC(11) User=1.02s Sys=0.04s Real=0.28s</pre>&#13;
&#13;
<p>As in a regular young collection, the application threads were&#13;
stopped (for 0.28 seconds), and the young generation was emptied (so eden&#13;
ends with a size of 0).&#13;
71 MB of data was moved from the young generation to the old generation. That’s&#13;
a little difficult to tell in JDK 8 (it is 2,093 – 3,242 + 1,220); the JDK 11&#13;
output shows that more clearly.</p>&#13;
&#13;
<p>On the other hand, the JDK 11 output contains references to a few things&#13;
we haven’t discussed yet. First is that the sizes are in regions and not in&#13;
MB. We’ll discuss region sizes later in this chapter, but in this example,&#13;
the region size is 1 MB. In addition, JDK 11 mentions a new area: humongous&#13;
regions. That is part of the old generation and is also discussed&#13;
later in this chapter.</p>&#13;
&#13;
<p>The initial-mark or concurrent start log message announces that the background concurrent cycle&#13;
has begun. Since the initial mark of the marking cycle phase also requires&#13;
all application threads to be stopped, G1 GC takes advantage of the young GC cycle to do that work.&#13;
The impact of adding the initial-mark phase to the young GC&#13;
wasn’t that large: it used 20% more CPU cycles than the previous collection&#13;
(which was just a regular young collection),&#13;
even though the pause was only slightly longer. (Fortunately, there&#13;
were spare CPU cycles on the machine for the parallel G1 threads, or the pause would have been longer.)</p>&#13;
&#13;
<p>Next, G1 GC scans the root region:</p>&#13;
&#13;
<pre data-type="programlisting">50.819: [GC concurrent-root-region-scan-start]&#13;
51.408: [GC concurrent-root-region-scan-end, 0.5890230]&#13;
&#13;
[50.819s][info ][gc             ] GC(20) Concurrent Cycle&#13;
[50.819s][info ][gc,marking     ] GC(20) Concurrent Clear Claimed Marks&#13;
[50.828s][info ][gc,marking     ] GC(20) Concurrent Clear Claimed Marks 0.008ms&#13;
[50.828s][info ][gc,marking     ] GC(20) Concurrent Scan Root Regions&#13;
[51.408s][info ][gc,marking     ] GC(20) Concurrent Scan Root Regions 589.023ms</pre>&#13;
&#13;
<p>This takes 0.58 seconds, but it doesn’t stop the application threads; it&#13;
uses only the background threads. However, this phase cannot&#13;
be interrupted by a young collection, so having available CPU cycles for&#13;
those background threads is&#13;
crucial. If the young generation happens to fill up during the root region&#13;
scanning, the young collection (which has stopped all the application&#13;
threads) must wait for the root scanning to complete. In effect, this means a longer-than-usual&#13;
pause to collect the young generation. That situation is shown in the GC log like this:</p>&#13;
&#13;
<pre data-type="programlisting">350.994: [GC pause (young)&#13;
	351.093: [GC concurrent-root-region-scan-end, 0.6100090]&#13;
	351.093: [GC concurrent-mark-start],&#13;
	0.37559600 secs]&#13;
&#13;
[350.384s][info][gc,marking   ] GC(50) Concurrent Scan Root Regions&#13;
[350.384s][info][gc,marking   ] GC(50) Concurrent Scan Root Regions 610.364ms&#13;
[350.994s][info][gc,marking   ] GC(50) Concurrent Mark (350.994s)&#13;
[350.994s][info][gc,marking   ] GC(50) Concurrent Mark From Roots&#13;
[350.994s][info][gc,task      ] GC(50) Using 1 workers of 1 for marking&#13;
[350.994s][info][gc,start     ] GC(51) Pause Young (Normal) (G1 Evacuation Pause)</pre>&#13;
&#13;
<p>The GC pause here starts before the end of the root region scanning. In JDK&#13;
8, the interleaved output in the GC log indicates that the young collection&#13;
had to pause for the root region scanning to complete before it proceeded. In&#13;
JDK 11, that’s a little more difficult to detect: you have to notice that the&#13;
timestamp of the end of the root region scanning is exactly the same at which&#13;
the next young collection begins.</p>&#13;
&#13;
<p>In either case, it is impossible to know exactly how long the young collection&#13;
was delayed. It wasn’t necessarily delayed the entire 610 ms in this example;&#13;
for some period of that time (until the young generation actually filled up),&#13;
things continued. But in this case, the timestamps show that application&#13;
threads waited about an extra 100 ms—that is&#13;
why the duration of the young GC pause is about 100 ms longer than the average&#13;
duration of other pauses in this log. (If this occurs frequently, it is an indication that G1 GC needs to be better tuned, as discussed in the next section.)</p>&#13;
&#13;
<p>After the root region scanning, G1 GC enters a concurrent marking phase. This happens completely in the background; a message is printed when it starts and ends:</p>&#13;
&#13;
<pre data-type="programlisting">111.382: [GC concurrent-mark-start]&#13;
....&#13;
120.905: [GC concurrent-mark-end, 9.5225160 sec]&#13;
&#13;
[111.382s][info][gc,marking   ] GC(20) Concurrent Mark (111.382s)&#13;
[111.382s][info][gc,marking   ] GC(20) Concurrent Mark From Roots&#13;
...&#13;
[120.905s][info][gc,marking   ] GC(20) Concurrent Mark From Roots 9521.994ms&#13;
[120.910s][info][gc,marking   ] GC(20) Concurrent Preclean&#13;
[120.910s][info][gc,marking   ] GC(20) Concurrent Preclean 0.522ms&#13;
[120.910s][info][gc,marking   ] GC(20) Concurrent Mark (111.382s, 120.910s)&#13;
                                         9522.516ms</pre>&#13;
&#13;
<p>Concurrent marking can be interrupted, so&#13;
young collections may occur during this phase (so there will be lots of GC&#13;
output where the ellipses are).</p>&#13;
&#13;
<p>Also note that in the JDK 11 example, the output has the same GC&#13;
entry—20—as did the entry where the root region scanning occurred. We are&#13;
breaking down the operations more finely than the JDK logging does: in the&#13;
JDK, the entire background scanning is considered one operation. We’re&#13;
splitting the discussion into more fine-grained, logical operations,&#13;
since, for example, the root scanning can introduce a pause when the&#13;
concurrent marking cannot.</p>&#13;
&#13;
<p>The marking phase is followed by a remarking phase and a normal cleanup phase:</p>&#13;
&#13;
<pre data-type="programlisting">120.910: [GC remark 120.959:&#13;
	[GC ref-PRC, 0.0000890 secs], 0.0718990 secs]&#13;
 	[Times: user=0.23 sys=0.01, real=0.08 secs]&#13;
120.985: [GC cleanup 3510M-&gt;3434M(4096M), 0.0111040 secs]&#13;
 	[Times: user=0.04 sys=0.00, real=0.01 secs]&#13;
&#13;
[120.909s][info][gc,start     ] GC(20) Pause Remark&#13;
[120.909s][info][gc,stringtable] GC(20) Cleaned string and symbol table,&#13;
                                           strings: 1369 processed, 0 removed,&#13;
                                           symbols: 17173 processed, 0 removed&#13;
[120.985s][info][gc            ] GC(20) Pause Remark 2283M-&gt;862M(3666M) 80.412ms&#13;
[120.985s][info][gc,cpu        ] GC(20) User=0.23s Sys=0.01s Real=0.08s</pre>&#13;
&#13;
<p>These phases stop the application threads, though usually for a&#13;
short time. Next an additional cleanup phase happens concurrently:</p>&#13;
&#13;
<pre data-type="programlisting">120.996: [GC concurrent-cleanup-start]&#13;
120.996: [GC concurrent-cleanup-end, 0.0004520]&#13;
&#13;
[120.878s][info][gc,start      ] GC(20) Pause Cleanup&#13;
[120.879s][info][gc            ] GC(20) Pause Cleanup 1313M-&gt;1313M(3666M) 1.192ms&#13;
[120.879s][info][gc,cpu        ] GC(20) User=0.00s Sys=0.00s Real=0.00s&#13;
[120.879s][info][gc,marking    ] GC(20) Concurrent Cleanup for Next Mark&#13;
[120.996s][info][gc,marking    ] GC(20) Concurrent Cleanup for Next Mark&#13;
                                          117.168ms&#13;
[120.996s][info][gc            ] GC(20) Concurrent Cycle 70,177.506ms</pre>&#13;
&#13;
<p>And with that, the normal G1 GC background marking cycle is complete—insofar&#13;
as finding the garbage goes, at least. But very little has actually been freed yet.&#13;
A little memory was reclaimed in the cleanup phase, but all G1 GC has&#13;
really done at this point is to identify old regions that are mostly&#13;
garbage and can be reclaimed (the ones marked with an X in&#13;
<a data-type="xref" href="#FigureG1Concurrent">Figure 6-5</a>).</p>&#13;
&#13;
<p><a data-primary="mixed garbage collection" data-type="indexterm" id="ix_ch06-asciidoc10"/>Now G1 GC executes a series of mixed GCs. They are called <em>mixed</em> because they&#13;
perform the normal young collection but also collect some of the marked&#13;
regions from the background scan. The effect of a mixed GC is shown in&#13;
<a data-type="xref" href="#FigureG1Mixed">Figure 6-6</a>.</p>&#13;
&#13;
<p>As is usual for a young collection, G1 GC has completely emptied eden and adjusted&#13;
the survivor spaces. Additionally, two of the marked regions have been&#13;
collected. Those regions were known to contain mostly garbage, so a large&#13;
part of them was freed. Any live data in those regions was moved to another&#13;
region (just as live data was moved from the young generation into regions&#13;
in the old generation). This is how G1 GC compacts the old generation—moving&#13;
the objects like this is essentially compacting the heap as G1 GC goes along.</p>&#13;
&#13;
<figure><div class="figure" id="FigureG1Mixed">&#13;
<img alt="A diagram of the heap before and after a G1 GC mixed collection." src="assets/jp2e_0606.png"/>&#13;
<h6><span class="label">Figure 6-6. </span>Mixed GC performed by G1 GC</h6>&#13;
</div></figure>&#13;
&#13;
<p><a data-primary="GC Pause (mixed)" data-type="indexterm" id="idm45775554166728"/>The mixed GC operation usually looks like this in the log:</p>&#13;
&#13;
<pre data-type="programlisting">79.826: [GC pause (mixed), 0.26161600 secs]&#13;
....&#13;
   [Eden: 1222M(1222M)-&gt;0B(1220M)&#13;
   	Survivors: 142M-&gt;144M Heap: 3200M(4096M)-&gt;1964M(4096M)]&#13;
   [Times: user=1.01 sys=0.00, real=0.26 secs]&#13;
&#13;
&#13;
[3.800s][info][gc,start      ] GC(24) Pause Young (Mixed) (G1 Evacuation Pause)&#13;
[3.800s][info][gc,task       ] GC(24) Using 4 workers of 4 for evacuation&#13;
[3.800s][info][gc,phases     ] GC(24)   Pre Evacuate Collection Set: 0.2ms&#13;
[3.825s][info][gc,phases     ] GC(24)   Evacuate Collection Set: 250.3ms&#13;
[3.826s][info][gc,phases     ] GC(24)   Post Evacuate Collection Set: 0.3ms&#13;
[3.826s][info][gc,phases     ] GC(24)   Other: 0.4ms&#13;
[3.826s][info][gc,heap       ] GC(24) Eden regions: 1222-&gt;0(1220)&#13;
[3.826s][info][gc,heap       ] GC(24) Survivor regions: 142-&gt;144(144)&#13;
[3.826s][info][gc,heap       ] GC(24) Old regions: 1834-&gt;1820&#13;
[3.826s][info][gc,heap       ] GC(24) Humongous regions: 4-&gt;4&#13;
[3.826s][info][gc,metaspace  ] GC(24) Metaspace: 3750K-&gt;3750K(1056768K)&#13;
[3.826s][info][gc            ] GC(24) Pause Young (Mixed) (G1 Evacuation Pause)&#13;
                                          3791M-&gt;3791M(3983M) 124.390ms&#13;
[3.826s][info][gc,cpu        ] GC(24) User=1.01s Sys=0.00s Real=0.26s&#13;
[3.826s][info][gc,start      ] GC(25) Pause Young (Mixed) (G1 Evacuation Pause)</pre>&#13;
&#13;
<p>Notice that the entire heap usage has been reduced by more than just the&#13;
1,222 MB removed from eden. That difference (16 MB) seems small, but remember that some of the&#13;
survivor space was promoted into the old generation at the same time;&#13;
in addition, each mixed GC cleans up only a portion of the targeted&#13;
old generation regions. As we continue, you’ll see that it is important to make sure that&#13;
the mixed GCs clean up enough memory to prevent future concurrent failures.</p>&#13;
&#13;
<p>In JDK 11, the first mixed GC is labeled <code>Prepared Mixed</code> and&#13;
immediately follows the concurrent cleanup.</p>&#13;
&#13;
<p>The mixed GC cycles will continue until (almost) all of the marked regions&#13;
have been collected, at which point G1 GC will resume regular young GC cycles.&#13;
Eventually, G1 GC will start another concurrent cycle to determine which regions&#13;
in the old generation should be freed next.</p>&#13;
&#13;
<p>Although a mixed GC cycle usually says <code>(Mixed)</code> for the GC cause,&#13;
the young collections are sometimes labeled normally following a concurrent&#13;
cycle (i.e., <code>G1 Evacuation Pause</code>). If the concurrent cycle found&#13;
regions in the old generation that can be completely&#13;
freed, those regions are reclaimed during the regular young evacuation pause.&#13;
Technically, this is not a mixed cycle in the implementation of the collector.&#13;
Logically, though, it is: objects are being freed from the young generation or&#13;
promoted into the old generation, and at the same time garbage objects&#13;
(regions, really) are being freed from the old generation.</p>&#13;
&#13;
<p>If all goes well, that’s the entire set of GC activities you’ll see in your&#13;
GC log. But there are some failure cases to consider.</p>&#13;
&#13;
<p>Sometimes you’ll observe a full GC in the log,&#13;
which is an indication that more tuning (including, possibly, more heap&#13;
space) will benefit the application performance. This is triggered primarily four times:</p>&#13;
<dl>&#13;
<dt>Concurrent mode failure</dt>&#13;
<dd>&#13;
<p><a data-primary="concurrent mode failure" data-type="indexterm" id="idm45775554156616"/>G1 GC starts a marking cycle, but the old generation fills up before the cycle is completed.  In that case, G1 GC aborts the marking cycle:</p>&#13;
&#13;
<pre data-type="programlisting">51.408: [GC concurrent-mark-start]&#13;
65.473: [Full GC 4095M-&gt;1395M(4096M), 6.1963770 secs]&#13;
 [Times: user=7.87 sys=0.00, real=6.20 secs]&#13;
71.669: [GC concurrent-mark-abort]&#13;
&#13;
[51.408][info][gc,marking     ] GC(30) Concurrent Mark From Roots&#13;
...&#13;
[65.473][info][gc             ] GC(32) Pause Full (G1 Evacuation Pause)&#13;
                                          4095M-&gt;1305M(4096M) 60,196.377&#13;
...&#13;
[71.669s][info][gc,marking     ] GC(30) Concurrent Mark From Roots 191ms&#13;
[71.669s][info][gc,marking     ] GC(30) Concurrent Mark Abort</pre>&#13;
&#13;
<p>This failure means that heap size should be increased, the G1 GC background processing must begin sooner, or&#13;
the cycle must be tuned to run more quickly (e.g., by using additional&#13;
background threads). Details on how to do that follow.</p>&#13;
</dd>&#13;
<dt>Promotion failure</dt>&#13;
<dd>&#13;
<p><a data-primary="promotion failure" data-type="indexterm" id="idm45775554152568"/>G1 GC has completed a marking cycle and has started performing mixed GCs to clean up the old regions. Before it can clean enough space, too many objects are promoted from the young generation, and so the old generation still runs out of space.&#13;
In the log, a full GC immediately follows a mixed GC:</p>&#13;
&#13;
<pre data-type="programlisting">2226.224: [GC pause (mixed)&#13;
	2226.440: [SoftReference, 0 refs, 0.0000060 secs]&#13;
	2226.441: [WeakReference, 0 refs, 0.0000020 secs]&#13;
	2226.441: [FinalReference, 0 refs, 0.0000010 secs]&#13;
	2226.441: [PhantomReference, 0 refs, 0.0000010 secs]&#13;
	2226.441: [JNI Weak Reference, 0.0000030 secs]&#13;
		(to-space exhausted), 0.2390040 secs]&#13;
....&#13;
    [Eden: 0.0B(400.0M)-&gt;0.0B(400.0M)&#13;
    	Survivors: 0.0B-&gt;0.0B Heap: 2006.4M(2048.0M)-&gt;2006.4M(2048.0M)]&#13;
    [Times: user=1.70 sys=0.04, real=0.26 secs]&#13;
2226.510: [Full GC (Allocation Failure)&#13;
	2227.519: [SoftReference, 4329 refs, 0.0005520 secs]&#13;
	2227.520: [WeakReference, 12646 refs, 0.0010510 secs]&#13;
	2227.521: [FinalReference, 7538 refs, 0.0005660 secs]&#13;
	2227.521: [PhantomReference, 168 refs, 0.0000120 secs]&#13;
	2227.521: [JNI Weak Reference, 0.0000020 secs]&#13;
		2006M-&gt;907M(2048M), 4.1615450 secs]&#13;
    [Times: user=6.76 sys=0.01, real=4.16 secs]&#13;
&#13;
&#13;
[2226.224s][info][gc            ] GC(26) Pause Young (Mixed)&#13;
                                            (G1 Evacuation Pause)&#13;
                                            2048M-&gt;2006M(2048M) 26.129ms&#13;
...&#13;
[2226.510s][info][gc,start      ] GC(27) Pause Full (G1 Evacuation Pause)</pre>&#13;
&#13;
<p>This failure means the mixed collections need to happen more quickly;&#13;
each young collection needs to process more regions in the old generation.<a data-startref="ix_ch06-asciidoc10" data-type="indexterm" id="idm45775554149016"/></p>&#13;
</dd>&#13;
<dt>Evacuation failure</dt>&#13;
<dd>&#13;
<p><a data-primary="evacuation failure" data-type="indexterm" id="idm45775554147160"/>When performing a young collection, there isn’t&#13;
enough room in the survivor spaces and the old generation to hold all the&#13;
surviving objects. This appears&#13;
in the GC logs as a specific kind of young GC:</p>&#13;
&#13;
<pre data-type="programlisting">60.238: [GC pause (young) (to-space overflow), 0.41546900 secs]&#13;
&#13;
[60.238s][info][gc,start       ] GC(28) Pause Young (Concurrent Start)&#13;
                                          (G1 Evacuation Pause)&#13;
[60.238s][info][gc,task        ] GC(28) Using 4 workers of 4&#13;
                                          for evacuation&#13;
[60.238s][info][gc             ] GC(28) To-space exhausted</pre>&#13;
&#13;
<p>This is an indication that the heap is largely full or fragmented. G1 GC&#13;
will attempt to compensate, but you can expect this to end badly:&#13;
the JVM will resort to performing a full GC. The easy way to overcome this&#13;
is to increase the heap size, though possible solutions are given in&#13;
<a data-type="xref" href="#advance-tunings-sec">“Advanced Tunings”</a>.</p>&#13;
</dd>&#13;
<dt>Humongous allocation failure</dt>&#13;
<dd>&#13;
<p><a data-primary="humongous allocation failure" data-type="indexterm" id="idm45775554142344"/>Applications that allocate very large objects can trigger another kind of&#13;
full GC in G1 GC; see <a data-type="xref" href="#HumongousObjects">“G1 GC allocation of humongous objects”</a> for more details&#13;
(including how to avoid it). In JDK 8, it isn’t&#13;
possible to diagnose this situation without resorting to special logging&#13;
parameters, but in JDK 11 that is shown&#13;
with this log:</p>&#13;
</dd>&#13;
</dl>&#13;
&#13;
<pre data-type="programlisting">[3023.091s][info][gc,start     ] GC(54) Pause Full (G1 Humongous Allocation)</pre>&#13;
<dl>&#13;
<dt>Metadata GC threshold</dt>&#13;
<dd>&#13;
<p><a data-primary="Metadata GC Threshold" data-type="indexterm" id="idm45775554138168"/>As I’ve mentioned, the metaspace is essentially a separate heap and is&#13;
collected independently of the main heap. It is not collected via G1 GC, but&#13;
still when it needs to be collected in JDK 8, G1 GC will perform a full GC&#13;
(immediately preceded by a young collection) on the main heap:</p>&#13;
</dd>&#13;
</dl>&#13;
&#13;
<pre data-type="programlisting">0.0535: [GC (Metadata GC Threshold) [PSYoungGen: 34113K-&gt;20388K(291328K)]&#13;
    73838K-&gt;60121K(794112K), 0.0282912 secs]&#13;
    [Times: user=0.05 sys=0.01, real=0.03 secs]&#13;
0.0566: [Full GC (Metadata GC Threshold) [PSYoungGen: 20388K-&gt;0K(291328K)]&#13;
    [ParOldGen: 39732K-&gt;46178K(584192K)] 60121K-&gt;46178K(875520K),&#13;
    [Metaspace: 59040K-&gt;59036K(1101824K)], 0.1121237 secs]&#13;
    [Times: user=0.28 sys=0.01, real=0.11 secs]</pre>&#13;
&#13;
<p>In JDK 11, the metaspace can be collected/resized without requiring a full GC.</p>&#13;
<div data-type="tip"><h1>Quick Summary</h1>&#13;
<ul>&#13;
<li>&#13;
<p>G1 has multiple cycles (and phases within the concurrent cycle). A well-tuned JVM running G1 should experience only young, mixed, and concurrent GC cycles.</p>&#13;
</li>&#13;
<li>&#13;
<p>Small pauses occur for some of the G1 concurrent phases.</p>&#13;
</li>&#13;
<li>&#13;
<p>G1 should be tuned if necessary to avoid full GC cycles.</p>&#13;
</li>&#13;
</ul>&#13;
</div>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Tuning G1 GC" data-type="sect2"><div class="sect2" id="G1GCThreadTuning">&#13;
<h2>Tuning G1 GC</h2>&#13;
&#13;
<p><a data-primary="G1 GC (garbage first garbage collector)" data-secondary="tuning" data-type="indexterm" id="ix_ch06-asciidoc11"/><a data-primary="tuning (garbage collection algorithms)" data-secondary="G1 GC" data-type="indexterm" id="ix_ch06-asciidoc12"/>The major goal in tuning G1 GC is to make sure that&#13;
no concurrent mode or evacuation failures end up requiring a&#13;
full GC. The techniques used to prevent a full GC can also be used when&#13;
frequent young GCs must wait for a root region scan to complete.</p>&#13;
&#13;
<p class="pagebreak-before">Tuning to prevent a full collection is critical in JDK 8, because when G1 GC&#13;
executes a full GC in JDK 8, it does so using a single thread. That creates&#13;
a longer than usual pause time. In JDK 11, the full GC is executed by multiple threads,&#13;
leading to a shorter pause time (essentially, the same pause time as a full&#13;
GC with the throughput collector). This difference is one reason it is&#13;
preferable to update to JDK 11 if you are using G1 GC (though a JDK 8&#13;
application that avoids full GCs will perform just fine).</p>&#13;
&#13;
<p>Secondarily, tuning can minimize the pauses that occur along the&#13;
way.</p>&#13;
&#13;
<p>These are the options to prevent a full GC:</p>&#13;
&#13;
<ul>&#13;
<li>&#13;
<p>Increase the size of the old generation either by increasing the heap space overall or by adjusting the ratio between the generations.</p>&#13;
</li>&#13;
<li>&#13;
<p>Increase the number of background threads (assuming there is sufficient CPU).</p>&#13;
</li>&#13;
<li>&#13;
<p>Perform G1 GC background activities more frequently.</p>&#13;
</li>&#13;
<li>&#13;
<p>Increase the amount of work done in mixed GC cycles.</p>&#13;
</li>&#13;
</ul>&#13;
&#13;
<p>A lot of tunings can be applied here, but&#13;
one of the goals of G1 GC is that it shouldn’t have to be tuned that much.&#13;
<a data-primary="-XX:MaxGCPauseMillis=N" data-type="indexterm" id="idm45775554119224"/>To that end, G1 GC is primarily tuned via a single flag: the same&#13;
<span class="keep-together"><code>-XX:MaxGCPauseMillis=</code><em><code>N</code></em></span> flag that was used to tune the throughput <span class="keep-together">collector</span>.</p>&#13;
&#13;
<p>When used with G1 GC (and unlike the throughput collector), that flag does&#13;
have a default value: 200 ms. If pauses for any of the stop-the-world phases&#13;
of G1 GC start to exceed&#13;
that value, G1 GC will attempt to compensate—adjusting the young-to-old&#13;
ratio, adjusting the heap size, starting the background processing sooner,&#13;
changing the tenuring threshold, and&#13;
(most significantly) processing more&#13;
or fewer old generation regions during a mixed GC cycle.</p>&#13;
&#13;
<p>Some trade-offs apply here: if that value is reduced, the young size&#13;
will contract to meet the pause-time goal, but more frequent&#13;
young GCs will be performed. In addition, the number of old generation&#13;
regions that can be collected during a mixed GC will decrease to meet the&#13;
pause-time goal, which increases the chances of a concurrent mode failure.</p>&#13;
&#13;
<p>If setting a pause-time goal does not prevent the full GCs from happening,&#13;
these various aspects can be tuned individually.&#13;
Tuning the heap sizes for G1 GC is accomplished in the same way as for other&#13;
GC algorithms.</p>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Tuning the G1 background threads" data-type="sect3"><div class="sect3" id="idm45775554113784">&#13;
<h3>Tuning the G1 background threads</h3>&#13;
&#13;
<p><a data-primary="G1 GC (garbage first garbage collector)" data-secondary="tuning background threads" data-type="indexterm" id="idm45775554112376"/><a data-primary="threads" data-secondary="tuning G1 background threads" data-type="indexterm" id="idm45775554111320"/>You can consider the concurrent marking of G1 GC to be in a race with the&#13;
application threads: G1 GC must clear out the old generation faster than the&#13;
application is promoting new data into it.&#13;
To make that happen, try increasing the number of background marking&#13;
threads (assuming sufficient CPU is available on the machine).</p>&#13;
&#13;
<p><a data-primary="-XX:ParallelGCThreads=N" data-type="indexterm" id="idm45775554109640"/>Two sets of threads are used by G1 GC. The first set is controlled via the&#13;
<span class="keep-together"><code>-XX:ParallelGCThreads=<em>N</em></code></span>&#13;
flag that you first saw in <a data-type="xref" href="ch05.html#GC">Chapter 5</a>. That value affects the number of threads used for&#13;
phases when application threads are stopped: young and mixed collections,&#13;
and the phases of the concurrent remark cycle where threads must be stopped.&#13;
<a data-primary="-XX:ConcGCThreads=N" data-type="indexterm" id="idm45775554106584"/>The second flag is&#13;
<span class="keep-together"><code>-XX:ConcGCThreads=<em>N</em></code>,</span>&#13;
which affects the number of threads used for the concurrent remarking.</p>&#13;
&#13;
<p>The default value for the&#13;
<span class="keep-together"><code>ConcGCThreads</code></span>&#13;
flag is defined as follows:</p>&#13;
&#13;
<pre data-type="programlisting">ConcGCThreads = (ParallelGCThreads + 2) / 4</pre>&#13;
&#13;
<p>This division is integer-based,&#13;
so there will be one background scanning thread for up to five parallel&#13;
threads, two background scanning threads for between six and nine parallel&#13;
threads, and so on.</p>&#13;
&#13;
<p>Increasing the number of background scanning threads will make the concurrent&#13;
cycle shorter, which should make it easier for G1 GC to finish freeing the&#13;
old generation during the mixed GC cycles before other threads have filled it&#13;
again. As always, this assumes that the CPU cycles are available;&#13;
otherwise, the scanning threads will take CPU away from the application and&#13;
effectively introduce pauses in it, as you saw when we compared the serial&#13;
collector to G1 GC in <a data-type="xref" href="ch05.html#GC">Chapter 5</a>.</p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Tuning G1 GC to run more (or less) frequently" data-type="sect3"><div class="sect3" id="idm45775554099944">&#13;
<h3>Tuning G1 GC to run more (or less) frequently</h3>&#13;
&#13;
<p><a data-primary="G1 GC (garbage first garbage collector)" data-secondary="tuning to run more/less frequently" data-type="indexterm" id="idm45775554098712"/><a data-primary="tuning (garbage collection algorithms)" data-secondary="G1 GC frequency of operation" data-type="indexterm" id="idm45775554097704"/><a data-primary="tuning (garbage collection algorithms)" data-secondary="G1 GC to run more/less frequently" data-type="indexterm" id="idm45775554096728"/>G1 GC can also win its race if it starts the background marking cycle earlier.&#13;
<a data-primary="-XX:InitiatingHeapOccupancyPercent=N" data-type="indexterm" id="idm45775554095624"/><span class="keep-together">That cycle begins</span> when the heap hits the occupancy ratio specified by&#13;
<span class="keep-together"><code>-XX:InitiatingHeapOccupancyPercent=</code><em><code>N</code></em></span>,&#13;
which has a default value of 45. This percentage refers to the entire heap, not just the&#13;
old generation.</p>&#13;
&#13;
<p>The <code>InitiatingHeapOccupancyPercent</code> value is constant; G1 GC never changes&#13;
that number as it attempts to meet its pause-time goals. If that value is set&#13;
too high, the application will end up performing full GCs because the&#13;
concurrent phases don’t have enough time to complete before the rest of the&#13;
heap fills up. If that value is too small, the application will&#13;
perform more background GC processing than it might <span class="keep-together">otherwise.</span></p>&#13;
&#13;
<p>At some point, of course, those background threads will have to run, so&#13;
presumably the hardware has enough CPU to accommodate them. Still,&#13;
a significant penalty can result from running them too frequently, because&#13;
more small pauses will occur for those concurrent phases that stop the&#13;
application threads. Those pauses can add up quickly, so performing&#13;
background sweeping too frequently for G1 GC should be avoided.&#13;
Check the size of the heap after a concurrent cycle, and make sure that the&#13;
<span class="keep-together"><code>InitiatingHeapOccupancyPercent</code></span>&#13;
value is set higher than that.</p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Tuning G1 GC mixed GC cycles" data-type="sect3"><div class="sect3" id="idm45775554088728">&#13;
<h3>Tuning G1 GC mixed GC cycles</h3>&#13;
&#13;
<p><a data-primary="G1 GC (garbage first garbage collector)" data-secondary="tuning G1 GC mixed GC cycles" data-type="indexterm" id="idm45775554087336"/><a data-primary="tuning (garbage collection algorithms)" data-secondary="G1 GC mixed GC cycles" data-type="indexterm" id="idm45775554086280"/>After a concurrent cycle, G1 GC cannot begin a new concurrent cycle until&#13;
all previously marked regions in the old generation have been collected.&#13;
So another way to make G1 GC start a marking cycle earlier is to process more&#13;
regions in a mixed GC cycle (so that there will end up being fewer mixed&#13;
GC cycles).</p>&#13;
&#13;
<p>The amount of work a mixed GC does depends on three factors. The first is&#13;
how many regions were found to be mostly garbage in the first place. There&#13;
is no way to directly affect that: a region is declared eligible for&#13;
collection during a mixed GC if it is 85% garbage.</p>&#13;
&#13;
<p>The second factor is the maximum number of mixed GC cycles over which G1 GC will&#13;
process those regions, <a data-primary="-XX:G1MixedGCCountTarget=N" data-type="indexterm" id="idm45775554083656"/>which is specified by the value of the flag&#13;
<span class="keep-together"><code>-XX:G1Mixed</code></span><code>GCCountTarget=</code><em><code>N</code></em>.&#13;
The default value for that is 8; reducing that value can help overcome&#13;
promotion failures (at the expense of longer pause times during the mixed&#13;
GC cycle).</p>&#13;
&#13;
<p>On the other hand, if mixed GC pause times are too long, that value can&#13;
be increased so that&#13;
less work is done during the mixed GC. Just be sure that increasing that&#13;
number does not delay the next G1 GC concurrent cycle too long, or a&#13;
concurrent mode failure may result.</p>&#13;
&#13;
<p><a data-primary="-XX:GCTimeRatio=N" data-type="indexterm" id="idm45775554080152"/><a data-primary="-XX:MaxGCPauseMillis=N" data-type="indexterm" id="idm45775554079448"/>Finally, the third factor is the maximum desired length&#13;
of a GC pause (i.e., the value specified by&#13;
<span class="keep-together"><code>MaxGCPauseMillis</code>).</span>&#13;
The&#13;
number of mixed cycles specified by the&#13;
<span class="keep-together"><code>G1MixedGCCountTarget</code></span>&#13;
flag is an&#13;
upper bound; if time is available within the pause target, G1 GC will&#13;
collect more than one-eighth (or whatever value has been specified) of the&#13;
marked old generation regions. Increasing the value of the&#13;
<code class="keep-together">MaxGCPauseMillis</code>&#13;
flag allows more old generation regions to be collected during each&#13;
mixed GC, which in turn can allow G1 GC to begin the next concurrent cycle sooner.</p>&#13;
<div data-type="tip"><h1>Quick Summary</h1>&#13;
<ul>&#13;
<li>&#13;
<p>G1 GC tuning should begin by setting a reasonable pause-time target.</p>&#13;
</li>&#13;
<li>&#13;
<p>If full GCs are still an issue after that and the heap size cannot be increased, specific tunings can be applied for specific <span class="keep-together">failure:</span></p>&#13;
&#13;
<ul>&#13;
<li>&#13;
<p>To make the background threads run more frequently, adjust&#13;
<span class="keep-together"><code>InitiatingHeapOccupancyPercent</code></span>.</p>&#13;
</li>&#13;
<li>&#13;
<p>If additional CPU is available, adjust the number of threads via the&#13;
<span class="keep-together"><code>ConcGCThreads</code></span> flag.<a data-startref="ix_ch06-asciidoc12" data-type="indexterm" id="idm45775554068008"/><a data-startref="ix_ch06-asciidoc11" data-type="indexterm" id="idm45775554067304"/></p>&#13;
</li>&#13;
<li>&#13;
<p>To prevent promotion failures, decrease the size of&#13;
<span class="keep-together"><code>G1MixedGCCountTarget</code></span>.<a data-startref="ix_ch06-asciidoc9" data-type="indexterm" id="idm45775554064888"/><a data-startref="ix_ch06-asciidoc8" data-type="indexterm" id="idm45775554064184"/></p>&#13;
</li>&#13;
</ul>&#13;
</li>&#13;
</ul>&#13;
</div>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Understanding the CMS Collector" data-type="sect1"><div class="sect1" id="GCCMS">&#13;
<h1>Understanding the CMS Collector</h1>&#13;
&#13;
<p><a data-primary="CMS garbage collector" data-type="indexterm" id="ix_ch06-asciidoc13"/><a data-primary="garbage collection algorithms" data-secondary="CMS collector" data-type="indexterm" id="ix_ch06-asciidoc14"/>Although the CMS collector is deprecated, it is still available in current JDK&#13;
builds. So this section covers how to tune it, as well as why it has been deprecated.</p>&#13;
&#13;
<p>CMS has three basic operations:</p>&#13;
&#13;
<ul>&#13;
<li>&#13;
<p>Collecting the young generation (stopping all application threads)</p>&#13;
</li>&#13;
<li>&#13;
<p>Running a concurrent cycle to clean data out of the old generation</p>&#13;
</li>&#13;
<li>&#13;
<p>Performing a full GC to compact the old generation, if necessary</p>&#13;
</li>&#13;
</ul>&#13;
&#13;
<p>A CMS collection of the young generation appears in <a data-type="xref" href="#FigureCMSYoung">Figure 6-7</a>.</p>&#13;
&#13;
<figure><div class="figure" id="FigureCMSYoung">&#13;
<img alt="A diagram of the heap before and after a CMS young collection." src="assets/jp2e_0607.png"/>&#13;
<h6><span class="label">Figure 6-7. </span>Young collection performed by CMS</h6>&#13;
</div></figure>&#13;
&#13;
<p>A CMS young collection is similar to a throughput young collection:&#13;
data is moved from eden into one survivor space (and into the old generation if the survivor space fills up).</p>&#13;
&#13;
<p>The GC log entry for CMS is also similar (I’ll show only the JDK 8 log format):</p>&#13;
&#13;
<pre data-type="programlisting">89.853: [GC 89.853: [ParNew: 629120K-&gt;69888K(629120K), 0.1218970 secs]&#13;
		1303940K-&gt;772142K(2027264K), 0.1220090 secs]&#13;
		[Times: user=0.42 sys=0.02, real=0.12 secs]</pre>&#13;
&#13;
<p>The size of the young generation is presently 629 MB; after collection, 69 MB&#13;
of it remains (in a survivor space). Similarly, the size of the entire&#13;
heap is 2,027 MB—772 MB of which is occupied after the collection. The&#13;
entire process took 0.12 seconds, though the parallel GC threads racked up&#13;
0.42 seconds in CPU usage.</p>&#13;
&#13;
<p>A concurrent cycle is shown in <a data-type="xref" href="#FigureCMSConcurrent">Figure 6-8</a>.</p>&#13;
&#13;
<p>CMS starts a concurrent cycle based on the occupancy of the heap.&#13;
When it is sufficiently full, the&#13;
background threads that cycle through the heap and remove objects are started.&#13;
At the end of the cycle, the heap looks like the bottom row in this&#13;
diagram. Notice that the old generation is not compacted: there are areas&#13;
where objects are allocated, and free areas.&#13;
When a young collection moves objects from eden into the old&#13;
generation, the JVM will attempt to use those free areas to hold the objects.&#13;
Often those objects won’t fit into one of the free areas, which is why&#13;
after the CMS cycle, the high-water mark of the heap is larger.</p>&#13;
&#13;
<figure><div class="figure" id="FigureCMSConcurrent">&#13;
<img alt="A diagram of the heap before and after a CMS concurrent cycle." src="assets/jp2e_0608.png"/>&#13;
<h6><span class="label">Figure 6-8. </span>Concurrent collection performed by CMS</h6>&#13;
</div></figure>&#13;
&#13;
<p>In the GC log, this cycle appears as a number of phases. Although a majority&#13;
of the concurrent cycle uses background threads,&#13;
some phases introduce short pauses where all&#13;
application threads are stopped.</p>&#13;
&#13;
<p>The concurrent cycle starts with an initial-mark phase, which stops&#13;
all the application threads:</p>&#13;
&#13;
<pre data-type="programlisting">89.976: [GC [1 CMS-initial-mark: 702254K(1398144K)]&#13;
		772530K(2027264K), 0.0830120 secs]&#13;
		[Times: user=0.08 sys=0.00, real=0.08 secs]</pre>&#13;
&#13;
<p>This phase is responsible for finding&#13;
all the GC root objects in the heap. The first set of numbers shows&#13;
that objects currently occupy 702 MB of 1,398 MB of the old generation, while&#13;
the second set shows that the occupancy of the entire 2,027 MB heap is&#13;
772 MB. The application threads were stopped for a period of 0.08 seconds&#13;
during this phase of the CMS cycle.</p>&#13;
&#13;
<p>The next phase is the mark phase, and it does not stop the application threads.&#13;
The phase is represented in the GC log by these lines:</p>&#13;
&#13;
<pre data-type="programlisting">90.059: [CMS-concurrent-mark-start]&#13;
90.887: [CMS-concurrent-mark: 0.823/0.828 secs]&#13;
		[Times: user=1.11 sys=0.00, real=0.83 secs]</pre>&#13;
&#13;
<p>The mark phase took 0.83 seconds (and 1.11 seconds of CPU time). Since&#13;
it is just a marking phase, it hasn’t done anything to the heap occupancy,&#13;
so no data is shown about that. If there were data,&#13;
it would likely show a growth in the heap from objects allocated in&#13;
the young generation during those 0.83 seconds, since the application&#13;
threads have continued to execute.</p>&#13;
&#13;
<p>Next comes a preclean phase, which also runs concurrently with&#13;
the application threads:</p>&#13;
&#13;
<pre data-type="programlisting">90.887: [CMS-concurrent-preclean-start]&#13;
90.892: [CMS-concurrent-preclean: 0.005/0.005 secs]&#13;
		[Times: user=0.01 sys=0.00, real=0.01 secs]</pre>&#13;
&#13;
<p>The next phase is a remark phase, but it involves several operations:</p>&#13;
&#13;
<pre data-type="programlisting">90.892: [CMS-concurrent-abortable-preclean-start]&#13;
92.392: [GC 92.393: [ParNew: 629120K-&gt;69888K(629120K), 0.1289040 secs]&#13;
		1331374K-&gt;803967K(2027264K), 0.1290200 secs]&#13;
		[Times: user=0.44 sys=0.01, real=0.12 secs]&#13;
94.473: [CMS-concurrent-abortable-preclean: 3.451/3.581 secs]&#13;
		[Times: user=5.03 sys=0.03, real=3.58 secs]&#13;
&#13;
94.474: [GC[YG occupancy: 466937 K (629120 K)]&#13;
	94.474: [Rescan (parallel) , 0.1850000 secs]&#13;
	94.659: [weak refs processing, 0.0000370 secs]&#13;
	94.659: [scrub string table, 0.0011530 secs]&#13;
		[1 CMS-remark: 734079K(1398144K)]&#13;
		1201017K(2027264K), 0.1863430 secs]&#13;
	[Times: user=0.60 sys=0.01, real=0.18 secs]</pre>&#13;
&#13;
<p>Wait, didn’t CMS just execute a preclean phase? What’s up with this abortable&#13;
preclean phase?</p>&#13;
&#13;
<p>The abortable preclean phase is used because the remark phase&#13;
(which, strictly speaking, is the final entry&#13;
in this output) is not concurrent—it will stop all the application threads. CMS wants to&#13;
avoid the situation where a young generation collection occurs and is&#13;
immediately followed by a remark phase, in which case the application threads&#13;
would be stopped for two back-to-back pause operations. The goal here is to&#13;
minimize pause lengths by preventing back-to-back pauses.</p>&#13;
&#13;
<p>Hence, the abortable preclean phase waits until the young generation is about&#13;
50% full. In theory, that is halfway between young generation collections,&#13;
giving CMS the best chance to avoid those back-to-back pauses. In this  example,&#13;
the abortable preclean phase starts at 90.8 seconds&#13;
and waits about 1.5 seconds for the regular young collection to occur (at&#13;
92.392 seconds into the log). CMS uses past behavior to calculate when&#13;
the next young collection is likely to occur—in this case, CMS calculated it would occur in about&#13;
4.2 seconds. So after 2.1 seconds (at 94.4&#13;
seconds), CMS ends the preclean phase (which it calls <em>aborting</em> the&#13;
phase, even though that is the only way the phase is stopped).&#13;
Then, finally, CMS executes the remark phase, which pauses the&#13;
application threads for 0.18 seconds (the application threads were not paused&#13;
during the abortable preclean phase).</p>&#13;
&#13;
<p>Next comes another concurrent phase—the sweep phase:</p>&#13;
&#13;
<pre data-type="programlisting">94.661: [CMS-concurrent-sweep-start]&#13;
95.223: [GC 95.223: [ParNew: 629120K-&gt;69888K(629120K), 0.1322530 secs]&#13;
		999428K-&gt;472094K(2027264K), 0.1323690 secs]&#13;
		[Times: user=0.43 sys=0.00, real=0.13 secs]&#13;
95.474: [CMS-concurrent-sweep: 0.680/0.813 secs]&#13;
		[Times: user=1.45 sys=0.00, real=0.82 secs]</pre>&#13;
&#13;
<p>This phase took 0.82 seconds and ran concurrently with the application threads.&#13;
It also happened to be interrupted by a young collection.&#13;
This young collection had nothing to do with the sweep phase, but it is left&#13;
in here as an example that the young collections can occur simultaneously with&#13;
the old collection phases. In <a data-type="xref" href="#FigureCMSConcurrent">Figure 6-8</a>, notice that the&#13;
state of the young generation changed during the concurrent collection—there may have been an arbitrary number of young collections during the&#13;
sweep phase (and there will have been at least one young collection because&#13;
of the abortable preclean phase).</p>&#13;
&#13;
<p>Next comes the concurrent reset phase:</p>&#13;
&#13;
<pre data-type="programlisting">95.474: [CMS-concurrent-reset-start]&#13;
95.479: [CMS-concurrent-reset: 0.005/0.005 secs]&#13;
	[Times: user=0.00 sys=0.00, real=0.00 secs]</pre>&#13;
&#13;
<p>That is the last of the concurrent phases; the CMS cycle is complete,&#13;
and the unreferenced objects found in the old generation are now free&#13;
(resulting in the heap shown in <a data-type="xref" href="#FigureCMSConcurrent">Figure 6-8</a>).&#13;
Unfortunately, the log doesn’t provide any information about how many&#13;
objects were freed; the&#13;
reset line doesn’t give any information about the heap occupancy.&#13;
To get an idea of that, look to the next young collection:</p>&#13;
&#13;
<pre data-type="programlisting">98.049: [GC 98.049: [ParNew: 629120K-&gt;69888K(629120K), 0.1487040 secs]&#13;
		1031326K-&gt;504955K(2027264K), 0.1488730 secs]</pre>&#13;
&#13;
<p>Now compare the occupancy of the old generation at 89.853 seconds&#13;
(before the CMS cycle began), which was roughly 703 MB (the entire heap&#13;
occupied 772 MB at that point, which included 69 MB in the survivor space, so&#13;
the old generation consumed the remaining 703 MB). In the collection at 98.049&#13;
seconds, the old generation occupies about 504 MB; the CMS cycle therefore&#13;
cleaned up about 199 MB of memory.</p>&#13;
&#13;
<p>If all goes well, these are the only cycles that CMS will run and the only&#13;
log messages that will appear in the CMS GC log. But there&#13;
are three more messages to look for, which indicate that CMS ran into a&#13;
problem. The first is a concurrent mode failure:</p>&#13;
&#13;
<pre data-type="programlisting">267.006: [GC 267.006: [ParNew: 629120K-&gt;629120K(629120K), 0.0000200 secs]&#13;
	267.006: [CMS267.350: [CMS-concurrent-mark: 2.683/2.804 secs]&#13;
	[Times: user=4.81 sys=0.02, real=2.80 secs]&#13;
 	(concurrent mode failure):&#13;
	1378132K-&gt;1366755K(1398144K), 5.6213320 secs]&#13;
	2007252K-&gt;1366755K(2027264K),&#13;
	[CMS Perm : 57231K-&gt;57222K(95548K)], 5.6215150 secs]&#13;
	[Times: user=5.63 sys=0.00, real=5.62 secs]</pre>&#13;
&#13;
<p>When a young collection occurs and there isn’t enough room in the old&#13;
generation to hold all the objects that are expected to be promoted, CMS&#13;
executes what is essentially a full GC. All application threads are stopped,&#13;
and the old generation is cleaned of any dead objects, reducing its&#13;
occupancy to 1,366 MB—an operation that kept the application&#13;
threads paused for a full 5.6 seconds. That operation is single-threaded,&#13;
which is one reason it takes so long (and one reason concurrent mode&#13;
failures are worse as the heap grows).</p>&#13;
&#13;
<p>This concurrent mode failure is a major reason CMS is deprecated.  G1 GC&#13;
can have a concurrent mode failure, but when it reverts to a full GC, that&#13;
full GC occurs in parallel in JDK 11 (though not in JDK 8). A CMS full GC&#13;
will take many times longer to execute because it must execute in a single&#13;
thread.<sup><a data-type="noteref" href="ch06.html#idm45775554022120" id="idm45775554022120-marker">2</a></sup></p>&#13;
&#13;
<p>The second problem occurs when there is enough room in the old generation to&#13;
hold the promoted objects but the free space is fragmented and so the&#13;
promotion fails:</p>&#13;
&#13;
<pre data-type="programlisting">6043.903: [GC 6043.903:&#13;
	[ParNew (promotion failed): 614254K-&gt;629120K(629120K), 0.1619839 secs]&#13;
	6044.217: [CMS: 1342523K-&gt;1336533K(2027264K), 30.7884210 secs]&#13;
	2004251K-&gt;1336533K(1398144K),&#13;
	[CMS Perm : 57231K-&gt;57231K(95548K)], 28.1361340 secs]&#13;
	[Times: user=28.13 sys=0.38, real=28.13 secs]</pre>&#13;
&#13;
<p>Here, CMS started a young collection and assumed that space existed&#13;
to hold all the promoted objects (otherwise, it would have declared a&#13;
concurrent mode failure). That assumption proved incorrect: CMS couldn’t promote the objects because the old <span class="keep-together">generation</span> was fragmented (or, much&#13;
less likely, because the amount of memory to be promoted was bigger than CMS expected).</p>&#13;
&#13;
<p>As a result, in the middle&#13;
of the young collection (when all threads were already stopped), CMS collected&#13;
and compacted the entire old generation. The good news is that with&#13;
the heap compacted, fragmentation issues have been solved (at least for a while).&#13;
But that came with a hefty 28-second pause time. This time&#13;
is much longer than when CMS had a concurrent mode failure because the entire&#13;
heap was compacted; the concurrent mode failure simply freed objects in the&#13;
heap.  The heap at this point appears as&#13;
it did at the end of the throughput collector’s full GC (<a data-type="xref" href="#FigureParOld">Figure 6-2</a>):&#13;
the young generation is completely empty, and the old generation has been&#13;
compacted.</p>&#13;
&#13;
<p>Finally, the CMS log may show a full GC&#13;
without any of the usual concurrent GC <span class="keep-together">messages</span>:</p>&#13;
&#13;
<pre data-type="programlisting">279.803: [Full GC 279.803:&#13;
		[CMS: 88569K-&gt;68870K(1398144K), 0.6714090 secs]&#13;
		558070K-&gt;68870K(2027264K),&#13;
		[CMS Perm : 81919K-&gt;77654K(81920K)],&#13;
		0.6716570 secs]</pre>&#13;
&#13;
<p>This occurs when the metaspace has filled up and needs to be collected.&#13;
CMS does not collect the metaspace, so if it fills up, a&#13;
full GC is needed to discard any unreferenced classes. <a data-type="xref" href="#advance-tunings-sec">“Advanced Tunings”</a>&#13;
shows how to overcome this issue.</p>&#13;
<div data-type="tip"><h1>Quick Summary</h1>&#13;
<ul>&#13;
<li>&#13;
<p>CMS has several GC operations, but the expected operations are minor GCs and concurrent cycles.</p>&#13;
</li>&#13;
<li>&#13;
<p>Concurrent mode failures and promotion failures in CMS are expensive; CMS should be tuned to avoid these as much as possible.</p>&#13;
</li>&#13;
<li>&#13;
<p>By default, CMS does not collect metaspace.</p>&#13;
</li>&#13;
</ul>&#13;
</div>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Tuning to Solve Concurrent Mode Failures" data-type="sect2"><div class="sect2" id="idm45775554008600">&#13;
<h2>Tuning to Solve Concurrent Mode Failures</h2>&#13;
&#13;
<p><a data-primary="CMS garbage collector" data-secondary="tuning to solve concurrent mode failures" data-type="indexterm" id="ix_ch06-asciidoc15"/><a data-primary="mode failures" data-type="indexterm" id="ix_ch06-asciidoc16"/><a data-primary="promotion failure" data-type="indexterm" id="ix_ch06-asciidoc17"/><a data-primary="tuning (garbage collection algorithms)" data-secondary="of CMS garbage collector to solve concurrent mode failures" data-type="indexterm" id="ix_ch06-asciidoc18"/>The primary concern when tuning CMS is to make sure that&#13;
no concurrent mode or promotion failures occur. As the CMS GC log showed, a&#13;
concurrent mode failure occurs because CMS did not clean out the old&#13;
generation fast enough: when it comes time to perform a collection in&#13;
the young generation, CMS calculates that it doesn’t have enough room to&#13;
promote those objects to the old generation and instead collects&#13;
the old generation first.</p>&#13;
&#13;
<p>The old generation initially fills up by placing the objects right next to&#13;
each other. When a certain amount of the old generation is filled (by default,&#13;
70%), the <span class="keep-together">concurrent</span> cycle begins and the background CMS&#13;
thread(s) start scanning the old generation for garbage. At this point, the&#13;
race is on: CMS must complete scanning the old generation and freeing objects&#13;
before the remainder (30%) of the old generation fills up. If the concurrent&#13;
cycle loses the race, CMS will experience a concurrent mode failure.</p>&#13;
&#13;
<p>We can attempt to avoid this failure in multiple ways:</p>&#13;
&#13;
<ul>&#13;
<li>&#13;
<p>Make the old generation larger, either by shifting the proportion of the new generation to the old generation or by adding more heap space altogether.</p>&#13;
</li>&#13;
<li>&#13;
<p>Run the background thread more often.</p>&#13;
</li>&#13;
<li>&#13;
<p>Use more background threads.</p>&#13;
</li>&#13;
</ul>&#13;
<aside data-type="sidebar" epub:type="sidebar"><div class="sidebar" id="idm45775553996664">&#13;
<h5>Adaptive Sizing and CMS</h5>&#13;
<p><a data-primary="-XX:MaxGCPauseMillis=N" data-type="indexterm" id="idm45775553995464"/><a data-primary="CMS garbage collector" data-secondary="adaptive sizing and" data-type="indexterm" id="idm45775553994760"/>CMS uses the&#13;
<span class="keep-together"><code>MaxGCPauseMllis=</code><em><code>N</code></em></span>&#13;
and&#13;
<span class="keep-together"><code>GCTimeRatio=</code><em><code>N</code></em></span>&#13;
settings to determine how large the heap and the generations should be.</p>&#13;
&#13;
<p>One significant difference in the approach CMS takes is that the young&#13;
generation is never resized unless a full GC occurs. Since the goal of CMS&#13;
is to never have a full collection, this means a well-tuned CMS application&#13;
will never resize its young <span class="keep-together">generation</span>.</p>&#13;
&#13;
<p>Concurrent mode failures can be frequent during program startup, as CMS&#13;
adaptively sizes the heap and the metaspace. It can be a good&#13;
idea to start CMS with a&#13;
larger initial heap size (and larger metaspace), which is a special&#13;
case of making the heap&#13;
larger to prevent those failures.</p>&#13;
</div></aside>&#13;
&#13;
<p>If more memory is available, the better solution is to increase the size of&#13;
the heap. Otherwise, change the way the background&#13;
threads operate.</p>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Running the background thread more often" data-type="sect3"><div class="sect3" id="idm45775553988136">&#13;
<h3>Running the background thread more often</h3>&#13;
&#13;
<p>One way to let CMS win the race is to start the concurrent cycle sooner.&#13;
If the concurrent cycle starts when 60% of the old generation is filled,&#13;
CMS has a better chance&#13;
of finishing than if the cycle starts when 70% of the old generation is filled.&#13;
<a data-primary="-XX:CMSInitiatingOccupancyFraction=N" data-type="indexterm" id="ix_ch06-asciidoc19"/>The easiest way to achieve that is to set both these flags:</p>&#13;
&#13;
<ul>&#13;
<li>&#13;
<p><span class="keep-together"><code>-XX:CMSInitiatingOccupancyFraction=</code><em><code>N</code></em></span></p>&#13;
</li>&#13;
<li>&#13;
<p><span class="keep-together"><code>-XX:+UseCMSInitiatingOccupancyOnly</code></span></p>&#13;
</li>&#13;
</ul>&#13;
&#13;
<p>Using both flags also makes CMS easier to understand: if both are set,&#13;
CMS determines when to start the background thread based only on the&#13;
percentage of the old generation that is filled. (Note that unlike G1 GC, the&#13;
occupancy ratio here is only the old generation and not the entire heap.)</p>&#13;
&#13;
<p><a data-primary="-XX:+UseCMSInitiatingOccupancyOnly" data-type="indexterm" id="idm45775553980056"/>By default, the&#13;
<span class="keep-together"><code>UseCMSInitiatingOccupancyOnly</code></span>&#13;
flag is <code>false</code>, and CMS uses a more complex algorithm to determine when&#13;
to start the background thread. If the background thread needs to be started&#13;
earlier, it’s better to start it the simplest way possible and set the&#13;
<span class="keep-together"><code>UseCMSInitiatingOccupancyOnly</code></span>&#13;
flag to <code>true</code>.</p>&#13;
&#13;
<p>Tuning the value of the&#13;
<span class="keep-together"><code>CMSInitiatingOccupancyFraction</code></span>&#13;
may require a few iterations. If&#13;
<span class="keep-together"><code>UseCMSInitiatingOccupancyOnly</code></span>&#13;
is enabled, the default value for&#13;
<span class="keep-together"><code>CMSInitiatingOccupancyFraction</code></span>&#13;
is 70: the CMS cycle starts when the old generation is 70% occupied.</p>&#13;
&#13;
<p>A better value for that flag for a given application can&#13;
be found in the GC log by figuring out when the failed CMS cycle started&#13;
in the first place. Find the concurrent mode failure in the log, and then&#13;
look back to when the most recent CMS cycle started. The <code>CMS-initial-mark</code>&#13;
line will show how full the old generation was when the CMS cycle started:</p>&#13;
&#13;
<pre data-type="programlisting">89.976: [GC [1 CMS-initial-mark: 702254K(1398144K)]&#13;
		772530K(2027264K), 0.0830120 secs]&#13;
		[Times: user=0.08 sys=0.00, real=0.08 secs]</pre>&#13;
&#13;
<p>In this example, that works out to about 50% (702 MB&#13;
out of 1,398 MB). That was not soon enough, so the&#13;
<span class="keep-together"><code>CMSInitiatingOccupancyFraction</code></span>&#13;
needs to be set to something lower than 50. (Although the default&#13;
value for that flag is 70, this example started the CMS threads when the old&#13;
generation was 50% full because the <code>UseCMS</code><span class="keep-together"><code>InitiatingOccupancyOnly</code></span> flag was not set.)</p>&#13;
&#13;
<p>The temptation here is just to set the value to 0 or another small number&#13;
so that the background CMS cycle runs all the time. That’s usually&#13;
discouraged, but as long as you are aware of the trade-offs being made,&#13;
it may work out fine.</p>&#13;
&#13;
<p>The first trade-off comes in CPU time: the CMS background thread(s) will&#13;
run continually, and they consume a fair amount of CPU—each background&#13;
CMS thread will consume 100% of a CPU. There will also be very&#13;
short bursts when multiple CMS threads run and the total CPU on the box&#13;
spikes as a result. If these threads are running needlessly, that wastes CPU resources.</p>&#13;
&#13;
<p>On the other hand, it isn’t necessarily a problem to use those CPU cycles. The&#13;
background CMS threads have&#13;
to run sometimes, even in the best case. Hence, the machine must always&#13;
have enough CPU cycles available to run those CMS threads.&#13;
So when sizing the machine, you must plan for that CPU usage.</p>&#13;
&#13;
<p>The second trade-off is far more significant and has to do with pauses.&#13;
As the GC log showed, certain phases of the CMS cycle stop all the application&#13;
threads. The main reason CMS is used is to limit the effect of GC pauses, so running&#13;
CMS more often than needed is counterproductive. The CMS pauses&#13;
are generally much shorter than a young generation pause, and a particular&#13;
application may not be sensitive to those additional pauses—it’s a&#13;
trade-off between the additional pauses and the reduced chance of a&#13;
concurrent mode failure. But continually running the background GC pauses&#13;
will likely lead to excessive overall pauses, which will, in the end, ultimately&#13;
reduce the performance of the application.</p>&#13;
&#13;
<p>Unless those trade-offs are acceptable, take care not to set the <code>CMSInitiatingOccupancyFraction</code>&#13;
higher than the amount of live data in the heap, plus at least 10% to 20%.<a data-startref="ix_ch06-asciidoc19" data-type="indexterm" id="idm45775553964312"/></p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Adjusting the CMS background threads" data-type="sect3"><div class="sect3" id="idm45775553987512">&#13;
<h3>Adjusting the CMS background threads</h3>&#13;
&#13;
<p>Each CMS background thread will consume 100% of a CPU on a machine.&#13;
If an application experiences a concurrent mode failure and extra&#13;
CPU cycles are available,&#13;
<a data-primary="-XX:ConcGCThreads=N" data-type="indexterm" id="idm45775553961912"/>the number of those background threads can be increased by setting the&#13;
<span class="keep-together"><code>-XX:ConcGCThreads=</code><em><code>N</code></em></span>&#13;
flag. CMS sets this flag differently than G1 GC; it uses this <span class="keep-together">calculation:</span></p>&#13;
&#13;
<pre data-type="programlisting">ConcGCThreads = (3 + ParallelGCThreads) / 4</pre>&#13;
&#13;
<p>So CMS increases the value of <code>ConcGCThreads</code> one step earlier than does G1 GC.</p>&#13;
<div data-type="tip"><h1>Quick Summary</h1>&#13;
<ul>&#13;
<li>&#13;
<p>Avoiding concurrent mode failures is the key to achieving the best possible performance with CMS.</p>&#13;
</li>&#13;
<li>&#13;
<p>The simplest way to avoid those failures (when possible) is to increase the size of the heap.</p>&#13;
</li>&#13;
<li>&#13;
<p>Otherwise, the next step is to start the concurrent background threads sooner by adjusting <code>CMSInitiatingOccupancy​Frac⁠tion</code>.</p>&#13;
</li>&#13;
<li>&#13;
<p>Tuning the number of background threads can also help<a data-startref="ix_ch06-asciidoc18" data-type="indexterm" id="idm45775553952136"/><a data-startref="ix_ch06-asciidoc17" data-type="indexterm" id="idm45775553951432"/><a data-startref="ix_ch06-asciidoc16" data-type="indexterm" id="idm45775553950760"/><a data-startref="ix_ch06-asciidoc15" data-type="indexterm" id="idm45775553950088"/>.<a data-startref="ix_ch06-asciidoc14" data-type="indexterm" id="idm45775553949288"/><a data-startref="ix_ch06-asciidoc13" data-type="indexterm" id="idm45775553948584"/></p>&#13;
</li>&#13;
</ul>&#13;
</div>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Advanced Tunings" data-type="sect1"><div class="sect1" id="advance-tunings-sec">&#13;
<h1>Advanced Tunings</h1>&#13;
&#13;
<p><a data-primary="garbage collection algorithms" data-secondary="advanced tunings" data-type="indexterm" id="ix_ch06-asciidoc20"/><a data-primary="tuning (garbage collection algorithms)" data-secondary="advanced GC tunings" data-type="indexterm" id="ix_ch06-asciidoc21"/>This section on tunings covers some fairly unusual situations. Even though these&#13;
situations are not encountered frequently, many of the low-level details of&#13;
the GC algorithms are explained in this section.</p>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Tenuring and Survivor Spaces" data-type="sect2"><div class="sect2" id="SurvivorSpaces">&#13;
<h2>Tenuring and Survivor Spaces</h2>&#13;
&#13;
<p><a data-primary="garbage collection (GC)" data-secondary="tenuring and survivor spaces" data-type="indexterm" id="ix_ch06-asciidoc22"/><a data-primary="survivor spaces" data-type="indexterm" id="ix_ch06-asciidoc23"/><a data-primary="tenuring" data-type="indexterm" id="ix_ch06-asciidoc24"/><a data-primary="tuning (garbage collection algorithms)" data-secondary="tenuring and survivor spaces" data-type="indexterm" id="ix_ch06-asciidoc25"/>When the young generation is collected, some objects will still be alive.&#13;
This includes not only newly created objects that are destined to exist for a long&#13;
time but also objects that are otherwise short-lived. Consider the loop of&#13;
<span class="keep-together"><code>BigDecimal</code></span>&#13;
calculations at the beginning of <a data-type="xref" href="ch05.html#GC">Chapter 5</a>. If the JVM performs GC in the middle of that loop, some&#13;
of those short-lived&#13;
<span class="keep-together"><code>BigDecimal</code></span>&#13;
objects will be unlucky: they&#13;
will have been just created and in use, so they can’t be freed—but they&#13;
aren’t going to live long enough to justify moving them to the old generation.</p>&#13;
&#13;
<p>This is the reason that the young generation is divided into&#13;
two survivor spaces and eden. This setup allows objects to have&#13;
additional chances to be collected while still in the young&#13;
generation, rather than being promoted into (and filling up) the old <span class="keep-together">generation.</span></p>&#13;
&#13;
<p>When the young generation is&#13;
collected and the JVM finds an object that is still alive, that object&#13;
is moved to a survivor space rather than to the old generation.&#13;
During the first young generation collection, objects&#13;
are moved from eden into survivor space 0. During the&#13;
next collection, live objects are moved from both survivor space 0 and from&#13;
eden into survivor space 1. At that point, eden and survivor space 0 are&#13;
completely empty. The next collection moves live objects&#13;
from survivor space 1 and eden into survivor space 0, and&#13;
so on. (The survivor spaces are also referred to as the <em>to</em> and&#13;
<em>from</em> spaces; during each collection, objects are moved out of the from&#13;
space and into the to space. <em>from</em> and <em>to</em> are simply pointers that&#13;
switch between the two survivor spaces on every collection.)</p>&#13;
&#13;
<p>Clearly this cannot continue forever, or nothing would ever be moved into the&#13;
old generation. Objects are moved into the old generation in two&#13;
circumstances. First, the survivor spaces are fairly small. When the target&#13;
survivor space fills up&#13;
during a young collection, any remaining live objects in eden are moved directly&#13;
into the old generation. <a data-primary="tenuring threshold" data-type="indexterm" id="idm45775553929576"/>Second, there is a limit to the number of GC&#13;
cycles during which an object can remain in the survivor spaces.&#13;
That limit is called the <em>tenuring threshold</em>.</p>&#13;
&#13;
<p>Tunings can affect each of those situations. The survivor spaces&#13;
take up part of the allocation for the young generation, and like other&#13;
areas of the heap, the JVM sizes them dynamically. <a data-primary="-XX:InitialSurvivorRatio=N" data-type="indexterm" id="idm45775553927560"/>The initial size of&#13;
the survivor spaces is determined by the&#13;
<span class="keep-together"><code>-XX:InitialSurvivorRatio=</code><em><code>N</code></em></span>&#13;
flag, which is used in this equation:</p>&#13;
&#13;
<pre data-type="programlisting">survivor_space_size = new_size / (initial_survivor_ratio + 2)</pre>&#13;
&#13;
<p>For the default initial survivor ratio of 8,&#13;
each survivor space will occupy 10% of the young generation.</p>&#13;
&#13;
<p><a data-primary="-XX:MinSurvivorRatio=N" data-type="indexterm" id="idm45775553923720"/>The JVM may increase the survivor spaces&#13;
size to a maximum determined by the setting of the&#13;
<span class="keep-together"><code>-XX:MinSurvivorRatio=</code><em><code>N</code></em></span>&#13;
flag. That flag is used in this equation:</p>&#13;
&#13;
<pre data-type="programlisting">maximum_survivor_space_size = new_size / (min_survivor_ratio + 2)</pre>&#13;
&#13;
<p>By default, this value is 3, meaning the maximum size of a survivor space&#13;
will be 20% of the young generation. Note again that the value is a ratio,&#13;
so the minimum value of the ratio gives the maximum size of the survivor&#13;
space. The name is hence a little <span class="keep-together">counterintuitive</span>.</p>&#13;
&#13;
<p>To keep the survivor spaces at a fixed size, set the&#13;
<span class="keep-together"><code>SurvivorRatio</code></span>&#13;
to the desired&#13;
value and <a data-primary="-XX:+UseAdaptiveSizePolicy" data-type="indexterm" id="idm45775553917960"/>disable the&#13;
<span class="keep-together"><code>UseAdaptiveSizePolicy</code></span>&#13;
flag (though remember that&#13;
disabling adaptive sizing will apply to the old and new generations as well).</p>&#13;
&#13;
<p>The JVM determines whether to increase or decrease the size of the survivor&#13;
spaces (subject to the defined ratios) based on how full a survivor space is&#13;
after a GC. The survivor spaces will be resized so that they are, by default,&#13;
50% full after a GC. <a data-primary="-XX:TargetSurvivorRatio=N" data-type="indexterm" id="idm45775553915464"/>That value can be changed with the&#13;
<span class="keep-together"><code>-XX:TargetSurvivorRatio=</code><em><code>N</code></em></span>&#13;
flag.</p>&#13;
&#13;
<p>Finally, there is the question of how many GC cycles an object will remain&#13;
ping-ponging between the survivor spaces before being moved into the old&#13;
generation. That answer is determined by the tenuring threshold. The JVM&#13;
continually calculates what it thinks the best tenuring threshold is. <a data-primary="-XX:InitialTenuringThreshold=N" data-type="indexterm" id="idm45775553912648"/>The&#13;
threshold starts at the value specified by the&#13;
<span class="keep-together"><code>-XX:InitialTenuringThreshold=</code><em><code>N</code></em></span>&#13;
flag (the default is 7 for the throughput and G1 GC collectors, and 6 for&#13;
CMS). <a data-primary="-XX:MaxTenuringThreshold=N" data-type="indexterm" id="idm45775553910456"/>The JVM will ultimately determine a threshold between 1 and the value&#13;
specified by the&#13;
<span class="keep-together"><code>-XX:MaxTenuringThreshold=</code><em><code>N</code></em></span>&#13;
flag; for the throughput and G1 GC&#13;
collectors, the default maximum threshold is 15, and for CMS it is 6.</p>&#13;
<aside data-type="sidebar" epub:type="sidebar"><div class="sidebar" id="idm45775553907944">&#13;
<h5>Always and Never Tenure</h5>&#13;
<p>The tenuring threshold will always take on a range between 1 and&#13;
<span class="keep-together"><code>MaxTenuringThreshold</code></span>.&#13;
Even if the JVM is started with an initial tenuring&#13;
threshold equal to the maximum tenuring threshold, the JVM may decrease&#13;
that value.</p>&#13;
&#13;
<p>Two flags can circumvent that behavior at either extreme.&#13;
If you know that objects that survive a young collection will always be&#13;
around for a long time, <a data-primary="-XX:+AlwaysTenure" data-type="indexterm" id="idm45775553905032"/>you can specify&#13;
<span class="keep-together"><code>-XX:+AlwaysTenure</code></span>&#13;
(by default, <code>false</code>), which is essentially the same as setting the&#13;
<span class="keep-together"><code>MaxTenuringThreshold</code></span>&#13;
to 0. This is a rare situation; it means that objects will always be promoted&#13;
to the old generation rather than stored in a survivor space.</p>&#13;
&#13;
<p><a data-primary="-XX:+NeverTenure" data-type="indexterm" id="idm45775553901608"/>The second flag is&#13;
<span class="keep-together"><code>-XX:+NeverTenure</code></span> (also&#13;
<code>false</code> by default). This flag affects two things:&#13;
it behaves as if the initial and max tenuring thresholds are infinity,&#13;
and it prevents the JVM from adjusting that threshold down. In other words,&#13;
as long as there is room in the survivor space, no object will ever be&#13;
promoted to the old generation.</p>&#13;
</div></aside>&#13;
&#13;
<p>Given all that, which values might be tuned under which circumstances? It&#13;
is helpful to look at the tenuring statistics; these are not printed using&#13;
the GC logging commands we’ve used so far.</p>&#13;
&#13;
<p>In JDK 8, the tenuring distribution can be added to the&#13;
GC log by including the flag&#13;
<a data-primary="-XX:+PrintTenuringDistribution" data-type="indexterm" id="idm45775553897816"/><span class="keep-together"><code>-XX:+PrintTenuringDistribution</code></span>&#13;
(which is <code>false</code> by default). In JDK 11, it is added by including&#13;
<code>age*=debug</code> or <code>age*=trace</code> to the <code>Xlog</code> argument.</p>&#13;
&#13;
<p>The most important thing to look for is whether the survivor spaces are so&#13;
small that during a minor GC, objects are promoted directly from eden&#13;
into the old generation. The reason to avoid that is short-lived objects will end&#13;
up filling the old generation, causing full GCs to occur too frequently.</p>&#13;
&#13;
<p>In GC logs taken with the throughput collector, the only hint for&#13;
that condition is this line:</p>&#13;
&#13;
<pre data-type="programlisting">Desired survivor size 39059456 bytes, new threshold 1 (max 15)&#13;
	 [PSYoungGen: 657856K-&gt;35712K(660864K)]&#13;
	 1659879K-&gt;1073807K(2059008K), 0.0950040 secs]&#13;
	 [Times: user=0.32 sys=0.00, real=0.09 secs]</pre>&#13;
&#13;
<p>The JDK 11 log with <code>age*=debug</code> is similar; it will print the desired&#13;
survivor size during the collection.</p>&#13;
&#13;
<p>The desired size for a single survivor space here is 39 MB out&#13;
of a young generation of 660 MB:&#13;
the JVM has calculated that the two survivor spaces should take up about 11% of&#13;
the young generation. But the open question is whether that is large enough&#13;
to prevent overflow. This log provides no definitive answer, but&#13;
the fact that the JVM has adjusted the tenuring threshold to 1 indicates&#13;
that it has determined it is directly promoting most objects to the old&#13;
generation anyway, so it has minimized the tenuring threshold. This&#13;
application is probably promoting directly to the old generation without fully&#13;
using the survivor spaces.</p>&#13;
&#13;
<p>When G1 GC is used, more-informative output is obtained in the JDK 8 log:</p>&#13;
&#13;
<pre data-type="programlisting"> Desired survivor size 35782656 bytes, new threshold 2 (max 6)&#13;
 - age   1:   33291392 bytes,   33291392 total&#13;
 - age   2:    4098176 bytes,   37389568 total</pre>&#13;
&#13;
<p>In JDK 11, that information comes by including <code>age*=trace</code> in the logging&#13;
<span class="keep-together">configuration.</span></p>&#13;
&#13;
<p>The desired survivor space is similar to the previous example—35 MB—but the output&#13;
also shows the size of all the objects in the survivor space. With&#13;
37 MB of data to promote, the survivor space is indeed overflowing.</p>&#13;
&#13;
<p>Whether this situation can be improved depends on the&#13;
application. If the objects are going to live longer than a few more GC cycles,&#13;
they will eventually end up in the old generation anyway, so adjusting the&#13;
survivor spaces and tenuring threshold won’t really help. But if the objects&#13;
would go away after just a few more GC cycles, some performance can be gained by&#13;
arranging for the survivor spaces to be more efficient.</p>&#13;
&#13;
<p>If the size of the survivor spaces is increased (by decreasing the survivor&#13;
ratio), memory is taken away from the eden section of the&#13;
young generation. That is where the objects actually are allocated, meaning&#13;
fewer objects can be allocated before incurring a minor GC. So&#13;
that option is usually not recommended.</p>&#13;
&#13;
<p>Another possibility is to increase the size of the young generation. That&#13;
can be counterproductive in this situation: objects might be promoted less&#13;
often into the old generation, but since the old generation is smaller, the&#13;
application may do full GCs more often.</p>&#13;
&#13;
<p>If the size of the heap can be increased altogether, both the&#13;
young generation and the survivor spaces can get more memory, which will&#13;
be the best solution. A good process is to increase the&#13;
heap size (or at least the young generation size) and to decrease the&#13;
survivor ratio. That will increase the size of the survivor spaces more&#13;
than it will increase the size of eden. The application should end up&#13;
having roughly the same number of&#13;
young collections as before. It should have fewer full GCs, though, since fewer objects&#13;
will be promoted into the old generation (again, assuming that the objects&#13;
will no longer be live after a few more GC cycles).</p>&#13;
&#13;
<p>If the sizes of the survivor spaces have been adjusted so that they never&#13;
overflow, objects will be promoted to the old generation only after the&#13;
<span class="keep-together"><code>MaxTenuringThreshold</code></span>&#13;
is reached. That&#13;
value can be increased to keep the objects in the survivor spaces for a&#13;
few more young&#13;
GC cycles. But be aware that if the tenuring threshold is increased and&#13;
objects stay in the survivor space longer, there will be less room in the&#13;
survivor space during future young collections: it is then more likely that&#13;
the survivor&#13;
space will overflow and start promoting directly into the old generation again.</p>&#13;
<div data-type="tip"><h1>Quick Summary</h1>&#13;
<ul>&#13;
<li>&#13;
<p>Survivor spaces are designed to allow objects (particularly just-allocated objects) to remain in the young generation for a few GC cycles. This increases the probability the object will be freed before it is promoted to the old generation.</p>&#13;
</li>&#13;
<li>&#13;
<p>If the survivor spaces are too small, objects will promoted directly into the old generation, which in turn causes more old GC cycles.</p>&#13;
</li>&#13;
<li>&#13;
<p>The best way to handle that situation is to increase the size of the heap (or at least the young generation) and allow the JVM to handle the survivor spaces.</p>&#13;
</li>&#13;
<li>&#13;
<p>In rare cases, adjusting the tenuring threshold or survivor space sizes can prevent promotion of objects into the old <span class="keep-together">generation.</span><a data-startref="ix_ch06-asciidoc25" data-type="indexterm" id="idm45775553875688"/><a data-startref="ix_ch06-asciidoc24" data-type="indexterm" id="idm45775553874984"/><a data-startref="ix_ch06-asciidoc23" data-type="indexterm" id="idm45775553874312"/><a data-startref="ix_ch06-asciidoc22" data-type="indexterm" id="idm45775553873640"/></p>&#13;
</li>&#13;
</ul>&#13;
</div>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Allocating Large Objects" data-type="sect2"><div class="sect2" id="idm45775553943048">&#13;
<h2>Allocating Large Objects</h2>&#13;
&#13;
<p><a data-primary="allocation" data-secondary="large objects" data-type="indexterm" id="ix_ch06-asciidoc26"/><a data-primary="garbage collection algorithms" data-secondary="allocating large objects" data-type="indexterm" id="ix_ch06-asciidoc27"/><a data-primary="objects" data-secondary="allocating large objects" data-type="indexterm" id="ix_ch06-asciidoc28"/>This section describes in detail how the JVM allocates objects. This is&#13;
interesting background information, and it is important to applications&#13;
that frequently create a significant number of large objects. In this&#13;
context, <em>large</em> is a relative term;&#13;
it depends, as you’ll see, on the size of a particular kind of buffer within the&#13;
JVM.</p>&#13;
&#13;
<p>This buffer is known as a <em>thread-local allocation buffer</em> (TLAB).&#13;
TLAB sizing is a consideration for all GC algorithms, and G1 GC has an&#13;
additional consideration for very large objects (again, a relative term—but for a 2 GB heap, objects larger than 512 MB). The effects of very&#13;
large objects on G1 GC can be important—TLAB sizing (to overcome&#13;
somewhat large objects when using any collector) is fairly unusual,&#13;
but G1 GC region sizing (to overcome very large objects when using G1) is&#13;
more common.</p>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Thread-local allocation buffers" data-type="sect3"><div class="sect3" id="TLABS">&#13;
<h3>Thread-local allocation buffers</h3>&#13;
&#13;
<p><a data-primary="allocation" data-secondary="thread-local allocation buffers" data-type="indexterm" id="ix_ch06-asciidoc29"/><a data-primary="thread-local allocation buffers (TLABs)" data-type="indexterm" id="ix_ch06-asciidoc30"/><a data-primary="TLABs (thread-local allocation buffers)" data-type="indexterm" id="ix_ch06-asciidoc31"/><a data-type="xref" href="ch05.html#GC">Chapter 5</a> discusses how objects are allocated within eden; this allows for&#13;
faster allocation (particularly for objects that are quickly discarded).</p>&#13;
&#13;
<p>It turns out that one reason allocation in eden is so fast is that each thread&#13;
has a dedicated region where it allocates objects—a&#13;
thread-local allocation buffer, or TLAB. When objects are allocated directly in&#13;
a shared space such as eden, some synchronization is required to manage the&#13;
free-space pointers within that space. By setting up each thread with its own&#13;
dedicated allocation area,&#13;
the thread needn’t perform any synchronization when allocating&#13;
objects.<sup><a data-type="noteref" href="ch06.html#idm45775553858312" id="idm45775553858312-marker">3</a></sup></p>&#13;
&#13;
<p>Usually, the use of TLABs is transparent to developers and end users:&#13;
TLABs are enabled by default, and the JVM manages their sizes and how they are used. The&#13;
important thing to realize about TLABs is that they have a small size,&#13;
so large objects cannot be allocated within a TLAB. Large objects must be&#13;
allocated directly from the heap, which requires extra time because of the&#13;
synchronization.</p>&#13;
&#13;
<p>As a TLAB becomes full, objects of a certain size can no longer be allocated&#13;
in it. At this point, the JVM has a choice. One option is to “retire” the TLAB&#13;
and allocate a new one for the thread. Since the TLAB is just a section&#13;
within eden, the retired TLAB will be cleaned at the next young collection&#13;
and can be reused subsequently. Alternately, the JVM can allocate the&#13;
object directly on the heap and keep the existing TLAB (at least until the thread&#13;
allocates additional objects into the TLAB). Say a&#13;
TLAB is 100 KB, and 75 KB has already been allocated. If a new 30 KB allocation&#13;
is needed, the TLAB can be retired, which wastes 25 KB of eden space. Or the&#13;
30 KB object can be allocated directly from the heap, and the thread can hope&#13;
that the next object that is allocated will fit in the 25 KB of space that&#13;
is still free within the TLAB.</p>&#13;
&#13;
<p>Parameters can control this (as discussed later in this&#13;
section), but the key is that the size of the TLAB is crucial.&#13;
By default, the size of a TLAB is based on three factors: the number of&#13;
threads in the application, the size of eden, and the allocation rate of&#13;
threads.</p>&#13;
&#13;
<p>Hence, two types of applications may benefit from tuning the TLAB parameters:&#13;
applications that allocate a lot of large objects, and applications that&#13;
have a relatively large number of threads compared to the size of eden.&#13;
<a data-primary="-XX:-UseTLAB" data-type="indexterm" id="idm45775553853480"/>By default, TLABs are enabled; they can be disabled by specifying&#13;
<span class="keep-together"><code>-XX:-UseTLAB</code></span>,&#13;
although they give such a performance boost that disabling them is always a bad idea.</p>&#13;
&#13;
<p>Since the calculation of the TLAB size is based in part on the allocation&#13;
rate of the threads, it is impossible to definitively predict the best TLAB&#13;
size for an application. Instead, we can monitor the TLAB allocation to see if any&#13;
allocations occur outside the TLABs. If a significant number of allocations&#13;
occur outside of TLABs, we have two choices: reduce the size of the&#13;
object being allocated or adjust the TLAB sizing parameters.</p>&#13;
&#13;
<p><a data-primary="Java Flight Recorder (JFR)" data-secondary="TLAB allocation monitoring" data-type="indexterm" id="idm45775553850632"/>Monitoring the TLAB allocation is another case where Java Flight Recorder&#13;
is much more powerful than other tools. <a data-type="xref" href="#FigureJFRTLAB">Figure 6-9</a> shows a sample of&#13;
the TLAB allocation screen from a JFR recording.</p>&#13;
&#13;
<figure><div class="figure" id="FigureJFRTLAB">&#13;
<img alt="jp2e 0609" src="assets/jp2e_0609.png"/>&#13;
<h6><span class="label">Figure 6-9. </span>View of TLABs in Java Flight Recorder</h6>&#13;
</div></figure>&#13;
&#13;
<p>In the 5 seconds selected in this recording, 49 objects were allocated&#13;
outside TLABs; the maximum size of those objects was 48 bytes. Since the&#13;
minimum TLAB size is 1.35 MB, we know that these objects were allocated on&#13;
the heap only because the TLAB was full at the time of allocation: they&#13;
were not allocated directly in the heap because of their size. That is&#13;
typical immediately before a young GC occurs (as eden—and hence the TLABs&#13;
carved out of eden—becomes full).</p>&#13;
&#13;
<p>The total allocation in this&#13;
period is 1.59 KB; neither the number of allocations nor the size in this&#13;
example is a cause for concern. Some objects will always be allocated&#13;
outside TLABs, particularly as eden approaches a young collection. Compare&#13;
that example to <a data-type="xref" href="#FigureTLABBad">Figure 6-10</a>, which shows a great deal of allocation&#13;
occurring outside the TLABs.</p>&#13;
&#13;
<figure><div class="figure" id="FigureTLABBad">&#13;
<img alt="jp2e 0610" src="assets/jp2e_0610.png"/>&#13;
<h6><span class="label">Figure 6-10. </span>Excessive allocation occurring outside TLABs</h6>&#13;
</div></figure>&#13;
&#13;
<p>The total memory allocated inside TLABs during this recording is 952.96 MB,&#13;
and the total memory allocated for objects outside TLABs is 568.32 MB.&#13;
This is a case where either changing the application to use&#13;
smaller objects or tuning the JVM to allocate those objects in larger TLABs&#13;
can have a beneficial effect. Note that other tabs&#13;
can display the actual objects that were allocated out the TLAB; we&#13;
can even arrange to get the stacks from when those objects were allocated.&#13;
If there is a problem with TLAB allocation, JFR will pinpoint it quickly.</p>&#13;
&#13;
<p>Outside JFR, the best way to look at this is to monitor the TLAB allocation by adding the&#13;
<span class="keep-together"><code>-XX:+PrintTLAB</code></span>&#13;
flag to the command line in JDK 8 or including <code>tlab*=trace</code> in the log&#13;
configuration for JDK 11 (which provides the following information plus more).&#13;
Then, at every young collection, the GC log will contain two kinds of lines: a line&#13;
for each thread describing the TLAB usage for that thread, and a summary line&#13;
describing the overall TLAB usage of the JVM.</p>&#13;
&#13;
<p>The per thread line looks like this:</p>&#13;
&#13;
<pre data-type="programlisting">TLAB: gc thread: 0x00007f3c10b8f800 [id: 18519] desired_size: 221KB&#13;
    slow allocs: 8  refill waste: 3536B alloc: 0.01613    11058KB&#13;
    refills: 73 waste  0.1% gc: 10368B slow: 2112B fast: 0B</pre>&#13;
&#13;
<p>The <code>gc</code> in this output means that the line was printed during GC; the thread&#13;
itself is a regular application thread. The size of this thread’s TLAB is&#13;
221 KB. Since the last young collection, it allocated eight objects from the&#13;
heap (<code>slow allocs</code>); that was 1.6% (0.01613) of the total&#13;
amount of allocation done by this thread, and it amounted to 11,058 KB. 0.1% of&#13;
the TLAB being “wasted,” which comes from three things: 10,336 bytes were free&#13;
in the TLAB when the current GC cycle started; 2,112 bytes were free in other&#13;
(retired) TLABs, and 0 bytes were allocated via a special “fast” <span class="keep-together">allocator.</span></p>&#13;
&#13;
<p>After the TLAB data for each thread has been printed, the JVM provides a&#13;
line of summary data (this data is provided in JDK 11 by configuring the&#13;
log for <code>tlab*=debug</code>):</p>&#13;
&#13;
<pre data-type="programlisting">TLAB totals: thrds: 66  refills: 3234 max: 105&#13;
        slow allocs: 406 max 14 waste:  1.1% gc: 7519856B&#13;
        max: 211464B slow: 120016B max: 4808B fast: 0B max: 0B</pre>&#13;
&#13;
<p>In this case, 66 threads performed some sort of allocation since the last&#13;
young collection. Among those threads, they refilled their TLABs 3,234 times;&#13;
the most any particular thread refilled its TLAB was 105. Overall,&#13;
406 allocations were made to the heap (with a maximum of 14 done by one&#13;
thread), and 1.1% of the TLABs were wasted from the free space in retired&#13;
TLABs.</p>&#13;
&#13;
<p>In the per thread data, if threads show many allocations outside TLABs, consider resizing them.<a data-startref="ix_ch06-asciidoc31" data-type="indexterm" id="idm45775553831928"/><a data-startref="ix_ch06-asciidoc30" data-type="indexterm" id="idm45775553831224"/><a data-startref="ix_ch06-asciidoc29" data-type="indexterm" id="idm45775553830552"/></p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Sizing TLABs" data-type="sect3"><div class="sect3" id="idm45775553864568">&#13;
<h3>Sizing TLABs</h3>&#13;
&#13;
<p><a data-primary="allocation" data-secondary="sizing TLABs" data-type="indexterm" id="idm45775553828824"/>Applications that spend a lot of time allocating objects outside TLABs&#13;
will benefit from changes that can move the allocation to a TLAB. If&#13;
only a few specific object types are always allocated outside&#13;
a TLAB, programmatic changes are the best <span class="keep-together">solution.</span></p>&#13;
&#13;
<p>Otherwise—or if programmatic changes are not possible—you can attempt&#13;
to resize the TLABs to fit the application use case. Because the TLAB size&#13;
is based on the size of eden, adjusting the new size parameters will&#13;
automatically increase the size of the TLABs.</p>&#13;
&#13;
<p><a data-primary="-XX:TLABSize=N" data-type="indexterm" id="idm45775553825960"/>The size of the TLABs can be set explicitly using the flag&#13;
<code>-XX:TLABSize=<em><code>N</code></em></code>&#13;
(the default value, 0, means to use the dynamic calculation&#13;
previously described). That flag sets only the initial size of the TLABs; <a data-primary="-XX:-ResizeTLAB" data-type="indexterm" id="idm45775553823944"/>to&#13;
prevent resizing at each GC, add&#13;
<span class="keep-together"><code>-XX:-ResizeTLAB</code></span>&#13;
(the default for that&#13;
flag is <code>true</code>). This is the easiest (and, frankly,&#13;
the only useful) option for exploring the performance of adjusting the TLABs.</p>&#13;
&#13;
<p>When a new object does not fit in the current TLAB (but would fit within a&#13;
new, empty TLAB), the JVM has a decision to make: whether to&#13;
allocate the object in the heap or whether to retire the current TLAB&#13;
and allocate a new one.&#13;
That decision is based on several parameters. In the TLAB logging output,&#13;
the <code>refill waste</code> value gives the current threshold for that decision:&#13;
if the TLAB cannot accommodate a new object that is larger than that value,&#13;
the new object will be allocated in the heap. If the object in question&#13;
is smaller than that value, the TLAB will be retired.</p>&#13;
&#13;
<p>That value is dynamic, but it begins by default at 1% of the TLAB size—or, specifically, <a data-primary="-XX:TLABWasteTargetPercent=N" data-type="indexterm" id="idm45775553819624"/>at the value specified by&#13;
<span class="keep-together"><code>-XX:TLABWasteTargetPercent</code>=<em><code>N</code></em></span>.&#13;
<a data-primary="-XX:TLABWasteIncrement=N" data-type="indexterm" id="idm45775553817336"/>As each allocation <span class="keep-together">is done outside</span> the heap, that value is increased by the value of&#13;
<span class="keep-together"><code>-XX:TLABWasteIncrement=</code><em><code>N</code></em></span>&#13;
(the default is 4). This prevents a thread from reaching the threshold in the TLAB&#13;
and continually allocating objects in the heap: as the target percentage&#13;
increases, the chances of the TLAB being retired also increases. Adjusting the&#13;
<span class="keep-together"><code>TLABWasteTargetPercent</code></span>&#13;
value also adjusts the size of the TLAB, so&#13;
while it is possible to play with this value, its effect is not always&#13;
predictable.</p>&#13;
&#13;
<p><a data-primary="-XX:MinTLABSize=N" data-type="indexterm" id="idm45775553813176"/>Finally, when TLAB resizing is in effect, the minimum size of a TLAB can be specified with&#13;
<span class="keep-together"><code>-XX:MinTLABSize=</code><em><code>N</code></em></span>&#13;
(the default is 2 KB). The maximum size&#13;
of a TLAB is slightly less than 1 GB (the maximum space that can be occupied&#13;
by an array of integers, rounded down for object alignment purposes) and cannot be changed.</p>&#13;
<div data-type="tip"><h1>Quick Summary</h1>&#13;
<ul>&#13;
<li>&#13;
<p>Applications that allocate a lot of large objects may need to tune the TLABs (though often using smaller objects in the application is a better approach).</p>&#13;
</li>&#13;
</ul>&#13;
</div>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Humongous objects" data-type="sect3"><div class="sect3" id="idm45775553808184">&#13;
<h3>Humongous objects</h3>&#13;
&#13;
<p><a data-primary="allocation" data-secondary="humongous objects" data-type="indexterm" id="idm45775553806984"/><a data-primary="objects" data-secondary="humongous" data-type="indexterm" id="idm45775553806008"/>Objects <a data-primary="humongous objects" data-type="indexterm" id="ix_ch06-asciidoc32"/>that are allocated outside a TLAB are still allocated within&#13;
eden when possible. If the object cannot fit within eden, it must be&#13;
allocated directly in the old generation. That prevents the normal GC&#13;
life cycle for that object, so if it is short-lived, GC is negatively affected.&#13;
There’s little to do in that case other than change the application so that&#13;
it doesn’t need those short-lived huge objects.</p>&#13;
&#13;
<p>Humongous objects are treated differently in G1 GC, however: G1 will allocate&#13;
them in the old generation if they are bigger than a G1 region. So&#13;
applications that use a lot of humongous objects in G1 GC&#13;
may need special tuning to compensate for that.</p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="G1 GC region sizes" data-type="sect3"><div class="sect3" id="GCG1RegionSize">&#13;
<h3>G1 GC region sizes</h3>&#13;
&#13;
<p><a data-primary="G1 GC (garbage first garbage collector)" data-secondary="allocation of region sizes" data-type="indexterm" id="idm45775553800792"/><a data-primary="heap" data-secondary="allocation of region sizes" data-type="indexterm" id="idm45775553799880"/><a data-primary="regions, allocation of sizes" data-type="indexterm" id="idm45775553798920"/>G1 GC divides the heap into regions, each of which has a fixed size.&#13;
The region size is not dynamic; it is determined at startup based on&#13;
the minimum size of the heap (the value of <code>Xms</code>). The minimum region size is 1 MB.&#13;
If the minimum heap size is greater&#13;
than 2 GB, the size of the regions will be set according to this formula&#13;
(using log base 2):</p>&#13;
&#13;
<pre data-type="programlisting">region_size = 1 &lt;&lt; log(Initial Heap Size / 2048);</pre>&#13;
&#13;
<p>In short, the region size is the smallest power of 2 such that there are&#13;
close to 2,048 regions when the initial heap size is divided.&#13;
Some minimum and maximum constraints are in use here too; the&#13;
region size is always at least 1 MB and never more than 32 MB.&#13;
<a data-type="xref" href="#TableG1RegionSize">Table 6-3</a> sorts out all the possibilities.</p>&#13;
<table id="TableG1RegionSize">&#13;
<caption><span class="label">Table 6-3. </span>Default G1 region sizes</caption>&#13;
<thead>&#13;
<tr>&#13;
<th>Heap size</th>&#13;
<th>Default G1 region size</th>&#13;
</tr>&#13;
</thead>&#13;
<tbody>&#13;
<tr>&#13;
<td><p>Less than 4 GB</p></td>&#13;
<td><p>1 MB</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td><p>Between 4 GB and 8 GB</p></td>&#13;
<td><p>2 MB</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td><p>Between 8 GB and 16 GB</p></td>&#13;
<td><p>4 MB</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td><p>Between 16 GB and 32 GB</p></td>&#13;
<td><p>8 MB</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td><p>Between 32 GB and 64 GB</p></td>&#13;
<td><p>16 MB</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td><p>Larger than 64 GB</p></td>&#13;
<td><p>32 MB</p></td>&#13;
</tr>&#13;
</tbody>&#13;
</table>&#13;
&#13;
<p>The size of a G1 region can be set with the&#13;
<span class="keep-together"><code>-XX:G1HeapRegionSize=</code><em><code>N</code></em></span>&#13;
flag (the default is nominally 0, meaning to use the dynamic value&#13;
just described). The value given here should be a power of 2 (e.g., 1 MB&#13;
or 2 MB); otherwise, it is rounded down to the nearest power of 2.</p>&#13;
<aside data-type="sidebar" epub:type="sidebar"><div class="sidebar" id="idm45775553779944">&#13;
<h5>G1 Region Sizes and Large Heaps</h5>&#13;
<p>Normally, the G1 GC region size needs to be tuned only to handle humongous&#13;
object allocation, but it might need to be tuned in one other case.</p>&#13;
&#13;
<p>Consider an application that specifies a very large heap range; <span class="keep-together"><code>-Xms2G -Xmx32G</code></span>, for example. In that case, the&#13;
region size will be 1 MB. When the heap is fully expanded, there will be&#13;
32,000 G1 GC regions. That is a lot of separate regions to process; the G1 GC&#13;
algorithm is designed around the idea that the number of regions is closer&#13;
to 2,048. Increasing the size of the G1 GC region will make G1 GC&#13;
a little more efficient in this example; select a value so that there will&#13;
be close to 2,048 regions at the expected heap size.</p>&#13;
</div></aside>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="G1 GC allocation of humongous objects" data-type="sect3"><div class="sect3" id="HumongousObjects">&#13;
<h3>G1 GC allocation of humongous objects</h3>&#13;
&#13;
<p><a data-primary="G1 GC (garbage first garbage collector)" data-secondary="allocation of humongous objects" data-type="indexterm" id="idm45775553774792"/>If the G1 GC region size is 1 MB and a program allocates an array of 2 million bytes,&#13;
the array will not fit within a single G1 GC region.&#13;
But these humongous objects must be allocated in contiguous G1 GC regions.&#13;
If the G1 GC&#13;
region size is 1 MB, then to allocate a 3.1 MB array, G1 GC must find four&#13;
regions within the old generation in which to allocate the&#13;
array. (The rest of the last region will remain empty, wasting 0.9 MB of space.)&#13;
This defeats the way G1 GC normally performs compaction, which is to free&#13;
arbitrary regions based on how full they are.</p>&#13;
&#13;
<p>In fact, G1 GC defines a <em>humongous object</em> as one that is half of the region&#13;
size, so allocating an array of 512 KB (plus 1 byte) will, in this case, trigger&#13;
the humongous allocation we’re discussing.</p>&#13;
&#13;
<p>Because the humongous object is allocated directly in the old generation,&#13;
it cannot be freed during a young collection. So if the object is&#13;
short-lived, this also defeats the generational design of the collector.&#13;
The humongous object will be collected during the concurrent G1 GC cycle.&#13;
On the bright side, the humongous object can be freed quickly because it&#13;
is the only object in the regions it occupies. Humongous objects are&#13;
freed during the cleanup phase of the concurrent cycle (rather than during&#13;
a mixed GC).</p>&#13;
&#13;
<p>Increasing the size of a G1 GC region so that all objects the program will allocate can fit&#13;
within a single G1 GC region can make G1 GC more efficient. This means having a&#13;
G1 region size of twice the largest object’s size plus 1 byte.</p>&#13;
&#13;
<p>Humongous allocation used to be a far bigger problem in G1 GC because finding&#13;
the necessary regions to allocate the object would usually require a full GC&#13;
(and because such full GCs were not parallelized). Improvements in G1 GC in&#13;
JDK 8u60 (and in all JDK 11 builds) minimize this issue so it isn’t necessarily&#13;
the critical problem it sometimes used to be.<a data-startref="ix_ch06-asciidoc32" data-type="indexterm" id="idm45775553769656"/></p>&#13;
<div data-type="tip"><h1>Quick Summary</h1>&#13;
<ul>&#13;
<li>&#13;
<p>G1 regions are sized in powers of 2, starting at 1 MB.</p>&#13;
</li>&#13;
<li>&#13;
<p>Heaps that have a very different maximum size than initial size will have too many G1 regions; the G1 region size should be increased in that case.</p>&#13;
</li>&#13;
<li>&#13;
<p>Applications that allocate objects larger than half the size of a G1 region should increase the G1 region size so that the objects can fit within a G1 region. An application must allocate an object that is at least 512 KB for this to apply (since the smallest G1 region is 1 MB).<a data-startref="ix_ch06-asciidoc28" data-type="indexterm" id="idm45775553764872"/><a data-startref="ix_ch06-asciidoc27" data-type="indexterm" id="idm45775553764168"/><a data-startref="ix_ch06-asciidoc26" data-type="indexterm" id="idm45775553763496"/></p>&#13;
</li>&#13;
</ul>&#13;
</div>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="AggressiveHeap" data-type="sect2"><div class="sect2" id="AggressiveHeap">&#13;
<h2>AggressiveHeap</h2>&#13;
&#13;
<p><a data-primary="-XX:-AggressiveHeap" data-type="indexterm" id="ix_ch06-asciidoc33"/><a data-primary="tuning (garbage collection algorithms)" data-secondary="AggressiveHeap" data-type="indexterm" id="ix_ch06-asciidoc34"/>The&#13;
<span class="keep-together"><code>AggressiveHeap</code></span>&#13;
flag (by default, <code>false</code>), was introduced in an early version of Java as an attempt to make it easier to set a variety of command-line arguments—arguments that would be appropriate for a very large machine with a lot of memory running a single JVM. Although the flag has been carried forward since those versions and is still present, it is no longer recommended&#13;
(though it is not yet officially deprecated).</p>&#13;
&#13;
<p>The problem with this flag is that it hides the actual tunings it adopts, making it hard to figure out what the JVM is setting. Some of the values it sets are now set ergonomically based on better information about the machine running the JVM, so in some cases enabling this flag hurts performance. I have often seen command lines that include this flag and then later override values that it sets. (For the record, that works: later values in the command line currently override earlier values. That behavior is not guaranteed.)</p>&#13;
&#13;
<p><a data-type="xref" href="#TableAggressiveHeap">Table 6-4</a> lists all the tunings that are automatically set when the&#13;
<span class="keep-together"><code>AggressiveHeap</code></span>&#13;
flag is enabled.</p>&#13;
<table id="TableAggressiveHeap">&#13;
<caption><span class="label">Table 6-4. </span>Tunings enabled with <code>AggressiveHeap</code></caption>&#13;
<thead>&#13;
<tr>&#13;
<th>Flag</th>&#13;
<th>Value</th>&#13;
</tr>&#13;
</thead>&#13;
<tbody>&#13;
<tr>&#13;
<td><p><code>Xmx</code></p></td>&#13;
<td><p>The minimum of half of all memory, or all memory: 160 MB</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td><p><code>Xms</code></p></td>&#13;
<td><p>The same as <code>Xmx</code></p></td>&#13;
</tr>&#13;
<tr>&#13;
<td><p><code>NewSize</code></p></td>&#13;
<td><p>3/8 of whatever was set as <code>Xmx</code></p></td>&#13;
</tr>&#13;
<tr>&#13;
<td><p><code>UseLargePages</code></p></td>&#13;
<td><p><code>true</code></p></td>&#13;
</tr>&#13;
<tr>&#13;
<td><p><code>ResizeTLAB</code></p></td>&#13;
<td><p><code>false</code></p></td>&#13;
</tr>&#13;
<tr>&#13;
<td><p><code>TLABSize</code></p></td>&#13;
<td><p>256 KB</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td><p><code>UseParallelGC</code></p></td>&#13;
<td><p><code>true</code></p></td>&#13;
</tr>&#13;
<tr>&#13;
<td><p><code>ParallelGCThreads</code></p></td>&#13;
<td><p>Same as current default</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td><p><code>YoungPLABSize</code></p></td>&#13;
<td><p>256 KB (default is 4 KB)</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td><p><code>OldPLABSize</code></p></td>&#13;
<td><p>8 KB (default is 1 KB)</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td><p><code>CompilationPolicyChoice</code></p></td>&#13;
<td><p>0 (the current default)</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td><p><code>ThresholdTolerance</code></p></td>&#13;
<td><p>100  (default is 10)</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td><p><code>ScavengeBeforeFullGC</code></p></td>&#13;
<td><p><code>false</code> (default is <code>true</code>)</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td><p><code>BindGCTaskThreadsToCPUs</code></p></td>&#13;
<td><p><code>true</code> (default is <code>false</code>)</p></td>&#13;
</tr>&#13;
</tbody>&#13;
</table>&#13;
&#13;
<p>Those last six flags are obscure enough that I have not discussed them&#13;
elsewhere in this book. Briefly, they cover these areas:</p>&#13;
<dl>&#13;
<dt>PLAB sizing</dt>&#13;
<dd>&#13;
<p><a data-primary="PLABs (promotion-local allocation buffers)" data-type="indexterm" id="idm45775553720952"/><a data-primary="promotion-local allocation buffers (PLABs)" data-type="indexterm" id="idm45775553720216"/>  <em>PLABs</em> are <em>promotion-local allocation buffers</em>—these are per thread regions used during scavenging the generations in&#13;
a GC. Each thread can promote into a specific PLAB, negating the need for&#13;
synchronization (analogous to the way TLABs work).</p>&#13;
</dd>&#13;
<dt>Compilation policies</dt>&#13;
<dd>&#13;
<p>The JVM ships with alternate JIT compilation algorithms. The current default algorithm was, at one time, somewhat experimental, but this is now the recommended policy.</p>&#13;
</dd>&#13;
<dt>Disabling young GCs before full GCs</dt>&#13;
<dd>&#13;
<p>  <a data-primary="-XX:+ScavengeBeforeFullGC" data-type="indexterm" id="idm45775553715528"/>Setting&#13;
<span class="keep-together"><code>ScavengeBeforeFullGC</code></span> to <code>false</code>&#13;
means that when a full GC occurs, the JVM will not perform&#13;
a young GC before a full GC. That is usually a bad thing, since it means&#13;
that garbage objects in the young generation (which are eligible&#13;
for collection) can prevent objects in the old generation from being collected.&#13;
Clearly, there was a time when that setting made sense&#13;
(at least for certain benchmarks), but the general recommendation is&#13;
not to change that flag.</p>&#13;
</dd>&#13;
<dt>Binding GC threads to CPUs</dt>&#13;
<dd>&#13;
<p>  Setting the last flag in that list means that each parallel GC thread&#13;
is bound to a particular CPU (using OS-specific&#13;
calls). In limited circumstances—when the GC threads are the only thing&#13;
running on the machine, and heaps are very large—that makes sense. In the&#13;
general case, it is better if GC threads can run on any available CPU.</p>&#13;
</dd>&#13;
</dl>&#13;
&#13;
<p>As with all tunings, your mileage may vary, and if you carefully test the&#13;
<span class="keep-together"><code>AggressiveHeap</code></span>&#13;
flag and find that it improves performance, then by all means use it. Just be aware of what it is doing behind the scenes, and realize that whenever the JVM is upgraded, the relative benefit of this flag will need to be reevaluated.</p>&#13;
<div data-type="tip"><h1>Quick Summary</h1>&#13;
<ul>&#13;
<li>&#13;
<p>The&#13;
<span class="keep-together"><code>AggressiveHeap</code></span>&#13;
flag is a legacy attempt to set heap parameters to values that make sense for a single JVM running on a very large machine.</p>&#13;
</li>&#13;
<li>&#13;
<p>Values set by this flag are not adjusted as JVM technology improves, so its usefulness in the long run is dubious (even though it still is often used).<a data-startref="ix_ch06-asciidoc34" data-type="indexterm" id="idm45775553705496"/><a data-startref="ix_ch06-asciidoc33" data-type="indexterm" id="idm45775553704792"/></p>&#13;
</li>&#13;
</ul>&#13;
</div>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Full Control Over Heap Size" data-type="sect2"><div class="sect2" id="idm45775553761880">&#13;
<h2>Full Control Over Heap Size</h2>&#13;
&#13;
<p><a data-primary="heap" data-secondary="full control over heap size" data-type="indexterm" id="ix_ch06-asciidoc35"/><a data-primary="sizing the heap" data-type="indexterm" id="ix_ch06-asciidoc36"/><a data-primary="tuning (garbage collection algorithms)" data-secondary="full control over heap size" data-type="indexterm" id="ix_ch06-asciidoc37"/><a data-type="xref" href="ch05.html#GCHeapSize">“Sizing the Heap”</a> discussed the default values for the initial minimum and maximum&#13;
sizes of the heap. Those values are dependent on the amount of memory on the&#13;
machine as well as the JVM in use, and the data presented there had a number of corner cases.&#13;
If you’re curious about the full details of how the default heap size is calculated, this section explains. Those details include low-level tuning flags;&#13;
in certain circumstances, it might&#13;
be more convenient to adjust the way those calculations are done (rather than&#13;
simply setting the heap size). This might be the case if, for example,&#13;
you want to run multiple JVMs with a common (but adjusted) set of&#13;
ergonomic heap sizes. For the most part, the real goal of this section is&#13;
to complete the explanation of how those default values are chosen.</p>&#13;
&#13;
<p><a data-primary="-XX:MaxRAM=N" data-type="indexterm" id="idm45775553696840"/>The default sizes are based on the amount of memory on a machine, which&#13;
can be set with the&#13;
<span class="keep-together"><code>-XX:MaxRAM=</code><em><code>N</code></em></span>&#13;
flag. Normally, that value is calculated by the JVM by inspecting the&#13;
amount of memory on the machine. However, the JVM limits&#13;
<span class="keep-together"><code>MaxRAM</code></span>&#13;
to 4 GB for 32-bit Windows servers and to 128 GB for 64-bit JVMs.&#13;
The maximum heap size is one-quarter of&#13;
<span class="keep-together"><code>MaxRAM</code></span>.&#13;
This is why the default heap size can vary: if the physical&#13;
memory on a machine is less than&#13;
<span class="keep-together"><code>MaxRAM</code></span>,&#13;
the default heap size is&#13;
one-quarter of that. But even if hundreds of gigabytes of RAM are available, the most the JVM&#13;
will use by default is 32 GB: one-quarter of 128 GB.</p>&#13;
&#13;
<p>The default maximum heap calculation is actually this:</p>&#13;
&#13;
<pre data-type="programlisting">Default Xmx = MaxRAM / MaxRAMFraction</pre>&#13;
&#13;
<p><a data-primary="-XX:MaxRAMFraction=N" data-type="indexterm" id="idm45775553690280"/>Hence, the default maximum heap can also be set by adjusting the value of the&#13;
<span class="keep-together"><code>-XX:MaxRAMFraction=</code><em><code>N</code></em></span>&#13;
flag, which defaults to 4. <a data-primary="-XX:ErgoHeapSizeLimit=N" data-type="indexterm" id="idm45775553688024"/>Finally, just to keep things interesting, the&#13;
<span class="keep-together"><code>-XX:ErgoHeapSizeLimit=</code><em><code>N</code></em></span>&#13;
flag can also be set to a&#13;
maximum default value that the JVM should use. That value is 0 by default&#13;
(meaning to ignore it); otherwise, that limit is used if it is smaller than&#13;
<code>MaxRAM</code> / <code>MaxRAMFraction</code>.</p>&#13;
&#13;
<p>On the other hand, on a machine with a very small amount of&#13;
physical memory, the JVM wants to be sure it leaves enough memory for the&#13;
operating system. This is why the JVM will limit the maximum&#13;
heap to 96 MB or less on machines with only 192 MB of memory. <a data-primary="-XX:MinRAMFraction=N" data-type="indexterm" id="idm45775553684344"/>That&#13;
calculation is based on the value of the&#13;
<span class="keep-together"><code>-XX:MinRAMFraction=</code><em><code>N</code></em></span>&#13;
flag, which defaults to 2:</p>&#13;
&#13;
<pre data-type="programlisting">if ((96 MB * MinRAMFraction) &gt; Physical Memory) {&#13;
    Default Xmx = Physical Memory / MinRAMFraction;&#13;
}</pre>&#13;
&#13;
<p>The initial heap size choice is similar, though it has fewer complications.&#13;
The initial heap size value is determined like this:</p>&#13;
&#13;
<pre data-type="programlisting">Default Xms =  MaxRAM / InitialRAMFraction</pre>&#13;
&#13;
<p><a data-primary="-XX:InitialRAMFraction=N" data-type="indexterm" id="idm45775553679848"/>As can be concluded from the default minimum heap sizes,&#13;
the default value of the&#13;
<span class="keep-together"><code>InitialRAMFraction</code></span>&#13;
flag is 64. <a data-primary="-XX:NewSize=N" data-type="indexterm" id="idm45775553678040"/><a data-primary="-XX:OldSize=N" data-type="indexterm" id="idm45775553677336"/>The one caveat here occurs if that value is less than 5 MB—or,&#13;
strictly speaking, less than the values specified by&#13;
<span class="keep-together"><code>-XX:OldSize=</code><em><code>N</code></em></span>&#13;
(which defaults to 4 MB) plus&#13;
<span class="keep-together"><code>-XX:NewSize=</code><em><code>N</code></em></span>&#13;
(which defaults to 1 MB). In that case, the sum of the old and new sizes is used as&#13;
the initial heap size.</p>&#13;
<div data-type="tip"><h1>Quick Summary</h1>&#13;
<ul>&#13;
<li>&#13;
<p>The calculations for the default initial and maximum heap sizes are fairly straightforward on most machines.</p>&#13;
</li>&#13;
<li>&#13;
<p>Around the edges, these calculations can be quite involved<a data-startref="ix_ch06-asciidoc37" data-type="indexterm" id="idm45775553671048"/><a data-startref="ix_ch06-asciidoc36" data-type="indexterm" id="idm45775553670344"/><a data-startref="ix_ch06-asciidoc35" data-type="indexterm" id="idm45775553669672"/>.<a data-startref="ix_ch06-asciidoc21" data-type="indexterm" id="idm45775553668872"/><a data-startref="ix_ch06-asciidoc20" data-type="indexterm" id="idm45775553668168"/></p>&#13;
</li>&#13;
</ul>&#13;
</div>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Experimental GC Algorithms" data-type="sect1"><div class="sect1" id="idm45775553703144">&#13;
<h1>Experimental GC Algorithms</h1>&#13;
&#13;
<p><a data-primary="garbage collection algorithms" data-secondary="experimental" data-type="indexterm" id="ix_ch06-asciidoc38"/>In JDK 8 and JDK 11 production VMs with multiple CPUs, you’ll use either the G1 GC or throughput&#13;
collector, depending on your application requirements. On small machines, you’ll&#13;
use the serial collector if that is appropriate for your hardware. Those are the production-supported collectors.</p>&#13;
&#13;
<p>JDK 12 introduces new collectors. Although these collectors are not necessarily production-ready, we’ll take a peek into them for experimental purposes.</p>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Concurrent Compaction: ZGC and Shenandoah" data-type="sect2"><div class="sect2" id="ZGC">&#13;
<h2>Concurrent Compaction: ZGC and Shenandoah</h2>&#13;
&#13;
<p><a data-primary="garbage collection algorithms" data-secondary="Shenandoah" data-type="indexterm" id="ix_ch06-asciidoc39"/><a data-primary="garbage collection algorithms" data-secondary="ZGC" data-type="indexterm" id="ix_ch06-asciidoc40"/><a data-primary="Shenandoah garbage collector" data-type="indexterm" id="ix_ch06-asciidoc41"/><a data-primary="Z garbage collector (ZGC)" data-type="indexterm" id="ix_ch06-asciidoc42"/>Existing concurrent collectors are not fully concurrent. Neither G1 GC nor&#13;
CMS has concurrent collection of the young generation: freeing the young&#13;
generation requires all application threads to be stopped. And neither of&#13;
those collectors does concurrent compaction. In G1 GC, the old generation is&#13;
compacted as an effect of the mixed GC cycles: within a target region, objects&#13;
that are not freed are compacted into empty regions. In CMS, the old generation&#13;
is compacted when it becomes too fragmented to allow new allocations.&#13;
Collections of the young generation also compact that portion&#13;
of the heap by moving surviving objects into the survivor spaces or&#13;
the old <span class="keep-together">generation.</span></p>&#13;
&#13;
<p>During compaction, objects move their position in memory. This is the primary&#13;
reason the JVM stops all application threads during that&#13;
operation—the algorithms to update the memory references are much simpler if&#13;
the application threads are known to be stopped. So the pause times of&#13;
an application are dominated by the time spent moving objects and making sure&#13;
references to them are up-to-date.</p>&#13;
&#13;
<p>Two experimental collectors are designed to address this&#13;
problem. The first is the Z garbage collector, or ZGC; the second&#13;
is the Shenandoah garbage collector. ZGC first appeared in JDK 11; Shenandoah GC first&#13;
appeared in JDK 12 but has now been backported to JDK 8 and JDK 11.&#13;
JVM builds from AdoptOpenJDK (or that you compile yourself from source) contain&#13;
both collectors; builds that come from Oracle contain only ZGC.</p>&#13;
&#13;
<p><a data-primary="-XX:+UnlockExperimentalVMOptions" data-type="indexterm" id="idm45775553653784"/>To use these collectors, you must specify the&#13;
<span class="keep-together"><code>-XX:+UnlockExperimentalVMOptions</code></span>&#13;
flag (by default, it is <code>false</code>). <a data-primary="-XX:+UseShenandoahGC" data-type="indexterm" id="idm45775553651512"/><a data-primary="-XX:+UseZGC" data-type="indexterm" id="idm45775553650808"/>Then you specify either&#13;
<span class="keep-together"><code>-XX:+UseZGC</code></span>&#13;
or&#13;
<span class="keep-together"><code>-XX:+UseShenandoahGC</code></span>&#13;
in place of other GC algorithms. Like other GC algorithms, they have several&#13;
tunings knobs, but these are changing as the algorithms are in&#13;
development, so for now we’ll run with the default arguments. (And both&#13;
collectors have the goal of running with minimal tuning.)</p>&#13;
&#13;
<p>Although they take different approaches, both collectors&#13;
allow concurrent compaction of the heap, meaning that objects in the heap can&#13;
be moved without stopping all application threads. This has two main effects.</p>&#13;
&#13;
<p>First, the heap is no longer generational (i.e., there is&#13;
no longer a young and old generation; there is simply a single heap). The&#13;
idea behind the young generation is that it is faster to collect a small&#13;
portion of the heap rather than the entire heap, and many (ideally most) of&#13;
those objects will be garbage. So the young generation allows for shorter&#13;
pauses for much of the time. If the application threads don’t need to be paused during collection,&#13;
the need for the young generation disappears, and so these algorithms&#13;
no longer need to segment the heap into generations.</p>&#13;
&#13;
<p>The second effect is that the latency of operations performed by the&#13;
application threads can be expected to be reduced (at least in many cases).&#13;
Consider a REST call that normally executes in 200 milliseconds; if that&#13;
call is interrupted by a young collection in G1 GC and that collection takes&#13;
500 ms, then the user will see that the REST call took 700 ms.&#13;
Most of the calls, of course, won’t hit that situation, but some will,&#13;
and these outliers will affect the overall performance of the system.&#13;
Without the need to stop the application threads, the concurrent compacting&#13;
collectors will not see these same outliers.</p>&#13;
&#13;
<p>This simplifies the situation somewhat. Recall from the discussion of G1 GC that&#13;
the background threads that marked the free objects in the heap regions&#13;
sometimes had short pauses. So G1 GC has three types of pauses: relatively&#13;
long pauses for a full GC (well, ideally you’ve tuned well enough for that&#13;
not to happen), shorter pauses for a young GC collection (including a mixed&#13;
collection that frees and compacts some of the old generation), and very short&#13;
pauses for the marking threads.</p>&#13;
&#13;
<p>Both ZGC and Shenandoah have similar pauses that fall into that latter&#13;
category; for short periods of time, all the application&#13;
threads are stopped. The goal of these collectors is to keep those times very&#13;
short, on the order of 10 milliseconds.</p>&#13;
&#13;
<p>These collectors can also introduce latency on individual thread&#13;
operations. The details differ between the algorithms, but in a nutshell,&#13;
access to an object by an application thread is guarded by a barrier. If the&#13;
object happens to be in the process of being moved, the application&#13;
thread waits at the barrier until the move is complete. (For that matter,&#13;
if the application thread is accessing the object, the GC thread must&#13;
wait at the barrier until it can relocate the object.) In effect, this is a&#13;
form of locking on the object reference, but that term makes this process&#13;
seem far more heavyweight than it actually is. In general, this has a&#13;
small effect on the application throughput.</p>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Latency effects of concurrent compaction" data-type="sect3"><div class="sect3" id="idm45775553642616">&#13;
<h3>Latency effects of concurrent compaction</h3>&#13;
&#13;
<p><a data-primary="concurrent garbage collector" data-secondary="latency effects of concurrent compaction" data-type="indexterm" id="idm45775553641208"/><a data-primary="Shenandoah garbage collector" data-secondary="latency effects of concurrent compaction" data-type="indexterm" id="idm45775553640120"/>To get a feel for the overall impact of these algorithms, consider the data&#13;
in <a data-type="xref" href="#TableZGC">Table 6-5</a>. This table shows the response times from a REST server&#13;
handling a fixed load of 500 OPS using various collectors.&#13;
The operation here is very fast; it simply allocates and saves a fairly&#13;
large byte array (replacing an existing presaved array to keep memory&#13;
pressure constant).</p>&#13;
<table id="TableZGC">&#13;
<caption><span class="label">Table 6-5. </span>Latency effects of concurrent compacting collectors</caption>&#13;
<thead>&#13;
<tr>&#13;
<th>Collector</th>&#13;
<th>Average time</th>&#13;
<th>90th% time</th>&#13;
<th>99th% time</th>&#13;
<th>Max time</th>&#13;
</tr>&#13;
</thead>&#13;
<tbody>&#13;
<tr>&#13;
<td><p>Throughput GC</p></td>&#13;
<td><p>13 ms</p></td>&#13;
<td><p>60 ms</p></td>&#13;
<td><p>160 ms</p></td>&#13;
<td><p>265 ms</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td><p>G1 GC</p></td>&#13;
<td><p>5 ms</p></td>&#13;
<td><p>10 ms</p></td>&#13;
<td><p>35 ms</p></td>&#13;
<td><p>87 ms</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td><p>ZGC</p></td>&#13;
<td><p>1 ms</p></td>&#13;
<td><p>5 ms</p></td>&#13;
<td><p>5 ms</p></td>&#13;
<td><p>20 ms</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td><p>Shenandoah GC</p></td>&#13;
<td><p>1 ms</p></td>&#13;
<td><p>5 ms</p></td>&#13;
<td><p>5 ms</p></td>&#13;
<td><p>22 ms</p></td>&#13;
</tr>&#13;
</tbody>&#13;
</table>&#13;
&#13;
<p>These results are just what we’d expect from the various collectors. The&#13;
full GC times of the throughput collector cause a maximum response time of 265&#13;
milliseconds and lots of outliers with a response time of more than 50&#13;
milliseconds. With G1 GC, those full GC times have gone away, but&#13;
shorter times still remain for the young collections, yielding a maximum time&#13;
of 87 ms and outliers of Tabout 10 ms. And with the concurrent&#13;
collectors, those young collection pauses have disappeared so that the maximum&#13;
times are now around 20 ms and the outliers only 5 ms.</p>&#13;
&#13;
<p>One caveat: garbage collection pauses traditionally have been the&#13;
largest contributor to latency outliers like those we’re discussing here. But&#13;
other causes exist: temporary network congestion between server and client,&#13;
OS scheduling delays, and so on. So while a lot of the outliers in the&#13;
previous two cases are because of those short pauses of a few milliseconds&#13;
that the concurrent collectors still have, we’re now entering the realm where&#13;
those other things also have a large impact on the total latency.</p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Throughput effects of concurrent compacting collectors" data-type="sect3"><div class="sect3" id="idm45775553617368">&#13;
<h3>Throughput effects of concurrent compacting collectors</h3>&#13;
&#13;
<p><a data-primary="concurrent garbage collector" data-secondary="throughput effects of concurrent compacting collectors" data-type="indexterm" id="idm45775553616136"/><a data-primary="Shenandoah garbage collector" data-secondary="throughput effects of concurrent compacting collectors" data-type="indexterm" id="idm45775553615096"/>The throughput effects of these collectors is harder to categorize. Like&#13;
G1 GC, these collectors rely on background threads to scan and process the&#13;
heap. So if sufficient CPU cycles are not available for these threads, the&#13;
collectors will experience the same sort of concurrent failure we’ve seen&#13;
before and end up doing a full GC. The concurrent compacting collectors will&#13;
typically use even more background processing than the G1 GC background&#13;
threads.</p>&#13;
&#13;
<p>On the other hand, if sufficient CPU is available for those background threads,&#13;
throughput when using these collectors will be higher than the&#13;
throughput of G1 GC or the throughput collector. This again is in line with&#13;
what you saw in <a data-type="xref" href="ch05.html#GC">Chapter 5</a>. Examples from that chapter showed that G1 GC can have&#13;
higher throughput than the throughput collector when it offloads GC processing&#13;
to background threads. The concurrent compacting collectors have that same&#13;
advantage over the throughput collector, and a similar (but smaller) advantage&#13;
over G1 GC.<a data-startref="ix_ch06-asciidoc42" data-type="indexterm" id="idm45775553611704"/><a data-startref="ix_ch06-asciidoc41" data-type="indexterm" id="idm45775553611032"/><a data-startref="ix_ch06-asciidoc40" data-type="indexterm" id="idm45775553610360"/><a data-startref="ix_ch06-asciidoc39" data-type="indexterm" id="idm45775553609688"/></p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="No Collection: Epsilon GC" data-type="sect2"><div class="sect2" id="EpsilonGC">&#13;
<h2>No Collection: Epsilon GC</h2>&#13;
&#13;
<p><a data-primary="Epsilon garbage collector" data-type="indexterm" id="idm45775553607080"/><a data-primary="garbage collection algorithms" data-secondary="Epsilon GC" data-type="indexterm" id="idm45775553606312"/>JDK 11 also contains a collector that does nothing: the <em>epsilon collector</em>.&#13;
When you use this collector, objects are never freed from the heap, and when&#13;
the heap fills up, you will get an out-of-memory error.</p>&#13;
&#13;
<p>Traditional programs will not be able to use this collector, of course. It is&#13;
really designed for internal JDK testing but can conceivably be useful&#13;
in two situations:</p>&#13;
&#13;
<ul>&#13;
<li>&#13;
<p>Very short-lived programs</p>&#13;
</li>&#13;
<li>&#13;
<p>Programs carefully written to reuse memory and never perform new allocations</p>&#13;
</li>&#13;
</ul>&#13;
&#13;
<p>That second category is useful in some embedded environments with limited&#13;
memory. That sort of programming is specialized; we won’t consider it&#13;
here. But the first case holds interesting possibilities.</p>&#13;
&#13;
<p>Consider the case of a program that allocates an array list of 4,096 elements,&#13;
each of which is a 0.5 MB byte array. The time&#13;
to run that program with various collectors is shown in <a data-type="xref" href="#TableEpsilonTime">Table 6-6</a>.&#13;
Default GC tunings are used in this example.</p>&#13;
<table id="TableEpsilonTime">&#13;
<caption><span class="label">Table 6-6. </span>Performance metrics of a small allocation-based program</caption>&#13;
<thead>&#13;
<tr>&#13;
<th>Collector</th>&#13;
<th>Time</th>&#13;
<th>Heap required</th>&#13;
</tr>&#13;
</thead>&#13;
<tbody>&#13;
<tr>&#13;
<td><p>Throughput GC</p></td>&#13;
<td><p>2.3 s</p></td>&#13;
<td><p>3,072 MB</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td><p>G1 GC</p></td>&#13;
<td><p>3.24 s</p></td>&#13;
<td><p>4,096 MB</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td><p>Epsilon</p></td>&#13;
<td><p>1.6 s</p></td>&#13;
<td><p>2,052 MB</p></td>&#13;
</tr>&#13;
</tbody>&#13;
</table>&#13;
&#13;
<p>Disabling garbage collection is a significant advantage in this case, yielding&#13;
a 30% improvement. And the other collectors require significant memory&#13;
overhead: like the other experimental collectors we’ve seen, the epsilon&#13;
collector is not generational (because the objects cannot be freed, there’s no&#13;
need to set up a separate space to be able to free them quickly). <a data-primary="-Xmx" data-type="indexterm" id="idm45775553588728"/>So for this&#13;
test that produces an object of about 2 GB, the total heap required for the&#13;
epsilon collector is just over that; we can run that case with <code>-Xmx2052m</code>.&#13;
The throughput collector needs one-third more memory to hold its young generation,&#13;
while G1 GC needs even more memory to set up all its regions.</p>&#13;
&#13;
<p><a data-primary="-XX:+UnlockExperimentalVMOptions" data-type="indexterm" id="idm45775553586904"/><a data-primary="-XX:+UseEpsilonGC" data-type="indexterm" id="idm45775553586136"/>To use this collector, you again specify the&#13;
<span class="keep-together"><code>-XX:+UnlockExperimentalVMOptions</code></span>&#13;
flag with&#13;
<span class="keep-together"><code>-XX:+UseEpsilonGC</code>.</span></p>&#13;
&#13;
<p>Running with this collector is risky unless you are certain that the program&#13;
will never need more memory than you provide it. But in those cases, it can&#13;
give a nice performance boost.<a data-startref="ix_ch06-asciidoc38" data-type="indexterm" id="idm45775553583032"/></p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Summary" data-type="sect1"><div class="sect1" id="idm45775553608296">&#13;
<h1>Summary</h1>&#13;
&#13;
<p>The past two chapters have spent a lot of time delving into the  details of&#13;
how GC (and its various algorithms) work. If GC is taking longer&#13;
than you’d like, knowing how all of that works should aid you in taking&#13;
the necessary steps to improve things.</p>&#13;
&#13;
<p>Now that you understand all the details, let’s take a step back to determine an approach to choosing and tuning&#13;
a garbage collector. <a data-primary="garbage collection algorithms" data-secondary="questions to ask when choosing/tuning" data-type="indexterm" id="idm45775553580200"/>Here’s a quick set of questions to ask yourself to&#13;
help put everything in context:</p>&#13;
<dl>&#13;
<dt>Can your application tolerate some full GC pauses?</dt>&#13;
<dd>&#13;
<p>If not, G1 GC is the algorithm of choice. Even if you can tolerate&#13;
some full pauses, G1 GC will often be better than parallel GC unless your&#13;
application is CPU bound.</p>&#13;
</dd>&#13;
<dt>Are you getting the performance you need with the default settings?</dt>&#13;
<dd>&#13;
<p>Try the default settings first. As GC technology matures, the&#13;
ergonomic (automatic) tuning gets better all the time. If you’re not getting the performance you need, make sure that GC is your&#13;
problem. Look at the GC logs and see how much time you’re spending in GC&#13;
and how frequently the long pauses occur. For a busy application, if you’re&#13;
spending 3% or less time in GC, you’re not going to get a lot out of&#13;
tuning (though you can always try to reduce outliers if that is your&#13;
goal).</p>&#13;
</dd>&#13;
<dt>Are the pause times that you have somewhat close to your goal?</dt>&#13;
<dd>&#13;
<p>If they are, adjusting the maximum pause time may be all you need.&#13;
If they aren’t, you need to do something else. If the pause times&#13;
are too large but your throughput is OK, you can reduce the size&#13;
of the young generation (and for full GC pauses, the old generation);&#13;
you’ll get more, but shorter, pauses.</p>&#13;
</dd>&#13;
<dt>Is throughput lagging even though GC pause times are short?</dt>&#13;
<dd>&#13;
<p>You need to increase the size of the heap (or at least the&#13;
young generation). More isn’t always better: bigger heaps lead to longer pause times.&#13;
Even with a concurrent collector, a bigger heap means a bigger young&#13;
generation by default, so you’ll see longer pause times for young&#13;
collections. But if you can, increase the heap size, or at least the&#13;
relative sizes of the generations.</p>&#13;
</dd>&#13;
<dt>Are you using a concurrent collector and seeing full GCs due to concurrent-mode <span class="keep-together">failures</span>?</dt>&#13;
<dd>&#13;
<p>If you have available CPU, try increasing the number of concurrent GC&#13;
threads or starting the background sweep sooner by adjusting <code>InitiatingHeapOccupancyPercent</code>. For G1, the concurrent cycle won’t start if there&#13;
are pending mixed GCs; try reducing the mixed GC count target.</p>&#13;
</dd>&#13;
<dt>Are you using a concurrent collector and seeing full GCs due to promotion failures?</dt>&#13;
<dd>&#13;
<p>In G1 GC, an&#13;
evacuation failure (to-space overflow) indicates that the heap is fragmented,&#13;
but that can usually be solved if G1 GC performs its&#13;
background sweeping sooner and mixed GCs faster. Try increasing the number&#13;
of concurrent G1 threads, adjusting <code>InitiatingHeapOccupancyPercent</code>,&#13;
or reducing the mixed GC count target.<a data-startref="ix_ch06-asciidoc0" data-type="indexterm" id="idm45775553567160"/></p>&#13;
</dd>&#13;
</dl>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<div data-type="footnotes"><p data-type="footnote" id="idm45775554356120"><sup><a href="ch06.html#idm45775554356120-marker">1</a></sup> Actually, 227,893 KB is only 222 MB. For ease of discussion, I’ll truncate the KBs by 1,000 in this chapter; pretend I am a disk manufacturer.</p><p data-type="footnote" id="idm45775554022120"><sup><a href="ch06.html#idm45775554022120-marker">2</a></sup> Similar work could have been done to make CMS full GCs run with parallel threads, but G1 GC work was prioritized.</p><p data-type="footnote" id="idm45775553858312"><sup><a href="ch06.html#idm45775553858312-marker">3</a></sup> This is a variation of the way thread-local variables can prevent lock contention (see <a data-type="xref" href="ch09.html#ThreadPerformance">Chapter 9</a>).</p></div></div></section></body></html>