<html><head></head><body>
<div id="sbo-rt-content" class="calibre2"><section data-type="chapter" type="chapter" data-pdf-bookmark="Chapter 4. Charting and Alerting" class="calibre3"><div class="preface" id="ch_charting_alerting">
<h1 class="calibre17" id="8IL24-2d714b853a094e9a910510217e0e3d73"><span class="keep-together">Chapter 4. </span>Charting and Alerting</h1>


<p class="author1"><a data-type="indexterm" data-primary="charting and alerting" id="ix_ch04-asciidoc0" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre"/>Monitoring doesn’t have to be an all-in proposition. If you only add a measure of error ratio for end-user interactions where you have no monitoring (or only resource monitoring like CPU/memory utilization), you’ve already taken a huge step forward in terms of understanding your software. After all, CPU and memory can look good but a user-facing API is failing 5% of all requests, and failure rate is a much easier idea to communicate between engineering organizations and their business partners.</p>

<p class="author1">While Chapters <a data-type="xref" data-xrefstyle="select:labelnumber" href="part0006_split_000.html#5N3C4-2d714b853a094e9a910510217e0e3d73" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre">2</a> and <a data-type="xref" data-xrefstyle="select:labelnumber" href="part0008_split_000.html#7K4G4-2d714b853a094e9a910510217e0e3d73" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre">3</a> covered different forms of monitoring instrumentation, here we present the ways we can <em class="calibre12">use</em> that data effectively to promote action via alerting and visualization. This chapter covers three main topics.</p>

<p class="author1">First, we should think about what makes for a good visualization of an SLI. We’re only going to show charts from the commonly used <a href="https://grafana.com" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre">Grafana</a> charting and alerting tool, because it is a freely available open source tool that has datasource plug-ins for many different monitoring systems (so learning a little Grafana is a largely transferable skill from one monitoring system to another). Many of the same suggestions apply to charting solutions integrated into vendor products.</p>

<p class="author1">Next, we’ll discuss specifics about the measurements that generate the most value and how to visualize and alert on them. Treat these as a checklist of SLIs that you can add incrementally. Incrementalism may even be preferable to implementing them all at once, because by adding an indicator at a time, you can really study and understand what it means in the context of your business and shape it in little ways to generate the most value to you. If I walked into the network operation center of an insurance company, I’d be much more relieved to see only indicators on the error ratio of policy rating and submissions than I would be to see a hundred low-level signals and no measure of business performance.</p>

<p class="author1">Taking an incremental approach to introducing alerts is also an important trust-building exercise. Introducing too many alerts too quickly risks overwhelming engineers and leading to “alert fatigue.” You want engineers to feel comfortable subscribing to more alerts, not mute them! This also gives you a bit of time, if you are not already accustomed, to working through the on-call process, and training engineers how to respond to one alert condition at a time helps the team build a reservoir of knowledge about how to address anomalies.</p>

<p class="author1">So the focus in this chapter will be providing advice about those SLIs that are as close to business performance (e.g., API failure rate and the response times users see) as possible without being tied to any particular business. To the extent we cover things like heap utilization or file descriptors, they will be a select group of indicators that are most likely to be the direct cause of business performance degradation.</p>

<p class="author1">Recreating NASA mission control (<a data-type="xref" href="part0009_split_000.html#nasa_mission_control" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre">Figure 4-1</a>) should not be the end result of a well-monitored distributed system. While arraying screens across a wall and filling them with dashboards may look visually impressive, screens are not actions. They require somebody to be looking at them to respond to a visual indicator of a problem. I think this makes sense when you’re monitoring a single instance of a rocket with exorbitant costs and human lives on the line. Your API requests, of course, don’t have the same per-occurrence importance.</p>

<figure class="calibre32"><div id="nasa_mission_control" class="figure">
<img src="../images/00065.png" alt="srej 0401" class="calibre101"/>
<h6 class="calibre34"><span class="keep-together">Figure 4-1. </span>This is not a good role model!</h6>
</div></figure>

<p class="author1">Almost every metrics collector will collect more data than you will find useful at any given time. While every metric may have usefulness in some circumstance, plotting every one is not helpful. However, several indicators (e.g., max latency, error ratio, resource utilization) are strong reliability signals for practically every Java microservice (with some tweaks to the alert thresholds). These are the ones we’ll focus on.</p>

<p class="author1">Lastly, the market is eager to apply artificial intelligence methods to monitoring data to automate the delivery of insights into your systems without requiring much understanding of alert criteria and key performance indicators. In this chapter, we’ll survey several traditional statistical methods and artificial intelligence methods in the context of application monitoring. You should have a solid understanding of the strength and weakness of each method so that you can cut through the marketing hype and apply the best methods for your needs.</p>

<p class="author1">Before going any further, it’s worth considering the breadth of variation in monitoring systems on the market and the impact that has on your decisions for how to instrument code and get data to these systems.</p>






</div></section></div>



  

<div id="sbo-rt-content" class="calibre2">
<section data-type="chapter" type="chapter" data-pdf-bookmark="Chapter 4. Charting and Alerting" class="calibre3">
<div class="preface" id="ch_charting_alerting">
<section data-type="sect1" data-pdf-bookmark="Differences in Monitoring Systems" class="calibre3"><div class="preface" id="idm45139267964312">
<h1 class="calibre19" id="8IL2S-2d714b853a094e9a910510217e0e3d73">Differences in Monitoring Systems</h1>

<p class="author1"><a data-type="indexterm" data-primary="charting and alerting" data-secondary="differences in monitoring systems" id="ix_ch04-asciidoc1" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre"/><a data-type="indexterm" data-primary="monitoring" data-secondary="differences in monitoring systems" id="ix_ch04-asciidoc2" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre"/>The point of discussing differences in monitoring systems here is that we are about to see specifics about how to chart and alert with Prometheus. A product like Datadog has a very different query system than Prometheus. Both are useful. More products are going to emerge in the future with capabilities we aren’t yet imagining. Ideally, we want our monitoring instrumentation (what we will put in our applications) to be portable across these monitoring systems with no changes in application code required (other than a new binary dependency and some registry-wide <span class="keep-together">configuration).</span></p>

<p class="author1"><a data-type="indexterm" data-primary="distributed tracing" data-secondary="metrics systems versus" id="idm45139267958616" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre"/><a data-type="indexterm" data-primary="metrics systems, distributed tracing versus" id="idm45139267957640" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre"/>There tends to be quite a bit more consistency in the way distributed tracing backend systems receive data than the way metrics systems receive data. Distributed tracing instrumentation libraries may have different propagation formats, requiring a degree of uniformity in the selection of an instrumentation library across the stack, but the data itself is fundamentally similar from backend to backend. This intuitively makes sense because of what the data is: distributed tracing really consists of per-event timing information (contextually stitched together by trace ID).</p>

<p class="author1">Metrics systems could potentially represent not only aggregated timing information, but also gauges, counters, histogram data, percentiles, etc. They don’t agree on the way in which this data should be aggregated. They don’t have the same capabilities for performing further aggregation or calculation at query time. There is an inverse relationship between the number of time series a metrics instrumentation library must publish and the query capabilities of a particular metrics backend, as shown in <a data-type="xref" href="part0009_split_001.html#query_capabilities_vs_time_series" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre">Figure 4-2</a>.</p>

<figure class="calibre32"><div id="query_capabilities_vs_time_series" class="figure">
<img src="../images/00044.png" alt="srej 0402" class="calibre102"/>
<h6 class="calibre34"><span class="keep-together">Figure 4-2. </span>Inverse relationship between published time series and query capabilities</h6>
</div></figure>

<p class="author1">So, for example, when Dropwizard Metrics was initially developed, the popular monitoring system was Graphite, which didn’t have rate-calculating functions available in modern monitoring systems like Prometheus. As a result, when publishing a counter, Dropwizard had to publish cumulative count, 1-minute rate, 5-minute rate, 15-minute rate, etc. And because this was inefficient if you never needed to look at a rate, the instrumentation library itself distinguished between <code class="calibre24">@Counted</code> and <code class="calibre24">@Metered</code>. The instrumentation API was designed with the capabilities of its contemporary monitoring systems in mind.</p>

<p class="author1">Fast forward to today, and a metrics instrumentation library intending to publish to multiple destination metrics systems needs to be aware of these subtleties. A Micrometer <code class="calibre24">Counter</code> is going to be presented to Graphite in terms of a cumulative count and several moving rates, but to Prometheus only as a cumulative count, because these rates can be computed at query time with a PromQL <code class="calibre24">rate</code> function.</p>

<p class="author1">It’s important to the design of the API of any instrumentation library today to not simply lift all concepts found in earlier implementations forward, but to consider the historical context behind why these constructs existed at that time. <a data-type="xref" href="part0009_split_001.html#metrics_instrumentation_capabilities" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre">Figure 4-3</a> shows where Micrometer has overlap with Dropwizard and Prometheus simple client predecessors, and where it has extended capabilities beyond those of its predecessors. Significantly, some concepts have been left behind, recognizing the evolution in the monitoring space since. In some cases, this difference is subtle. Micrometer incorporates histograms as a feature of a plain <code class="calibre24">Timer</code> (or <code class="calibre24">DistributionSummary</code>). It is often unclear at the point of instrumentation deep in a library where an operation is being timed whether the application incorporating this functionality views this operation as critical enough to warrant the extra expense of shipping histogram data. (So the decision should be left up to the downstream application author rather than the library author.)</p>

<figure class="calibre32"><div id="metrics_instrumentation_capabilities" class="figure">
<img src="../images/00073.png" alt="srej 0403" class="calibre103"/>
<h6 class="calibre34"><span class="keep-together">Figure 4-3. </span>Metrics instrumentation capability overlap</h6>
</div></figure>

<p class="author1">Similarly, in the Dropwizard Metrics era, monitoring systems didn’t include query functionality that helped to reason about timing data (no percentile approximations, no latency heatmaps, etc.). So this concept of “don’t gauge something you can count, don’t count something you can time” wasn’t applicable yet. It wasn’t uncommon to add <code class="calibre24">@Counted</code> to a method, where now <code class="calibre24">@Counted</code> is almost never the right choice for a method (which is inherently timeable, and timers always publish with a count as well).</p>

<p class="author1"><a data-type="indexterm" data-primary="OpenTelemetry" id="ix_ch04-asciidoc3" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre"/>While at the time of this writing OpenTelemetry’s metrics API is still in beta, it hasn’t changed substantially in the last couple years, and it appears the meter primitives won’t do a sufficient job to build usable abstractions for timing and counting. <a data-type="xref" href="part0009_split_001.html#micrometer_timer_vs_ot" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre">Example 4-1</a> shows a Micrometer <code class="calibre24">Timer</code> with varying tags, depending on the outcome of an operation (this is the most verbose a timer gets in Micrometer).</p>
<div id="micrometer_timer_vs_ot" data-type="example" class="calibre61">
<h5 class="calibre62"><span class="keep-together">Example 4-1. </span>A Micrometer timer with a variable outcome tag</h5>

<pre data-type="programlisting" data-code-language="java" class="calibre63"><code class="k">public</code> <code class="k">class</code> <code class="nc">MyService</code> <code class="o">{</code>
  <code class="n">MeterRegistry</code> <code class="n">registry</code><code class="o">;</code>

  <code class="k">public</code> <code class="kt">void</code> <code class="nf">call</code><code class="o">()</code> <code class="o">{</code>
    <code class="k">try</code> <code class="o">(</code><code class="n">Timer</code><code class="o">.</code><code class="na">ResourceSample</code> <code class="n">t</code> <code class="o">=</code> <code class="n">Timer</code><code class="o">.</code><code class="na">resource</code><code class="o">(</code><code class="n">registry</code><code class="o">,</code> <code class="s">"calls"</code><code class="o">)</code>
        <code class="o">.</code><code class="na">description</code><code class="o">(</code><code class="s">"calls to something"</code><code class="o">)</code>
        <code class="o">.</code><code class="na">publishPercentileHistogram</code><code class="o">()</code>
        <code class="o">.</code><code class="na">serviceLevelObjectives</code><code class="o">(</code><code class="n">Duration</code><code class="o">.</code><code class="na">ofSeconds</code><code class="o">(</code><code class="mi">1</code><code class="o">))</code>
        <code class="o">.</code><code class="na">tags</code><code class="o">(</code><code class="s">"service"</code><code class="o">,</code> <code class="s">"hi"</code><code class="o">))</code> <code class="o">{</code>
      <code class="k">try</code> <code class="o">{</code>
        <code class="c">// Do something</code>
        <code class="n">t</code><code class="o">.</code><code class="na">tag</code><code class="o">(</code><code class="s">"outcome"</code><code class="o">,</code> <code class="s">"success"</code><code class="o">);</code>
      <code class="o">}</code> <code class="k">catch</code> <code class="o">(</code><code class="n">Exception</code> <code class="n">e</code><code class="o">)</code> <code class="o">{</code>
        <code class="n">t</code><code class="o">.</code><code class="na">tags</code><code class="o">(</code><code class="s">"outcome"</code><code class="o">,</code> <code class="s">"error"</code><code class="o">,</code> <code class="s">"exception"</code><code class="o">,</code> <code class="n">e</code><code class="o">.</code><code class="na">getClass</code><code class="o">().</code><code class="na">getName</code><code class="o">());</code>
      <code class="o">}</code>
    <code class="o">}</code>
  <code class="o">}</code>
<code class="o">}</code></pre></div>

<p class="author1">Even trying to get close to this with the OpenTelemetry metrics API right now is difficult, as shown in <a data-type="xref" href="part0009_split_001.html#8IL70-2d714b853a094e9a910510217e0e3d73" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre">Example 4-2</a>. No attempt has been made to record something similar to percentile histograms or SLO boundary counts like in the Micrometer equivalent. That would of course substantially increase the verbosity of this implementation, which is already getting lengthy.</p>
<div id="ot_timer_vs_micrometer" data-type="example" class="calibre61">
<h5 class="calibre62" id="8IL70-2d714b853a094e9a910510217e0e3d73"><span class="keep-together">Example 4-2. </span>OpenTelemetry timing with variable outcome tags</h5>

<pre data-type="programlisting" data-code-language="java" class="calibre63"><code class="k">public</code> <code class="k">class</code> <code class="nc">MyService</code> <code class="o">{</code>
  <code class="n">Meter</code> <code class="n">meter</code> <code class="o">=</code> <code class="n">OpenTelemetry</code><code class="o">.</code><code class="na">getMeter</code><code class="o">(</code><code class="s">"registry"</code><code class="o">);</code>
  <code class="n">Map</code><code class="o">&lt;</code><code class="n">String</code><code class="o">,</code> <code class="n">AtomicLong</code><code class="o">&gt;</code> <code class="n">callSum</code> <code class="o">=</code> <code class="n">Map</code><code class="o">.</code><code class="na">of</code><code class="o">(</code>
      <code class="s">"success"</code><code class="o">,</code> <code class="k">new</code> <code class="n">AtomicLong</code><code class="o">(</code><code class="mi">0</code><code class="o">),</code>
      <code class="s">"failure"</code><code class="o">,</code> <code class="k">new</code> <code class="n">AtomicLong</code><code class="o">(</code><code class="mi">0</code><code class="o">)</code>
  <code class="o">);</code>

  <code class="k">public</code> <code class="nf">MyService</code><code class="o">()</code> <code class="o">{</code>
    <code class="n">registerCallSum</code><code class="o">(</code><code class="s">"success"</code><code class="o">);</code>
    <code class="n">registerCallSum</code><code class="o">(</code><code class="s">"failure"</code><code class="o">);</code>
  <code class="o">}</code>

  <code class="k">private</code> <code class="kt">void</code> <code class="nf">registerCallSum</code><code class="o">(</code><code class="n">String</code> <code class="n">outcome</code><code class="o">)</code> <code class="o">{</code>
    <code class="n">meter</code><code class="o">.</code><code class="na">doubleSumObserverBuilder</code><code class="o">(</code><code class="s">"calls.sum"</code><code class="o">)</code>
        <code class="o">.</code><code class="na">setDescription</code><code class="o">(</code><code class="s">"calls to something"</code><code class="o">)</code>
        <code class="o">.</code><code class="na">setConstantLabels</code><code class="o">(</code><code class="n">Map</code><code class="o">.</code><code class="na">of</code><code class="o">(</code><code class="s">"service"</code><code class="o">,</code> <code class="s">"hi"</code><code class="o">))</code>
        <code class="o">.</code><code class="na">build</code><code class="o">()</code>
        <code class="o">.</code><code class="na">setCallback</code><code class="o">(</code><code class="n">result</code> <code class="o">-&gt;</code> <code class="n">result</code><code class="o">.</code><code class="na">observe</code><code class="o">(</code>
            <code class="o">(</code><code class="kt">double</code><code class="o">)</code> <code class="n">callSum</code><code class="o">.</code><code class="na">get</code><code class="o">(</code><code class="n">outcome</code><code class="o">).</code><code class="na">get</code><code class="o">()</code> <code class="o">/</code> <code class="mi">1</code><code class="n">e9</code><code class="o">,</code>
            <code class="s">"outcome"</code><code class="o">,</code> <code class="n">outcome</code><code class="o">));</code>
  <code class="o">}</code>

  <code class="k">public</code> <code class="kt">void</code> <code class="nf">call</code><code class="o">()</code> <code class="o">{</code>
    <code class="n">DoubleCounter</code><code class="o">.</code><code class="na">Builder</code> <code class="n">callCounter</code> <code class="o">=</code> <code class="n">meter</code>
        <code class="o">.</code><code class="na">doubleCounterBuilder</code><code class="o">(</code><code class="s">"calls.count"</code><code class="o">)</code>
        <code class="o">.</code><code class="na">setDescription</code><code class="o">(</code><code class="s">"calls to something"</code><code class="o">)</code>
        <code class="o">.</code><code class="na">setConstantLabels</code><code class="o">(</code><code class="n">Map</code><code class="o">.</code><code class="na">of</code><code class="o">(</code><code class="s">"service"</code><code class="o">,</code> <code class="s">"hi"</code><code class="o">))</code>
        <code class="o">.</code><code class="na">setUnit</code><code class="o">(</code><code class="s">"requests"</code><code class="o">);</code>

    <code class="kt">long</code> <code class="n">start</code> <code class="o">=</code> <code class="n">System</code><code class="o">.</code><code class="na">nanoTime</code><code class="o">();</code>
    <code class="k">try</code> <code class="o">{</code>
      <code class="c">// Do something</code>
      <code class="n">callCounter</code><code class="o">.</code><code class="na">build</code><code class="o">().</code><code class="na">add</code><code class="o">(</code><code class="mi">1</code><code class="o">,</code> <code class="s">"outcome"</code><code class="o">,</code> <code class="s">"success"</code><code class="o">);</code>
      <code class="n">callSum</code><code class="o">.</code><code class="na">get</code><code class="o">(</code><code class="s">"success"</code><code class="o">).</code><code class="na">addAndGet</code><code class="o">(</code><code class="n">System</code><code class="o">.</code><code class="na">nanoTime</code><code class="o">()</code> <code class="o">-</code> <code class="n">start</code><code class="o">);</code>
    <code class="o">}</code> <code class="k">catch</code> <code class="o">(</code><code class="n">Exception</code> <code class="n">e</code><code class="o">)</code> <code class="o">{</code>
      <code class="n">callCounter</code><code class="o">.</code><code class="na">build</code><code class="o">().</code><code class="na">add</code><code class="o">(</code><code class="mi">1</code><code class="o">,</code> <code class="s">"outcome"</code><code class="o">,</code> <code class="s">"failure"</code><code class="o">,</code>
          <code class="s">"exception"</code><code class="o">,</code> <code class="n">e</code><code class="o">.</code><code class="na">getClass</code><code class="o">().</code><code class="na">getName</code><code class="o">());</code>
      <code class="n">callSum</code><code class="o">.</code><code class="na">get</code><code class="o">(</code><code class="s">"failure"</code><code class="o">).</code><code class="na">addAndGet</code><code class="o">(</code><code class="n">System</code><code class="o">.</code><code class="na">nanoTime</code><code class="o">()</code> <code class="o">-</code> <code class="n">start</code><code class="o">);</code>
    <code class="o">}</code>
  <code class="o">}</code>
<code class="o">}</code></pre></div>

<p class="author1">I believe the problem for OpenTelemetry is an emphasis on polyglot support, which naturally puts pressure on the project to want to define a consistent data structure for meter primitives like the “double sum observer” or “double counter.” The impact on the resulting API forces the end user to compose from lower-level building blocks the constituent parts of a higher-level abstraction like a Micrometer <code class="calibre24">Timer</code>. This not only leads to exceedingly verbose instrumentation code, but also leads to instrumentation that is specific to a particular monitoring system. For example, if we attempt to publish a counter to an older monitoring system like Graphite while we gradually migrate to Prometheus, we need to explicitly calculate per-interval moving rates and ship those too. The “double counter” data structure doesn’t support this. The reverse problem exists as well, the need to include the union of all possibly usable statistics for a “double counter” in the OpenTelemetry data structure to satisfy the widest array of monitoring systems, even though shipping this extra data is pure waste to a modern metrics backend.<a data-type="indexterm" data-startref="ix_ch04-asciidoc3" id="idm45139267810712" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre"/></p>

<p class="author1">As you get into exploring charting and alerting, you may want to experiment with different backends. And making a selection today based on what you know, you may find yourself transitioning with more experience in a year. Make sure your metrics <em class="calibre12">instrumentation</em> permits you to move fluidly between monitoring systems (and even publish to both while you transition).</p>

<p class="author1">Before we get into any particular SLIs, let’s first go over what makes for an effective chart.<a data-type="indexterm" data-startref="ix_ch04-asciidoc2" id="idm45139267808392" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre"/><a data-type="indexterm" data-startref="ix_ch04-asciidoc1" id="idm45139267807688" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre"/></p>
</div></section>













</div></section></div>



  

<div id="sbo-rt-content" class="calibre2">
<section data-type="chapter" type="chapter" data-pdf-bookmark="Chapter 4. Charting and Alerting" class="calibre3">
<div class="preface" id="ch_charting_alerting">
<section data-type="sect1" data-pdf-bookmark="Effective Visualizations of Service Level Indicators" class="calibre3"><div class="preface" id="idm45139267963688">
<h1 class="calibre19" id="8ILEN-2d714b853a094e9a910510217e0e3d73">Effective Visualizations of Service Level Indicators</h1>

<p class="author1"><a data-type="indexterm" data-primary="charting and alerting" data-secondary="effective visualizations of service level indicators" id="ix_ch04-asciidoc4" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre"/><a data-type="indexterm" data-primary="Grafana" data-secondary="effective visualizations of service level indicators" id="ix_ch04-asciidoc5" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre"/><a data-type="indexterm" data-primary="Grafana" data-seealso="charting and alerting" id="ix_ch04-asciidoc5a" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre"/><a data-type="indexterm" data-primary="service level indicators (SLIs)" data-secondary="effective visualizations of" id="ix_ch04-asciidoc6" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre"/><a data-type="indexterm" data-primary="visualizations" data-secondary="service level indicators" id="ix_ch04-asciidoc7" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre"/>The recommendations offered here are naturally subjective. I’m going to state a preference for bolder lines and less “ink” on the chart, both of which deviate from Grafana’s defaults. To be honest, I’m a little embarrassed to offer these suggestions, because I don’t want to presume that my aesthetic sense is in some way greater than that of the excellent design team at Grafana.</p>

<p class="author1">The stylistic sensibility I will offer is derived from two significant influences over my last few years of work:</p>
<dl class="calibre20">
<dt class="calibre21">Watching engineers stare and squint at charts</dt>
<dd class="calibre22">
<p class="calibre23">I worry when an engineer looks at a chart and squints. I worry especially that the lesson they take from an overly complex visualization is that monitoring itself is complex, and maybe too complex for them. Most of these indicators are <em class="calibre12">really</em> simple when presented correctly. It should feel that way.</p>
</dd>
<dt class="calibre21"><em class="calibre12">The Visual Display of Quantitative Information</em></dt>
<dd class="calibre22">
<p class="calibre23">For a time, I asked the same question of every member of the rare population of user experience designers I met who focus on operations engineering and developer experience: which book(s) did they find were the greatest influence on them? <a data-type="indexterm" data-primary="Tufte, Edward" id="idm45139267598456" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre"/><a data-type="indexterm" data-primary="Visual Display of Quantitative Information, The (Tufte)" id="idm45139267597752" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre"/><em class="calibre12">The Visual Display of Quantitative Information</em> by Edward Tufte (Graphics Press) was always among their answers. One of the ideas most relevant to time series visualization that comes from this book is “data-ink” ratio, specifically to <em class="calibre12">increase</em> it as much as possible. If “ink” (or pixels) on a chart isn’t conveying information, it is conveying complexity. Complexity leads to squinting. Squinting leads to me worrying.</p>
</dd>
</dl>

<p class="author1">Let’s think then from this perspective that data-ink ratio needs to go <em class="calibre12">up</em>. The specific recommendations that follow change the default styling of Grafana to maximize this ratio.</p>








</div></section>













</div></section></div>



  

<div id="sbo-rt-content" class="calibre2">
<section data-type="chapter" type="chapter" data-pdf-bookmark="Chapter 4. Charting and Alerting" class="calibre3">
<div class="preface" id="ch_charting_alerting">
<section data-type="sect1" data-pdf-bookmark="Effective Visualizations of Service Level Indicators" class="calibre3">
<div class="preface" id="idm45139267963688">
<section data-type="sect2" data-pdf-bookmark="Styles for Line Width and Shading" class="calibre3"><div class="preface" id="idm45139267594472">
<h2 class="calibre37" id="calibre_pb_3">Styles for Line Width and Shading</h2>

<p class="author1"><a data-type="indexterm" data-primary="line width, styles for" id="idm45139267593064" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre"/><a data-type="indexterm" data-primary="shading, styles for" id="idm45139267592360" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre"/><a data-type="indexterm" data-primary="visualizations" data-secondary="styles for line width/shading" id="idm45139267591688" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre"/>Grafana’s default chart contains a 1 px solid line, a 10% transparency fill under the line, and interpolation between time slices. For better readability, increase the solid line width to 2 px and remove the fill. The fill reduces the data-ink ratio of the chart, and the overlapping colors of fills get disorienting with more than a couple lines on a chart. Interpolation is a little misleading, since it implies to a casual observer that the value may have briefly existed at intermediate points along the diagonal between two time slices. The opposite of interpolation is called “step” in Grafana’s options. The chart on the top in <a data-type="xref" href="part0009_split_003.html#grafana_line_width" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre">Figure 4-4</a> uses the default options, and the chart on the bottom is adjusted with these recommendations.</p>

<figure class="calibre32"><div id="grafana_line_width" class="figure">
<img src="../images/00018.png" alt="srej 0404" class="calibre104"/>
<h6 class="calibre34"><span class="keep-together">Figure 4-4. </span>Grafana chart style default versus recommended</h6>
</div></figure>

<p class="author1">Change the options in the “Visualization” tab of the chart editor, as shown in <a data-type="xref" href="part0009_split_003.html#grafana_line_width_options" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre">Figure 4-5</a>.</p>

<figure class="calibre32"><div id="grafana_line_width_options" class="figure">
<img src="../images/00080.png" alt="srej 0405" class="calibre105"/>
<h6 class="calibre34"><span class="keep-together">Figure 4-5. </span>Grafana line width options</h6>
</div></figure>
</div></section>













</div></section>













</div></section></div>



  

<div id="sbo-rt-content" class="calibre2">
<section data-type="chapter" type="chapter" data-pdf-bookmark="Chapter 4. Charting and Alerting" class="calibre3">
<div class="preface" id="ch_charting_alerting">
<section data-type="sect1" data-pdf-bookmark="Effective Visualizations of Service Level Indicators" class="calibre3">
<div class="preface" id="idm45139267963688">
<section data-type="sect2" class="calibre3" data-pdf-bookmark="Errors Versus Successes"><div class="preface" id="idm45139267583720">
<h2 class="calibre37" id="calibre_pb_4">Errors Versus Successes</h2>

<p class="author1"><a data-type="indexterm" data-primary="errors" data-secondary="display of errors versus successes" id="ix_ch04-asciidoc8" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre"/><a data-type="indexterm" data-primary="Grafana" data-secondary="display of errors versus successes" id="ix_ch04-asciidoc9" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre"/><a data-type="indexterm" data-primary="visualizations" data-secondary="display of errors versus successes" id="ix_ch04-asciidoc10" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre"/>Plotting a stacked representation of outcomes (success, error, etc.) is very common for timers, as we’ll see in <a data-type="xref" href="part0009_split_013.html#8ILNL-2d714b853a094e9a910510217e0e3d73" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre">“Errors”</a>, and shows up in other scenarios as well. When we think of successes and errors as colors, many of us will immediately think of green and red: stoplight colors. Unfortunately, a significant portion of the population has color vision impairments that affect their ability to perceive color differences. For the most common impairements, deuteranopia and protanopia, the difference between green and red is difficult or impossible to distinguish! Those affected by monochromacy cannot distinguish colors at all, only brightness. Because this book is printed monochromatically, we all get to experience this briefly for the stacked chart of errors and successes in <a data-type="xref" href="part0009_split_004.html#grafana_error_colorblindness" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre">Figure 4-6</a>.</p>

<figure class="calibre32"><div id="grafana_error_colorblindness" class="figure">
<img src="../images/00089.png" alt="srej 0406" class="calibre106"/>
<h6 class="calibre34"><span class="keep-together">Figure 4-6. </span>Display errors with a different line style for accessibility</h6>
</div></figure>

<p class="author1">We need to provide some sort of visual indicator of errors versus successes other than strictly color. In this case, we’ve chosen to plot “successful” outcomes as stacked lines and the errors above these outcomes as thick points to make them stand out.</p>

<p class="author1">Additionally, Grafana doesn’t offer an option to specify the order of time series as they appear in a stacked representation (i.e., “success” on the bottom or top of the stack), even for a limited set of possible values. We can force an ordering of them by selecting each value in a separate query and ordering the queries themselves, as shown in <a data-type="xref" href="part0009_split_004.html#grafana_outcomes_separate_queries" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre">Figure 4-7</a>.</p>

<figure class="calibre32"><div id="grafana_outcomes_separate_queries" class="figure">
<img src="../images/00088.png" alt="srej 0407" class="calibre107"/>
<h6 class="calibre34"><span class="keep-together">Figure 4-7. </span>Ordering outcomes in a Grafana stack representation</h6>
</div></figure>

<p class="author1">Lastly, we can override the styling of each individual query, as shown in <a data-type="xref" href="part0009_split_004.html#grafana_line_style_override" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre">Figure 4-8</a>.<a data-type="indexterm" data-startref="ix_ch04-asciidoc10" id="idm45139267568168" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre"/><a data-type="indexterm" data-startref="ix_ch04-asciidoc9" id="idm45139267567464" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre"/><a data-type="indexterm" data-startref="ix_ch04-asciidoc8" id="idm45139267566792" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre"/></p>

<figure class="calibre32"><div id="grafana_line_style_override" class="figure">
<img src="../images/00092.png" alt="srej 0408" class="calibre108"/>
<h6 class="calibre34"><span class="keep-together">Figure 4-8. </span>Overriding line styles for each outcome</h6>
</div></figure>
</div></section>













</div></section>













</div></section></div>



  

<div id="sbo-rt-content" class="calibre2">
<section data-type="chapter" type="chapter" data-pdf-bookmark="Chapter 4. Charting and Alerting" class="calibre3">
<div class="preface" id="ch_charting_alerting">
<section data-type="sect1" data-pdf-bookmark="Effective Visualizations of Service Level Indicators" class="calibre3">
<div class="preface" id="idm45139267963688">
<section data-type="sect2" data-pdf-bookmark="“Top k” Visualizations" class="calibre3"><div class="preface" id="idm45139267564040">
<h2 class="calibre37" id="calibre_pb_5">“Top k” Visualizations</h2>

<p class="author1"><a data-type="indexterm" data-primary="charting and alerting" data-secondary="top k visualizations" id="idm45139267562632" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre"/><a data-type="indexterm" data-primary="Grafana" data-secondary="top k visualizations" id="idm45139267561496" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre"/><a data-type="indexterm" data-primary="top k visualizations" id="idm45139267560552" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre"/><a data-type="indexterm" data-primary="visualizations" data-secondary="top k" id="idm45139267559880" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre"/>In many cases, we want to display some indicator of the “worst” performers by some category. Many monitoring systems offer some sort of query function to select the “top k” time series for some criteria. Selecting “top 3” worst performers doesn’t mean that there will be a maximum of three lines on the chart, however, because this race to the bottom is perpetual, and the worst performers can change over the course of the time interval visualized by the chart. At worst, you are displaying <em class="calibre12">N</em> datapoints on a particular visualization, and there will be 3*<em class="calibre12">N</em> distinct time series displayed! If you draw a vertical line down any part of <a data-type="xref" href="part0009_split_005.html#grafana_table_to_right" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre">Figure 4-9</a> and count the number of unique colors it intersects, it will always be less than or equal to three because this chart was built with a “top 3” query. But there are six items in the legend.</p>

<figure class="calibre32"><div id="grafana_table_to_right" class="figure">
<img src="../images/00053.png" alt="srej 0409" class="calibre109"/>
<h6 class="calibre34"><span class="keep-together">Figure 4-9. </span>Top k visualization with more than k distinct time series</h6>
</div></figure>

<p class="author1">It can get far busier than this very easily. Consider <a data-type="xref" href="part0009_split_005.html#topk_many_lines" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre">Figure 4-10</a>, which shows the top five longest Gradle build task times over a period of time. Since the set of build tasks running changes rapidly over the time slices shown in this chart, the legend fills up with many more values than simply five.</p>

<figure class="calibre32"><div id="topk_many_lines" class="figure">
<img src="../images/00029.png" alt="srej 0410" class="calibre110"/>
<h6 class="calibre34"><span class="keep-together">Figure 4-10. </span>Top k can still yield many more items in the legend than k</h6>
</div></figure>

<p class="author1">In such cases, the legend is overwhelmed with labels, to the point where it is illegible. Use the Grafana options to shift the legend to a table on the right, and add a summary statistic like “maximum,” as shown in <a data-type="xref" href="part0009_split_005.html#grafana_table_to_right_options" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre">Figure 4-11</a>. You can then click the summary statistic in the table to sort the legend-as-table by this statistic. Now when we look at the chart, we can quickly see which performers are overall worst for the time range that we are viewing.</p>

<figure class="calibre32"><div id="grafana_table_to_right_options" class="figure">
<img src="../images/00040.png" alt="srej 0411" class="calibre111"/>
<h6 class="calibre34"><span class="keep-together">Figure 4-11. </span>Overriding line styles for each outcome</h6>
</div></figure>
</div></section>













</div></section>













</div></section></div>



  

<div id="sbo-rt-content" class="calibre2">
<section data-type="chapter" type="chapter" data-pdf-bookmark="Chapter 4. Charting and Alerting" class="calibre3">
<div class="preface" id="ch_charting_alerting">
<section data-type="sect1" data-pdf-bookmark="Effective Visualizations of Service Level Indicators" class="calibre3">
<div class="preface" id="idm45139267963688">
<section data-type="sect2" data-pdf-bookmark="Prometheus Rate Interval Selection" class="calibre3"><div class="preface" id="idm45139267547352">
<h2 class="calibre37" id="calibre_pb_6">Prometheus Rate Interval Selection</h2>

<p class="author1"><a data-type="indexterm" data-primary="charting and alerting" data-secondary="Prometheus rate interval selection" id="idm45139267546184" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre"/><a data-type="indexterm" data-primary="Prometheus" data-secondary="rate interval selection" id="idm45139267545144" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre"/><a data-type="indexterm" data-primary="visualizations" data-secondary="Prometheus rate interval selection" id="idm45139267544200" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre"/>Throughout this chapter, we are going to see Prometheus queries that use <a href="https://oreil.ly/RnMk3" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre">range vectors</a>. I highly suggest using range vectors that are at least twice as long as the scrape interval (by default one minute). Otherwise, you risk missing datapoints due to slight variations in scrape timing that may cause adjacent datapoints to be just slightly more than the scrape interval apart. Similarly, if a service is restarted and a datapoint is missing, the rate function will not be able to make a rate during the gap or next datapoint until the interval contains at least two points. Using a higher interval for the rate avoids these problems. Because application startup may be longer than a scrape interval, depending on your application, if it is important to you to totally avoid gaps, you may choose a range vector longer than twice the scrape interval (something in fact closer to whatever application startup plus two intervals would be).</p>

<p class="author1">Range vectors are a somewhat unique concept to Prometheus, but the same principle applies in other contexts in other monitoring systems. For example, you’d want to construct a “min over interval” type query to compensate for potential gaps during application restart if you are setting a minimum threshold on an alert.<a data-type="indexterm" data-startref="ix_ch04-asciidoc7" id="idm45139267540840" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre"/><a data-type="indexterm" data-startref="ix_ch04-asciidoc6" id="idm45139267540136" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre"/><a data-type="indexterm" data-startref="ix_ch04-asciidoc5" id="idm45139267539464" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre"/><a data-type="indexterm" data-startref="ix_ch04-asciidoc5a" id="idm45139267538792" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre"/><a data-type="indexterm" data-startref="ix_ch04-asciidoc4" id="idm45139267538120" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre"/></p>
</div></section>





</div></section>













</div></section></div>



  

<div id="sbo-rt-content" class="calibre2">
<section data-type="chapter" type="chapter" data-pdf-bookmark="Chapter 4. Charting and Alerting" class="calibre3">
<div class="preface" id="ch_charting_alerting">
<section data-type="sect1" data-pdf-bookmark="Gauges" class="calibre3"><div class="preface" id="idm45139267537192">
<h1 class="calibre19" id="calibre_pb_7">Gauges</h1>

<p class="author1"><a data-type="indexterm" data-primary="charting and alerting" data-secondary="gauges" id="ix_ch04-asciidoc11" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre"/><a data-type="indexterm" data-primary="gauges" id="ix_ch04-asciidoc12" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre"/><a data-type="indexterm" data-primary="visualizations" data-secondary="gauges" id="ix_ch04-asciidoc13" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre"/>A time series representation of a gauge presents more information about as compactly as an instantaneous gauge. It is just as obvious when a line crosses an alert threshold, and the historical information about the gauge’s prior values provides useful context. As a result, the bottom chart is preferable in <a data-type="xref" href="part0009_split_007.html#gauge_instantaneous_vs_line" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre">Figure 4-12</a>.</p>

<figure class="calibre32"><div id="gauge_instantaneous_vs_line" class="figure">
<img src="../images/00046.png" alt="srej 0412" class="calibre112"/>
<h6 class="calibre34"><span class="keep-together">Figure 4-12. </span>Prefer a line chart over an instantaneous gauge</h6>
</div></figure>

<p class="author1">Gauges have a tendency to be spiky. Thread pools can appear to be temporarily near exhaustion and then recover. Queues get full and then empty. Memory utilization in Java is especially tricky to alert on since short-term allocations can quickly appear to fill up a significant portion of allocated space only for garbage collection to sweep away much of the consumption.</p>

<p class="author1">One of the most effective methods to limit alert chattiness is to use a rolling count function, the results of which are shown in <a data-type="xref" href="part0009_split_007.html#rolling_count" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre">Figure 4-13</a>. In this way we can define an alert that only fires if a threshold is exceeded more than three times in the last five intervals, or some other combination of frequency and number of lookback intervals. The longer the lookback, the more time will elapse before the alert first fires, so be careful to not look back too far for critical indicators.</p>

<figure class="calibre32"><div id="rolling_count" class="figure">
<img src="../images/00055.png" alt="The alarm fires only when there is clearly a problem developing" class="calibre113"/>
<h6 class="calibre34"><span class="keep-together">Figure 4-13. </span>Rolling count to limit alert chattiness</h6>
</div></figure>

<p class="author1">Being instantaneous values, gauges are basically just graphed as is on each monitoring system. Counters are a little more nuanced.<a data-type="indexterm" data-startref="ix_ch04-asciidoc13" id="idm45139267524152" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre"/><a data-type="indexterm" data-startref="ix_ch04-asciidoc12" id="idm45139267523448" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre"/><a data-type="indexterm" data-startref="ix_ch04-asciidoc11" id="idm45139267522776" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre"/></p>
</div></section>













</div></section></div>



  

<div id="sbo-rt-content" class="calibre2">
<section data-type="chapter" type="chapter" data-pdf-bookmark="Chapter 4. Charting and Alerting" class="calibre3">
<div class="preface" id="ch_charting_alerting">
<section data-type="sect1" data-pdf-bookmark="Counters" class="calibre3"><div class="preface" id="idm45139267521976">
<h1 class="calibre19" id="8ILIV-2d714b853a094e9a910510217e0e3d73">Counters</h1>

<p class="author1"><a data-type="indexterm" data-primary="charting and alerting" data-secondary="counters" id="ix_ch04-asciidoc14" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre"/><a data-type="indexterm" data-primary="counters" id="ix_ch04-asciidoc15" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre"/><a data-type="indexterm" data-primary="visualizations" data-secondary="counters" id="ix_ch04-asciidoc16" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre"/>Counters are often tested against a maximum (or less frequently, a minimum) threshold. The need to test against a threshold reinforces the idea that counters should be observed as rates rather than a cumulative statistic, regardless of how the statistic is stored in the monitoring system.</p>

<p class="author1"><a data-type="xref" href="part0009_split_008.html#counter_cumulative_vs_rate" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre">Figure 4-14</a> shows an HTTP endpoint’s request throughput as a rate (yellow solid line) and also the cumulative count (green dots) of all requests to this endpoint since the application process started. Also, the chart shows a fixed minimum threshold alert (red line and area) of 1,000 requests/second that has been set on this endpoint’s throughput. This threshold makes sense relative to throughput represented as a rate (which in this window varies between 1,500 and 2,000 requests/second). It makes little sense against the cumulative count though, since the cumulative count is effectively a measure of both the rate of throughput and the longevity of the process. The longevity of the process is irrelevant to this alert.</p>

<figure class="calibre32"><div id="counter_cumulative_vs_rate" class="figure">
<img src="../images/00102.png" alt="The alert threshold only makes sense against the rate." class="calibre114"/>
<h6 class="calibre34"><span class="keep-together">Figure 4-14. </span>A counter with a minimum alert threshold on rate, with cumulative count displayed as well</h6>
</div></figure>

<p class="author1">Sometimes a fixed threshold is difficult to determine a priori. Also, the rate at which an event is occurring may fluctuate periodically based on something like peak and off-peak business hours. This is especially common with a throughput measure like requests/second, as seen in <a data-type="xref" href="part0009_split_008.html#counter_dynamic_threshold" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre">Figure 4-15</a>. If we set a fixed threshold on this service to detect when traffic was suddenly not reaching the service (a minimum threshold), we would have to set it somewhere below 40 RPS, the minimum throughput this service sees. Suppose the minimum threshold is set at 30 RPS. This alert fires when traffic drops below 75% of the expected value during off-peak hours, but only when traffic drops below 10% of the expected value during peak hours! The alert threshold is not equally valuable during all periods.</p>

<figure class="calibre32"><div id="counter_dynamic_threshold" class="figure">
<img src="../images/00051.png" alt="A fixed threshold would not quickly detect a sudden change in RPS during peak hours." class="calibre115"/>
<h6 class="calibre34"><span class="keep-together">Figure 4-15. </span>A service with periodic increases in traffic based on the time of day</h6>
</div></figure>

<p class="author1">In these cases, consider framing an alert in terms of finding sharp increases or decreases in rate. A good general approach to this, seen in <a data-type="xref" href="part0009_split_008.html#des" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre">Figure 4-16</a>, is to take the counter rate, apply a smoothing function to it, and multiply the smoothing function by some factor (85% in the example). Because the smoothing function naturally takes at least a little time to respond to a sudden change in the rate, a test to ensure that the counter rate doesn’t fall below the smoothed line detects sudden change without having to know what the expected rate is at all. A much more detailed explanation of statistical methods for smoothing for dynamic alerting is presented in <a data-type="xref" href="part0009_split_026.html#8INDM-2d714b853a094e9a910510217e0e3d73" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre">“Building Alerts Using Forecasting Methods”</a>.</p>

<figure class="calibre32"><div id="des" class="figure">
<img src="../images/00104.png" alt="The alert fires when there is a sudden drop in throughput." class="calibre116"/>
<h6 class="calibre34"><span class="keep-together">Figure 4-16. </span>A counter with a double-exponentially smoothed threshold, forming a dynamic alert threshold</h6>
</div></figure>

<p class="author1">It is Micrometer’s responsibility to ship the data to your monitoring system of choice in such a way that you can draw a rate representation of a counter in your chart. In the case of Atlas, counters are already shipped in a rate-normalized way, so a query for a counter already returns a rate value that can be directly plotted, as shown in <a data-type="xref" href="part0009_split_008.html#atlas_counter_is_a_rate" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre">Example 4-3</a>.</p>
<div id="atlas_counter_is_a_rate" data-type="example" class="calibre61">
<h5 class="calibre62"><span class="keep-together">Example 4-3. </span>Atlas counters are already a rate, so selecting them charts a rate</h5>

<pre data-type="programlisting" class="calibre63">name,cache.gets,:eq,</pre></div>

<p class="author1">Other monitoring systems expect cumulative values to be shipped to the monitoring system and include some sort of rate function for use at query time. <a data-type="xref" href="part0009_split_008.html#prometheus_counter_is_cumulative" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre">Example 4-4</a> would display roughly the same rate line as the Atlas equivalent, depending on what you select as the range vector (the time period in the <code class="calibre24">[]</code>).</p>
<div id="prometheus_counter_is_cumulative" data-type="example" class="calibre61">
<h5 class="calibre62"><span class="keep-together">Example 4-4. </span>Prometheus counters are cumulative, so we need to explicitly convert them to a rate</h5>

<pre data-type="programlisting" class="calibre63">rate(cache_gets[2m])</pre></div>

<p class="author1">There is one problem with the Prometheus rate function: when new tag values are added rapidly inside a chart’s time domain, the Prometheus rate function can generate a NaN value as opposed to a zero. In <a data-type="xref" href="part0009_split_008.html#prometheus_rate_zero_fill" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre">Figure 4-17</a>, we are charting Gradle build task throughput over time. Since in this window, build tasks are uniquely described by project and task name, and once a task is complete it isn’t incremented again, several new time series are coming into existence inside of the time domain we’ve selected for the chart.</p>

<figure class="calibre32"><div id="prometheus_rate_zero_fill" class="figure">
<img src="../images/00097.png" alt="srej 0417" class="calibre117"/>
<h6 class="calibre34"><span class="keep-together">Figure 4-17. </span>Zero-filling Prometheus counter rates when new tag values are coming into existence inside the time domain</h6>
</div></figure>

<p class="author1">The query in <a data-type="xref" href="part0009_split_008.html#prometheus_rate_zero_fill_query" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre">Example 4-5</a> shows the method we can use to zero-fill the gaps.</p>
<div id="prometheus_rate_zero_fill_query" data-type="example" class="calibre61">
<h5 class="calibre62"><span class="keep-together">Example 4-5. </span>The query to zero-filling Prometheus counter rates</h5>

<pre data-type="programlisting" class="calibre63">sum(gradle_task_seconds_count) by (gradle_root_project_name) -
(
  sum(gradle_task_seconds_count offset 10s) by (gradle_root_project_name) &gt; 0 or
  (
    (sum(gradle_task_seconds_count) by (gradle_root_project_name)) * 0
  )
)</pre></div>

<p class="author1">How to chart counters varies a bit from monitoring system to monitoring system. Sometimes we have to explicitly create rates, and sometimes counters are stored as rates up front. Timers have even more options.<a data-type="indexterm" data-startref="ix_ch04-asciidoc16" id="idm45139267488200" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre"/><a data-type="indexterm" data-startref="ix_ch04-asciidoc15" id="idm45139267487496" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre"/><a data-type="indexterm" data-startref="ix_ch04-asciidoc14" id="idm45139267486824" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre"/></p>
</div></section>













</div></section></div>



  

<div id="sbo-rt-content" class="calibre2">
<section data-type="chapter" type="chapter" data-pdf-bookmark="Chapter 4. Charting and Alerting" class="calibre3">
<div class="preface" id="ch_charting_alerting">
<section data-type="sect1" data-pdf-bookmark="Timers" class="calibre3"><div class="preface" id="charting_timers">
<h1 class="calibre19" id="8ILKM-2d714b853a094e9a910510217e0e3d73">Timers</h1>

<p class="author1"><a data-type="indexterm" data-primary="charting and alerting" data-secondary="timers" id="ix_ch04-asciidoc17" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre"/><a data-type="indexterm" data-primary="latency" data-secondary="timers and" id="ix_ch04-asciidoc18" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre"/><a data-type="indexterm" data-primary="Micrometer" data-secondary="timers" id="ix_ch04-asciidoc19" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre"/><a data-type="indexterm" data-primary="timers" id="ix_ch04-asciidoc20" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre"/><a data-type="indexterm" data-primary="visualizations" data-secondary="timers" id="ix_ch04-asciidoc21" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre"/>A <code class="calibre24">Timer</code> Micrometer meter generates a variety of different time series with one operation. Wrapping a block of code with a timer (<code class="calibre24">timer.record(() -&gt; { ... })</code>) is enough to collect data on throughput through this block, maximum latency (decaying over time), the total sum of latency, and optionally other distribution statistics like histograms, percentiles, and SLO boundaries.</p>

<p class="author1">On dashboards, latency is the most important to view, because it is most directly tied to user experience. After all, users care mostly about the performance of <em class="calibre12">their</em> individual requests. They care little to nothing about the total throughput the system is capable of, except indirectly to the extent that at a certain throughput level their response time is affected.</p>

<p class="author1">Secondarily, throughput can be included if there is an expectation of a certain shape to traffic (which may be periodic based on business hours, customer time zones, etc.). For example, a sharp decline in throughput during an expected peak period can be a strong indicator of a systemic problem where traffic that should be reaching the system is not.</p>

<p class="author1"><a data-type="indexterm" data-primary="maximum latency" id="ix_ch04-asciidoc22" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre"/><a data-type="indexterm" data-primary="timers" data-secondary="maximum latency" id="ix_ch04-asciidoc23" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre"/>For many cases, it is best to set alerts on maximum latency (in this case meaning maximum observed for each interval) and use high-percentile approximations like the 99th percentile for comparative analysis (see <a data-type="xref" href="part0010_split_013.html#9H5VC-2d714b853a094e9a910510217e0e3d73" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre">“Automated Canary Analysis”</a>).</p>
</div></section>













</div></section></div>



  

<div id="sbo-rt-content" class="calibre2">
<section data-type="chapter" type="chapter" data-pdf-bookmark="Chapter 4. Charting and Alerting" class="calibre3">
<div class="preface" id="ch_charting_alerting">
<section data-type="sect1" data-pdf-bookmark="Timers" class="calibre3">
<div class="preface" id="charting_timers">
<div data-type="tip" class="calibre28"><h1 class="calibre54" id="calibre_pb_10">Set Timer Alerts on Maximum Latency</h1>
<p class="author1">It is exceedingly common in Java applications for maximum timings to be an order of magnitude worse than the 99th percentile. It is best to set your alerts on maximum latency.</p>
</div>

<p class="author1">I didn’t discover the importance of even measuring maximum latency until after I left Netflix and was introduced to a <a href="https://oreil.ly/ErwIo" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre">compelling argument</a> by Gil Tene for alerting on maximum latency. He makes a particularly visceral point about worst case, drawing an analogy to pacemaker performance and emphasizing that “‘your heart will keep beating 99.9% of the time’ is not reassuring.” Always a sucker for a well-reasoned argument, I added maximum latency as a key statistic shipped by Micrometer <code class="calibre24">Timer</code> and <code class="calibre24">DistributionSummary</code> implementations just in time for the SpringOne conference in 2017. There I met a former colleague from Netflix and sheepishly suggested this new idea, conscious of the fact that Netflix wasn’t actually monitoring max latency. He immediately laughed off the idea and left for a talk, leaving me a bit deflated. A short while later, I got a message from him with the chart shown in <a data-type="xref" href="part0009_split_010.html#max_p99_logging_service" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre">Figure 4-18</a>, showing max latency an order of magnitude worse than P99 on a key internal Netflix service (which he had gone and added max to as a quick experiment to test this hypothesis).</p>

<figure class="calibre32"><div id="max_p99_logging_service" class="figure">
<img src="../images/00037.png" alt="srej 0418" class="calibre118"/>
<h6 class="calibre34"><span class="keep-together">Figure 4-18. </span>Max versus P99 in a Netflix logging service (in nanoseconds)</h6>
</div></figure>

<p class="author1">Even more amazing, Netflix had recently undergone an architectural shift that made P99 a little bit better but made max substantially worse! It’s easy to argue it was actually worse off for having made the change. I cherish the memory of this interaction because it is such an acute illustration of how every organization has something it can learn from another: in this case a highly sophisticated monitoring culture at Netflix learned a trick from Domo which in turn learned it from Azul Systems.</p>

<p class="author1">In <a data-type="xref" href="part0009_split_010.html#max_vs_p99_latency" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre">Figure 4-19</a>, we see the order-of-magnitude difference between maximum and 99th percentile. Response latency tends to be tightly packed around the 99th percentile with at least one separate grouping near the maximum reflective of garbage collection, VM pauses, etc.</p>

<figure class="calibre32"><div id="max_vs_p99_latency" class="figure">
<img src="../images/00114.png" alt="A comparison of maximum and P99 latency" class="calibre119"/>
<h6 class="calibre34"><span class="keep-together">Figure 4-19. </span>Maximum versus P99 latency</h6>
</div></figure>

<p class="author1">In <a data-type="xref" href="part0009_split_010.html#avg_vs_p99_latency" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre">Figure 4-20</a>, a real-world service is exhibiting the characteristic that the average floats above the 99th percentile because requests are so densely packed around the 99th.</p>

<figure class="calibre32"><div id="avg_vs_p99_latency" class="figure">
<img src="../images/00110.png" alt="srej 0420" class="calibre120"/>
<h6 class="calibre34"><span class="keep-together">Figure 4-20. </span>Average versus P99 latency</h6>
</div></figure>

<p class="author1">As insignificant as this top 1% may seem, real users are affected by these latencies, so it is important to recognize where that boundary is and compensate for it where needed. One recognized approach to limiting the effect of the top 1% is a client-side load-balancing strategy called hedge requests (see <a data-type="xref" href="part0012_split_014.html#hedge_requests" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre">“Hedge Requests”</a>).</p>

<p class="author1">Setting an alert on max latency is key (we’ll talk more about why in <a data-type="xref" href="part0009_split_017.html#8ILV9-2d714b853a094e9a910510217e0e3d73" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre">“Latency”</a>). But once an engineer has been alerted to a problem, the dashboard that they use to start understanding the problem doesn’t necessarily need to have this indicator on it. It would be far more useful to see the distribution of latencies as a heatmap (as shown in <a data-type="xref" href="part0009_split_010.html#timer_heatmap" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre">Figure 4-21</a>), which would include a nonzero bucket where the max is that caused the alert, to see how significant the problem is relative to the normative request coming through the system at that time. In a heatmap visualization, each vertical column represents a histogram (refer to <a data-type="xref" href="part0007_split_007.html#6LKA8-2d714b853a094e9a910510217e0e3d73" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre">“Histograms”</a> for a definition) at a particular time slice. The colored boxes represent the frequency of latencies that are in a range of times defined on the <em class="calibre12">y</em>-axis. So the normative latency an end user is experiencing should look “hot” and outliers look cooler.</p>

<figure class="calibre32"><div id="timer_heatmap" class="figure">
<img src="../images/00094.png" alt="srej 0421" class="calibre121"/>
<h6 class="calibre34"><span class="keep-together">Figure 4-21. </span>A timer heatmap</h6>
</div></figure>

<p class="author1">Are most requests failing close to the max value, or are there just one or a few stray outliers? The answer to this question likely affects how quickly an alerted engineer escalates the issue and brings others in to help. There’s no need to plot both the max and heatmap on a diagnostic dashboard, as shown in <a data-type="xref" href="part0009_split_010.html#max_vs_heatmap" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre">Figure 4-22</a>. Just include the heatmap.</p>

<figure class="calibre32"><div id="max_vs_heatmap" class="figure">
<img src="../images/00077.png" alt="srej 0422" class="calibre122"/>
<h6 class="calibre34"><span class="keep-together">Figure 4-22. </span>Max latency versus heatmap of latency distribution</h6>
</div></figure>

<p class="author1">The latency heatmap is also expensive to draw, since it involves retrieving potentially dozens or hundreds of buckets (which are individual time series in the monitoring system) for each time slice on the chart, for a total that often amounts to thousands of time series. This reinforces the idea that there’s no reason to have this chart auto-updating on a prominent display somewhere hanging on a wall. Allow the alerting system to do its job and view the dashboard as needed to limit the load on the monitoring system.<a data-type="indexterm" data-startref="ix_ch04-asciidoc23" id="idm45139267443576" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre"/><a data-type="indexterm" data-startref="ix_ch04-asciidoc22" id="idm45139267442872" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre"/></p>

<p class="author1">The toolbox of useful representations has now grown to the point that a word of caution is necessary.<a data-type="indexterm" data-startref="ix_ch04-asciidoc21" id="idm45139267441704" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre"/><a data-type="indexterm" data-startref="ix_ch04-asciidoc20" id="idm45139267441000" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre"/><a data-type="indexterm" data-startref="ix_ch04-asciidoc19" id="idm45139267440328" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre"/><a data-type="indexterm" data-startref="ix_ch04-asciidoc18" id="idm45139267439656" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre"/><a data-type="indexterm" data-startref="ix_ch04-asciidoc17" id="idm45139267438984" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre"/></p>
</div></section>













</div></section></div>



  

<div id="sbo-rt-content" class="calibre2">
<section data-type="chapter" type="chapter" data-pdf-bookmark="Chapter 4. Charting and Alerting" class="calibre3">
<div class="preface" id="ch_charting_alerting">
<section data-type="sect1" class="calibre3" data-pdf-bookmark="When to Stop Creating Dashboards"><div class="preface" id="idm45139267485240">
<h1 class="calibre19" id="calibre_pb_11">When to Stop Creating Dashboards</h1>

<p class="author1"><a data-type="indexterm" data-primary="charting and alerting" data-secondary="when to stop creating dashboards" id="idm45139267436776" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre"/><a data-type="indexterm" data-primary="dashboards, when to stop creating" id="idm45139267435736" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre"/><a data-type="indexterm" data-primary="visualizations" data-secondary="when to stop creating dashboards" id="idm45139267435048" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre"/>I visited with a former colleague of mine, now VP of operations at Datadog, in 2019. He lamented that, ironically, a lack of healthy moderation in dashboards built by customers is one of the key capacity problems confronting Datadog. Imagine legions of computer screens and TV displays arrayed around the world, each automatically refreshing at prescribed intervals a series of charts that look nice. I found this to be such a fascinating business problem, because clearly lots of TV displays showing Datadog branding improve the visibility and stickiness of the product while simultaneously producing an operational nightmare for a SaaS.</p>

<p class="author1">I’ve always found the “mission control” dashboard view a bit of a curiosity. After all, what is it about a chart that visually indicates to me a problem? If it’s a sharp spike, a deep trough, or simply a value that has crept above all reasonable expectation, then an alert threshold can be created to define where that point of unacceptability is, and the metric can be monitored automatically (and around the clock).</p>

<p class="author1">As an on-call engineer, it’s nice to receive an alert with an instantaneous visualization of the indicator (or a link to one). Ultimately, when we open alerts, we want to dig for information to discover a root cause (or sometimes determine that the alert isn’t worth paying attention to). If the alert links to a dashboard, ideally that dashboard is configured in such a way as to allow immediate dimensional explosion or exploration. In other words, the TV display dashboard treats humans as a sort of low-attention span, notoriously unreliable alerting system.</p>

<p class="author1">The visualizations useful for alerting may not be useful to include on a dashboard at all, and not all charts on a dashboard are possible to build alerts on. For example, <a data-type="xref" href="part0009_split_010.html#max_vs_heatmap" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre">Figure 4-22</a> shows two representations of the same timer: a decaying max and a heatmap. The alerting system is going to watch max, but when an engineer is alerted to the anomalous condition, it’s much more useful to see the distribution of latencies around that time to know how severe the impact was (and the max should be captured in a latency bucket that’s visible on the heatmap).</p>

<p class="author1">However, be careful about how you construct these queries! If you look closely you will see that there is no latency around 15 ms on the heatmap. The Prometheus range vector in this case was too close to the scrape interval, and the resulting momentary gap in the chart that is invisible hides the 15 ms latency! Since Micrometer decays max, we still see it on the max chart.</p>

<p class="author1">Heatmaps are also much more computationally expensive to render than a simple max line. For one chart this is fine, but add up this cost across many individual displays across business units in a large organization and this can be taxing on the monitoring system itself.</p>

<p class="author1">Charts aren’t a substitute for alerts. Focus first on delivering them as alerts to the right people when they stray from acceptable levels rather than rushing to set up monitors.</p>
<div data-type="tip" class="calibre28"><h6 class="calibre29">Tip</h6>
<p class="author1">A human constantly watching a monitor is just an expensive alerting system polling visually for unacceptable levels.</p>
</div>

<p class="author1">Alerts should be delivered to on-call personnel in such a way that they can quickly jump to a dashboard and start drilling down on the failing metric dimensionally to reason about where the problem is.</p>

<p class="author1">Not every alert or violation of an SLO needs be treated as a stop-the-world <span class="keep-together">emergency.</span></p>
</div></section>













</div></section></div>



  

<div id="sbo-rt-content" class="calibre2">
<section data-type="chapter" type="chapter" data-pdf-bookmark="Chapter 4. Charting and Alerting" class="calibre3">
<div class="preface" id="ch_charting_alerting">
<section data-type="sect1" data-pdf-bookmark="Service Level Indicators for Every Java Microservice" class="calibre3"><div class="preface" id="idm45139267438056">
<h1 class="calibre19" id="8ILNF-2d714b853a094e9a910510217e0e3d73">Service Level Indicators for Every Java Microservice</h1>

<p class="author1"><a data-type="indexterm" data-primary="charting and alerting" data-secondary="service level indicators for every Java microservice" id="ix_ch04-asciidoc24" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre"/><a data-type="indexterm" data-primary="service level indicators (SLIs)" data-secondary="for every Java microservice" data-secondary-sortas="every" id="ix_ch04-asciidoc25" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre"/>Now that we have a sense of how to visually present SLIs on charts, we will turn our focus to the indicators you can add. They are presented in approximately the order of importance. So if you are following the incrementalist approach to adding charts and alerts, implement these in sequence.</p>








</div></section>













</div></section></div>



  

<div id="sbo-rt-content" class="calibre2">
<section data-type="chapter" type="chapter" data-pdf-bookmark="Chapter 4. Charting and Alerting" class="calibre3">
<div class="preface" id="ch_charting_alerting">
<section data-type="sect1" data-pdf-bookmark="Service Level Indicators for Every Java Microservice" class="calibre3">
<div class="preface" id="idm45139267438056">
<section data-type="sect2" data-pdf-bookmark="Errors" class="calibre3"><div class="preface" id="kpi_errors">
<h2 class="calibre37" id="8ILNL-2d714b853a094e9a910510217e0e3d73">Errors</h2>

<p class="author1"><a data-type="indexterm" data-primary="errors" data-secondary="SLIs and" id="ix_ch04-asciidoc26" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre"/><a data-type="indexterm" data-primary="service level indicators (SLIs)" data-secondary="errors" id="ix_ch04-asciidoc27" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre"/>When timing a block of code it’s useful to differentiate between successful and unsuccessful operations for two reasons.</p>

<p class="author1">First, we can directly use the ratio of unsuccessful to total timings as a measure of the frequency of errors occurring in the system.</p>

<p class="author1">Also, successful and unsuccessful outcomes can have radically different response times, depending on the failure mode. For example, a <code class="calibre24">NullPointerException</code> resulting from making a bad assumption about the presence of some data in request input can fail early in a request handler. It then doesn’t get far enough to call other downstream services, interact with the database, etc., where the majority of time is spent when a request is successful. In this case, unsuccessful requests that fail in this way will skew our perspective on the latency of the system. Latency will in fact appear better than it actually is! On the other hand, a request handler that makes a blocking downstream request to another microservice that is under duress and for which the response ultimately times out may exhibit a much higher-than-normal latency (something close to the timeout on the HTTP client making the call). By not segregating errors, we present an overly pessimistic view of the latency of our system.</p>

<p class="author1">Status tags (recall <a data-type="xref" href="part0006_split_007.html#5N3ND-2d714b853a094e9a910510217e0e3d73" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre">“Naming Metrics”</a>) should be added to timing instrumentation in most cases on two levels.</p>
<dl class="calibre20">
<dt class="calibre21">Status</dt>
<dd class="calibre22">
<p class="calibre23"><a data-type="indexterm" data-primary="status tags" id="idm45139267259768" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre"/>A tag that provides a detailed error code, exception name, or some other specific indicator of the failure mode</p>
</dd>
<dt class="calibre21">Outcome</dt>
<dd class="calibre22">
<p class="calibre23"><a data-type="indexterm" data-primary="outcome tags" id="idm45139267257656" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre"/>A tag that provides a more course-grained error category that separates success, user-caused error, and service-caused error</p>
</dd>
</dl>

<p class="author1">When writing alerts, rather than trying to select a tag by matching a status code pattern (e.g., using Prometheus’s not-regex tag selector for <code class="calibre24">status !~"2.."</code>), it is preferable to perform an exact match on the outcome tag (<code class="calibre24">outcome="SERVER_ERROR"</code>). By selecting “not 2xx,” we are grouping server errors, like the common HTTP 500 Internal Server Error, with errors caused by the user, like HTTP 400 Bad Request or HTTP 403 Forbidden. A high rate of HTTP 400s may indicate that you recently released code that contained an accidental backward incompatibility in an API, or it could indicate that a new end user (e.g., some other upstream microservice) is trying to onboard onto using your service and hasn’t gotten the payload right yet.</p>
</div></section>













</div></section>













</div></section></div>



  

<div id="sbo-rt-content" class="calibre2">
<section data-type="chapter" type="chapter" data-pdf-bookmark="Chapter 4. Charting and Alerting" class="calibre3">
<div class="preface" id="ch_charting_alerting">
<section data-type="sect1" data-pdf-bookmark="Service Level Indicators for Every Java Microservice" class="calibre3">
<div class="preface" id="idm45139267438056">
<section data-type="sect2" data-pdf-bookmark="Errors" class="calibre3">
<div class="preface" id="kpi_errors">
<div data-type="tip" class="calibre28"><h1 class="calibre54" id="calibre_pb_14">Panera Faced Chatty Alerts Not Distinguishing Client from Server Errors</h1>
<p class="author1"><a data-type="indexterm" data-primary="Panera Bread, Inc." id="idm45139267253320" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre"/>Panera Bread, Inc., faced an overly chatty alert from an anomaly detector implemented by its monitoring system vendor for HTTP errors. It caused several email alerts in one day because a single user provided the wrong password five times. Engineers discovered that the anomaly detector didn’t differentiate between client and server error ratio! Alerts on client error ratio might be nice for intrusion detection, but the threshold would be much higher than server error ratio (and certainly higher than five errors in a short period of time).</p>
</div>

<p class="author1">An HTTP 500 basically always is your fault as a service owner and needs attention. At best, an HTTP 500 shines a spotlight on where more up-front validation could have instead yielded a useful HTTP 400 back to the end user. I think “HTTP 500—Internal Server Error” is too passive. Something like “HTTP 500—Sorry, It’s My Fault” feels better.</p>

<p class="author1">When you are writing your own timers, a common pattern involves using a <code class="calibre24">Timer</code> sample and deferring the determination of tags until it’s known whether the request will succeed or fail, as in <a data-type="xref" href="part0009_split_014.html#timer_sample_exception" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre">Example 4-6</a>. The sample holds the state of the time that the operation started for you.</p>
<div id="timer_sample_exception" data-type="example" class="calibre61">
<h5 class="calibre62"><span class="keep-together">Example 4-6. </span>Determining an error and outcome tag dynamically based on the result of an operation</h5>

<pre data-type="programlisting" data-code-language="java" class="calibre63"><code class="n">Timer</code><code class="o">.</code><code class="na">Sample</code><code class="calibre24"> </code><code class="n">sample</code><code class="calibre24"> </code><code class="o">=</code><code class="calibre24"> </code><code class="n">Timer</code><code class="o">.</code><code class="na">start</code><code class="o">(</code><code class="o">)</code><code class="o">;</code><code class="calibre24">
</code><code class="k">try</code><code class="calibre24"> </code><code class="o">{</code><code class="calibre24">
</code><code class="calibre24">  </code><code class="c">// Some operation that might fail...
</code><code class="calibre24">
</code><code class="calibre24">  </code><code class="n">sample</code><code class="o">.</code><code class="na">stop</code><code class="o">(</code><code class="calibre24">
</code><code class="calibre24">    </code><code class="n">registry</code><code class="o">.</code><code class="na">timer</code><code class="o">(</code><code class="calibre24">
</code><code class="calibre24">      </code><code class="s">"my.operation"</code><code class="o">,</code><code class="calibre24">
</code><code class="calibre24">      </code><code class="n">Tags</code><code class="o">.</code><code class="na">of</code><code class="o">(</code><code class="calibre24">
</code><code class="calibre24">        </code><code class="s">"exception"</code><code class="o">,</code><code class="calibre24"> </code><code class="s">"none"</code><code class="o">,</code><code class="calibre24"> </code><a class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre" id="co_charting_and_alerting_CO1-1" href="part0009_split_014.html#callout_charting_and_alerting_CO1-1"><img src="../images/00112.png" alt="1" class="calibre66"/></a><code class="calibre24">
</code><code class="calibre24">        </code><code class="s">"outcome"</code><code class="o">,</code><code class="calibre24"> </code><code class="s">"success"</code><code class="calibre24">
</code><code class="calibre24">      </code><code class="o">)</code><code class="calibre24">
</code><code class="calibre24">    </code><code class="o">)</code><code class="calibre24">
</code><code class="calibre24">  </code><code class="o">)</code><code class="o">;</code><code class="calibre24">
</code><code class="o">}</code><code class="calibre24"> </code><code class="k">catch</code><code class="o">(</code><code class="n">Exception</code><code class="calibre24"> </code><code class="n">e</code><code class="o">)</code><code class="calibre24"> </code><code class="o">{</code><code class="calibre24">
</code><code class="calibre24">  </code><code class="n">sample</code><code class="o">.</code><code class="na">stop</code><code class="o">(</code><code class="calibre24">
</code><code class="calibre24">    </code><code class="n">registry</code><code class="o">.</code><code class="na">timer</code><code class="o">(</code><code class="calibre24">
</code><code class="calibre24">      </code><code class="s">"my.operation"</code><code class="o">,</code><code class="calibre24">
</code><code class="calibre24">      </code><code class="n">Tags</code><code class="o">.</code><code class="na">of</code><code class="o">(</code><code class="calibre24">
</code><code class="calibre24">        </code><code class="s">"exception"</code><code class="o">,</code><code class="calibre24"> </code><code class="n">e</code><code class="o">.</code><code class="na">getClass</code><code class="o">(</code><code class="o">)</code><code class="o">.</code><code class="na">getName</code><code class="o">(</code><code class="o">)</code><code class="o">,</code><code class="calibre24"> </code><a class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre" id="co_charting_and_alerting_CO1-2" href="part0009_split_014.html#callout_charting_and_alerting_CO1-2"><img src="../images/00059.png" alt="2" class="calibre66"/></a><code class="calibre24">
</code><code class="calibre24">        </code><code class="s">"outcome"</code><code class="o">,</code><code class="calibre24"> </code><code class="s">"failure"</code><code class="calibre24">
</code><code class="calibre24">      </code><code class="o">)</code><code class="calibre24">
</code><code class="calibre24">    </code><code class="o">)</code><code class="calibre24">
</code><code class="calibre24">  </code><code class="o">)</code><code class="o">;</code><code class="calibre24">
</code><code class="o">}</code></pre></div>
<dl class="calibre20">
<dt class="calibre21"><a class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre" id="callout_charting_and_alerting_CO1-1" href="part0009_split_014.html#co_charting_and_alerting_CO1-1"><img src="../images/00112.png" alt="1" class="calibre66"/></a></dt>
<dd class="calibre67"><p class="calibre68">Some monitoring systems like Prometheus expect a consistent set of tag keys to appear on metrics with the same name. So even though there is no exception here, we should tag it with some placeholder value like “none” to mirror what tags are present in the failure cases as well.</p></dd>
<dt class="calibre21"><a class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre" id="callout_charting_and_alerting_CO1-2" href="part0009_split_014.html#co_charting_and_alerting_CO1-2"><img src="../images/00059.png" alt="2" class="calibre66"/></a></dt>
<dd class="calibre67"><p class="calibre68">Perhaps you have a way of better cataloging the failure conditions and can provide a more descriptive tag value here, but even adding the exception class name can go a long way toward understanding what <em class="calibre12">kinds</em> of failures there are. <code class="calibre24">NullPointerException</code> is a very different type of exception than a poorly handled connection timeout on a call to a downstream service. When error ratio spikes, it’s useful to be able to drill down on the exception name to get a brief glimpse at what the error is. From this exception name, you can hop over to your debuggability observability tools like logs and search for occurrences of the exception name around the time of the alert condition.</p></dd>
</dl>
</div></section>













</div></section>













</div></section></div>



  

<div id="sbo-rt-content" class="calibre2">
<section data-type="chapter" type="chapter" data-pdf-bookmark="Chapter 4. Charting and Alerting" class="calibre3">
<div class="preface" id="ch_charting_alerting">
<section data-type="sect1" data-pdf-bookmark="Service Level Indicators for Every Java Microservice" class="calibre3">
<div class="preface" id="idm45139267438056">
<section data-type="sect2" data-pdf-bookmark="Errors" class="calibre3">
<div class="preface" id="kpi_errors">
<div data-type="warning" type="warning" class="calibre30"><h1 class="calibre69" id="calibre_pb_15">Be Careful with Class.getSimpleName(), etc., as a Tag Value</h1>
<p class="author1">Be aware of the fact that <code class="calibre24">Class.getSimpleName()</code> and <code class="calibre24">Class.getCanonicalName()</code> can return null or empty values, for example in the case of anonymous class instances. If you use one of them as a tag value, at least null/empty check the value and fall back on <code class="calibre24">Class.getName()</code>.</p>
</div>

<p class="author1">For HTTP request metrics, for example, Spring Boot automatically tags <code class="calibre24">http.server.requests</code> with a <code class="calibre24">status</code> tag indicating the HTTP status code and an <code class="calibre24">outcome</code> tag that is one of <code class="calibre24">SUCCESS</code>, <code class="calibre24">CLIENT_ERROR</code>, or <code class="calibre24">SERVER_ERROR</code>.</p>

<p class="author1">Based on this tag, it is possible to plot the error <em class="calibre12">rate</em> per interval. Error rate is difficult to establish an alert threshold for, because it can fluctuate wildly under the same failure conditions, depending on how much traffic is coming through the system.</p>

<p class="author1">For Atlas, use the <code class="calibre24">:and</code> operator to select only <code class="calibre24">SERVER_ERROR</code> outcomes, as shown in <a data-type="xref" href="part0009_split_015.html#http_error_rate_atlas" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre">Example 4-7</a>.</p>
<div id="http_error_rate_atlas" data-type="example" class="calibre61">
<h5 class="calibre62"><span class="keep-together">Example 4-7. </span>Error rate of HTTP server requests in Atlas</h5>

<pre data-type="programlisting" class="calibre63"># don't do this because it fluctuates with throughput!
name,http.server.requests,:eq,
outcome,SERVER_ERROR,:eq,
:and,
uri,$ENDPOINT,:eq,:cq</pre></div>

<p class="author1">For Prometheus, use a tag selector, as shown in <a data-type="xref" href="part0009_split_015.html#http_error_rate_prometheus" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre">Example 4-8</a>.</p>
<div id="http_error_rate_prometheus" data-type="example" class="calibre61">
<h5 class="calibre62"><span class="keep-together">Example 4-8. </span>Error rate of HTTP server requests in Prometheus</h5>

<pre data-type="programlisting" class="calibre63"># don't do this because it fluctuates with throughput!
sum(
  rate(
    http_server_requests_seconds_count{outcome="SERVER_ERROR", uri="$ENDPOINT"}[2m]
  )
)</pre></div>

<p class="author1">If every 10th request fails, and 100 requests/second are coming through the system, then the error rate is 10 failures/second. If 1,000 requests/second are coming through the system, the error rate climbs to 100 failures/second! In both cases, the error <em class="calibre12">ratio</em> relative to throughput is 10%. This error ratio normalizes the rate and is easy to set a fixed threshold for. In <a data-type="xref" href="part0009_split_015.html#error_ratio_vs_rate" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre">Figure 4-23</a>, the error ratio hovers around 10–15% in spite of the fact that throughput, and therefore error rate, spikes.</p>

<figure class="calibre32"><div id="error_ratio_vs_rate" class="figure">
<img src="../images/00010.png" alt="srej 0423" class="calibre123"/>
<h6 class="calibre34"><span class="keep-together">Figure 4-23. </span>Error ratio versus error rate</h6>
</div></figure>

<p class="author1">The coarse-grained outcome tag is used to construct queries that represent the error ratio of the timed operation. In the case of <code class="calibre24">http.server.requests</code>, this is the ratio of <code class="calibre24">SERVER_ERROR</code> to the total number of requests.</p>

<p class="author1">For Atlas, use the <code class="calibre24">:div</code> function to divide <code class="calibre24">SERVER_ERROR</code> outcomes by the total count of all requests, as shown in <a data-type="xref" href="part0009_split_015.html#http_error_ratio_atlas" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre">Example 4-9</a>.</p>
<div id="http_error_ratio_atlas" data-type="example" class="calibre61">
<h5 class="calibre62"><span class="keep-together">Example 4-9. </span>Error ratio of HTTP server requests in Atlas</h5>

<pre data-type="programlisting" class="calibre63">name,http.server.requests,:eq,
:dup,
outcome,SERVER_ERROR,:eq,
:div,
uri,$ENDPOINT,:eq,:cq</pre></div>

<p class="author1">For Prometheus, use the <code class="calibre24">/</code> operator similarly, as in <a data-type="xref" href="part0009_split_015.html#http_error_ratio_prometheus" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre">Example 4-10</a>.</p>
<div id="http_error_ratio_prometheus" data-type="example" class="calibre61">
<h5 class="calibre62"><span class="keep-together">Example 4-10. </span>Error ratio of HTTP server requests in Prometheus</h5>

<pre data-type="programlisting" class="calibre63">sum(
  rate(
    http_server_requests_seconds_count{outcome="SERVER_ERROR", uri="$ENDPOINT"}[2m]
  )
) /
sum(
  rate(
    http_server_requests_seconds_count{uri="$ENDPOINT"}[2m]
  )
)</pre></div>
</div></section>













</div></section>













</div></section></div>



  

<div id="sbo-rt-content" class="calibre2">
<section data-type="chapter" type="chapter" data-pdf-bookmark="Chapter 4. Charting and Alerting" class="calibre3">
<div class="preface" id="ch_charting_alerting">
<section data-type="sect1" data-pdf-bookmark="Service Level Indicators for Every Java Microservice" class="calibre3">
<div class="preface" id="idm45139267438056">
<section data-type="sect2" data-pdf-bookmark="Errors" class="calibre3">
<div class="preface" id="kpi_errors">
<div data-type="note" type="note" class="calibre28"><h1 class="calibre54" id="calibre_pb_16">Error Rate Is Better Than Error Ratio for Low-Throughput Services</h1>
<p class="author1"><a data-type="indexterm" data-primary="error ratio" data-secondary="error rate versus" id="idm45139267063272" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre"/>In general, prefer error ratio to error rate, <em class="calibre12">unless</em> the endpoint has a very low throughput. In this case, even a small difference in errors can lead to wild shifts in the error ratio. It is more appropriate in these situations to pick a fixed error rate threshold.<a data-type="indexterm" data-startref="ix_ch04-asciidoc27" id="idm45139267061560" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre"/><a data-type="indexterm" data-startref="ix_ch04-asciidoc26" id="idm45139267060856" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre"/></p>
</div>

<p class="author1">Error rate and ratio are just one view of a timer. Latency is the other essential view.</p>
</div></section>













</div></section>













</div></section></div>



  

<div id="sbo-rt-content" class="calibre2">
<section data-type="chapter" type="chapter" data-pdf-bookmark="Chapter 4. Charting and Alerting" class="calibre3">
<div class="preface" id="ch_charting_alerting">
<section data-type="sect1" data-pdf-bookmark="Service Level Indicators for Every Java Microservice" class="calibre3">
<div class="preface" id="idm45139267438056">
<section data-type="sect2" data-pdf-bookmark="Latency" class="calibre3"><div class="preface" id="kpi_latency">
<h2 class="calibre37" id="8ILV9-2d714b853a094e9a910510217e0e3d73">Latency</h2>

<p class="author1"><a data-type="indexterm" data-primary="charting and alerting" data-secondary="latency" id="ix_ch04-asciidoc28" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre"/><a data-type="indexterm" data-primary="latency" data-secondary="SLIs and" id="ix_ch04-asciidoc29" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre"/><a data-type="indexterm" data-primary="service level indicators (SLIs)" data-secondary="latency" id="ix_ch04-asciidoc30" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre"/>Alert on maximum latency (in this case meaning maximum observed for each interval), and use high-percentile approximations like the 99th percentile for comparative analysis, as shown in <a data-type="xref" href="part0010_split_013.html#9H5VC-2d714b853a094e9a910510217e0e3d73" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre">“Automated Canary Analysis”</a>. Popular Java web frameworks, as part of their “white box” (see <a data-type="xref" href="part0006_split_001.html#blackbox_whitebox" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre">“Black Box Versus White Box Monitoring”</a>) autoconfiguration of metrics, offer instrumentation of inbound and outbound requests with rich tags. I’ll present details of Spring Boot’s automatic instrumentation of requests, but most other popular Java web frameworks have done something very similar with Micrometer.</p>










<section data-type="sect3" data-pdf-bookmark="Server (inbound) requests" class="calibre3"><div class="preface" id="idm45139267052280">
<h3 class="calibre51">Server (inbound) requests</h3>

<p class="author1"><a data-type="indexterm" data-primary="http.server.requests" id="ix_ch04-asciidoc31" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre"/><a data-type="indexterm" data-primary="inbound (server) requests" id="ix_ch04-asciidoc32" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre"/><a data-type="indexterm" data-primary="latency" data-secondary="server (inbound) requests" id="ix_ch04-asciidoc33" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre"/><a data-type="indexterm" data-primary="server (inbound) requests" id="ix_ch04-asciidoc34" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre"/><a data-type="indexterm" data-primary="Spring Boot" data-secondary="server (inbound) requests" id="ix_ch04-asciidoc35" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre"/>Spring Boot autoconfigures a timer metric called <code class="calibre24">http.server.requests</code> for both blocking and reactive REST endpoints. If the latency of a particular endpoint(s) is a key indicator of the performance of an application and it will also be used for comparative analysis, then add the <code class="calibre24">management.metrics.distribution.percentiles-histogram.http.server.requests=true</code> property to your <code class="calibre24">application.properties</code> to export percentile histograms from your application. To be more fine-grained about enabling percentile histograms for a particular set of API endpoints, you can add the <code class="calibre24">@Timed</code> annotation in Spring Boot, like in <a data-type="xref" href="part0009_split_017.html#timed_histogram" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre">Example 4-11</a>.</p>
<div id="timed_histogram" data-type="example" class="calibre61">
<h5 class="calibre62"><span class="keep-together">Example 4-11. </span>Using @Timed to add histograms to just a single endpoint</h5>

<pre data-type="programlisting" data-code-language="java" class="calibre63"><code class="nd">@Timed</code><code class="o">(</code><code class="n">histogram</code> <code class="o">=</code> <code class="k">true</code><code class="o">)</code>
<code class="nd">@GetMapping</code><code class="o">(</code><code class="s">"/api/something"</code><code class="o">)</code>
<code class="n">Something</code> <code class="nf">getSomething</code><code class="o">()</code> <code class="o">{</code>
  <code class="o">...</code>
<code class="o">}</code></pre></div>

<p class="author1">Alternatively, you can add a <code class="calibre24">MeterFilter</code> that responds to a tag, as shown in <a data-type="xref" href="part0009_split_017.html#meter_filter_histogram" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre">Example 4-12</a>.</p>
<div id="meter_filter_histogram" data-type="example" class="calibre61">
<h5 class="calibre62"><span class="keep-together">Example 4-12. </span>A MeterFilter that adds percentile histograms for certain endpoints</h5>

<pre data-type="programlisting" data-code-language="java" class="calibre63"><code class="nd">@Bean</code>
<code class="n">MeterFilter</code> <code class="nf">histogramsForSomethingEndpoints</code><code class="o">()</code> <code class="o">{</code>
  <code class="k">return</code> <code class="k">new</code> <code class="nf">MeterFilter</code><code class="o">()</code> <code class="o">{</code>
    <code class="nd">@Override</code>
    <code class="k">public</code> <code class="n">DistributionStatisticConfig</code> <code class="nf">configure</code><code class="o">(</code><code class="n">Meter</code><code class="o">.</code><code class="na">Id</code> <code class="n">id</code><code class="o">,</code>
        <code class="n">DistributionStatisticConfig</code> <code class="n">config</code><code class="o">)</code> <code class="o">{</code>
      <code class="k">if</code><code class="o">(</code><code class="n">id</code><code class="o">.</code><code class="na">getName</code><code class="o">().</code><code class="na">equals</code><code class="o">(</code><code class="s">"http.server.requests"</code><code class="o">)</code> <code class="o">&amp;&amp;</code>
          <code class="n">id</code><code class="o">.</code><code class="na">getTag</code><code class="o">(</code><code class="s">"uri"</code><code class="o">).</code><code class="na">startsWith</code><code class="o">(</code><code class="s">"/api/something"</code><code class="o">))</code> <code class="o">{</code>
        <code class="k">return</code> <code class="n">DistributionStatisticConfig</code><code class="o">.</code><code class="na">builder</code><code class="o">()</code>
            <code class="o">.</code><code class="na">percentilesHistogram</code><code class="o">(</code><code class="k">true</code><code class="o">)</code>
            <code class="o">.</code><code class="na">build</code><code class="o">()</code>
            <code class="o">.</code><code class="na">merge</code><code class="o">(</code><code class="n">config</code><code class="o">);</code>
      <code class="o">}</code>
      <code class="k">return</code> <code class="n">config</code><code class="o">;</code>
    <code class="o">}</code>
  <code class="o">};</code>
<code class="o">}</code></pre></div>

<p class="author1">For Atlas, <a data-type="xref" href="part0009_split_017.html#atlas_latency" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre">Example 4-13</a> shows how to compare max latency against some predetermined threshold.</p>
<div id="atlas_latency" data-type="example" class="calibre61">
<h5 class="calibre62"><span class="keep-together">Example 4-13. </span>Atlas max API latency</h5>

<pre data-type="programlisting" class="calibre63">name,http.server.requests,:eq,
statistic,max,:eq,
:and,
$THRESHOLD,
:gt</pre></div>

<p class="author1">For Prometheus, <a data-type="xref" href="part0009_split_017.html#prometheus_latency" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre">Example 4-14</a> is a simple comparison.</p>
<div id="prometheus_latency" data-type="example" class="calibre61">
<h5 class="calibre62"><span class="keep-together">Example 4-14. </span>Prometheus max API latency</h5>

<pre data-type="programlisting" class="calibre63">http_server_requests_seconds_max &gt; $THRESHOLD</pre></div>

<p class="author1">The tags that are added to <code class="calibre24">http.server.requests</code> are customizable. For the blocking Spring WebMVC model, use a <code class="calibre24">WebMvcTagsProvider</code>. For example, we could extract information about the browser and its version from the “User-Agent” request header, as shown in <a data-type="xref" href="part0009_split_017.html#webmvc_tags" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre">Example 4-15</a>. This sample uses the MIT-licensed <a href="https://oreil.ly/mkLpG" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre">Browscap</a> library to extract browser information from the user-agent header.</p>
<div id="webmvc_tags" data-type="example" class="calibre61">
<h5 class="calibre62"><span class="keep-together">Example 4-15. </span>Adding browser tags to Spring WebMVC metrics</h5>

<pre data-type="programlisting" data-code-language="java" class="calibre63"><code class="nd">@Configuration</code>
<code class="k">public</code> <code class="k">class</code> <code class="nc">MetricsConfiguration</code> <code class="o">{</code>
  <code class="nd">@Bean</code>
  <code class="n">WebMvcTagsProvider</code> <code class="nf">customizeRestMetrics</code><code class="o">()</code> <code class="k">throws</code> <code class="n">IOException</code><code class="o">,</code> <code class="n">ParseException</code> <code class="o">{</code>
    <code class="n">UserAgentParser</code> <code class="n">userAgentParser</code> <code class="o">=</code> <code class="k">new</code> <code class="n">UserAgentService</code><code class="o">().</code><code class="na">loadParser</code><code class="o">();</code>

    <code class="k">return</code> <code class="k">new</code> <code class="nf">DefaultWebMvcTagsProvider</code><code class="o">()</code> <code class="o">{</code>
      <code class="nd">@Override</code>
      <code class="k">public</code> <code class="n">Iterable</code><code class="o">&lt;</code><code class="n">Tag</code><code class="o">&gt;</code> <code class="nf">getTags</code><code class="o">(</code><code class="n">HttpServletRequest</code> <code class="n">request</code><code class="o">,</code>
        <code class="n">HttpServletResponse</code> <code class="n">response</code><code class="o">,</code> <code class="n">Object</code> <code class="n">handler</code><code class="o">,</code> <code class="n">Throwable</code> <code class="n">exception</code><code class="o">)</code> <code class="o">{</code>

        <code class="n">Capabilities</code> <code class="n">capabilities</code> <code class="o">=</code> <code class="n">userAgentParser</code><code class="o">.</code><code class="na">parse</code><code class="o">(</code><code class="n">request</code>
          <code class="o">.</code><code class="na">getHeader</code><code class="o">(</code><code class="s">"User-Agent"</code><code class="o">));</code>

        <code class="k">return</code> <code class="n">Tags</code>
          <code class="o">.</code><code class="na">concat</code><code class="o">(</code>
            <code class="k">super</code><code class="o">.</code><code class="na">getTags</code><code class="o">(</code><code class="n">request</code><code class="o">,</code> <code class="n">response</code><code class="o">,</code> <code class="n">handler</code><code class="o">,</code> <code class="n">exception</code><code class="o">),</code>
            <code class="s">"browser"</code><code class="o">,</code> <code class="n">capabilities</code><code class="o">.</code><code class="na">getBrowser</code><code class="o">(),</code>
            <code class="s">"browser.version"</code><code class="o">,</code> <code class="n">capabilities</code><code class="o">.</code><code class="na">getBrowserMajorVersion</code><code class="o">()</code>
          <code class="o">);</code>
      <code class="o">}</code>
    <code class="o">};</code>
  <code class="o">}</code>
<code class="o">}</code></pre></div>

<p class="author1">For Spring WebFlux (the nonblocking reactive model), configure a <code class="calibre24">WebFluxTagsProvider</code> similarly, as in <a data-type="xref" href="part0009_split_017.html#webflux_tags" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre">Example 4-16</a>.</p>
<div id="webflux_tags" data-type="example" class="calibre61">
<h5 class="calibre62"><span class="keep-together">Example 4-16. </span>Adding browser tags to Spring WebFlux metrics</h5>

<pre data-type="programlisting" data-code-language="java" class="calibre63"><code class="nd">@Configuration</code>
<code class="k">public</code> <code class="k">class</code> <code class="nc">MetricsConfiguration</code> <code class="o">{</code>
  <code class="nd">@Bean</code>
  <code class="n">WebFluxTagsProvider</code> <code class="nf">customizeRestMetrics</code><code class="o">()</code> <code class="k">throws</code> <code class="n">IOException</code><code class="o">,</code> <code class="n">ParseException</code> <code class="o">{</code>
      <code class="n">UserAgentParser</code> <code class="n">userAgentParser</code> <code class="o">=</code> <code class="k">new</code> <code class="n">UserAgentService</code><code class="o">().</code><code class="na">loadParser</code><code class="o">();</code>

      <code class="k">return</code> <code class="k">new</code> <code class="nf">DefaultWebFluxTagsProvider</code><code class="o">()</code> <code class="o">{</code>
          <code class="nd">@Override</code>
          <code class="k">public</code> <code class="n">Iterable</code><code class="o">&lt;</code><code class="n">Tag</code><code class="o">&gt;</code> <code class="nf">httpRequestTags</code><code class="o">(</code><code class="n">ServerWebExchange</code> <code class="n">exchange</code><code class="o">,</code>
              <code class="n">Throwable</code> <code class="n">exception</code><code class="o">)</code> <code class="o">{</code>

            <code class="n">Capabilities</code> <code class="n">capabilities</code> <code class="o">=</code> <code class="n">userAgentParser</code><code class="o">.</code><code class="na">parse</code><code class="o">(</code><code class="n">exchange</code><code class="o">.</code><code class="na">getRequest</code><code class="o">()</code>
              <code class="o">.</code><code class="na">getHeaders</code><code class="o">().</code><code class="na">getFirst</code><code class="o">(</code><code class="s">"User-Agent"</code><code class="o">));</code>

            <code class="k">return</code> <code class="n">Tags</code>
              <code class="o">.</code><code class="na">concat</code><code class="o">(</code>
                <code class="k">super</code><code class="o">.</code><code class="na">httpRequestTags</code><code class="o">(</code><code class="n">exchange</code><code class="o">,</code> <code class="n">exception</code><code class="o">),</code>
                <code class="s">"browser"</code><code class="o">,</code> <code class="n">capabilities</code><code class="o">.</code><code class="na">getBrowser</code><code class="o">(),</code>
                <code class="s">"browser.version"</code><code class="o">,</code> <code class="n">capabilities</code><code class="o">.</code><code class="na">getBrowserMajorVersion</code><code class="o">()</code>
              <code class="o">);</code>
          <code class="o">}</code>
      <code class="o">};</code>
  <code class="o">}</code>
<code class="o">}</code></pre></div>

<p class="author1">Note that the <code class="calibre24">http.server.requests</code> timer only begins timing a request once it is being processed by the service. If the request thread pool is routinely at capacity, requests from users are sitting in the thread pool waiting to be handled, and this elapse of time is very real to the user waiting for a response. The missing information in <code class="calibre24">http.server.requests</code> is one example of a larger problem first described by Gil Tene called coordinated omission (see <a data-type="xref" href="part0007_split_014.html#coordinated_omission" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre">“Coordinated Omission”</a>), which comes in several other forms.</p>

<p class="author1">It is also useful to monitor latency from the perspective of the caller (client). In this case, by client I generally mean service-to-service callers and not human consumers to your API gateway or first service interaction. A service’s view of its own latency doesn’t include the effects of network delays or  thread pool contention (e.g., Tomcat’s request thread pool or the thread pool of a proxy like Nginx).<a data-type="indexterm" data-startref="ix_ch04-asciidoc35" id="idm45139266753288" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre"/><a data-type="indexterm" data-startref="ix_ch04-asciidoc34" id="idm45139266752584" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre"/><a data-type="indexterm" data-startref="ix_ch04-asciidoc33" id="idm45139266751912" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre"/><a data-type="indexterm" data-startref="ix_ch04-asciidoc32" id="idm45139266751240" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre"/><a data-type="indexterm" data-startref="ix_ch04-asciidoc31" id="idm45139266750568" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre"/></p>
</div></section>













<section data-type="sect3" data-pdf-bookmark="Client (outbound) requests" class="calibre3"><div class="preface" id="idm45139267051688">
<h3 class="calibre51">Client (outbound) requests</h3>

<p class="author1"><a data-type="indexterm" data-primary="client (outbound) requests" id="ix_ch04-asciidoc36" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre"/><a data-type="indexterm" data-primary="http.client.requests" id="ix_ch04-asciidoc37" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre"/><a data-type="indexterm" data-primary="latency" data-secondary="client (outbound) requests" id="ix_ch04-asciidoc38" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre"/><a data-type="indexterm" data-primary="outbound (client) requests" id="ix_ch04-asciidoc39" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre"/><a data-type="indexterm" data-primary="Spring Boot" data-secondary="client (outbound) requests" id="ix_ch04-asciidoc40" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre"/>Spring Boot also autoconfigures a timer metric called <code class="calibre24">http.client.requests</code> for both blocking and reactive <em class="calibre12">outbound</em> calls. This allows you to instead (or also) monitor a service’s latency from the perspective of all of its callers, provided they each make the same conclusion about what the name of the called service is. <a data-type="xref" href="part0009_split_017.html#http_client_metrics" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre">Figure 4-24</a> shows three service instances calling the same service.</p>

<figure class="calibre32"><div id="http_client_metrics" class="figure">
<img src="../images/00091.png" alt="srej 0424" class="calibre124"/>
<h6 class="calibre34"><span class="keep-together">Figure 4-24. </span>HTTP client metrics from multiple callers</h6>
</div></figure>

<p class="author1">We can identify the performance of a particular endpoint for the called service by selecting on the <code class="calibre24">uri</code> and <code class="calibre24">serviceName</code> tags. By aggregating over all other tags, we see the performance of the endpoint across all callers. Dimensionally drilling down by the  <code class="calibre24">clientName</code> tag would show the service’s performance from just that client’s perspective. Even if the called service processes every request in the same amount of time, the client perspective could vary (e.g., if one client is deployed in a different zone or region). Where there is the possibility for this variance between clients, you can use something like Prometheus’s <code class="calibre24">topk</code> query to compare against an alert threshold so that the totality of the experience of an endpoint’s performance for all clients doesn’t wash away the outlier for some particular client, as shown in <a data-type="xref" href="part0009_split_017.html#max_client_latency_by_client" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre">Example 4-17</a>.</p>
<div id="max_client_latency_by_client" data-type="example" class="calibre61">
<h5 class="calibre62"><span class="keep-together">Example 4-17. </span>Max outbound request latency by client name</h5>

<pre data-type="programlisting" class="calibre63">topk(
  1,
  sum(
    rate(
      http_client_requests_seconds_max{serviceName="CALLED", uri="/api/..."}[2m]
    )
  ) by (clientName)
) &gt; $THRESHOLD</pre></div>

<p class="author1">To autoconfigure HTTP client instrumentation for Spring’s <code class="calibre24">RestTemplate</code> (blocking) and <code class="calibre24">WebClient</code> (nonblocking) interfaces, you do need to treat path variables and request parameters a certain way. Specifically, you have to let the implementations do path variable and request parameter substitution for you rather than using string concatenation or a similar technique to construct a path, as shown in <a data-type="xref" href="part0009_split_017.html#rest_template_uri_tagging" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre">Example 4-18</a>.</p>
<div id="rest_template_uri_tagging" data-type="example" class="calibre61">
<h5 class="calibre62"><span class="keep-together">Example 4-18. </span>Allowing RestTemplate to handle path variable substitution</h5>

<pre data-type="programlisting" data-code-language="java" class="calibre63"><code class="nd">@RestController</code><code class="calibre24">
</code><code class="k">public</code><code class="calibre24"> </code><code class="k">class</code><code class="calibre24"> </code><code class="nc">CustomerController</code><code class="calibre24"> </code><code class="o">{</code><code class="calibre24"> </code><a class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre" id="co_charting_and_alerting_CO2-1" href="part0009_split_017.html#callout_charting_and_alerting_CO2-1"><img src="../images/00112.png" alt="1" class="calibre66"/></a><code class="calibre24">
</code><code class="calibre24">  </code><code class="k">private</code><code class="calibre24"> </code><code class="k">final</code><code class="calibre24"> </code><code class="n">RestTemplate</code><code class="calibre24"> </code><code class="n">client</code><code class="o">;</code><code class="calibre24">
</code><code class="calibre24">
</code><code class="calibre24">  </code><code class="k">public</code><code class="calibre24"> </code><code class="nf">CustomerController</code><code class="o">(</code><code class="n">RestTemplate</code><code class="calibre24"> </code><code class="n">client</code><code class="o">)</code><code class="calibre24"> </code><code class="o">{</code><code class="calibre24">
</code><code class="calibre24">    </code><code class="k">this</code><code class="o">.</code><code class="na">client</code><code class="calibre24"> </code><code class="o">=</code><code class="calibre24"> </code><code class="n">client</code><code class="o">;</code><code class="calibre24">
</code><code class="calibre24">  </code><code class="o">}</code><code class="calibre24">
</code><code class="calibre24">
</code><code class="calibre24">  </code><code class="nd">@GetMapping</code><code class="o">(</code><code class="s">"/customers"</code><code class="o">)</code><code class="calibre24">
</code><code class="calibre24">  </code><code class="k">public</code><code class="calibre24"> </code><code class="n">Customer</code><code class="calibre24"> </code><code class="nf">findCustomer</code><code class="o">(</code><code class="nd">@RequestParam</code><code class="calibre24"> </code><code class="n">String</code><code class="calibre24"> </code><code class="n">q</code><code class="o">)</code><code class="calibre24"> </code><code class="o">{</code><code class="calibre24">
</code><code class="calibre24">    </code><code class="n">String</code><code class="calibre24"> </code><code class="n">customerId</code><code class="o">;</code><code class="calibre24">
</code><code class="calibre24">    </code><code class="c">// ... Look up customer ID according to 'q'
</code><code class="calibre24">
</code><code class="calibre24">    </code><code class="k">return</code><code class="calibre24"> </code><code class="n">client</code><code class="o">.</code><code class="na">getForEntity</code><code class="o">(</code><code class="calibre24">
</code><code class="calibre24">      </code><code class="s">"http://customerService/customer/{id}?detail={detail}"</code><code class="o">,</code><code class="calibre24">
</code><code class="calibre24">      </code><code class="n">Customer</code><code class="o">.</code><code class="na">class</code><code class="o">,</code><code class="calibre24">
</code><code class="calibre24">      </code><code class="n">customerId</code><code class="o">,</code><code class="calibre24">
</code><code class="calibre24">      </code><code class="s">"no-address"</code><code class="calibre24">
</code><code class="calibre24">    </code><code class="o">)</code><code class="o">;</code><code class="calibre24">
</code><code class="calibre24">  </code><code class="o">}</code><code class="calibre24">
</code><code class="o">}</code><code class="calibre24">
</code><code class="calibre24">
</code><code class="o">.</code><code class="o">.</code><code class="o">.</code><code class="calibre24">
</code><code class="calibre24">
</code><code class="nd">@Configuration</code><code class="calibre24">
</code><code class="k">public</code><code class="calibre24"> </code><code class="k">class</code><code class="calibre24"> </code><code class="nc">RestTemplateConfiguration</code><code class="calibre24"> </code><code class="o">{</code><code class="calibre24">
</code><code class="calibre24">  </code><code class="nd">@Bean</code><code class="calibre24">
</code><code class="calibre24">  </code><code class="n">RestTemplateBuilder</code><code class="calibre24"> </code><code class="nf">restTemplateBuilder</code><code class="o">(</code><code class="o">)</code><code class="calibre24"> </code><code class="o">{</code><code class="calibre24"> </code><a class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre" id="co_charting_and_alerting_CO2-2" href="part0009_split_017.html#callout_charting_and_alerting_CO2-2"><img src="../images/00059.png" alt="2" class="calibre66"/></a><code class="calibre24">
</code><code class="calibre24">    </code><code class="k">return</code><code class="calibre24"> </code><code class="k">new</code><code class="calibre24"> </code><code class="nf">RestTemplateBuilder</code><code class="o">(</code><code class="o">)</code><code class="calibre24">
</code><code class="calibre24">      </code><code class="o">.</code><code class="na">addAdditionalInterceptors</code><code class="o">(</code><code class="o">.</code><code class="o">.</code><code class="o">)</code><code class="calibre24">
</code><code class="calibre24">      </code><code class="o">.</code><code class="na">build</code><code class="o">(</code><code class="o">)</code><code class="o">;</code><code class="calibre24">
</code><code class="calibre24">  </code><code class="o">}</code><code class="calibre24">
</code><code class="o">}</code></pre></div>
<dl class="calibre20">
<dt class="calibre21"><a class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre" id="callout_charting_and_alerting_CO2-1" href="part0009_split_017.html#co_charting_and_alerting_CO2-1"><img src="../images/00112.png" alt="1" class="calibre66"/></a></dt>
<dd class="calibre67"><p class="calibre68">Sounds nefarious?</p></dd>
<dt class="calibre21"><a class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre" id="callout_charting_and_alerting_CO2-2" href="part0009_split_017.html#co_charting_and_alerting_CO2-2"><img src="../images/00059.png" alt="2" class="calibre66"/></a></dt>
<dd class="calibre67"><p class="calibre68">To take advantage of Spring Boot’s autoconfiguration of <code class="calibre24">RestTemplate</code> metrics, ensure that you are creating any custom bean wirings for <code class="calibre24">RestTemplateBuilder</code> and not <code class="calibre24">RestTemplate</code> (and note that Spring also provides a <code class="calibre24">RestTemplateBuilder</code> for you automatically with the defaults via autoconfiguration). Spring Boot attaches an additional metrics interceptor to any such beans that it finds. Once the <code class="calibre24">RestTemplate</code> is created, it is too late for this configuration to take place.</p></dd>
</dl>

<p class="author1">The idea is that the <code class="calibre24">uri</code> tag should still contain the requested path with path variables <em class="calibre12">pre-substitution</em> so that you can reason about the total number and latency of requests going to that endpoint regardless of what particular values were being looked up. Also, this is essential to controlling the total number of tags that the <code class="calibre24">http.client.requests</code> metrics contains. Allowing unbounded growth in unique tags would eventually overwhelm the monitoring system (or get really expensive for you if the monitoring system vendor charges by time series).</p>

<p class="author1">The equivalent for the nonblocking <code class="calibre24">WebClient</code> is shown in <a data-type="xref" href="part0009_split_017.html#8IMH3-2d714b853a094e9a910510217e0e3d73" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre">Example 4-19</a>.</p>
<div id="web_client_uri_tagging" data-type="example" class="calibre61">
<h5 class="calibre62" id="8IMH3-2d714b853a094e9a910510217e0e3d73"><span class="keep-together">Example 4-19. </span>Allowing WebClient to handle path variable substitution</h5>

<pre data-type="programlisting" data-code-language="java" class="calibre63"><code class="nd">@RestController</code><code class="calibre24">
</code><code class="k">public</code><code class="calibre24"> </code><code class="k">class</code><code class="calibre24"> </code><code class="nc">CustomerController</code><code class="calibre24"> </code><code class="o">{</code><code class="calibre24"> </code><a class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre" id="co_charting_and_alerting_CO3-1" href="part0009_split_017.html#callout_charting_and_alerting_CO3-1"><img src="../images/00112.png" alt="1" class="calibre66"/></a><code class="calibre24">
</code><code class="calibre24">  </code><code class="k">private</code><code class="calibre24"> </code><code class="k">final</code><code class="calibre24"> </code><code class="n">WebClient</code><code class="calibre24"> </code><code class="n">client</code><code class="o">;</code><code class="calibre24">
</code><code class="calibre24">
</code><code class="calibre24">  </code><code class="k">public</code><code class="calibre24"> </code><code class="nf">CustomerController</code><code class="o">(</code><code class="n">WebClient</code><code class="calibre24"> </code><code class="n">client</code><code class="o">)</code><code class="calibre24"> </code><code class="o">{</code><code class="calibre24">
</code><code class="calibre24">    </code><code class="k">this</code><code class="o">.</code><code class="na">client</code><code class="calibre24"> </code><code class="o">=</code><code class="calibre24"> </code><code class="n">client</code><code class="o">;</code><code class="calibre24">
</code><code class="calibre24">  </code><code class="o">}</code><code class="calibre24">
</code><code class="calibre24">
</code><code class="calibre24">  </code><code class="nd">@GetMapping</code><code class="o">(</code><code class="s">"/customers"</code><code class="o">)</code><code class="calibre24">
</code><code class="calibre24">  </code><code class="k">public</code><code class="calibre24"> </code><code class="n">Mono</code><code class="o">&lt;</code><code class="n">Customer</code><code class="o">&gt;</code><code class="calibre24"> </code><code class="nf">findCustomer</code><code class="o">(</code><code class="nd">@RequestParam</code><code class="calibre24"> </code><code class="n">String</code><code class="calibre24"> </code><code class="n">q</code><code class="o">)</code><code class="calibre24"> </code><code class="o">{</code><code class="calibre24">
</code><code class="calibre24">    </code><code class="n">Mono</code><code class="o">&lt;</code><code class="n">String</code><code class="o">&gt;</code><code class="calibre24"> </code><code class="n">customerId</code><code class="o">;</code><code class="calibre24">
</code><code class="calibre24">    </code><code class="c">// ... Look up customer ID according to 'q', hopefully in a non-blocking way
</code><code class="calibre24">
</code><code class="calibre24">    </code><code class="k">return</code><code class="calibre24"> </code><code class="n">customerId</code><code class="calibre24">
</code><code class="calibre24">      </code><code class="o">.</code><code class="na">flatMap</code><code class="o">(</code><code class="n">id</code><code class="calibre24"> </code><code class="o">-</code><code class="o">&gt;</code><code class="calibre24"> </code><code class="n">webClient</code><code class="calibre24">
</code><code class="calibre24">          </code><code class="o">.</code><code class="na">get</code><code class="o">(</code><code class="o">)</code><code class="calibre24">
</code><code class="calibre24">          </code><code class="o">.</code><code class="na">uri</code><code class="o">(</code><code class="calibre24">
</code><code class="calibre24">            </code><code class="s">"http://customerService/customer/{id}?detail={detail}"</code><code class="o">,</code><code class="calibre24">
</code><code class="calibre24">            </code><code class="n">id</code><code class="o">,</code><code class="calibre24">
</code><code class="calibre24">            </code><code class="s">"no-address"</code><code class="calibre24">
</code><code class="calibre24">          </code><code class="o">)</code><code class="calibre24">
</code><code class="calibre24">          </code><code class="o">.</code><code class="na">retrieve</code><code class="o">(</code><code class="o">)</code><code class="calibre24">
</code><code class="calibre24">          </code><code class="o">.</code><code class="na">bodyToMono</code><code class="o">(</code><code class="n">Customer</code><code class="o">.</code><code class="na">class</code><code class="o">)</code><code class="calibre24">
</code><code class="calibre24">      </code><code class="o">)</code><code class="o">;</code><code class="calibre24">
</code><code class="calibre24">  </code><code class="o">}</code><code class="calibre24">
</code><code class="o">}</code><code class="calibre24">
</code><code class="calibre24">
</code><code class="o">.</code><code class="o">.</code><code class="o">.</code><code class="calibre24">
</code><code class="calibre24">
</code><code class="nd">@Configuration</code><code class="calibre24">
</code><code class="k">public</code><code class="calibre24"> </code><code class="k">class</code><code class="calibre24"> </code><code class="nc">WebClientConfiguration</code><code class="calibre24"> </code><code class="o">{</code><code class="calibre24">
</code><code class="calibre24">  </code><code class="nd">@Bean</code><code class="calibre24">
</code><code class="calibre24">  </code><code class="n">WebClient</code><code class="o">.</code><code class="na">Builder</code><code class="calibre24"> </code><code class="nf">webClientBuilder</code><code class="o">(</code><code class="o">)</code><code class="calibre24"> </code><code class="o">{</code><code class="calibre24"> </code><a class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre" id="co_charting_and_alerting_CO3-2" href="part0009_split_017.html#callout_charting_and_alerting_CO3-2"><img src="../images/00059.png" alt="2" class="calibre66"/></a><code class="calibre24">
</code><code class="calibre24">    </code><code class="k">return</code><code class="calibre24"> </code><code class="n">WebClient</code><code class="calibre24">
</code><code class="calibre24">      </code><code class="o">.</code><code class="na">builder</code><code class="o">(</code><code class="o">)</code><code class="o">;</code><code class="calibre24">
</code><code class="calibre24">  </code><code class="o">}</code><code class="calibre24">
</code><code class="o">}</code></pre></div>
<dl class="calibre20">
<dt class="calibre21"><a class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre" id="callout_charting_and_alerting_CO3-1" href="part0009_split_017.html#co_charting_and_alerting_CO3-1"><img src="../images/00112.png" alt="1" class="calibre66"/></a></dt>
<dd class="calibre67"><p class="calibre68">Sounds nefarious?</p></dd>
<dt class="calibre21"><a class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre" id="callout_charting_and_alerting_CO3-2" href="part0009_split_017.html#co_charting_and_alerting_CO3-2"><img src="../images/00059.png" alt="2" class="calibre66"/></a></dt>
<dd class="calibre67"><p class="calibre68">Make sure you are creating bean wirings for <code class="calibre24">WebClient.Builder</code> and not <code class="calibre24">WebClient</code>. Spring Boot attaches an additional metrics <code class="calibre24">WebClientCustomizer</code> to the builder, not the completed <code class="calibre24">WebClient</code> instance.</p></dd>
</dl>

<p class="author1">While the default set of tags that Spring Boot adds to client metrics is reasonably complete, it is customizable. It is especially common to tag metrics with the value of some request header (or response header). Be sure when you add tag customizations that the total number of possible tag values is well bounded. You shouldn’t add tags for things like unique customer ID (when you can have more than maybe 1,000 customers), a randomly generated request ID, etc. Remember, the purpose of metrics is to get an idea of aggregate performance, not the performance of some individual request.</p>

<p class="author1">As a slightly different example than the one we used in <code class="calibre24">http.server.requests</code> tag customization earlier, we could additionally tag the retrievals of customers by their subscription level, where subscription level is a response header on the retrieval of a customer by ID. By doing so, we could chart the latency and error ratio of the retrieval of premium customers versus basic customers separately. Perhaps the business places a higher level of expectation on the reliability or performance of requests to premium customers, manifesting in a tighter service level agreement based on this custom tag.</p>

<p class="author1">To customize tags for <code class="calibre24">RestTemplate</code>, add your own <code class="calibre24">@Bean RestTemplateExchangeTagsProvider</code>, as shown in <a data-type="xref" href="part0009_split_017.html#rest_template_tags_provider" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre">Example 4-20</a>.</p>
<div id="rest_template_tags_provider" data-type="example" class="calibre61">
<h5 class="calibre62"><span class="keep-together">Example 4-20. </span>Allowing RestTemplate to handle path variable substitution</h5>

<pre data-type="programlisting" data-code-language="java" class="calibre63"><code class="nd">@Configuration</code><code class="calibre24">
</code><code class="k">public</code><code class="calibre24"> </code><code class="k">class</code><code class="calibre24"> </code><code class="nc">MetricsConfiguration</code><code class="calibre24"> </code><code class="o">{</code><code class="calibre24">
</code><code class="calibre24">  </code><code class="nd">@Bean</code><code class="calibre24">
</code><code class="calibre24">  </code><code class="n">RestTemplateExchangeTagsProvider</code><code class="calibre24"> </code><code class="nf">customizeRestTemplateMetrics</code><code class="o">(</code><code class="o">)</code><code class="calibre24"> </code><code class="o">{</code><code class="calibre24">
</code><code class="calibre24">    </code><code class="k">return</code><code class="calibre24"> </code><code class="k">new</code><code class="calibre24"> </code><code class="nf">DefaultRestTemplateExchangeTagsProvider</code><code class="o">(</code><code class="o">)</code><code class="calibre24"> </code><code class="o">{</code><code class="calibre24">
</code><code class="calibre24">      </code><code class="nd">@Override</code><code class="calibre24">
</code><code class="calibre24">      </code><code class="k">public</code><code class="calibre24"> </code><code class="n">Iterable</code><code class="o">&lt;</code><code class="n">Tag</code><code class="o">&gt;</code><code class="calibre24"> </code><code class="nf">getTags</code><code class="o">(</code><code class="n">String</code><code class="calibre24"> </code><code class="n">urlTemplate</code><code class="o">,</code><code class="calibre24">
</code><code class="calibre24">        </code><code class="n">HttpRequest</code><code class="calibre24"> </code><code class="n">request</code><code class="o">,</code><code class="calibre24"> </code><code class="n">ClientHttpResponse</code><code class="calibre24"> </code><code class="n">response</code><code class="o">)</code><code class="calibre24"> </code><code class="o">{</code><code class="calibre24">
</code><code class="calibre24">
</code><code class="calibre24">        </code><code class="k">return</code><code class="calibre24"> </code><code class="n">Tags</code><code class="o">.</code><code class="na">concat</code><code class="o">(</code><code class="calibre24">
</code><code class="calibre24">          </code><code class="k">super</code><code class="o">.</code><code class="na">getTags</code><code class="o">(</code><code class="n">urlTemplate</code><code class="o">,</code><code class="calibre24"> </code><code class="n">request</code><code class="o">,</code><code class="calibre24"> </code><code class="n">response</code><code class="o">)</code><code class="o">,</code><code class="calibre24">
</code><code class="calibre24">          </code><code class="s">"subscription.level"</code><code class="o">,</code><code class="calibre24">
</code><code class="calibre24">          </code><code class="n">Optional</code><code class="calibre24">
</code><code class="calibre24">            </code><code class="o">.</code><code class="na">ofNullable</code><code class="o">(</code><code class="n">response</code><code class="o">.</code><code class="na">getHeaders</code><code class="o">(</code><code class="o">)</code><code class="o">.</code><code class="na">getFirst</code><code class="o">(</code><code class="s">"subscription"</code><code class="o">)</code><code class="o">)</code><code class="calibre24"> </code><a class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre" id="co_charting_and_alerting_CO4-1" href="part0009_split_017.html#callout_charting_and_alerting_CO4-1"><img src="../images/00112.png" alt="1" class="calibre66"/></a><code class="calibre24">
</code><code class="calibre24">            </code><code class="o">.</code><code class="na">orElse</code><code class="o">(</code><code class="s">"basic"</code><code class="o">)</code><code class="calibre24">
</code><code class="calibre24">        </code><code class="o">)</code><code class="o">;</code><code class="calibre24">
</code><code class="calibre24">      </code><code class="o">}</code><code class="calibre24">
</code><code class="calibre24">    </code><code class="o">}</code><code class="o">;</code><code class="calibre24">
</code><code class="calibre24">  </code><code class="o">}</code><code class="calibre24">
</code><code class="o">}</code></pre></div>
<dl class="calibre20">
<dt class="calibre21"><a class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre" id="callout_charting_and_alerting_CO4-1" href="part0009_split_017.html#co_charting_and_alerting_CO4-1"><img src="../images/00112.png" alt="1" class="calibre66"/></a></dt>
<dd class="calibre67"><p class="calibre68">Beware that <code class="calibre24">response.getHeaders().get("subscription")</code> can potentially return <code class="calibre24">null</code>! So whether we use <code class="calibre24">get</code> or <code class="calibre24">getFirst</code>, we need to <code class="calibre24">null</code> check <span class="keep-together">somehow.</span></p></dd>
</dl>

<p class="author1">To customize tags for <code class="calibre24">WebClient</code>, add your own <code class="calibre24">@Bean WebClientExchangeTagsProvider</code>, as shown in <a data-type="xref" href="part0009_split_017.html#web_client_tags_provider" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre">Example 4-21</a>.</p>
<div id="web_client_tags_provider" data-type="example" class="calibre61">
<h5 class="calibre62"><span class="keep-together">Example 4-21. </span>Allowing WebClient to handle path variable substitution</h5>

<pre data-type="programlisting" data-code-language="java" class="calibre63"><code class="nd">@Configuration</code>
<code class="k">public</code> <code class="k">class</code> <code class="nc">MetricsConfiguration</code> <code class="o">{</code>
  <code class="nd">@Bean</code>
  <code class="n">WebClientExchangeTagsProvider</code> <code class="nf">webClientExchangeTagsProvider</code><code class="o">()</code> <code class="o">{</code>
    <code class="k">return</code> <code class="k">new</code> <code class="nf">DefaultWebClientExchangeTagsProvider</code><code class="o">()</code> <code class="o">{</code>
      <code class="nd">@Override</code>
      <code class="k">public</code> <code class="n">Iterable</code><code class="o">&lt;</code><code class="n">Tag</code><code class="o">&gt;</code> <code class="nf">tags</code><code class="o">(</code><code class="n">ClientRequest</code> <code class="n">request</code><code class="o">,</code>
        <code class="n">ClientResponse</code> <code class="n">response</code><code class="o">,</code> <code class="n">Throwable</code> <code class="n">throwable</code><code class="o">)</code> <code class="o">{</code>

        <code class="k">return</code> <code class="n">Tags</code><code class="o">.</code><code class="na">concat</code><code class="o">(</code>
          <code class="k">super</code><code class="o">.</code><code class="na">tags</code><code class="o">(</code><code class="n">request</code><code class="o">,</code> <code class="n">response</code><code class="o">,</code> <code class="n">throwable</code><code class="o">),</code>
          <code class="s">"subscription.level"</code><code class="o">,</code>
          <code class="n">response</code><code class="o">.</code><code class="na">headers</code><code class="o">().</code><code class="na">header</code><code class="o">(</code><code class="s">"subscription"</code><code class="o">).</code><code class="na">stream</code><code class="o">()</code>
            <code class="o">.</code><code class="na">findFirst</code><code class="o">()</code>
            <code class="o">.</code><code class="na">orElse</code><code class="o">(</code><code class="s">"basic"</code><code class="o">)</code>
        <code class="o">);</code>
      <code class="o">}</code>
    <code class="o">};</code>
  <code class="o">}</code>
<code class="o">}</code></pre></div>

<p class="author1">To this point we’ve focused on latency and errors. Now let’s consider a common saturation measurement related to memory consumption<a data-type="indexterm" data-startref="ix_ch04-asciidoc40" id="idm45139266164792" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre"/><a data-type="indexterm" data-startref="ix_ch04-asciidoc39" id="idm45139266164184" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre"/><a data-type="indexterm" data-startref="ix_ch04-asciidoc38" id="idm45139266404856" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre"/><a data-type="indexterm" data-startref="ix_ch04-asciidoc37" id="idm45139266404216" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre"/><a data-type="indexterm" data-startref="ix_ch04-asciidoc36" id="idm45139266403544" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre"/>.<a data-type="indexterm" data-startref="ix_ch04-asciidoc30" id="idm45139266402744" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre"/><a data-type="indexterm" data-startref="ix_ch04-asciidoc29" id="idm45139266408712" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre"/><a data-type="indexterm" data-startref="ix_ch04-asciidoc28" id="idm45139266408040" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre"/></p>
</div></section>



</div></section>













</div></section>













</div></section></div>



  

<div id="sbo-rt-content" class="calibre2">
<section data-type="chapter" type="chapter" data-pdf-bookmark="Chapter 4. Charting and Alerting" class="calibre3">
<div class="preface" id="ch_charting_alerting">
<section data-type="sect1" data-pdf-bookmark="Service Level Indicators for Every Java Microservice" class="calibre3">
<div class="preface" id="idm45139267438056">
<section data-type="sect2" data-pdf-bookmark="Garbage Collection Pause Times" class="calibre3"><div class="preface" id="kpi_gc_pause_times">
<h2 class="calibre37" id="8IMVJ-2d714b853a094e9a910510217e0e3d73">Garbage Collection Pause Times</h2>

<p class="author1"><a data-type="indexterm" data-primary="garbage collection (GC)" data-secondary="pause times" id="ix_ch04-asciidoc41" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre"/><a data-type="indexterm" data-primary="service level indicators (SLIs)" data-secondary="garbage collection pause times" id="ix_ch04-asciidoc42" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre"/>Garbage collection (GC) pauses often delay the delivery of a response to a user request, and they can be a bellwether of an impending “out of memory” application failure. There are a few ways we can look at this indicator.</p>










<section data-type="sect3" data-pdf-bookmark="Max pause time" class="calibre3"><div class="preface" id="idm45139266346152">
<h3 class="calibre51">Max pause time</h3>

<p class="author1"><a data-type="indexterm" data-primary="garbage collection (GC)" data-secondary="max pause time" id="idm45139266351640" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre"/>Set a fixed alert threshold on the maximum GC pause time you find acceptable (knowing that a GC pause directly contributes to end-user response time as well), potentially selecting different thresholds for minor and major GC types. Plot the max from the <code class="calibre24">jvm.gc.pause</code> timer to set your thresholds, as shown in <a data-type="xref" href="part0009_split_018.html#gc_pause_times" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre">Figure 4-25</a>. A heatmap of pause times may also be interesting if your application undergoes frequent pauses and you want to understand what typical behavior looks like over time.</p>

<figure class="calibre32"><div id="gc_pause_times" class="figure">
<img src="../images/00012.png" alt="srej 0425" class="calibre125"/>
<h6 class="calibre34"><span class="keep-together">Figure 4-25. </span>Max garbage collection pause times</h6>
</div></figure>
</div></section>













<section data-type="sect3" class="calibre3" data-pdf-bookmark="Proportion of time spent in garbage collection"><div class="preface" id="gc_time_proportion">
<h3 class="calibre51" id="8IN04-2d714b853a094e9a910510217e0e3d73">Proportion of time spent in garbage collection</h3>

<p class="author1"><a data-type="indexterm" data-primary="garbage collection (GC)" data-secondary="proportion of time spent in" id="ix_ch04-asciidoc43" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre"/>Since <code class="calibre24">jvm.gc.pause</code> is a timer, we can look at its sum independently. Specifically, we can add the increases in this sum over an interval of time and divide it by the interval to determine what proportion of the time the CPU is engaged in doing garbage <span class="keep-together">collection.</span> And since our Java process does nothing else during these times, when a significant enough proportion of time is spent in GC, an alert is warranted. <a data-type="xref" href="part0009_split_018.html#prometheus_time_spent_in_gc" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre">Example 4-22</a> shows the Prometheus query for this technique.</p>
<div id="prometheus_time_spent_in_gc" data-type="example" class="calibre61">
<h5 class="calibre62"><span class="keep-together">Example 4-22. </span>Prometheus query for time spent in garbage collection by cause</h5>

<pre data-type="programlisting" class="calibre63">sum( <a class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre" id="co_charting_and_alerting_CO5-1" href="part0009_split_018.html#callout_charting_and_alerting_CO5-1"><img src="../images/00112.png" alt="1" class="calibre66"/></a>
  sum_over_time( <a class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre" id="co_charting_and_alerting_CO5-2" href="part0009_split_018.html#callout_charting_and_alerting_CO5-2"><img src="../images/00059.png" alt="2" class="calibre66"/></a>
    sum(increase(jvm_gc_pause_seconds_sum[2m])[1m:] <a class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre" id="co_charting_and_alerting_CO5-3" href="part0009_split_018.html#callout_charting_and_alerting_CO5-3"><img src="../images/00067.png" alt="3" class="calibre66"/></a>
  )
) / 60 <a class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre" id="co_charting_and_alerting_CO5-4" href="part0009_split_018.html#callout_charting_and_alerting_CO5-4"><img src="../images/00016.png" alt="4" class="calibre66"/></a></pre></div>
<dl class="calibre20">
<dt class="calibre21"><a class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre" id="callout_charting_and_alerting_CO5-1" href="part0009_split_018.html#co_charting_and_alerting_CO5-1"><img src="../images/00112.png" alt="1" class="calibre66"/></a></dt>
<dd class="calibre67"><p class="calibre68">Sums over all the individual causes, like “end of minor GC.”</p></dd>
<dt class="calibre21"><a class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre" id="callout_charting_and_alerting_CO5-2" href="part0009_split_018.html#co_charting_and_alerting_CO5-2"><img src="../images/00059.png" alt="2" class="calibre66"/></a></dt>
<dd class="calibre67"><p class="calibre68">The total time spent in an individual cause in the last minute.</p></dd>
<dt class="calibre21"><a class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre" id="callout_charting_and_alerting_CO5-3" href="part0009_split_018.html#co_charting_and_alerting_CO5-3"><img src="../images/00067.png" alt="3" class="calibre66"/></a></dt>
<dd class="calibre67"><p class="calibre68">This is the first time we’ve seen a Prometheus <a href="https://oreil.ly/34AJs" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre">subquery</a>. It allows us to treat the operation on the two indicators as a range vector for input into <code class="calibre24">sum_over_time</code>.</p></dd>
<dt class="calibre21"><a class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre" id="callout_charting_and_alerting_CO5-4" href="part0009_split_018.html#co_charting_and_alerting_CO5-4"><img src="../images/00016.png" alt="4" class="calibre66"/></a></dt>
<dd class="calibre67"><p class="calibre68">Since <code class="calibre24">jvm_gc_pause_seconds_sum</code> has a unit of seconds (and therefore so do the sums) and we’ve summed over a 1-minute period, divide by 60 seconds to arrive at a percentage in the range [0, 1] of the time we’ve spent in GC in the last minute.</p></dd>
</dl>

<p class="author1">This technique is flexible. You can use a tag to select particular GC causes and evaluate, for example, only the proportion of time spent in major GC events. Or, like we’ve done here, you can simply sum over all the causes and reason about overall GC time in a given interval. More than likely, you’re going to find that if you do separate these sums by cause, minor GC events don’t contribute that significantly to the proportion of time spent in GC. The app being monitored in <a data-type="xref" href="part0009_split_018.html#time_spent_in_gc" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre">Figure 4-26</a> was undergoing minor collections every minute and, unsurprisingly, it still only spent 0.0182% of its time in GC-related activities.</p>

<figure class="calibre32"><div id="time_spent_in_gc" class="figure">
<img src="../images/00002.png" alt="srej 0426" class="calibre126"/>
<h6 class="calibre34"><span class="keep-together">Figure 4-26. </span>The proportion of time spent in minor GC events</h6>
</div></figure>

<p class="author1">If you aren’t using a monitoring system that provides aggregation functions like <code class="calibre24">sum_over_time</code>, Micrometer provides a meter binder called <code class="calibre24">JvmHeapPressureMetrics</code>, shown in <a data-type="xref" href="part0009_split_018.html#configuring_jvm_heap_pressure_binder" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre">Example 4-23</a>, that precomputes this GC overhead and ships a gauge called <code class="calibre24">jvm.gc.overhead</code> that is a percentage in the range [0, 1] that you can then set a fixed threshold alert against. In a Spring Boot app, you can simply add an instance of <code class="calibre24">JvmHeapPressureMetrics</code> as a <code class="calibre24">@Bean</code> and it will be bound to your meter registries automatically.</p>
<div id="configuring_jvm_heap_pressure_binder" data-type="example" class="calibre61">
<h5 class="calibre62"><span class="keep-together">Example 4-23. </span>Configuring the JVM heap pressure meter binder</h5>

<pre data-type="programlisting" data-code-language="java" class="calibre63"><code class="n">MeterRegistry</code><code class="calibre24"> </code><code class="n">registry</code><code class="calibre24"> </code><code class="o">=</code><code class="calibre24"> </code><code class="o">.</code><code class="o">.</code><code class="o">.</code><code class="calibre24">
</code><code class="calibre24">
</code><code class="k">new</code><code class="calibre24"> </code><code class="nf">JvmHeapPressureMetrics</code><code class="o">(</code><code class="calibre24">
</code><code class="calibre24">  </code><code class="n">Tags</code><code class="o">.</code><code class="na">empty</code><code class="o">(</code><code class="o">)</code><code class="o">,</code><code class="calibre24">
</code><code class="calibre24">  </code><code class="n">Duration</code><code class="o">.</code><code class="na">ofMinutes</code><code class="o">(</code><code class="mi">1</code><code class="o">)</code><code class="o">,</code><code class="calibre24"> </code><a class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre" id="co_charting_and_alerting_CO6-1" href="part0009_split_018.html#callout_charting_and_alerting_CO6-1"><img src="../images/00112.png" alt="1" class="calibre66"/></a><code class="calibre24">
</code><code class="calibre24">  </code><code class="n">Duration</code><code class="o">.</code><code class="na">ofSeconds</code><code class="o">(</code><code class="mi">30</code><code class="o">)</code><code class="calibre24">
</code><code class="o">)</code><code class="o">.</code><code class="na">register</code><code class="o">(</code><code class="n">meterRegistry</code><code class="o">)</code><code class="o">;</code></pre></div>
<dl class="calibre20">
<dt class="calibre21"><a class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre" id="callout_charting_and_alerting_CO6-1" href="part0009_split_018.html#co_charting_and_alerting_CO6-1"><img src="../images/00112.png" alt="1" class="calibre66"/></a></dt>
<dd class="calibre67"><p class="calibre68">Controls the lookback window.<a data-type="indexterm" data-startref="ix_ch04-asciidoc43" id="idm45139265760424" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre"/></p></dd>
</dl>
</div></section>













<section data-type="sect3" data-pdf-bookmark="The presence of any humongous allocation" class="calibre3"><div class="preface" id="idm45139266367240">
<h3 class="calibre51">The presence of any humongous allocation</h3>

<p class="author1"><a data-type="indexterm" data-primary="garbage collection (GC)" data-secondary="presence of any humongous allocation" id="idm45139265758488" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre"/>In addition to choosing one of the above forms for monitoring time spent in GC, it’s also a good idea to set an alert on the presence of humongous allocation that GC causes in the G1 collector, because it indicates that somewhere in your code you are allocating an object &gt;50% of the total size of the Eden space! More than likely, there is a way to refactor the application to avoid such an allocation by chunking or streaming data. A humongous allocation could occur while doing something like parsing an input or retrieving an object from a datastore that is not yet as big as the application could theoretically see, and a larger object very well could bring the application down.</p>

<p class="author1">For this, specifically, you are looking for a nonzero count for <code class="calibre24">jvm.gc.pause</code> where the <code class="calibre24">cause</code> tag is equal to <code class="calibre24">G1 Humongous Allocation</code>.</p>

<p class="author1">Way back in <a data-type="xref" href="part0005_split_003.html#4OIT5-2d714b853a094e9a910510217e0e3d73" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre">“Monitoring for Availability”</a>, we mentioned that saturation metrics are usually preferable to utilization metrics when you have a choice between the two. This is certainly true of memory consumption. The views of time spent in garbage collection as a measure of memory resource problems are easier to get right. There are some interesting things we can do with utilization measurements, too, if we’re careful.<a data-type="indexterm" data-startref="ix_ch04-asciidoc42" id="idm45139265725848" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre"/><a data-type="indexterm" data-startref="ix_ch04-asciidoc41" id="idm45139265725176" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre"/></p>
</div></section>



</div></section>













</div></section>













</div></section></div>



  

<div id="sbo-rt-content" class="calibre2">
<section data-type="chapter" type="chapter" data-pdf-bookmark="Chapter 4. Charting and Alerting" class="calibre3">
<div class="preface" id="ch_charting_alerting">
<section data-type="sect1" data-pdf-bookmark="Service Level Indicators for Every Java Microservice" class="calibre3">
<div class="preface" id="idm45139267438056">
<section data-type="sect2" data-pdf-bookmark="Heap Utilization" class="calibre3"><div class="preface" id="kpi_heap_utilization">
<h2 class="calibre37" id="8IN3U-2d714b853a094e9a910510217e0e3d73">Heap Utilization</h2>

<p class="author1"><a data-type="indexterm" data-primary="heap utilization" id="ix_ch04-asciidoc44" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre"/><a data-type="indexterm" data-primary="service level indicators (SLIs)" data-secondary="heap utilization" id="ix_ch04-asciidoc45" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre"/>The Java heap is separated into several pools with each pool having a defined size. Java object instances are created in heap space. The most important parts of the heap are as follows:</p>
<dl class="calibre20">
<dt class="calibre21">Eden space (young generation)</dt>
<dd class="calibre22">
<p class="calibre23"><a data-type="indexterm" data-primary="Eden space" id="idm45139265718840" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre"/><a data-type="indexterm" data-primary="young generation (Eden space)" id="idm45139265718136" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre"/>All new objects are allocated here. A minor garbage collection event occurs when this space is filled.</p>
</dd>
</dl>
<dl class="calibre20">
<dt class="calibre21">Survivor space</dt>
<dd class="calibre22">
<p class="calibre23"><a data-type="indexterm" data-primary="survivor space" id="idm45139265715320" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre"/>When a minor garbage collection occurs, any live objects (that demonstrably still have references and therefore cannot be collected) are copied to the survivor space. Objects that reach the survivor space have their age incremented, and after an age threshold is met, are promoted to old generation. Promotion may happen prematurely if the survivor space cannot hold all of the live objects in young generation (objects skip the survivor space and go straight to old generation). This last fact will be key in how we measure dangerous levels of allocation pressure.</p>
</dd>
<dt class="calibre21">Old generation</dt>
<dd class="calibre22">
<p class="calibre23"><a data-type="indexterm" data-primary="old generation" id="idm45139265712760" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre"/>This is where long-surviving objects are stored. When objects are stored in the Eden space, an age for that object is set; and when it reaches that age, the object is moved to old generation.</p>
</dd>
</dl>

<p class="author1">Fundamentally, we want to know when one or more of these spaces is getting and <em class="calibre12">staying</em> too “full.” This is a tricky thing to monitor because JVM garbage collection by design kicks in as spaces get full. So having a space fill up isn’t itself an indicator of a problem. What is concerning is when it stays full.</p>

<p class="author1">Micrometer’s <code class="calibre24">JvmMemoryMetrics</code> meter binder automatically collects JVM memory pool usage, along with the current total maximum heap size (since this can increase and decrease at runtime). Most Java web frameworks automatically configure this binder.</p>

<p class="author1">Several metrics are plotted in <a data-type="xref" href="part0009_split_019.html#memory_fixed_threshold" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre">Figure 4-27</a>. The most straightforward idea for how to measure heap pressure is to use a simple fixed threshold, such as a percentage of total heap consumed. As we can see, the fixed threshold alert will fire far too frequently. The earliest alert is triggered at 11:44, well before it is apparent that a memory leak is present in this application. Even though the heap temporarily exceeds the percentage-of-total-heap threshold we have set, garbage collection events routinely bring total consumption back under the threshold.</p>

<p class="author1">In <a data-type="xref" href="part0009_split_019.html#memory_fixed_threshold" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre">Figure 4-27</a>:</p>

<ul class="printings">
<li class="calibre15">
<p class="calibre18">The solid vertical bars together are a stack graph of memory consumption by space.</p>
</li>
<li class="calibre15">
<p class="calibre18">The thin line around the 30.0 M level is the maximum heap space allowed. Notice how this fluctuates as the JVM attempts to pick the right value between initial heap size (<code class="calibre24">-Xms</code>) and max heap size (<code class="calibre24">-Xmx</code>) for the process.</p>
</li>
<li class="calibre15">
<p class="calibre18">The bold line around 24.0 M level represents a fixed percentage of this maximum allowed memory. This is the threshold. It is a fixed threshold relative to the max, but dynamic in the sense that it is a percentage of the max which itself can <span class="keep-together">fluctuate.</span></p>
</li>
<li class="calibre15">
<p class="calibre18">The lighter bars represent points where actual heap utilization (the top of the stack graph) exceeds the threshold. This is the “alert condition.”</p>
</li>
</ul>

<figure class="calibre32"><div id="memory_fixed_threshold" class="figure">
<img src="../images/00075.png" alt="The alarm fires frequently" class="calibre127"/>
<h6 class="calibre34"><span class="keep-together">Figure 4-27. </span>An alert on memory utilization with a fixed threshold</h6>
</div></figure>

<p class="author1">So this simple fixed threshold won’t work. There are better options available, depending on the capabilities of your target monitoring system.</p>










<section data-type="sect3" data-pdf-bookmark="Rolling count occurrences of heap space filling up" class="calibre3"><div class="preface" id="idm45139265697592">
<h3 class="calibre51">Rolling count occurrences of heap space filling up</h3>

<p class="author1"><a data-type="indexterm" data-primary="heap utilization" data-secondary="rolling count occurrences of heap space filling up" id="idm45139265696184" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre"/><a data-type="indexterm" data-primary="rolling count function" id="idm45139265695240" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre"/>By using a feature like the rolling count function in Atlas, we can alert only when the heap exceeds the threshold—say, three out of the five prior intervals—indicating that in spite of the garbage collector’s best effort, heap consumption continues to be a problem (see <a data-type="xref" href="part0009_split_019.html#memory_rolling_count" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre">Figure 4-28</a>).</p>

<p class="author1">Unfortunately, not many monitoring systems have a function like Atlas’s rolling count. Prometheus can do something like this with its <code class="calibre24">count_over_time</code> operation, but it is tricky to get a similar “three out of five” dynamic.</p>

<figure class="calibre32"><div id="memory_rolling_count" class="figure">
<img src="../images/00072.png" alt="The alarm fires only when there is clearly a problem developing" class="calibre127"/>
<h6 class="calibre34"><span class="keep-together">Figure 4-28. </span>Using rolling count to limit alert chattiness</h6>
</div></figure>

<p class="author1">There is an alternative approach that also works well.</p>
</div></section>













<section data-type="sect3" data-pdf-bookmark="Low pool memory after collection" class="calibre3"><div class="preface" id="idm45139265689880">
<h3 class="calibre51">Low pool memory after collection</h3>

<p class="author1"><a data-type="indexterm" data-primary="garbage collection (GC)" data-secondary="low pool memory after collection" id="idm45139265688824" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre"/><a data-type="indexterm" data-primary="heap utilization" data-secondary="low pool memory after collection" id="idm45139265687784" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre"/>Micrometer’s <code class="calibre24">JvmHeapPressureMetrics</code> adds a gauge <code class="calibre24">jvm.memory.usage.after.gc</code> for the percentage of Old Generation heap used after the last garbage collection event.</p>

<p class="author1"><code class="calibre24">jvm.memory.usage.after.gc</code> is a percentage expressed in the range [0, 1]. When it is high (a good starting alert threshold is greater than 90%), garbage collection isn’t able to sweep up much garbage. So long-term pause events which occur when Old Generation is swept can be expected to occur frequently, and frequent long-term pauses both significantly degrade the performance of the app and ultimately lead to <code class="calibre24">OutOfMemoryException</code> fatal errors.</p>

<p class="author1">A subtle variation on measuring low pool memory after collection is also effective.</p>
</div></section>













<section data-type="sect3" data-pdf-bookmark="Low total memory" class="calibre3"><div class="preface" id="idm45139265683512">
<h3 class="calibre51">Low total memory</h3>

<p class="author1"><a data-type="indexterm" data-primary="garbage collection (GC)" data-secondary="low total memory" id="ix_ch04-asciidoc46" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre"/><a data-type="indexterm" data-primary="heap utilization" data-secondary="low total memory" id="ix_ch04-asciidoc47" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre"/>This technique involves mixing indicators from heap usage and garbage collection activity. A problem is indicated when they <em class="calibre12">both</em> exceed a threshold:</p>
<dl class="calibre20">
<dt class="calibre21"><code class="calibre24">jvm.gc.overhead</code> &gt; 50%</dt>
<dd class="calibre22">
<p class="calibre23">Notice that this is a lower alert threshold than suggested in <a data-type="xref" href="part0009_split_018.html#8IMVJ-2d714b853a094e9a910510217e0e3d73" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre">“Garbage Collection Pause Times”</a> for the same indicator (where we suggested 90%). We can be more aggressive about this indicator because we are pairing it with a utilization indicator.</p>
</dd>
<dt class="calibre21"><code class="calibre24">jvm.memory.used/jvm.memory.max</code> &gt; 90% at any time in the last 5 minutes</dt>
<dd class="calibre22">
<p class="calibre23">Now we have an idea that GC overhead is going up because one or more of the pools keep filling up. You could constrain this to just the Old Generation pool as well if your app generates a lot of short-term garbage under normal circumstances.</p>
</dd>
</dl>

<p class="author1">The alert criteria for the GC overhead indicator is a simple test against the gauge value.</p>

<p class="author1">The query for total memory usage is a little less obvious. The Prometheus query is shown in <a data-type="xref" href="part0009_split_019.html#prometheus_memory_used" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre">Example 4-24</a>.</p>
<div id="prometheus_memory_used" data-type="example" class="calibre61">
<h5 class="calibre62"><span class="keep-together">Example 4-24. </span>Prometheus query for maximum memory used in the last five minutes</h5>

<pre data-type="programlisting" class="calibre63">max_over_time(
  (
    jvm_memory_used_bytes{id="G1 Old Gen"} /
    jvm_memory_committed_bytes{id="G1 Old Gen"}
  )[5m:]
)</pre></div>

<p class="author1">To understand better what <code class="calibre24">max_over_time</code> does, <a data-type="xref" href="part0009_split_019.html#prometheus_max_over_time" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre">Figure 4-29</a> shows the total amount of Eden space (<code class="calibre24">jvm.memory.used{id="G1 Eden Space"}</code> in this case) consumed at several points in time (the dots) and the result of applying a one-minute <code class="calibre24">max_over_time</code> query to the same query (the solid line). It is a moving maximum window over a prescribed interval.</p>

<p class="author1">As long as heap usage is going up (and hasn’t been below the current value in the lookback window), the <code class="calibre24">max_over_time</code> tracks it exactly. Once a garbage collection event happens, the current view of usage drops and <code class="calibre24">max_over_time</code> “sticks” at the higher value for the lookback window.</p>

<figure class="calibre32"><div id="prometheus_max_over_time" class="figure">
<img src="../images/00093.png" alt="srej 0429" class="calibre128"/>
<h6 class="calibre34"><span class="keep-together">Figure 4-29. </span>Prometheus max_over_time looking at max Eden space used in a one-minute lookback</h6>
</div></figure>

<p class="author1">This is also the first time we’ve considered an alert that is based on more than one condition. Alerting systems generally allow for the boolean combination of multiple criteria. In <a data-type="xref" href="part0009_split_019.html#low_total_memory_alert" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre">Figure 4-30</a>, assuming that the <code class="calibre24">jvm.gc.overhead</code> indicator represents Query A and the usage indicator represents Query B, an alert can be configured in Grafana on both together.</p>

<figure class="calibre32"><div id="low_total_memory_alert" class="figure">
<img src="../images/00109.png" alt="srej 0430" class="calibre129"/>
<h6 class="calibre34"><span class="keep-together">Figure 4-30. </span>Configuring a Grafana alert based on two indicators for low total memory</h6>
</div></figure>

<p class="author1">Another<a data-type="indexterm" data-startref="ix_ch04-asciidoc47" id="idm45139265659160" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre"/><a data-type="indexterm" data-startref="ix_ch04-asciidoc46" id="idm45139265658424" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre"/> common utilization measurement is CPU, which doesn’t have an easy saturation analog.<a data-type="indexterm" data-startref="ix_ch04-asciidoc45" id="idm45139265657624" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre"/><a data-type="indexterm" data-startref="ix_ch04-asciidoc44" id="idm45139265656952" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre"/></p>
</div></section>



</div></section>













</div></section>













</div></section></div>



  

<div id="sbo-rt-content" class="calibre2">
<section data-type="chapter" type="chapter" data-pdf-bookmark="Chapter 4. Charting and Alerting" class="calibre3">
<div class="preface" id="ch_charting_alerting">
<section data-type="sect1" data-pdf-bookmark="Service Level Indicators for Every Java Microservice" class="calibre3">
<div class="preface" id="idm45139267438056">
<section data-type="sect2" class="calibre3" data-pdf-bookmark="CPU Utilization"><div class="preface" id="kpi_cpu">
<h2 class="calibre37" id="calibre_pb_20">CPU Utilization</h2>

<p class="author1"><a data-type="indexterm" data-primary="CPU utilization" id="ix_ch04-asciidoc48" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre"/><a data-type="indexterm" data-primary="service level indicators (SLIs)" data-secondary="CPU utilization" id="ix_ch04-asciidoc49" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre"/>CPU usage is a common utilization alert to set, but unfortunately it is difficult to establish a general rule for what is a healthy amount of CPU because of the different programming models described below—this will have to be determined for each application, depending on its characteristics.</p>

<p class="author1">For example, a typical Java microservice running on Tomcat and serving requests using a blocking servlet model will typically consume available threads in the Tomcat thread pool well before overutilizing the CPU. In these types of applications, high memory saturation is far more common (e.g., lots of excess garbage created in the handling of each request or large request/response bodies).</p>

<p class="author1">A Java microservice running on Netty and using a reactive programming model all the way down will accept a much higher throughput per instance, and so CPU utilization tends to be much higher. In fact, better saturating available CPU resources is commonly cited as an advantage of the reactive programming model!</p>
</div></section>













</div></section>













</div></section></div>



  

<div id="sbo-rt-content" class="calibre2">
<section data-type="chapter" type="chapter" data-pdf-bookmark="Chapter 4. Charting and Alerting" class="calibre3">
<div class="preface" id="ch_charting_alerting">
<section data-type="sect1" data-pdf-bookmark="Service Level Indicators for Every Java Microservice" class="calibre3">
<div class="preface" id="idm45139267438056">
<section data-type="sect2" class="calibre3" data-pdf-bookmark="CPU Utilization">
<div class="preface" id="kpi_cpu">
<div data-type="warning" type="warning" class="calibre30"><h1 class="calibre69" id="calibre_pb_21">On Some Platforms, Consider CPU and Memory Utilization Together Before Resizing Instances</h1>
<p class="author1">A common feature of platform as a service is the simplification of instance sizing down to the amount of CPU or memory you desire with the other variable growing proportionally as you move up sizes. In the case of Cloud Foundry, this proportionality between CPU and memory was decided at a time when a blocking model of request handling like Tomcat was almost universal. As noted, CPU tends to be underused in this model. I once consulted at a company that had adopted a nonblocking reactive model for its application, and noticing that memory was significantly underutilized, I downsized the company’s Cloud Foundry instances to not consume as much memory. But CPU is allocated to instances on this platform proportionally to how much memory is requested. By picking a lower memory requirement, the company also inadvertently starved its reactive app of the CPU it would otherwise have so efficiently saturated!</p>
</div>

<p class="author1">Micrometer exports two key metrics for CPU monitoring, which are listed in <a data-type="xref" href="part0009_split_021.html#processor_metrics" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre">Table 4-1</a>. Both of these metrics are reported from Java’s operating system MXBean (<code class="calibre24">ManagementFactory.getOperatingSystemMXBean()</code>).</p>
<table id="processor_metrics" class="calibre40">
<caption class="calibre41"><span class="keep-together">Table 4-1. </span>Micrometer reported processor metrics</caption>
<thead class="calibre42">
<tr class="calibre43">
<th class="calibre44">Metric</th>
<th class="calibre44">Type</th>
<th class="calibre44">Description</th>
</tr>
</thead>
<tbody class="calibre45">
<tr class="calibre46">
<td class="calibre47"><p class="calibre48">system.cpu.usage</p></td>
<td class="calibre47"><p class="calibre48">Gauge</p></td>
<td class="calibre47"><p class="calibre48">The recent CPU usage for the whole system</p></td>
</tr>
<tr class="calibre50">
<td class="calibre47"><p class="calibre48">process.cpu.usage</p></td>
<td class="calibre47"><p class="calibre48">Gauge</p></td>
<td class="calibre47"><p class="calibre48">The recent CPY usage for the Java virtual machine process</p></td>
</tr>
</tbody>
</table>

<p class="author1">For the most common case in the enterprise where an application is serving requests via a blocking servlet model, testing against a fixed threshold of 80% is reasonable. Reactive applications will need to be tested empirically to determine their appropriate saturation point.</p>

<p class="author1">For Atlas, use the <code class="calibre24">:gt</code> function, as shown in <a data-type="xref" href="part0009_split_021.html#atlas_processor_metrics" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre">Example 4-25</a>.</p>
<div id="atlas_processor_metrics" data-type="example" class="calibre61">
<h5 class="calibre62"><span class="keep-together">Example 4-25. </span>Atlas CPU alert threshold</h5>

<pre data-type="programlisting" class="calibre63">name,process.cpu.usage,:eq,
0.8,
:gt</pre></div>

<p class="author1">For Prometheus, <a data-type="xref" href="part0009_split_021.html#prometheus_processor_metrics" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre">Example 4-26</a> is just a comparison expression.</p>
<div id="prometheus_processor_metrics" data-type="example" class="calibre61">
<h5 class="calibre62"><span class="keep-together">Example 4-26. </span>Prometheus CPU alert threshold</h5>

<pre data-type="programlisting" class="calibre63">process_cpu_usage &gt; 0.8</pre></div>

<p class="author1">Process CPU usage should be plotted as a percentage (where the monitoring system should expect an input in the range 0–1 to appropriately draw the <em class="calibre12">y</em>-axis). Take note of the <em class="calibre12">y</em>-axis in <a data-type="xref" href="part0009_split_021.html#process_cpu_usage" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre">Figure 4-31</a> for what this should look like.</p>

<figure class="calibre32"><div id="process_cpu_usage" class="figure">
<img src="../images/00086.png" alt="srej 0431" class="calibre130"/>
<h6 class="calibre34"><span class="keep-together">Figure 4-31. </span>Process CPU usage as a percentage</h6>
</div></figure>

<p class="author1">In Grafana, “percent” is one of the units selectable in the “Visualization” tab. Make sure to select the option for “percent (0.0-1.0),” as shown in <a data-type="xref" href="part0009_split_021.html#grafana_percentage_unit" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre">Figure 4-32</a>.</p>

<figure class="calibre32"><div id="grafana_percentage_unit" class="figure">
<img src="../images/00106.png" alt="srej 0432" class="calibre131"/>
<h6 class="calibre34"><span class="keep-together">Figure 4-32. </span>Grafana percent unit</h6>
</div></figure>

<p class="author1">There is one more resource-based indicator you should measure on every application related to file descriptors.<a data-type="indexterm" data-startref="ix_ch04-asciidoc49" id="idm45139265621928" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre"/><a data-type="indexterm" data-startref="ix_ch04-asciidoc48" id="idm45139265621224" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre"/></p>
</div></section>













</div></section>













</div></section></div>



  

<div id="sbo-rt-content" class="calibre2">
<section data-type="chapter" type="chapter" data-pdf-bookmark="Chapter 4. Charting and Alerting" class="calibre3">
<div class="preface" id="ch_charting_alerting">
<section data-type="sect1" data-pdf-bookmark="Service Level Indicators for Every Java Microservice" class="calibre3">
<div class="preface" id="idm45139267438056">
<section data-type="sect2" data-pdf-bookmark="File Descriptors" class="calibre3"><div class="preface" id="kpi_file_descriptors">
<h2 class="calibre37" id="8IN93-2d714b853a094e9a910510217e0e3d73">File Descriptors</h2>

<p class="author1"><a data-type="indexterm" data-primary="file descriptors" id="ix_ch04-asciidoc50" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre"/><a data-type="indexterm" data-primary="service level indicators (SLIs)" data-secondary="file descriptors" id="ix_ch04-asciidoc51" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre"/>The “ulimits” Unix feature limits how many resources a single user can use, including concurrently open file descriptors. File descriptors are not just consumed for file access, but also for network connections, database connections, etc.</p>

<p class="author1">You can view your shell’s current ulimits with <code class="calibre24">ulimit -a</code>. The output is shown in <a data-type="xref" href="part0009_split_022.html#ulimit_output" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre">Example 4-27</a>. On many operating systems 1,024 is the default limit for open file descriptors. Scenarios like each service request requiring access to read or write a file where the number of concurrent threads can exceed the operating system limit are vulnerable to this issue. Throughput in the thousands of simultaneous requests is not unreasonable for a modern microservice, especially a nonblocking one.</p>
<div id="ulimit_output" data-type="example" class="calibre61">
<h5 class="calibre62"><span class="keep-together">Example 4-27. </span>Output of ulimit -a in a Unix shell</h5>

<pre data-type="programlisting" class="calibre63">$ ulimit -a
...
open files (-n) 1024 <a class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre" id="co_charting_and_alerting_CO7-1" href="part0009_split_022.html#callout_charting_and_alerting_CO7-1"><img src="../images/00112.png" alt="1" class="calibre66"/></a>
...
cpu time (seconds, -t) unlimited
max user processes (-u) 63796
virtual memory (kbytes, -v) unlimited</pre></div>
<dl class="calibre20">
<dt class="calibre21"><a class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre" id="callout_charting_and_alerting_CO7-1" href="part0009_split_022.html#co_charting_and_alerting_CO7-1"><img src="../images/00112.png" alt="1" class="calibre66"/></a></dt>
<dd class="calibre67"><p class="calibre68">This represents the number of <em class="calibre12">allowable</em> open files, not the number of currently open files.</p></dd>
</dl>

<p class="author1">This problem isn’t necessarily common, but the impact of reaching the file descriptor limit can be fatal, causing the application to stop responding entirely, depending on how file descriptors are used. Unlike an out-of-memory error or fatal exception, often the application will simply block but appear to be in service still, so this problem is especially pernicious. Because monitoring file descriptor utilization is so cheap, alert on this on every application. Applications using common techniques and web frameworks will probably never exceed 5% file descriptor utilization (and sometimes much lower); but when a problem sneaks in, it is trouble.</p>
</div></section>













</div></section>













</div></section></div>



  

<div id="sbo-rt-content" class="calibre2">
<section data-type="chapter" type="chapter" data-pdf-bookmark="Chapter 4. Charting and Alerting" class="calibre3">
<div class="preface" id="ch_charting_alerting">
<section data-type="sect1" data-pdf-bookmark="Service Level Indicators for Every Java Microservice" class="calibre3">
<div class="preface" id="idm45139267438056">
<section data-type="sect2" data-pdf-bookmark="File Descriptors" class="calibre3">
<div class="preface" id="kpi_file_descriptors">
<div data-type="note" type="note" class="calibre28"><h1 class="calibre54" id="calibre_pb_23">Experiencing the File Descriptor Problem While Writing This Book</h1>
<p class="author1">I’ve known for some time to monitor this, but never actually experienced a problem myself until writing this book. A Go build step involved in building Grafana from source repeatedly hung, never completing. Evidently the Go dependency resolution mechanism doesn’t carefully limit the number of open file descriptors!</p>
</div>

<p class="author1">An application which may have sockets open to hundreds of callers, HTTP connections to downstream services, connections open to datasources, and data files open could hit the limit of file descriptors. When a process runs out of file descriptors, it tends not to end well. You may see errors in logs like <a data-type="xref" href="part0009_split_023.html#tomcat_exhausted_file_descriptors" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre">Example 4-28</a> and <a data-type="xref" href="part0009_split_023.html#java_exhausted_file_descriptors" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre">Example 4-29</a>.</p>
<div id="tomcat_exhausted_file_descriptors" data-type="example" class="calibre61">
<h5 class="calibre62"><span class="keep-together">Example 4-28. </span>Tomcat exhausted file descriptors accepting a new HTTP connection</h5>

<pre data-type="programlisting" class="calibre63">java.net.SocketException: Too many open files
  at java.net.PlainSocketImpl.socketAccept(Native Method)
  at java.net.AbstractPlainSocketImpl.accept(AbstractPlainSocketImpl.java:398)</pre></div>
<div id="java_exhausted_file_descriptors" data-type="example" class="calibre61">
<h5 class="calibre62"><span class="keep-together">Example 4-29. </span>Java failing to open a file when file descriptors are exhausted</h5>

<pre data-type="programlisting" class="calibre63">java.io.FileNotFoundException: /myfile (Too many open files)
  at java.io.FileInputStream.open(Native Method)</pre></div>

<p class="author1">Micrometer reports two metrics shown in <a data-type="xref" href="part0009_split_023.html#file_descriptor_metrics" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre">Table 4-2</a> to alert you to a file descriptor problem in your applications.</p>
<table id="file_descriptor_metrics" class="calibre40">
<caption class="calibre41"><span class="keep-together">Table 4-2. </span>Micrometer-reported file descriptor metrics</caption>
<thead class="calibre42">
<tr class="calibre43">
<th class="calibre44">Metric</th>
<th class="calibre44">Type</th>
<th class="calibre44">Description</th>
</tr>
</thead>
<tbody class="calibre45">
<tr class="calibre46">
<td class="calibre47"><p class="calibre48">process.max.fds</p></td>
<td class="calibre47"><p class="calibre48">Gauge</p></td>
<td class="calibre47"><p class="calibre48">Maximum allowable open file descriptors, correspondng to <code class="calibre132">ulimit -a</code> output</p></td>
</tr>
<tr class="calibre50">
<td class="calibre47"><p class="calibre48">process.open.fds</p></td>
<td class="calibre47"><p class="calibre48">Gauge</p></td>
<td class="calibre47"><p class="calibre48">Number of open file descriptors</p></td>
</tr>
</tbody>
</table>

<p class="author1">Typically, open file descriptors should remain below the maximum, so a test against a fixed threshold like 80% is a good indicator of an impending problem. This alert should be set on <em class="calibre12">every application</em>, as file limits are a universally applicable hard limit that will take your application out of service.</p>

<p class="author1">For Atlas, use the <code class="calibre24">:div</code> and <code class="calibre24">:gt</code> functions, as shown in <a data-type="xref" href="part0009_split_023.html#atlas_file_descriptors" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre">Example 4-30</a>.</p>
<div id="atlas_file_descriptors" data-type="example" class="calibre61">
<h5 class="calibre62"><span class="keep-together">Example 4-30. </span>Atlas file descriptor alert threshold</h5>

<pre data-type="programlisting" class="calibre63">name,process.open.fds,:eq,
name,process.max.fds,:eq,
:div,
0.8,
:gt</pre></div>

<p class="author1">For Prometheus, <a data-type="xref" href="part0009_split_023.html#prometheus_file_descriptors" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre">Example 4-31</a> looks even simpler.</p>
<div id="prometheus_file_descriptors" data-type="example" class="calibre61">
<h5 class="calibre62"><span class="keep-together">Example 4-31. </span>Prometheus file descriptor alert threshold</h5>

<pre data-type="programlisting" class="calibre63">process_open_fds / process_max_fds &gt; 0.8</pre></div>

<p class="author1">At this point, we’ve covered the signals that are applicable to most every Java microservice. The ones that follow are commonly useful, but not as ubiquitous.<a data-type="indexterm" data-startref="ix_ch04-asciidoc51" id="idm45139265577640" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre"/><a data-type="indexterm" data-startref="ix_ch04-asciidoc50" id="idm45139265576936" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre"/></p>
</div></section>













</div></section>













</div></section></div>



  

<div id="sbo-rt-content" class="calibre2">
<section data-type="chapter" type="chapter" data-pdf-bookmark="Chapter 4. Charting and Alerting" class="calibre3">
<div class="preface" id="ch_charting_alerting">
<section data-type="sect1" data-pdf-bookmark="Service Level Indicators for Every Java Microservice" class="calibre3">
<div class="preface" id="idm45139267438056">
<section data-type="sect2" data-pdf-bookmark="Suspicious Traffic" class="calibre3"><div class="preface" id="kpi_suspicious_statuses">
<h2 class="calibre37" id="calibre_pb_24">Suspicious Traffic</h2>

<p class="author1"><a data-type="indexterm" data-primary="security issues" data-secondary="suspicious traffic" id="idm45139265574584" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre"/><a data-type="indexterm" data-primary="service level indicators (SLIs)" data-secondary="suspicious traffic" id="idm45139265573608" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre"/><a data-type="indexterm" data-primary="suspicious traffic" id="idm45139265572648" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre"/><a data-type="indexterm" data-primary="traffic management" data-secondary="suspicious traffic" id="idm45139265571976" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre"/>One other simple indicator that can be derived from metrics like <code class="calibre24">http.server.requests</code> involves watching the occurrence of unusual status codes. A rapid succession of HTTP 403 Forbidden (and similar) or HTTP 404 Not Found may indicate an intrusion attempt.</p>

<p class="author1">Unlike plotting errors, monitor total occurrences of a suspicious status code as a <em class="calibre12">rate</em> and not a ratio relative to total throughput. It’s probably safe to say that 10,000 HTTP 403s per second is equally suspicious if the system normally processes 15,000 requests per second or 15 million requests per second, so don’t let overall throughput hide the anomaly.</p>

<p class="author1">The Atlas query in <a data-type="xref" href="part0009_split_024.html#atlas_suspicious_403" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre">Example 4-32</a>, is similar to the error rate query we discussed earlier, but looks at the <code class="calibre24">status</code> tag for more granularity than the <code class="calibre24">outcome</code> tag.</p>
<div id="atlas_suspicious_403" data-type="example" class="calibre61">
<h5 class="calibre62"><span class="keep-together">Example 4-32. </span>Suspicious 403s in HTTP server requests in Atlas</h5>

<pre data-type="programlisting" class="calibre63">name,http.server.requests,:eq,
status,403,:eq,
:and,
uri,$ENDPOINT,:eq,:cq</pre></div>

<p class="author1">Use the Prometheus <code class="calibre24">rate</code> function to achieve the same result in Prometheus, as in <a data-type="xref" href="part0009_split_024.html#prometheus_suspicious_403" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre">Example 4-33</a>.</p>
<div id="prometheus_suspicious_403" data-type="example" class="calibre61">
<h5 class="calibre62"><span class="keep-together">Example 4-33. </span>Suspicious 403s in HTTP server requests in Prometheus</h5>

<pre data-type="programlisting" class="calibre63">sum(
  rate(
    http_server_requests_seconds_count{status="403", uri="$ENDPOINT"}[2m]
  )
)</pre></div>

<p class="author1">The next indicator is specialized to a particular kind of application but is still common enough to include.</p>
</div></section>













</div></section>













</div></section></div>



  

<div id="sbo-rt-content" class="calibre2">
<section data-type="chapter" type="chapter" data-pdf-bookmark="Chapter 4. Charting and Alerting" class="calibre3">
<div class="preface" id="ch_charting_alerting">
<section data-type="sect1" data-pdf-bookmark="Service Level Indicators for Every Java Microservice" class="calibre3">
<div class="preface" id="idm45139267438056">
<section data-type="sect2" data-pdf-bookmark="Batch Runs or Other Long-Running Tasks" class="calibre3"><div class="preface" id="idm45139265560312">
<h2 class="calibre37" id="calibre_pb_25">Batch Runs or Other Long-Running Tasks</h2>

<p class="author1"><a data-type="indexterm" data-primary="batch tasks" id="idm45139265558744" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre"/><a data-type="indexterm" data-primary="long-running tasks" id="idm45139265558040" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre"/><a data-type="indexterm" data-primary="monitoring" data-secondary="batch or other long-running tasks" id="idm45139265557368" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre"/><a data-type="indexterm" data-primary="service level indicators (SLIs)" data-secondary="batch or other long-running tasks" id="idm45139265556408" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre"/>One of the biggest risks of any long-running task is that it runs for significantly longer than expected. Earlier in my career, I was routinely on call for production deployments, which were always performed after a series of midnight batch runs. Under normal circumstances, the batch sequence should have completed maybe at 1:00 a.m. The deployment schedule was built around this assumption. So a network administrator manually uploading the deployed artifact (this is before <a data-type="xref" href="part0010_split_000.html#9H5K4-2d714b853a094e9a910510217e0e3d73" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre">Chapter 5</a>) needed to be at a computer ready to perform the task at 1:00 a.m. As the representative of the product’s engineering team, I needed to be ready to perform a brief smoke test at approximately 1:15 a.m. and be available to help remediate any issues that arose. At this time, I lived in a rural area without internet access, so I traveled along a state highway toward a population center until I could get a reliable enough cell signal to tether to my phone and connect to the VPN. When the batch processes didn’t complete in a reasonable amount of time, I sometimes spent hours sitting in my car on some country road waiting for them to complete. On days when production deployments weren’t happening, perhaps nobody knew that the batch cycle failed until the next business day.</p>

<p class="author1">If we wrap a long-running task in a Micrometer <code class="calibre24">Timer</code>, we won’t know that the SLO has been exceeded until the task actually completes. So if the task was supposed to take no more than 1 hour, but it actually runs for 16 hours, then we won’t see this appear on a monitoring chart until the first publishing interval <em class="calibre12">after</em> 16 hours when the sample is recorded to the timer.</p>

<p class="author1"><a data-type="indexterm" data-primary="long task timers" id="idm45139265551352" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre"/>To monitor long-running tasks, it is better to look at the running time of in-flight or active tasks. <code class="calibre24">LongTaskTimer</code> performs this kind of measurement. We can add this kind of timing to a potentially long-running task, as in <a data-type="xref" href="part0009_split_025.html#add_ltt" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre">Example 4-34</a>.</p>
<div id="add_ltt" data-type="example" class="calibre61">
<h5 class="calibre62"><span class="keep-together">Example 4-34. </span>An annotation-based long task timer for a scheduled operation</h5>

<pre data-type="programlisting" data-code-language="java" class="calibre63"><code class="nd">@Timed</code><code class="o">(</code><code class="n">name</code> <code class="o">=</code> <code class="s">"policy.renewal.batch"</code><code class="o">,</code> <code class="n">longTask</code> <code class="o">=</code> <code class="k">true</code><code class="o">)</code>
<code class="nd">@Scheduled</code><code class="o">(</code><code class="n">fixedRateString</code> <code class="o">=</code> <code class="s">"P1D"</code><code class="o">)</code>
<code class="kt">void</code> <code class="nf">renewPolicies</code><code class="o">()</code> <code class="o">{</code>
  <code class="c">// Bill and renew insurance policies that are beginning new terms today</code>
<code class="o">}</code></pre></div>

<p class="author1">Long task timers ship several distribution statistics: active task count, the maximum in-flight request duration, the sum of all in-flight request durations, and optionally percentile and histogram information about in-flight requests.</p>

<p class="author1">For Atlas, test against our expectation of one hour in nanoseconds, as shown in <a data-type="xref" href="part0009_split_025.html#atlas_ltt_max" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre">Example 4-35</a>.</p>
<div id="atlas_ltt_max" data-type="example" class="calibre61">
<h5 class="calibre62"><span class="keep-together">Example 4-35. </span>Atlas long task timer maximum alert threshold</h5>

<pre data-type="programlisting" class="calibre63">name,policy.renewal.batch.max,:eq,
3.6e12, <a class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre" id="co_charting_and_alerting_CO8-1" href="part0009_split_025.html#callout_charting_and_alerting_CO8-1"><img src="../images/00112.png" alt="1" class="calibre66"/></a>
:gt</pre></div>
<dl class="calibre20">
<dt class="calibre21"><a class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre" id="callout_charting_and_alerting_CO8-1" href="part0009_split_025.html#co_charting_and_alerting_CO8-1"><img src="../images/00112.png" alt="1" class="calibre66"/></a></dt>
<dd class="calibre67"><p class="calibre68">One hour in nanoseconds</p></dd>
</dl>

<p class="author1">For Prometheus, <a data-type="xref" href="part0009_split_025.html#prometheus_ltt_max" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre">Example 4-36</a> is tested against one hour in seconds.</p>
<div id="prometheus_ltt_max" data-type="example" class="calibre61">
<h5 class="calibre62"><span class="keep-together">Example 4-36. </span>Prometheus long task timer maximum alert threshold</h5>

<pre data-type="programlisting" class="calibre63">policy_renewal_batch_max_seconds &gt; 3600</pre></div>

<p class="author1">We’ve seen some examples of effective indicators to look at, and at this point hopefully you have one or more of them plotted on a dashboard and can see some meaningful insights. Next we turn to how to automate alerting when these indicators go awry so that you don’t have to watch your dashboards all the time to know when something isn’t right.<a data-type="indexterm" data-startref="ix_ch04-asciidoc25" id="idm45139265503624" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre"/><a data-type="indexterm" data-startref="ix_ch04-asciidoc24" id="idm45139265502920" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre"/></p>
</div></section>





</div></section>













</div></section></div>



  

<div id="sbo-rt-content" class="calibre2">
<section data-type="chapter" type="chapter" data-pdf-bookmark="Chapter 4. Charting and Alerting" class="calibre3">
<div class="preface" id="ch_charting_alerting">
<section data-type="sect1" data-pdf-bookmark="Building Alerts Using Forecasting Methods" class="calibre3"><div class="preface" id="forecasting_and_alerting">
<h1 class="calibre19" id="8INDM-2d714b853a094e9a910510217e0e3d73">Building Alerts Using Forecasting Methods</h1>

<p class="author1"><a data-type="indexterm" data-primary="charting and alerting" data-secondary="building alerts using forecasting methods" id="ix_ch04-asciidoc52" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre"/><a data-type="indexterm" data-primary="forecasting methods" data-secondary="building alerts using" id="ix_ch04-asciidoc53" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre"/>Fixed alert thresholds are often difficult to determine <em class="calibre12">a priori</em>, and since system performance is subject to drift over time, can be something that continually needs to be retuned. If performance over time tends to decline (but in such a way that the decline is still within acceptable levels), then a fixed alert threshold can easily become too chatty. If performance tends to improve, then the threshold is no longer as reliable of a measure of expected performance unless it is tuned.</p>

<p class="author1"><a data-type="indexterm" data-primary="machine learning" id="idm45139265496856" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre"/>Machine learning is the subject of a lot of hype that the monitoring system will automatically determine alert thresholds, but it hasn’t produced the promised results. For time series data, simpler classical statistical methods are still incredibly powerful. Surprisingly, the paper by S. Makridakis et al., <a href="https://oreil.ly/J43UW" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre">“Statistical and Machine Learning Forecasting Methods: Concerns and Ways Forward”</a>, shows that statistical methods have a lower prediction error (as shown in <a data-type="xref" href="part0009_split_026.html#forecasting_error" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre">Figure 4-33</a>) than machine learning methods do.</p>

<figure class="calibre32"><div id="forecasting_error" class="figure">
<img src="../images/00049.png" alt="srej 0433" class="calibre133"/>
<h6 class="calibre34"><span class="keep-together">Figure 4-33. </span>One-step forecasting error of statistical versus machine learning techniques</h6>
</div></figure>

<p class="author1">Let’s cover a few of these statistical methods, starting with the least predictive naive method, which can be used with any monitoring system. Later approaches have less universal support from monitoring systems since their math is complicated enough to require built-in query functions.</p>








</div></section>













</div></section></div>



  

<div id="sbo-rt-content" class="calibre2">
<section data-type="chapter" type="chapter" data-pdf-bookmark="Chapter 4. Charting and Alerting" class="calibre3">
<div class="preface" id="ch_charting_alerting">
<section data-type="sect1" data-pdf-bookmark="Building Alerts Using Forecasting Methods" class="calibre3">
<div class="preface" id="forecasting_and_alerting">
<section data-type="sect2" data-pdf-bookmark="Naive Method" class="calibre3"><div class="preface" id="idm45139265491464">
<h2 class="calibre37" id="calibre_pb_27">Naive Method</h2>

<p class="author1"><a data-type="indexterm" data-primary="forecasting methods" data-secondary="naive method" id="idm45139265489864" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre"/><a data-type="indexterm" data-primary="naive forecasting method" id="idm45139265488888" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre"/>The <a href="https://oreil.ly/W_D82" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre">naive method</a> is a simple heuristic that predicts the next value based on the last observed value:</p>
<div data-type="equation" class="calibre61">
<math alttext="ModifyingAbove y With caret Subscript upper T plus 1 vertical-bar upper T Baseline equals alpha y Subscript upper T" display="block">
  <mrow>
    <msub><mover accent="true"><mi>y</mi> <mo>^</mo></mover> <mrow><mi>T</mi><mo>+</mo><mn>1</mn><mo>|</mo><mi>T</mi></mrow> </msub>
    <mo>=</mo>
    <mi>α</mi>
    <msub><mi>y</mi> <mi>T</mi> </msub>
  </mrow>
</math>
</div>

<p class="author1">A dynamic alert threshold can be determined with the naive method by multiplying a time series offset by some factor. Then we can test whether the true line ever drops below (or exceeds if the multiplier is greater than one) the forecast line. For example, if the true line is a measure of throughput through a system, a sudden substantial drop in throughput may indicate an outage.</p>

<p class="author1">The alert criteria for Atlas is then whenever the query in <a data-type="xref" href="part0009_split_027.html#forecasting_naive_method_atlas" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre">Example 4-37</a> returns <code class="calibre24">1</code>. The query is designed against Atlas’s test dataset, so it’s easy for you to test out and try different multipliers to observe the effect.</p>
<div id="forecasting_naive_method_atlas" data-type="example" class="calibre61">
<h5 class="calibre62"><span class="keep-together">Example 4-37. </span>Atlas alert criteria for the naive forecasting method</h5>

<pre data-type="programlisting" class="calibre63">name,requestsPerSecond,:eq,
:dup,
0.5,:mul, <a class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre" id="co_charting_and_alerting_CO9-1" href="part0009_split_027.html#callout_charting_and_alerting_CO9-1"><img src="../images/00112.png" alt="1" class="calibre66"/></a>
1m,:offset, <a class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre" id="co_charting_and_alerting_CO9-2" href="part0009_split_027.html#callout_charting_and_alerting_CO9-2"><img src="../images/00059.png" alt="2" class="calibre66"/></a>
:rot,
:lt</pre></div>
<dl class="calibre20">
<dt class="calibre21"><a class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre" id="callout_charting_and_alerting_CO9-1" href="part0009_split_027.html#co_charting_and_alerting_CO9-1"><img src="../images/00112.png" alt="1" class="calibre66"/></a></dt>
<dd class="calibre67"><p class="calibre68">The tightness of the threshold is set with this factor.</p></dd>
<dt class="calibre21"><a class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre" id="callout_charting_and_alerting_CO9-2" href="part0009_split_027.html#co_charting_and_alerting_CO9-2"><img src="../images/00059.png" alt="2" class="calibre66"/></a></dt>
<dd class="calibre67"><p class="calibre68">“Look back” to some prior interval for the forecast.</p></dd>
</dl>

<p class="author1">The effect of the naive method can be seen in <a data-type="xref" href="part0009_split_027.html#forecasting_naive_method" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre">Figure 4-34</a>. The multiplicative factor (0.5 in the example query) controls how close to the true value we want to set the threshold and also reduces by the same amount the spikiness of the forecast (i.e., the looser the threshold, the less spiky the forecast). Since the method’s smoothing is proportional to looseness of fit, the alert threshold is still tripped four times in this time window (indicated by the vertical bars in the middle of the chart), even though we’ve allowed for a 50% drift from “normal.”</p>

<figure class="calibre32"><div id="forecasting_naive_method" class="figure">
<img src="../images/00027.png" alt="srej 0434" class="calibre134"/>
<h6 class="calibre34"><span class="keep-together">Figure 4-34. </span>Forecasting with the naive method</h6>
</div></figure>

<p class="author1">In order to prevent a chatty alert, we’d have to reduce the tightness of the forecast’s fit to our indicator (in this case a 0.45 multiplier silences the alert for this time window). Of course, doing so also allows for more drift from “normal” before an alert is fired.</p>
</div></section>













</div></section>













</div></section></div>



  

<div id="sbo-rt-content" class="calibre2">
<section data-type="chapter" type="chapter" data-pdf-bookmark="Chapter 4. Charting and Alerting" class="calibre3">
<div class="preface" id="ch_charting_alerting">
<section data-type="sect1" data-pdf-bookmark="Building Alerts Using Forecasting Methods" class="calibre3">
<div class="preface" id="forecasting_and_alerting">
<section data-type="sect2" data-pdf-bookmark="Single-Exponential Smoothing" class="calibre3"><div class="preface" id="idm45139265490840">
<h2 class="calibre37" id="8INF8-2d714b853a094e9a910510217e0e3d73">Single-Exponential Smoothing</h2>

<p class="author1"><a data-type="indexterm" data-primary="forecasting methods" data-secondary="single-exponential smoothing" id="idm45139265443336" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre"/><a data-type="indexterm" data-primary="single-exponential smoothing" id="idm45139265442296" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre"/><a data-type="indexterm" data-primary="smoothing, single-exponential" id="idm45139265441608" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre"/>By smoothing the original indicator before multiplying it by some factor, we can fit the threshold closer to the indicator. Single-exponential smoothing is defined by <a data-type="xref" href="part0009_split_028.html#single_exponential_eq" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre">Equation 4-1</a>.</p>
<div id="single_exponential_eq" data-type="equation" class="calibre61">
<h5 class="calibre72"><span class="keep-together">Equation 4-1. </span>Where <math alttext="0 less-than-or-equal-to alpha less-than-or-equal-to 1">
  <mrow>
    <mn>0</mn>
    <mo>≤</mo>
    <mi>α</mi>
    <mo>≤</mo>
    <mn>1</mn>
  </mrow>
</math></h5>
<math alttext="ModifyingAbove y With caret Subscript upper T plus 1 vertical-bar upper T Baseline equals alpha y Subscript upper T Baseline plus alpha left-parenthesis 1 minus alpha right-parenthesis y Subscript upper T minus 1 Baseline plus alpha left-parenthesis 1 minus alpha right-parenthesis squared y Subscript upper T minus 2 Baseline plus ellipsis equals alpha sigma-summation Underscript n equals 0 Overscript k Endscripts left-parenthesis 1 minus a right-parenthesis Superscript n Baseline y Subscript upper T minus n" display="block">
  <mrow>
    <msub><mover accent="true"><mi>y</mi> <mo>^</mo></mover> <mrow><mi>T</mi><mo>+</mo><mn>1</mn><mo>|</mo><mi>T</mi></mrow> </msub>
    <mo>=</mo>
    <mi>α</mi>
    <msub><mi>y</mi> <mi>T</mi> </msub>
    <mo>+</mo>
    <mi>α</mi>
    <mrow>
      <mo>(</mo>
      <mn>1</mn>
      <mo>-</mo>
      <mi>α</mi>
      <mo>)</mo>
    </mrow>
    <msub><mi>y</mi> <mrow><mi>T</mi><mo>-</mo><mn>1</mn></mrow> </msub>
    <mo>+</mo>
    <mi>α</mi>
    <msup><mrow><mo>(</mo><mn>1</mn><mo>-</mo><mi>α</mi><mo>)</mo></mrow> <mn>2</mn> </msup>
    <msub><mi>y</mi> <mrow><mi>T</mi><mo>-</mo><mn>2</mn></mrow> </msub>
    <mo>+</mo>
    <mo>...</mo>
    <mo>=</mo>
    <mi>α</mi>
    <munderover><mo>∑</mo> <mrow><mi>n</mi><mo>=</mo><mn>0</mn></mrow> <mi>k</mi> </munderover>
    <msup><mrow><mo>(</mo><mn>1</mn><mo>-</mo><mi>a</mi><mo>)</mo></mrow> <mi>n</mi> </msup>
    <msub><mi>y</mi> <mrow><mi>T</mi><mo>-</mo><mi>n</mi></mrow> </msub>
  </mrow>
</math>
</div>

<p class="author1"><math alttext="alpha">
  <mi>α</mi>
</math> is a smoothing parameter. When <math alttext="alpha equals 1">
  <mrow>
    <mi>α</mi>
    <mo>=</mo>
    <mn>1</mn>
  </mrow>
</math>, all the terms except the first are zeroed and we are left with the naive method. Values less than 1 suggest how important previous samples should be.</p>

<p class="author1">Like for the naive method, the alert criteria for Atlas is  whenever the query in <a data-type="xref" href="part0009_split_028.html#forecasting_single_exponential_method_atlas" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre">Example 4-38</a> returns <code class="calibre24">1</code>.</p>
<div id="forecasting_single_exponential_method_atlas" data-type="example" class="calibre61">
<h5 class="calibre62"><span class="keep-together">Example 4-38. </span>Atlas alert criteria for single-exponential smoothing</h5>

<pre data-type="programlisting" class="calibre63">alpha,0.2,:set,
coefficient,(,alpha,:get,1,alpha,:get,:sub,),:set,
name,requestsPerSecond,:eq,
:dup,:dup,:dup,:dup,:dup,:dup,
0,:roll,1m,:offset,coefficient,:fcall,0,:pow,:mul,:mul,
1,:roll,2m,:offset,coefficient,:fcall,1,:pow,:mul,:mul,
2,:roll,3m,:offset,coefficient,:fcall,2,:pow,:mul,:mul,
3,:roll,4m,:offset,coefficient,:fcall,3,:pow,:mul,:mul,
4,:roll,5m,:offset,coefficient,:fcall,4,:pow,:mul,:mul,
5,:roll,6m,:offset,coefficient,:fcall,5,:pow,:mul,:mul,
:add,:add,:add,:add,:add,
0.83,:mul, <a class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre" id="co_charting_and_alerting_CO10-1" href="part0009_split_028.html#callout_charting_and_alerting_CO10-1"><img src="../images/00112.png" alt="1" class="calibre66"/></a>
:lt,</pre></div>
<dl class="calibre20">
<dt class="calibre21"><a class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre" id="callout_charting_and_alerting_CO10-1" href="part0009_split_028.html#co_charting_and_alerting_CO10-1"><img src="../images/00112.png" alt="1" class="calibre66"/></a></dt>
<dd class="calibre67"><p class="calibre68">The tightness of the threshold is set with this factor.</p></dd>
</dl>

<p class="author1">The summation <math alttext="alpha sigma-summation Underscript n equals 0 Overscript k Endscripts left-parenthesis 1 minus a right-parenthesis Superscript n">
  <mrow>
    <mi>α</mi>
    <msubsup><mo>∑</mo> <mrow><mi>n</mi><mo>=</mo><mn>0</mn></mrow> <mi>k</mi> </msubsup>
    <msup><mrow><mo>(</mo><mn>1</mn><mo>-</mo><mi>a</mi><mo>)</mo></mrow> <mi>n</mi> </msup>
  </mrow>
</math> is a geometric series that converges to 1. For example, for <math alttext="alpha equals 0.5">
  <mrow>
    <mi>α</mi>
    <mo>=</mo>
    <mn>0</mn>
    <mo>.</mo>
    <mn>5</mn>
  </mrow>
</math>, see <a data-type="xref" href="part0009_split_028.html#alpha_zero_five_convergence" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre">Table 4-3</a>.</p>
<table id="alpha_zero_five_convergence" class="calibre40">
<caption class="calibre41"><span class="keep-together">Table 4-3. </span>The convergence to 1 of the geometric series where <math alttext="alpha equals 0.5">
  <mrow>
    <mi>α</mi>
    <mo>=</mo>
    <mn>0</mn>
    <mo>.</mo>
    <mn>5</mn>
  </mrow>
</math></caption>
<thead class="calibre42">
<tr class="calibre43">
<th class="calibre44"><math alttext="upper T">
  <mi>T</mi>
</math></th>
<th class="calibre44"><math alttext="left-parenthesis 1 minus alpha right-parenthesis Superscript upper T">
  <msup><mrow><mo>(</mo><mn>1</mn><mo>-</mo><mi>α</mi><mo>)</mo></mrow> <mi>T</mi> </msup>
</math></th>
<th class="calibre44"><math alttext="alpha sigma-summation Underscript n equals 0 Overscript k Endscripts left-parenthesis 1 minus a right-parenthesis Superscript n">
  <mrow>
    <mi>α</mi>
    <msubsup><mo>∑</mo> <mrow><mi>n</mi><mo>=</mo><mn>0</mn></mrow> <mi>k</mi> </msubsup>
    <msup><mrow><mo>(</mo><mn>1</mn><mo>-</mo><mi>a</mi><mo>)</mo></mrow> <mi>n</mi> </msup>
  </mrow>
</math></th>
</tr>
</thead>
<tbody class="calibre45">
<tr class="calibre46">
<td class="calibre47"><p class="calibre48">0</p></td>
<td class="calibre47"><p class="calibre48">0.5</p></td>
<td class="calibre47"><p class="calibre48">0.5</p></td>
</tr>
<tr class="calibre49">
<td class="calibre47"><p class="calibre48">1</p></td>
<td class="calibre47"><p class="calibre48">0.25</p></td>
<td class="calibre47"><p class="calibre48">0.75</p></td>
</tr>
<tr class="calibre46">
<td class="calibre47"><p class="calibre48">2</p></td>
<td class="calibre47"><p class="calibre48">0.125</p></td>
<td class="calibre47"><p class="calibre48">0.88</p></td>
</tr>
<tr class="calibre49">
<td class="calibre47"><p class="calibre48">3</p></td>
<td class="calibre47"><p class="calibre48">0.063</p></td>
<td class="calibre47"><p class="calibre48">0.938</p></td>
</tr>
<tr class="calibre46">
<td class="calibre47"><p class="calibre48">4</p></td>
<td class="calibre47"><p class="calibre48">0.031</p></td>
<td class="calibre47"><p class="calibre48">0.969</p></td>
</tr>
<tr class="calibre50">
<td class="calibre47"><p class="calibre48">5</p></td>
<td class="calibre47"><p class="calibre48">0.016</p></td>
<td class="calibre47"><p class="calibre48">0.984</p></td>
</tr>
</tbody>
</table>

<p class="author1">Since we don’t include <em class="calibre12">all</em> values of <code class="calibre24">T</code>, the smoothed function is effectively already multiplied by a factor equal to the cumulative sum of this geometric series up to the number of terms we have chosen. <a data-type="xref" href="part0009_split_028.html#single_exponential_scaling_effect" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre">Figure 4-35</a> shows summations of one term and two terms in the series relative to the true value (respectively from bottom to top).</p>

<figure class="calibre32"><div id="single_exponential_scaling_effect" class="figure">
<img src="../images/00009.png" alt="srej 0435" class="calibre135"/>
<h6 class="calibre34"><span class="keep-together">Figure 4-35. </span>Scaling effect of choosing a limited summation</h6>
</div></figure>

<p class="author1"><a data-type="xref" href="part0009_split_028.html#single_exponential_different_constants" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre">Figure 4-36</a> shows how different selections of <math alttext="alpha">
  <mi>α</mi>
</math> and <math alttext="upper T">
  <mi>T</mi>
</math> affect the dynamic threshold, in terms of both how smoothed it is and its approximate scaling factor relative to the true indicator.</p>

<figure class="calibre32"><div id="single_exponential_different_constants" class="figure">
<img src="../images/00105.png" alt="srej 0436" class="calibre136"/>
<h6 class="calibre34"><span class="keep-together">Figure 4-36. </span>Smoothing and scaling effect when choosing different <math alttext="alpha">
  <mi>α</mi>
</math> and <math alttext="upper T">
  <mi>T</mi>
</math></h6>
</div></figure>
</div></section>













</div></section>













</div></section></div>



  

<div id="sbo-rt-content" class="calibre2">
<section data-type="chapter" type="chapter" data-pdf-bookmark="Chapter 4. Charting and Alerting" class="calibre3">
<div class="preface" id="ch_charting_alerting">
<section data-type="sect1" data-pdf-bookmark="Building Alerts Using Forecasting Methods" class="calibre3">
<div class="preface" id="forecasting_and_alerting">
<section data-type="sect2" data-pdf-bookmark="Universal Scalability Law" class="calibre3"><div class="preface" id="usl">
<h2 class="calibre37" id="8INGH-2d714b853a094e9a910510217e0e3d73">Universal Scalability Law</h2>

<p class="author1"><a data-type="indexterm" data-primary="forecasting methods" data-secondary="universal scalability law" id="ix_ch04-asciidoc54" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre"/><a data-type="indexterm" data-primary="universal scalability law (USL)" id="ix_ch04-asciidoc55" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre"/>In this section, we are going to shift our mindset entirely from smoothing datapoints that happened in the <em class="calibre12">past</em> (which we used as dynamic alert thresholds) to a technique that allows us to predict what <em class="calibre12">future</em> performance will look like if concurrency/throughput increases beyond current levels, using only a small set of samples of what performance has looked like at already-seen concurrency levels. In this way, we can set <em class="calibre12">predictive</em> alerts as we approach a service-level objective boundary to hopefully head off problems rather than reacting to something already exceeding the boundary. In other words, this technique allows us to test a <em class="calibre12">predicted</em> service-level indicator value against our SLO at a throughput that we haven’t yet experienced.</p>

<p class="author1">This technique is based on a mathematical principle known as Little’s Law and the Universal Scalability Law (USL). We’ll keep the mathematical explanation here to a minimum. What little is discussed you can skip past. For more details, Baron Schwartz’s freely available <em class="calibre12">Practical Scalability Analysis with the Universal Scalability Law</em> (VividCortex) is a great reference.</p>
</div></section>





</div></section>













</div></section></div>



  

<div id="sbo-rt-content" class="calibre2">
<section data-type="chapter" type="chapter" data-pdf-bookmark="Chapter 4. Charting and Alerting" class="calibre3">
<div class="preface" id="ch_charting_alerting">
<section data-type="sect1" data-pdf-bookmark="Building Alerts Using Forecasting Methods" class="calibre3">
<div class="preface" id="forecasting_and_alerting">
<section data-type="sect2" data-pdf-bookmark="Universal Scalability Law" class="calibre3">
<div class="preface" id="usl">
<div data-type="tip" class="calibre28"><h1 class="calibre54" id="calibre_pb_30">Using Universal Scalability Law in the Delivery Pipeline</h1>
<p class="author1"><a data-type="indexterm" data-primary="delivery pipelines" data-secondary="using universal scalability law in" id="idm45139265330456" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre"/>In addition to predicting impending SLA violations in production systems, we can use the same telemetry in a delivery pipeline to throw some traffic at a piece of software that doesn’t need to be anywhere close to the maximum traffic it might see in production and predict whether production-level traffic will meet an SLA. And we can do this before deploying a new version of the software to production!</p>
</div>

<p class="author1"><a data-type="indexterm" data-primary="Little’s Law" id="idm45139265328536" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre"/>Little’s Law, <a data-type="xref" href="part0009_split_030.html#littles_law" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre">Equation 4-2</a>, describes the behavior of queues as a relationship between three variables: queue size (<math alttext="upper N">
  <mi>N</mi>
</math>), latency (<math alttext="upper R">
  <mi>R</mi>
</math>), and throughput (<math alttext="upper X">
  <mi>X</mi>
</math>). If the application of queuing theory to SLI predictions seems a little mind-bending, don’t worry (because it is). But for our purposes in predicting an SLI, <math alttext="upper N">
  <mi>N</mi>
</math> will represent the concurrency level of requests passing through our system, <math alttext="upper X">
  <mi>X</mi>
</math> the throughput, and <math alttext="upper R">
  <mi>R</mi>
</math> a latency measure like average or a high-percentile value. Since this is a relationship between three variables, provided any two we can derive the third. Since we care about <span class="keep-together">predicting</span> latency (<math alttext="upper R">
  <mi>R</mi>
</math>), we’d need to forecast this in the two dimensions of concurrency (<math alttext="upper N">
  <mi>N</mi>
</math>) and throughput (<math alttext="upper X">
  <mi>X</mi>
</math>).</p>
<div id="littles_law" data-type="equation" class="calibre61">
<h5 class="calibre72"><span class="keep-together">Equation 4-2. </span>Little’s Law</h5>
<math alttext="StartLayout 1st Row 1st Column upper N 2nd Column equals 3rd Column upper X upper R 2nd Row 1st Column upper X 2nd Column equals 3rd Column upper N slash upper R 3rd Row 1st Column upper R 2nd Column equals 3rd Column upper N slash upper X EndLayout" display="block">
  <mtable>
    <mtr>
      <mtd columnalign="left">
        <mi>N</mi>
      </mtd>
      <mtd>
        <mo>=</mo>
      </mtd>
      <mtd columnalign="left">
        <mrow>
          <mi>X</mi>
          <mi>R</mi>
        </mrow>
      </mtd>
    </mtr>
    <mtr>
      <mtd columnalign="left">
        <mi>X</mi>
      </mtd>
      <mtd>
        <mo>=</mo>
      </mtd>
      <mtd columnalign="left">
        <mrow>
          <mi>N</mi>
          <mo>/</mo>
          <mi>R</mi>
        </mrow>
      </mtd>
    </mtr>
    <mtr>
      <mtd columnalign="left">
        <mi>R</mi>
      </mtd>
      <mtd>
        <mo>=</mo>
      </mtd>
      <mtd columnalign="left">
        <mrow>
          <mi>N</mi>
          <mo>/</mo>
          <mi>X</mi>
        </mrow>
      </mtd>
    </mtr>
  </mtable>
</math>
</div>

<p class="author1">The Universal Scalability Law, <a data-type="xref" href="part0009_split_030.html#usl_formula" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre">Equation 4-3</a>, allows us instead to project latency in terms of only a single variable: either throughput or concurrency. This equation requires three coefficients, which will be derived and updated from a model maintained by Micrometer based on real observations about the system’s performance to this point. USL defines <math alttext="kappa">
  <mi>κ</mi>
</math> to be the cost of crosstalk, <math alttext="phi">
  <mi>ϕ</mi>
</math> to be the cost of contention, and <math alttext="lamda">
  <mi>λ</mi>
</math> to be how fast the system operates under unloaded conditions. The coefficients become fixed values making predictions on latency, throughput, or concurrency dependent on only one of the other three. Micrometer will also publish the values of these coefficients as they change over time, so you can compare the system’s major governing performance characteristics over time.</p>
<div id="usl_formula" data-type="equation" class="calibre61">
<h5 class="calibre72"><span class="keep-together">Equation 4-3. </span>Universal Scalability Law</h5>
<math alttext="upper X left-parenthesis upper N right-parenthesis equals StartFraction lamda upper N Over 1 plus phi left-parenthesis upper N minus 1 right-parenthesis plus kappa upper N left-parenthesis upper N minus 1 right-parenthesis EndFraction" display="block">
  <mrow>
    <mi>X</mi>
    <mrow>
      <mo>(</mo>
      <mi>N</mi>
      <mo>)</mo>
    </mrow>
    <mo>=</mo>
    <mfrac><mrow><mi>λ</mi><mi>N</mi></mrow> <mrow><mn>1</mn><mo>+</mo><mi>ϕ</mi><mo>(</mo><mi>N</mi><mo>-</mo><mn>1</mn><mo>)</mo><mo>+</mo><mi>κ</mi><mi>N</mi><mo>(</mo><mi>N</mi><mo>-</mo><mn>1</mn><mo>)</mo></mrow></mfrac>
  </mrow>
</math>
</div>

<p class="author1">With a series of substitutions, we get to express <math alttext="upper R">
  <mi>R</mi>
</math> in terms of <math alttext="upper X">
  <mi>X</mi>
</math> or <math alttext="upper N">
  <mi>N</mi>
</math> (see <a data-type="xref" href="part0009_split_030.html#usl_predicted_latency" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre">Equation 4-4</a>). Again, don’t think too hard about these relationships, because Micrometer is going to do these calculations for you.</p>
<div id="usl_predicted_latency" data-type="equation" class="calibre61">
<h5 class="calibre72"><span class="keep-together">Equation 4-4. </span>Predicted latency as a function of either throughput or concurrency</h5>
<math alttext="StartLayout 1st Row 1st Column upper R left-parenthesis upper N right-parenthesis 2nd Column equals 3rd Column StartFraction 1 plus phi left-parenthesis upper N minus 1 right-parenthesis plus kappa upper N left-parenthesis upper N minus 1 right-parenthesis Over lamda EndFraction 2nd Row 1st Column upper R left-parenthesis upper X right-parenthesis 2nd Column equals 3rd Column StartFraction minus StartRoot upper X squared left-parenthesis kappa squared plus 2 kappa left-parenthesis phi minus 2 right-parenthesis plus phi squared right-parenthesis plus 2 lamda upper X left-parenthesis kappa minus phi right-parenthesis plus lamda squared EndRoot plus kappa upper X plus lamda minus phi upper X Over 2 kappa upper X squared EndFraction EndLayout" display="block">
  <mtable>
    <mtr>
      <mtd columnalign="left">
        <mrow>
          <mi>R</mi>
          <mo>(</mo>
          <mi>N</mi>
          <mo>)</mo>
        </mrow>
      </mtd>
      <mtd>
        <mo>=</mo>
      </mtd>
      <mtd columnalign="left">
        <mfrac><mrow><mn>1</mn><mo>+</mo><mi>ϕ</mi><mo>(</mo><mi>N</mi><mo>-</mo><mn>1</mn><mo>)</mo><mo>+</mo><mi>κ</mi><mi>N</mi><mo>(</mo><mi>N</mi><mo>-</mo><mn>1</mn><mo>)</mo></mrow> <mi>λ</mi></mfrac>
      </mtd>
    </mtr>
    <mtr>
      <mtd columnalign="left">
        <mrow>
          <mi>R</mi>
          <mo>(</mo>
          <mi>X</mi>
          <mo>)</mo>
        </mrow>
      </mtd>
      <mtd>
        <mo>=</mo>
      </mtd>
      <mtd columnalign="left">
        <mfrac><mrow><mo>-</mo><msqrt><mrow><msup><mi>X</mi> <mn>2</mn> </msup><mrow><mo>(</mo><msup><mi>κ</mi> <mn>2</mn> </msup><mo>+</mo><mn>2</mn><mi>κ</mi><mrow><mo>(</mo><mi>ϕ</mi><mo>-</mo><mn>2</mn><mo>)</mo></mrow><mo>+</mo><msup><mi>ϕ</mi> <mn>2</mn> </msup><mo>)</mo></mrow><mo>+</mo><mn>2</mn><mi>λ</mi><mi>X</mi><mrow><mo>(</mo><mi>κ</mi><mo>-</mo><mi>ϕ</mi><mo>)</mo></mrow><mo>+</mo><msup><mi>λ</mi> <mn>2</mn> </msup></mrow></msqrt><mo>+</mo><mi>κ</mi><mi>X</mi><mo>+</mo><mi>λ</mi><mo>-</mo><mi>ϕ</mi><mi>X</mi></mrow> <mrow><mn>2</mn><mi>κ</mi><msup><mi>X</mi> <mn>2</mn> </msup></mrow></mfrac>
      </mtd>
    </mtr>
  </mtable>
</math>
</div>

<p class="author1">What we’ll get is a nice two-dimensional projection instead, as shown in <a data-type="xref" href="part0009_split_030.html#usl_prediction" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre">Figure 4-37</a>.</p>

<figure class="calibre32"><div id="usl_prediction" class="figure">
<img src="../images/00098.png" alt="srej 0437" class="calibre137"/>
<h6 class="calibre34"><span class="keep-together">Figure 4-37. </span>USL prediction of latency based on different throughput levels</h6>
</div></figure>

<p class="author1">USL forecasting is a form of “derived” <code class="calibre24">Meter</code> in Micrometer and can be enabled as shown in <a data-type="xref" href="part0009_split_030.html#usl_micrometer_config" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre">Example 4-39</a>. Micrometer will publish a set of <code class="calibre24">Gauge</code> meters forming a series of forecasts at various throughput/concurrency levels for each publishing interval. Throughput and concurrency are correlated measurements, so think of them interchangeably from this point on. When you select a related group of timers (which will always have the same name) to publish a forecast for, Micrometer will publish several additional metrics using the common metric name as a prefix:</p>
<dl class="calibre20">
<dt class="calibre21">timer.name.forecast</dt>
<dd class="calibre22">
<p class="calibre23">A series of <code class="calibre24">Gauge</code> meters with a tag <code class="calibre24">throughput</code> or <code class="calibre24">concurrency</code> based on the type of independent variable selected. At a certain time interval, plotting these gauges would generate a visualization like <a data-type="xref" href="part0009_split_030.html#usl_prediction" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre">Figure 4-37</a>.</p>
</dd>
<dt class="calibre21">timer.name.crosstalk</dt>
<dd class="calibre22">
<p class="calibre23">A direct measure of the system’s crosstalk (e.g., fan-out in a distributed system like that described in the paper by S. Cho et al.,  <a href="https://oreil.ly/y6qO9" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre">“Moolle: Fan-out Control for Scalable Distributed Data Stores”</a>).</p>
</dd>
<dt class="calibre21">timer.name.contention</dt>
<dd class="calibre22">
<p class="calibre23">A direct measure of the system’s contention (e.g., locking on relational database tables and in general any other form of lock synchronization).</p>
</dd>
<dt class="calibre21">timer.name.unloaded.performance</dt>
<dd class="calibre22">
<p class="calibre23">Improvements in ideal unloaded performance (e.g., framework performance improvements) can be expected to yield improvements in loaded conditions as well.</p>
</dd>
</dl>
<div id="usl_micrometer_config" data-type="example" class="calibre61">
<h5 class="calibre62"><span class="keep-together">Example 4-39. </span>Universal scalability law forecast configuration in Micrometer</h5>

<pre data-type="programlisting" data-code-language="java" class="calibre63"><code class="n">UniversalScalabilityLawForecast</code><code class="calibre24">
</code><code class="calibre24">    </code><code class="o">.</code><code class="na">builder</code><code class="o">(</code><code class="calibre24">
</code><code class="calibre24">      </code><code class="n">registry</code><code class="calibre24">
</code><code class="calibre24">        </code><code class="o">.</code><code class="na">find</code><code class="o">(</code><code class="s">"http.server.requests"</code><code class="o">)</code><code class="calibre24"> </code><a class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre" id="co_charting_and_alerting_CO11-1" href="part0009_split_030.html#callout_charting_and_alerting_CO11-1"><img src="../images/00112.png" alt="1" class="calibre66"/></a><code class="calibre24">
</code><code class="calibre24">        </code><code class="o">.</code><code class="na">tag</code><code class="o">(</code><code class="s">"uri"</code><code class="o">,</code><code class="calibre24"> </code><code class="s">"/myendpoint"</code><code class="o">)</code><code class="calibre24"> </code><a class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre" id="co_charting_and_alerting_CO11-2" href="part0009_split_030.html#callout_charting_and_alerting_CO11-2"><img src="../images/00059.png" alt="2" class="calibre66"/></a><code class="calibre24">
</code><code class="calibre24">        </code><code class="o">.</code><code class="na">tag</code><code class="o">(</code><code class="s">"status"</code><code class="o">,</code><code class="calibre24"> </code><code class="n">s</code><code class="calibre24"> </code><code class="o">-</code><code class="o">&gt;</code><code class="calibre24"> </code><code class="n">s</code><code class="o">.</code><code class="na">startsWith</code><code class="o">(</code><code class="s">"2"</code><code class="o">)</code><code class="o">)</code><code class="calibre24"> </code><a class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre" id="co_charting_and_alerting_CO11-3" href="part0009_split_030.html#callout_charting_and_alerting_CO11-3"><img src="../images/00067.png" alt="3" class="calibre66"/></a><code class="calibre24">
</code><code class="calibre24">    </code><code class="o">)</code><code class="calibre24">
</code><code class="calibre24">    </code><code class="o">.</code><code class="na">independentVariable</code><code class="o">(</code><code class="n">UniversalScalabilityLawForecast</code><code class="o">.</code><code class="na">Variable</code><code class="o">.</code><code class="na">THROUGHPUT</code><code class="o">)</code><code class="calibre24"> </code><a class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre" id="co_charting_and_alerting_CO11-4" href="part0009_split_030.html#callout_charting_and_alerting_CO11-4"><img src="../images/00016.png" alt="4" class="calibre66"/></a><code class="calibre24">
</code><code class="calibre24">    </code><code class="c">// In this case, forecast to up to 1,000 requests/second (throughput)
</code><code class="calibre24">    </code><code class="o">.</code><code class="na">maximumForecast</code><code class="o">(</code><code class="mi">1000</code><code class="o">)</code><code class="calibre24">
</code><code class="calibre24">    </code><code class="o">.</code><code class="na">register</code><code class="o">(</code><code class="n">registry</code><code class="o">)</code><code class="o">;</code></pre></div>
<dl class="calibre20">
<dt class="calibre21"><a class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre" id="callout_charting_and_alerting_CO11-1" href="part0009_split_030.html#co_charting_and_alerting_CO11-1"><img src="../images/00112.png" alt="1" class="calibre66"/></a></dt>
<dd class="calibre67"><p class="calibre68">The forecast will be based on the results of a Micrometer meter search for one or more timers with name <code class="calibre24">http.server.requests</code> (remember, there may be several such timers with different tag values).</p></dd>
<dt class="calibre21"><a class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre" id="callout_charting_and_alerting_CO11-2" href="part0009_split_030.html#co_charting_and_alerting_CO11-2"><img src="../images/00059.png" alt="2" class="calibre66"/></a></dt>
<dd class="calibre67"><p class="calibre68">We can further limit the set of timers to base the forecast on by only matching on timers that have a specific key-value tag pair.</p></dd>
<dt class="calibre21"><a class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre" id="callout_charting_and_alerting_CO11-3" href="part0009_split_030.html#co_charting_and_alerting_CO11-3"><img src="../images/00067.png" alt="3" class="calibre66"/></a></dt>
<dd class="calibre67"><p class="calibre68">Like with any search, the tag value can be constrained with a lambda as well. A good example is constraining the forecast to any “2xx” HTTP statuses.</p></dd>
<dt class="calibre21"><a class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre" id="callout_charting_and_alerting_CO11-4" href="part0009_split_030.html#co_charting_and_alerting_CO11-4"><img src="../images/00016.png" alt="4" class="calibre66"/></a></dt>
<dd class="calibre67"><p class="calibre68">The domain of the <code class="calibre24">Gauge</code> histogram will be either <code class="calibre24">UniversalScalabilityLawForecast.Variable.CONCURRENCY</code> or <code class="calibre24">UniversalScalabilityLawForecast.Variable.THROUGHPUT</code>, defaulting to <code class="calibre24">THROUGHPUT</code>.</p></dd>
</dl>

<p class="author1">The latency an application is experiencing at its current throughput in one of these time slices will closely follow the “predicted” latency from the forecast. We can set an alert based on some scaled-up value of whatever the current throughput is to determine if the predicted latency at that scaled-up throughput would still be under our SLO.</p>

<p class="author1">In addition to predicting an SLI under increased throughput, the modeled values for crosstalk, contention, and unloaded performance are a strong indicator of where performance improvements can be made in an application. After all, decreases in crosstalk and contention and increases in unloaded performance directly impact the system’s predicted and actual latency under various levels of load<a data-type="indexterm" data-startref="ix_ch04-asciidoc55" id="idm45139265101208" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre"/><a data-type="indexterm" data-startref="ix_ch04-asciidoc54" id="idm45139265100504" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre"/>.<a data-type="indexterm" data-startref="ix_ch04-asciidoc53" id="idm45139265099704" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre"/><a data-type="indexterm" data-startref="ix_ch04-asciidoc52" id="idm45139265099000" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre"/></p>
</div></section>





</div></section>













</div></section></div>



  

<div id="sbo-rt-content" class="calibre2">
<section data-type="chapter" type="chapter" data-pdf-bookmark="Chapter 4. Charting and Alerting" class="calibre3">
<div class="preface" id="ch_charting_alerting">
<section data-type="sect1" data-pdf-bookmark="Summary" class="calibre3"><div class="preface" id="idm45139265338728">
<h1 class="calibre19" id="calibre_pb_31">Summary</h1>

<p class="author1">This chapter has presented you with the tools you need to start monitoring every Java microservice for availability with signals that are included in Java frameworks like Spring Boot. We’ve also discussed more generally how to alert on and visualize classes of metrics like counters and timers.</p>

<p class="author1">Though you should strive for finding ways of measuring microservice availability in terms of business-focused metrics, using these basic signals is a huge step forward over simply looking at box metrics in terms of understanding how your service is performing.</p>

<p class="author1">Organizationally, you’ve committed to standing up a dashboarding/alerting tool. We showed Grafana in this chapter. Its open source availability and datasources for a wide array of popular monitoring systems make it a solid choice to build on top of without locking yourself in completely to a particular vendor.</p>

<p class="author1">In the next chapter, we’re going to transition to delivery automation, where we’ll see how some of these availability signals are used in making decisions about the fitness of new microservice releases. Effective delivery isn’t strictly about the motion of deploying; it turns monitoring into action.<a data-type="indexterm" data-startref="ix_ch04-asciidoc0" id="idm45139265094296" class="pcalibre2 pcalibre3 pcalibre1 pcalibre4 pcalibre"/></p>
</div></section>







</div></section></div>



  </body></html>