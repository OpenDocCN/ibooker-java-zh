<html><head></head><body><section class="pagenumrestart" data-pdf-bookmark="Chapter 1. Introduction" data-type="chapter" epub:type="chapter"><div class="chapter" id="Introduction">&#13;
<h1><span class="label">Chapter 1. </span>Introduction</h1>&#13;
&#13;
&#13;
<p>This is a book about the art and science of Java performance.</p>&#13;
&#13;
<p>The science part of this statement isn’t surprising; discussions about&#13;
performance include lots of numbers and measurements and analytics. Most&#13;
performance engineers have a background in the sciences, and applying&#13;
scientific rigor is a crucial part of achieving maximum performance.</p>&#13;
&#13;
<p>What about the art part? The notion that performance tuning is part art&#13;
and part science is hardly new, but it is rarely given explicit&#13;
acknowledgment in performance discussions. This is partly because the&#13;
idea of “art” goes against our training. But what looks like art to some people is fundamentally based on deep knowledge and experience. It is said that&#13;
magic is indistinguishable from sufficiently advanced technologies, and&#13;
certainly it is true that a cell phone would look magical to a knight of&#13;
the Round Table. Similarly, the work produced by a good performance&#13;
engineer may look like art, but that art is really an application of&#13;
deep knowledge, experience, and <span class="keep-together">&#13;
intuition.</span></p>&#13;
&#13;
<p>This book cannot help with the experience and intuition part of that&#13;
equation, but it can provide the deep knowledge—with the view&#13;
that applying knowledge over time will help you develop the&#13;
skills needed to be a good Java performance engineer. The goal is to give you an&#13;
in-depth understanding of the performance aspects of the Java platform.</p>&#13;
&#13;
<p>This knowledge falls into two broad categories.&#13;
<a data-primary="Java Virtual Machine (JVM)" data-type="indexterm" id="idm45775551679928"/>First is the performance&#13;
of the Java Virtual Machine (JVM) itself: the way that the JVM is&#13;
configured affects many aspects of a program’s performance. Developers&#13;
who are experienced in other languages may find the need for tuning to be&#13;
somewhat irksome, though in reality tuning the JVM is completely analogous&#13;
to testing and choosing compiler flags during compilation for C++ programmers,&#13;
or to setting appropriate variables in a <em>php.ini</em> file for PHP coders, and&#13;
so on.</p>&#13;
&#13;
<p>The second aspect is to understand how the features of the Java platform&#13;
affect performance. Note the use of the word <em>platform</em> here: some features&#13;
(e.g., threading and synchronization) are part of the language, and some&#13;
features (e.g., string handling) are part of the standard Java API.&#13;
Though important distinctions exist between the Java language and the&#13;
Java API, in this case they will be treated similarly. This book covers&#13;
both facets of the platform.</p>&#13;
&#13;
<p>The performance of the JVM is based largely on tuning flags, while the&#13;
performance of the platform is determined more by using best practices&#13;
within your application code. For a long time, these were considered&#13;
separate areas of expertise: developers code, and the performance group tests&#13;
and recommends fixes for performance issues.&#13;
That was never a particularly useful distinction—anyone who works with&#13;
Java should be equally adept at understanding how code behaves in the&#13;
JVM and what kinds of tuning are likely to help its performance. As projects&#13;
move to a devops model, this distinction is starting to become less strict.&#13;
Knowledge of&#13;
the complete sphere is what will give your work the patina of art.</p>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="A Brief Outline" data-type="sect1"><div class="sect1" id="idm45775551895992">&#13;
<h1>A Brief Outline</h1>&#13;
&#13;
<p>First things first, though: <a data-type="xref" href="ch02.html#SampleApplications">Chapter 2</a> discusses general&#13;
methodologies for testing Java applications, including pitfalls of Java&#13;
benchmarking. Since performance analysis requires visibility into what&#13;
the application is doing, <a data-type="xref" href="ch03.html#Tools">Chapter 3</a> provides an overview of some of&#13;
the tools available to monitor Java applications.</p>&#13;
&#13;
<p>Then it is time to dive into performance, focusing first on&#13;
common tuning aspects: just-in-time compilation (<a data-type="xref" href="ch04.html#JustInTimeCompilation">Chapter 4</a>) and garbage collection (<a data-type="xref" href="ch05.html#GC">Chapter 5</a> and <a data-type="xref" href="ch06.html#Collectors">Chapter 6</a>).&#13;
The remaining chapters focus&#13;
on best-practice uses of various parts of the Java platform:&#13;
memory use with the Java heap&#13;
(<a data-type="xref" href="ch07.html#Memory">Chapter 7</a>), native memory use (<a data-type="xref" href="ch08.html#NativeMemory">Chapter 8</a>),&#13;
thread performance (<a data-type="xref" href="ch09.html#ThreadPerformance">Chapter 9</a>), Java server&#13;
technology (<a data-type="xref" href="ch10.html#JavaServers">Chapter 10</a>), database access,&#13;
(<a data-type="xref" href="ch11.html#Database">Chapter 11</a>), and general Java SE API tips (<a data-type="xref" href="ch12.html#Misc">Chapter 12</a>).</p>&#13;
&#13;
<p><a data-type="xref" href="app01.html#FlagAppendix">Appendix A</a>&#13;
lists all the tuning flags discussed in this book, with cross-references&#13;
to the chapter where they are examined.</p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Platforms and Conventions" data-type="sect1"><div class="sect1" id="idm45775558472456">&#13;
<h1>Platforms and Conventions</h1>&#13;
&#13;
<p>While this book is about the performance of Java, that performance will be&#13;
influenced by a few factors: the version of Java itself, of course,&#13;
as well as the hardware and software platforms it is running on.</p>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Java Platforms" data-type="sect2"><div class="sect2" id="idm45775558470840">&#13;
<h2>Java Platforms</h2>&#13;
&#13;
<p><a data-primary="Java platform" data-type="indexterm" id="ix_ch01-asciidoc0"/>This book covers the performance of the Oracle HotSpot Java Virtual Machine (JVM)&#13;
and the <a data-primary="Java Development Kit (JDK)" data-type="indexterm" id="idm45775551889688"/>Java Development Kit (JDK), versions 8 and 11. This is also known as Java, Standard Edition (SE). The Java Runtime Environment (JRE) is a subset of the JDK containing only the JVM, but since the tools in the JDK are important for performance analysis, the JDK is the focus of this book. As&#13;
a practical matter, that means it also covers platforms derived from the&#13;
OpenJDK repository of that technology, which includes the JVMs released&#13;
from the <a href="http://adoptopenjdk.net">AdoptOpenJDK project</a>. Strictly speaking,&#13;
the Oracle binaries require a license for production use, and the AdoptOpenJdK&#13;
binaries come with an open source license. For our purposes, we’ll consider&#13;
the two versions to be the same thing, which we’ll refer to as the <em>JDK</em> or&#13;
the <em>Java platform</em>.<sup><a data-type="noteref" href="ch01.html#idm45775551886680" id="idm45775551886680-marker">1</a></sup></p>&#13;
&#13;
<p>These releases have gone through various bug fix releases. As I write this,&#13;
the current version of Java 8 is jdk8u222 (version 222), and the current version&#13;
of Java 11 is 11.0.5. It is important to use at least these versions (if&#13;
not later),&#13;
particularly in the case of Java 8. Early releases of Java 8 (through about&#13;
jdk8u60) do not contain many of the important performance enhancements and&#13;
features discussed throughout this book (particularly so with regard&#13;
to garbage collection and the G1 garbage collector).</p>&#13;
&#13;
<p>These versions of the JDK were selected because they carry long-term support&#13;
(LTS)&#13;
from Oracle. The Java community is free to develop their own support models&#13;
but so far have followed the Oracle model. So these releases will be&#13;
supported and available for quite some time: through at least 2023 for&#13;
Java 8 (via AdoptOpenJDK; later via extended Oracle support contracts), and&#13;
through at least 2022 for Java 11. The next long-term release is expected to&#13;
be in late 2021.</p>&#13;
&#13;
<p>For the interim releases, the discussion of Java 11 obviously includes&#13;
features that were first made available in Java 9 or Java 10, even though&#13;
those releases are unsupported both by Oracle and by the community&#13;
at large. In fact, I’m somewhat imprecise when discussing such features;&#13;
it may seem that I’m saying features X and Y were originally included in Java 11&#13;
when they&#13;
may have been available in Java 9 or 10. Java 11 is the first LTS release that carries&#13;
those features, and that’s the important part: since Java 9 and 10 aren’t in use,&#13;
it doesn’t really matter when the feature first appeared. Similarly, although&#13;
Java 13 will be out at the time of this book’s release, there isn’t a lot&#13;
of coverage of Java 12 or Java 13. You can use those releases in production,&#13;
but only for six months, after which you’ll need to upgrade to a new release&#13;
(so by the time you’re reading this, Java 12 is no longer supported, and&#13;
if Java 13 is supported, it will be soon replaced by Java 14). We’ll peek&#13;
into a few features of these interim releases, but since those releases are&#13;
not likely to be put into production in most environments, the focus remains&#13;
on Java 8 and 11.</p>&#13;
&#13;
<p>Other implementations of the Java Language specification are available,&#13;
including forks of the open source implementation. AdoptOpenJDK supplies&#13;
one of these (Eclipse OpenJ9), and others are available from other vendors.&#13;
Although all these platforms must pass a compatibility test in order to be&#13;
able to use the Java name, that compatibility does not always extend to&#13;
the topics discussed in this book. This is particularly true of tuning&#13;
flags. All JVM implementations have one or more garbage collectors, but&#13;
the flags to tune each vendor’s GC implementation are product-specific.&#13;
Thus, while the concepts of this book apply to any Java implementation, the&#13;
specific flags and recommendations apply only to the&#13;
HotSpot JVM.</p>&#13;
&#13;
<p>That caveat is applicable to earlier releases of the HotSpot JVM—flags and&#13;
their default values change from release to release. The flags discussed&#13;
here are valid for Java 8 (specifically, version 222) and 11 (specifically,&#13;
11.0.5). Later releases could slightly change some of this&#13;
information. Always consult the release notes for important changes.</p>&#13;
&#13;
<p>At an API level, different JVM implementations are much more compatible,&#13;
though even then subtle differences might exist between the way&#13;
a particular class is implemented in the Oracle HotSpot Java&#13;
platform and an alternate platform. The classes must be functionally&#13;
equivalent, but the actual implementation may change. Fortunately, that&#13;
is infrequent, and unlikely to drastically affect performance.</p>&#13;
&#13;
<p>For the remainder of this book, the terms <em>Java</em> and <em>JVM</em> should be understood&#13;
to refer specifically to the Oracle HotSpot implementation. Strictly&#13;
speaking, saying “The JVM does not compile code upon first execution” is&#13;
wrong; some Java implementations do compile code the first time&#13;
it is executed. But that shorthand is much easier than continuing to&#13;
write (and read), “The Oracle HotSpot JVM…”</p>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="JVM tuning flags" data-type="sect3"><div class="sect3" id="idm45775558531944">&#13;
<h3>JVM tuning flags</h3>&#13;
&#13;
<p><a data-primary="flags" data-seealso="-XX entries at beginning of index" data-type="indexterm" id="idm45775551712392"/><a data-primary="Java Virtual Machine (JVM)" data-secondary="tuning flag basics" data-type="indexterm" id="idm45775551711448"/>With a few exceptions, the JVM accepts two kinds of flags: boolean flags, and&#13;
flags that require a parameter.</p>&#13;
&#13;
<p><a data-primary="boolean flag syntax" data-type="indexterm" id="idm45775551710024"/>Boolean flags use this syntax:&#13;
<span class="keep-together"><code>-XX:+</code><em><code>FlagName</code></em></span>&#13;
enables the flag, and&#13;
<span class="keep-together"><code>-XX:-</code><em><code>FlagName</code></em></span>&#13;
disables the flag.</p>&#13;
&#13;
<p>Flags that require a parameter use this syntax:&#13;
<span class="keep-together"><code>-XX:</code><em><code>FlagName</code></em>=<em><code>something</code></em></span>,&#13;
meaning to set the value of&#13;
<span class="keep-together"><code>FlagName</code></span>&#13;
to&#13;
<span class="keep-together"><code>something</code></span>.&#13;
In the text, the&#13;
value of the flag is usually rendered with something indicating an arbitrary&#13;
value. For example,&#13;
<span class="keep-together"><code>-XX:NewRatio=</code><em><code>N</code></em></span>&#13;
means that the&#13;
<span class="keep-together"><code>NewRatio</code></span>&#13;
flag can&#13;
be set to an arbitrary value <em><code>N</code></em> (where the implications of <em><code>N</code></em> are the&#13;
focus of the discussion).</p>&#13;
&#13;
<p>The default value of each flag is discussed as the flag is introduced.&#13;
That default is often based on a combination of factors: the platform on which&#13;
the JVM is running and other command-line arguments to the JVM.&#13;
When in doubt, <a data-type="xref" href="ch03.html#VMInformation">“Basic VM Information”</a> shows how to use the&#13;
<span class="keep-together"><code>-XX:+PrintFlagsFinal</code></span>&#13;
flag (by default, <code>false</code>) to determine the&#13;
default value for a particular flag in a particular environment,&#13;
given a particular&#13;
command line. <a data-primary="ergonomics" data-type="indexterm" id="idm45775566215928"/>The process of automatically tuning flags based on the&#13;
environment is called <em>ergonomics</em>.</p>&#13;
&#13;
<p><a data-primary="product build" data-type="indexterm" id="idm45775566214520"/>The JVM that is downloaded from Oracle and AdoptOpenJDK sites is called the&#13;
<em>product build</em> of&#13;
the JVM. When the JVM is built from source code, many builds can be produced: debug builds, developer builds,&#13;
and so on. These builds often have additional functionality. In&#13;
particular, developer builds include an even larger set of tuning flags&#13;
so that developers can experiment with the most minute operations of various&#13;
algorithms used by the JVM. Those flags are generally not considered in&#13;
this book.<a data-startref="ix_ch01-asciidoc0" data-type="indexterm" id="idm45775566212872"/></p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Hardware Platforms" data-type="sect2"><div class="sect2" id="idm45775558470280">&#13;
<h2>Hardware Platforms</h2>&#13;
&#13;
<p>When the first edition of this book was published, the hardware landscape&#13;
looked different than it does today. Multicore machines were&#13;
popular, but 32-bit platforms and single-CPU platforms were still very much&#13;
in use. Other platforms in use today—virtual machines and software&#13;
containers—were coming into their own. Here’s an overview of how those&#13;
platforms affect the topics of this book.</p>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Multicore hardware" data-type="sect3"><div class="sect3" id="idm45775551483192">&#13;
<h3>Multicore hardware</h3>&#13;
&#13;
<p><a data-primary="muticore hardware" data-type="indexterm" id="idm45775551481752"/>Virtually all machines today have multiple cores of execution, which appear&#13;
to the JVM (and to any other program) as multiple CPUs. <a data-primary="hyper-threading" data-type="indexterm" id="idm45775551480776"/><a data-primary="simultaneous multithreading" data-type="indexterm" id="idm45775551480104"/>Typically, each&#13;
core is enabled for hyper-threading. <em>Hyper-threading</em> is the term that Intel&#13;
prefers, though AMD (and others) use the term <em>simultaneous multithreading</em>,&#13;
and some chip manufactures refer to hardware strands within a core. These&#13;
are all the same thing, and we’ll refer to this technology as&#13;
hyper-threading.</p>&#13;
&#13;
<p>From a performance perspective, the important thing about a machine is its number of cores. Let’s take a basic four-core machine: each core can&#13;
(for the most part) process independently of the others, so a machine with&#13;
four cores can achieve four times the throughput of a machine with a single&#13;
core. (This depends on other factors about the software, of&#13;
course.)</p>&#13;
&#13;
<p>In most cases, each core will contain two hardware or hyper-threads. These&#13;
threads are not independent of each other: the core can run only&#13;
one of them at a time. Often, the thread will stall: it will, for example,&#13;
need to load a value from main memory, and that process can take a few&#13;
cycles. In a core with a single thread, the thread stalls at that point,&#13;
and those CPU cycles are wasted. In a core with two threads, the core can&#13;
switch and execute instructions from the other thread.</p>&#13;
&#13;
<p>So our four-core machine with hyper-threading enabled appears as if it can&#13;
execute instructions from eight threads at once (even though, technically,&#13;
it can execute only four instructions per CPU cycle). To the operating&#13;
system—and hence to Java and other applications—the machine appears to&#13;
have eight CPUs. But all of those CPUs are not equal from a performance&#13;
perspective. If we run one CPU-bound task, it will use one core; a second&#13;
CPU-bound task will use a second core; and so on up to four: we can run&#13;
four independent CPU-bound tasks and get our fourfold increase in throughput.</p>&#13;
&#13;
<p>If we add a fifth task, it will be able to run only when one of the other&#13;
tasks stalls, which on average turns out to happen between&#13;
20% to 40% of the time. Each additional task faces the same challenge. So&#13;
adding a fifth task adds only about 30% more performance;&#13;
in the end, the eight CPUs will give us about five to six times the performance&#13;
of a single core (without hyper-threading).</p>&#13;
&#13;
<p>You’ll see this example in a few sections. Garbage collection is very much a&#13;
CPU-bound task, so <a data-type="xref" href="ch05.html#GC">Chapter 5</a> shows how hyper-threading affects the parallelization&#13;
of garbage collection algorithms. <a data-type="xref" href="ch09.html#ThreadPerformance">Chapter 9</a> discusses in general&#13;
how to exploit Java’s threading facilities to best effect, so you’ll see an&#13;
example of the scaling of hyper-threaded cores there as well.</p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Software containers" data-type="sect3"><div class="sect3" id="idm45775551417032">&#13;
<h3>Software containers</h3>&#13;
&#13;
<p><a data-primary="containers" data-type="indexterm" id="ix_ch01-asciidoc1"/>The biggest change in Java deployments in recent years is that they are&#13;
now frequently deployed within a software container. That change is&#13;
not limited to Java, of course; it’s an industry trend&#13;
hastened by the move to cloud computing.</p>&#13;
&#13;
<p>Two containers here are important. <a data-primary="virtual machines" data-secondary="container as" data-type="indexterm" id="idm45775551413848"/>First is the virtual machine,&#13;
which sets up a completely isolated copy of the operating system on a subset&#13;
of the hardware on which the virtual machine is running. This is the basis&#13;
of cloud computing: your cloud computing vendor has a data center with&#13;
very large machines. These machines have potentially 128 cores, though they&#13;
are likely smaller because of cost efficiencies. From the perspective of the&#13;
virtual machine, that doesn’t really matter: the virtual machine is given&#13;
access to a subset of that hardware. Hence, a given virtual machine may have&#13;
two cores (and four CPUs, since they are usually hyper-threaded) and 16 GB&#13;
of <span class="keep-together">memory.</span></p>&#13;
&#13;
<p>From Java’s perspective (and the perspective of&#13;
other applications), that virtual machine is indistinguishable from a regular&#13;
machine with two cores and 16 GB of memory. For tuning and performance&#13;
purposes, you need only consider it in the same way.</p>&#13;
&#13;
<p><a data-primary="Docker container" data-type="indexterm" id="idm45775551443800"/>The second container of note is the Docker container. A Java process running inside a Docker container doesn’t necessarily know it is in such a container (though it could figure it out by inspection), but the Docker container is just a process (potentially with resource constraints) within a running OS. As such, its isolation from other <span class="keep-together">processes’</span> CPU and memory usage is somewhat different. As you’ll see, the way Java handles that differs between early versions of Java 8 (up until update 192) and later version of Java 8 (and all versions of Java 11).</p>&#13;
<aside data-type="sidebar" epub:type="sidebar"><div class="sidebar" id="idm45775551441608">&#13;
<h5>Virtual Machine Oversubscription</h5>&#13;
<p><a data-primary="cloud vendors, VM oversubscription" data-type="indexterm" id="idm45775551440200"/><a data-primary="virtual machines" data-secondary="oversubscription" data-type="indexterm" id="idm45775551439432"/>Cloud vendors have the option of oversubscribing the virtual machines on&#13;
a physical box. Let’s say the physical box has 32 cores; the cloud vendor&#13;
will usually choose to deploy eight 4-core virtual machines on that box so&#13;
that each virtual machine has the four dedicated cores it expects.</p>&#13;
&#13;
<p>To save money, the vendor could choose to deploy 16 4-core virtual machines.&#13;
The theory here is that all 16 virtual machines are unlikely to be busy at&#13;
the same time; as long as only half of them are busy, there will be enough&#13;
physical cores to satisfy them. If too many of them are busy, though, they&#13;
will compete for CPU cycles, and their performance will suffer.</p>&#13;
&#13;
<p>Similarly, cloud vendors can choose to throttle the CPU used by a virtual&#13;
machine: they may allow the virtual machine to run bursts during which it consumes&#13;
the CPU it is allocated, but not to maintain that usage over time. This is&#13;
frequently seen in free or trial offerings, where you have a different&#13;
expectation of performance.</p>&#13;
&#13;
<p>These things obviously affect performance a great deal, but the effect isn’t&#13;
limited to Java, nor does it impact Java any differently than anything else&#13;
running in the virtual machine.</p>&#13;
</div></aside>&#13;
&#13;
<p>By default, a Docker container is free to use all of the machine’s resources:&#13;
it can use all the available CPUs and all the available memory on the machine.&#13;
That’s fine if we want to use Docker merely to streamline deployment of our&#13;
single application on&#13;
the machine (and hence the machine will run only that Docker container).&#13;
But frequently we want to deploy multiple Docker containers on a machine and&#13;
restrict the resources of each container. In effect, given our four-core&#13;
machine with 16 GB of memory, we might want to run two Docker containers,&#13;
each with access to only two cores and 8 GB of memory.</p>&#13;
&#13;
<p>Configuring Docker to do that is simple enough, but complications can arise&#13;
at the Java level. Numerous Java resources are configured&#13;
automatically (or ergonomically) based on the size of the machine running the&#13;
JVM. This includes the default heap size and the number of&#13;
threads used by the garbage collector, explained in detail in <a data-type="xref" href="ch05.html#GC">Chapter 5</a>,&#13;
and some thread pool settings, mentioned in <a data-type="xref" href="ch09.html#ThreadPerformance">Chapter 9</a>.</p>&#13;
&#13;
<p>If you are running a recent version of Java 8 (update version 192 or later) or&#13;
Java 11, the JVM handles this as you would hope: if you limit the Docker&#13;
container to use only two cores, the values set ergonomically based on the&#13;
CPU count of the machine will be based on the limit of the Docker&#13;
container.<sup><a data-type="noteref" href="ch01.html#idm45775551341432" id="idm45775551341432-marker">2</a></sup>&#13;
Similarly, heap and other settings that by default are based on the amount&#13;
of memory on a machine are based on any memory limit given to the Docker&#13;
container.</p>&#13;
&#13;
<p>In earlier versions of Java 8, the JVM has no knowledge&#13;
of any limits that the container will enforce: when it inspects the environment&#13;
to find out how much memory is available so it can calculate its&#13;
default heap size, it will see all the memory on the machine (instead of,&#13;
as we would prefer, the amount of memory the Docker container is allowed to&#13;
use). Similarly, when it checks how many CPUs are available to tune&#13;
the garbage collector, it will see all the CPUs on the machine, rather than&#13;
the number of CPUs assigned to the Docker container. As a result, the JVM&#13;
will run suboptimally: it will start too many threads&#13;
and will set up too large a heap. Having too many threads will lead to&#13;
some performance degradation, but the real issue here is the memory: the&#13;
maximum size of the heap will potentially be larger than the memory assigned&#13;
to the Docker container. When the heap grows to that size, the Docker&#13;
container (and hence the JVM) will be killed.</p>&#13;
&#13;
<p>In early Java 8 versions, you can set the appropriate values for the memory&#13;
and CPU usage by hand. As we come across those tunings, I’ll point out the&#13;
ones that will need to be adjusted for this situation, but it is better simply&#13;
to upgrade to a later Java 8 version (or Java 11).</p>&#13;
&#13;
<p>Docker containers provide one additional challenge to Java: Java comes with&#13;
a rich set of tools for diagnosing performance issues. These are&#13;
often not available in a Docker container. We’ll look at that issue a little&#13;
more in <a data-type="xref" href="ch03.html#Tools">Chapter 3</a>.<a data-startref="ix_ch01-asciidoc1" data-type="indexterm" id="idm45775551336856"/></p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="The Complete Performance Story" data-type="sect1"><div class="sect1" id="idm45775551335896">&#13;
<h1>The Complete Performance Story</h1>&#13;
&#13;
<p>This book is focused on how to best use the JVM and Java platform APIs&#13;
so that programs run faster, but many outside influences&#13;
affect performance. Those influences pop up from time to time in the&#13;
discussion, but because they are not specific to Java, they are not&#13;
necessarily discussed in detail. The performance of the JVM and the&#13;
Java platform is a small part of getting to fast performance.</p>&#13;
&#13;
<p>This section introduces the outside influences that are at least as important&#13;
as the Java tuning topics covered in this book. The Java knowledge-based&#13;
approach of this book complements these influences, but many of them are&#13;
beyond the scope of what we’ll discuss.</p>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Write Better Algorithms" data-type="sect2"><div class="sect2" id="idm45775551436824">&#13;
<h2>Write Better Algorithms</h2>&#13;
&#13;
<p>Many details about Java affect the performance&#13;
of an application, and a lot of tuning flags are discussed.&#13;
But there is no magical&#13;
<span class="keep-together"><code>-XX:+RunReallyFast</code></span>&#13;
option.</p>&#13;
&#13;
<p>Ultimately, the performance of an application is based on how well it&#13;
is written. If the program loops through all elements in an array, the&#13;
JVM will optimize the way it performs bounds checking of the array so that the loop runs faster,&#13;
and it may unroll the loop operations to provide an additional speedup. But&#13;
if the purpose of the loop is to find a specific item, no <span class="keep-together">optimization</span>&#13;
in the world is going to make the array-based code as fast as a different&#13;
version that uses a hash map.</p>&#13;
&#13;
<p>A good algorithm is the most important thing when it comes to fast&#13;
performance.</p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Write Less Code" data-type="sect2"><div class="sect2" id="idm45775551432216">&#13;
<h2>Write Less Code</h2>&#13;
&#13;
<p>Some of us write programs for money, some for fun, some to give back to&#13;
a community, but all of us write programs (or work on teams that write&#13;
programs). It is hard to feel like you’re making a contribution to a project&#13;
by pruning code, and some managers&#13;
still evaluate developers by the amount of code they write.</p>&#13;
&#13;
<p>I get that, but the conflict here is that a small well-written program will&#13;
run faster than a large well-written program. This is generally true for&#13;
all computer programs, and it applies specifically to Java programs. The&#13;
more code that has to be compiled, the longer it will take until that code&#13;
runs quickly. The more objects that have to be allocated and discarded,&#13;
the more work the garbage collector has to do. The more objects that are&#13;
allocated and retained, the longer a GC cycle will take.&#13;
The more classes that have to be loaded from disk into the JVM, the longer&#13;
it will take for a program to start. The more code that is&#13;
executed, the less likely that&#13;
it will fit in the hardware caches on the machine.&#13;
And the more code that has to be&#13;
executed, the longer that execution will take.</p>&#13;
&#13;
<p>I think of this as the “death by 1,000 cuts” principle. Developers will&#13;
argue that they are just adding a very small feature and it will take no time at all (especially if the feature isn’t used). And then other developers on the same project make the same claim, and suddenly the&#13;
performance has regressed by a few percent. The cycle is repeated in the next release, and now program performance has regressed by 10%. A couple of times during the process, performance testing may hit a certain resource threshold—a critical point in memory use, a code cache overflow, or something like that. In those cases, regular performance tests will catch that particular condition, and the performance team can fix what appears to be a major regression. But over time, as the small regressions creep in, it will be harder and harder to fix them.</p>&#13;
<aside class="less_space pagebreak-before" data-type="sidebar" epub:type="sidebar"><div class="sidebar" id="idm45775551393096">&#13;
<h5>We Will Ultimately Lose the War</h5>&#13;
<p>One aspect of performance that can be counterintuitive (and&#13;
depressing) is&#13;
that the performance&#13;
of every application can be expected to decrease over time—meaning&#13;
over new release cycles&#13;
of the application. Often, that performance difference is not noticed,&#13;
because hardware improvements make it possible to run the new programs at&#13;
acceptable speeds.</p>&#13;
&#13;
<p>Think what it would be like to run the Windows 10 interface on the same&#13;
computer that used to run Windows 95. My favorite computer ever was a Mac&#13;
Quadra 950, but it couldn’t run macOS Sierra (and it if did, it would be so&#13;
very, very slow compared to Mac OS 7.5). On a smaller level, it may seem&#13;
that Firefox 69.0 is faster than earlier versions, but those are&#13;
essentially minor&#13;
release versions. With its tabbed browsing and synced scrolling and&#13;
security features, Firefox is far more powerful than Mosaic ever was, but&#13;
Mosaic can load basic HTML files located on my hard disk about 50% faster&#13;
than Firefox 69.0.</p>&#13;
&#13;
<p>Of course, Mosaic cannot load actual URLs from almost any&#13;
popular website; it is no longer possible to use Mosaic as&#13;
a primary browser. That is also part of the general point here:&#13;
particularly between minor releases, code may be optimized and run faster.&#13;
As performance engineers, that’s what we can focus on, and if we are good&#13;
at our job, we can win the battle.</p>&#13;
&#13;
<p>That is a good and valuable thing;&#13;
my argument isn’t that we shouldn’t work to improve the performance of&#13;
existing applications. But the irony remains: as new features are added and new standards&#13;
adopted—which&#13;
is a requirement to match competing programs—programs can be expected&#13;
to get larger and slower.</p>&#13;
</div></aside>&#13;
&#13;
<p>I’m not advocating that you should never add a new feature or new code&#13;
to your product; clearly benefits result from enhancing programs. But&#13;
be aware of the trade-offs you are making, and when you can, streamline.</p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Oh, Go Ahead, Prematurely Optimize" data-type="sect2"><div class="sect2" id="idm45775551382904">&#13;
<h2>Oh, Go Ahead, Prematurely Optimize</h2>&#13;
&#13;
<p><a data-primary="optimization" data-secondary="premature" data-type="indexterm" id="idm45775551381464"/><a data-primary="premature optimization" data-type="indexterm" id="idm45775551380488"/>Donald Knuth is widely credited with coining the term <em>premature&#13;
optimization,</em> which is often used by developers to claim&#13;
that the performance of their code doesn’t matter, and&#13;
if it does matter, we won’t know that until the code is run. The full quote, if you’ve never come across it, is “We should forget about small&#13;
efficiencies, say about 97% of the time; premature optimization is the&#13;
root of all&#13;
evil.”<sup><a data-type="noteref" href="ch01.html#idm45775551378952" id="idm45775551378952-marker">3</a></sup></p>&#13;
&#13;
<p>The point of this dictum is that in the end, you should write clean,&#13;
straightforward code that is simple to read and understand.&#13;
In this context, <em>optimizing</em> is understood to mean employing&#13;
algorithmic and design&#13;
changes that complicate program structure but provide better performance.&#13;
Those kinds of optimizations indeed are best left undone until such time as the&#13;
profiling of a program shows that a large benefit is gained from performing&#13;
them.</p>&#13;
&#13;
<p>What optimization does not mean in this context, however, is&#13;
avoiding code constructs that&#13;
are known to be bad for performance. Every line of code involves&#13;
a choice, and if you have a choice between two simple, straightforward ways&#13;
of programming, choose the better-performing one.</p>&#13;
&#13;
<p>At one level, this is well understood by experienced Java developers (it&#13;
is an example of their art, as they have learned it over time).&#13;
Consider this code:</p>&#13;
&#13;
<pre data-code-language="java" data-type="programlisting"><code class="n">log</code><code class="o">.</code><code class="na">log</code><code class="o">(</code><code class="n">Level</code><code class="o">.</code><code class="na">FINE</code><code class="o">,</code> <code class="s">"I am here, and the value of X is "</code>&#13;
        <code class="o">+</code> <code class="n">calcX</code><code class="o">()</code> <code class="o">+</code> <code class="s">" and Y is "</code> <code class="o">+</code> <code class="n">calcY</code><code class="o">());</code></pre>&#13;
&#13;
<p>This code does a string concatenation that is likely unnecessary, since&#13;
the message won’t be logged unless the logging level is set quite high.&#13;
If the message isn’t printed, unnecessary calls are also made&#13;
to the&#13;
<code class="keep-together">calcX()</code>&#13;
and&#13;
<code class="keep-together">calcY()</code>&#13;
methods. Experienced Java&#13;
developers&#13;
will reflexively reject&#13;
that; some IDEs will even flag the code and suggest it be&#13;
changed.  (Tools aren’t perfect, though: the NetBeans IDE will flag the string concatenation, but the suggested improvement retains the unneeded  method calls.)</p>&#13;
&#13;
<p>This logging code is better written like this:</p>&#13;
&#13;
<pre data-code-language="java" data-type="programlisting"><code class="k">if</code> <code class="o">(</code><code class="n">log</code><code class="o">.</code><code class="na">isLoggable</code><code class="o">(</code><code class="n">Level</code><code class="o">.</code><code class="na">FINE</code><code class="o">))</code> <code class="o">{</code>&#13;
    <code class="n">log</code><code class="o">.</code><code class="na">log</code><code class="o">(</code><code class="n">Level</code><code class="o">.</code><code class="na">FINE</code><code class="o">,</code>&#13;
            <code class="s">"I am here, and the value of X is {} and Y is {}"</code><code class="o">,</code>&#13;
            <code class="k">new</code> <code class="n">Object</code><code class="o">[]{</code><code class="n">calcX</code><code class="o">(),</code> <code class="n">calcY</code><code class="o">()});</code>&#13;
<code class="o">}</code></pre>&#13;
&#13;
<p>This avoids the string concatenation altogether (the message format isn’t&#13;
necessarily more efficient, but it is cleaner), and there are no method&#13;
calls or allocation of the object array unless logging has been enabled.</p>&#13;
&#13;
<p>Writing code in this way is still clean and easy to read; it&#13;
took no more effort than writing the original code. Well, OK, it required&#13;
a few more keystrokes and an extra line of logic. But it isn’t the type&#13;
of premature optimization that&#13;
should be avoided; it’s the kind of choice that good coders learn to make.</p>&#13;
&#13;
<p>Don’t let out-of-context dogma from pioneering heroes prevent you from&#13;
thinking about the code you are writing. You’ll see other examples of this throughout this book, including&#13;
in <a data-type="xref" href="ch09.html#ThreadPerformance">Chapter 9</a>, which&#13;
discusses the performance of a benign-looking loop construct to process&#13;
a vector of objects.</p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Look Elsewhere: The Database Is Always the Bottleneck" data-type="sect2"><div class="sect2" id="idm45775551382280">&#13;
<h2>Look Elsewhere: The Database Is Always the Bottleneck</h2>&#13;
&#13;
<p><a data-primary="databases" data-secondary="as bottleneck" data-type="indexterm" id="ix_ch01-asciidoc2"/>If you are developing standalone Java applications that use no external&#13;
resources, the performance of that application is (mostly) all that&#13;
matters. Once an external resource (a database, for example) is added,&#13;
the performance of both programs is important. And in a&#13;
distributed environment—say with a Java REST&#13;
server, a load balancer, a database, and a backend enterprise information&#13;
system—the performance of the Java server may be the least&#13;
of the performance issues.</p>&#13;
&#13;
<p>This is not a book about holistic system performance. In such an environment,&#13;
a structured approach must be taken toward all aspects of the system.&#13;
CPU usage, I/O latencies, and throughput of all parts of the system&#13;
must be measured and analyzed;&#13;
only then can we determine which component is causing the performance&#13;
bottleneck. Excellent resources are available on that subject, and&#13;
those approaches and tools are not specific to Java. I assume you’ve&#13;
done that analysis and determined that it is the Java component of your&#13;
environment that needs to be improved.</p>&#13;
<aside data-type="sidebar" epub:type="sidebar"><div class="sidebar" id="idm45775552003272">&#13;
<h5>Bugs and Performance Issues Aren’t Limited to the JVM</h5>&#13;
<p>The performance of the database is the example used in this section, but&#13;
any part of the environment may be the source of a performance&#13;
issue.</p>&#13;
&#13;
<p>I once had a customer that installed a new version of an&#13;
application server, and then testing showed that the requests sent to the server&#13;
took longer and longer over time. Applying Occam’s razor led me to consider all aspects of the application server that might&#13;
be causing the issue.</p>&#13;
&#13;
<p>After those were ruled out, the performance issue remained, and we had&#13;
no backend database to blame. The next most likely issue,&#13;
therefore, was the test harness, and profiling determined that the&#13;
load generator—Apache JMeter—was the source of the regression: it was&#13;
keeping every response in a list, and when a new response came in, it&#13;
processed&#13;
the entire list in order to calculate the 90th% response time&#13;
(if that term is unfamiliar, see <a data-type="xref" href="ch02.html#SampleApplications">Chapter 2</a>).</p>&#13;
&#13;
<p>Performance issues can be caused by any part of the entire system where&#13;
an application is deployed. Common case analysis says to consider the&#13;
newest part of the system first (which is often the application in the JVM),&#13;
but be prepared to look at every possible component of the environment.</p>&#13;
</div></aside>&#13;
&#13;
<p>On the other hand, don’t overlook that initial analysis. If the database&#13;
is the bottleneck (and here’s a hint: it is), tuning the Java&#13;
application accessing the database won’t help overall performance at all.&#13;
In fact, it might&#13;
be counterproductive. As a general rule, when load is increased into&#13;
a system that is overburdened, performance of that system gets&#13;
worse. If something is changed in the Java application that makes it&#13;
more efficient—which only increases the load on an already overloaded&#13;
database—overall performance may actually go down.&#13;
The danger is then reaching the incorrect <span class="keep-together">&#13;
conclusion</span> that the&#13;
particular JVM improvement shouldn’t be used.</p>&#13;
&#13;
<p>This principle—that increasing load to a component in a system&#13;
that is performing badly&#13;
will make the entire system slower—isn’t confined to a database.&#13;
It applies when load is added to a server that is CPU-bound&#13;
or if more threads start accessing a lock that already has threads&#13;
waiting for it or any number of other scenarios.&#13;
An extreme example of this that involves only the JVM is shown in <a data-type="xref" href="ch09.html#ThreadPerformance">Chapter 9</a>.<a data-startref="ix_ch01-asciidoc2" data-type="indexterm" id="idm45775551654408"/></p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Optimize for the Common Case" data-type="sect2"><div class="sect2" id="idm45775551653576">&#13;
<h2>Optimize for the Common Case</h2>&#13;
&#13;
<p><a data-primary="optimization" data-secondary="focusing on common use scenarios" data-type="indexterm" id="idm45775551652440"/>It is tempting—particularly given the “death by 1,000 cuts” syndrome—to treat all performance aspects as equally important. But we should focus on the common use case scenarios. This principle manifests itself in several ways:</p>&#13;
&#13;
<ul>&#13;
<li>&#13;
<p>Optimize code by profiling it and focusing on the operations in the profile taking the most time. Note, however, that this does not mean looking at only the leaf methods in a profile (see <a data-type="xref" href="ch03.html#Tools">Chapter 3</a>).</p>&#13;
</li>&#13;
<li>&#13;
<p>Apply Occam’s razor to diagnosing performance problems. The simplest explanation for a performance issue is the most conceivable cause: a performance bug in new code is more likely than a configuration issue on a machine, which in turn is more likely than a bug in the JVM or operating system. Obscure OS or JVM bugs do exist, and as more credible causes for a performance issue are ruled out, it does become possible that somehow the test case in question has triggered such a latent bug. But don’t jump to the unlikely case first.</p>&#13;
</li>&#13;
<li>&#13;
<p>Write simple algorithms for the most common operations in an application. Say a program estimates a mathematical formula, and the user can choose whether to get an answer within a 10% margin of error or a 1% margin. If most users will be satisfied with the 10% margin, optimize that code path—even if it means slowing down the code that provides the 1% margin of error.</p>&#13;
</li>&#13;
</ul>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Summary" data-type="sect1"><div class="sect1" id="idm45775551645864">&#13;
<h1>Summary</h1>&#13;
&#13;
<p>Java has features and tools that make it possible&#13;
to get the best performance from a Java application. This book&#13;
will help you understand how best to use all the features of the JVM&#13;
in order to end up with fast-running programs.</p>&#13;
&#13;
<p>In many cases, though, remember that the JVM is a small part of the&#13;
overall performance picture. A systemic approach to&#13;
performance is required in Java environments where the&#13;
performance of databases and other backend systems is at least as important&#13;
as the performance of the JVM. That level of performance analysis is&#13;
not the focus of this book—it is assumed due diligence has been&#13;
performed to make sure that the Java component of the environment is the&#13;
important bottleneck in the system.</p>&#13;
&#13;
<p>However,&#13;
the interaction between the&#13;
JVM and other areas of the system is equally important—whether that&#13;
interaction is direct (e.g., the best way to make database calls) or indirect&#13;
(e.g., optimizing native memory usage of an application that shares a machine with several components of a large system). The information in this book should help solve&#13;
performance issues along those lines as well.<a data-primary="code compilation" data-see="just-in-time (JIT) compiler" data-type="indexterm" id="idm45775558857032"/><a data-primary="Concurrent Mark-Sweep (CMS)" data-see="CMS garbage collector" data-type="indexterm" id="idm45775558856088"/><a data-primary="garbage first garbage collector" data-see="G1 GC" data-type="indexterm" id="idm45775558855176"/><a data-primary="GC" data-see="garbage collection" data-type="indexterm" id="idm45775558854264"/><a data-primary="Java API for RESTful Web Services" data-see="JAX-RS" data-type="indexterm" id="idm45775558853320"/><a data-primary="Java Database Connectivity" data-see="JDBC" data-type="indexterm" id="idm45775558852408"/><a data-primary="Java Microbenchmark Harness (jmh)" data-see="jmh" data-type="indexterm" id="idm45775558851448"/><a data-primary="Java Persistence API" data-see="JPA" data-type="indexterm" id="idm45775558850488"/><a data-primary="JDK" data-see="Java Development Kit" data-type="indexterm" id="idm45775558849544"/><a data-primary="JFR" data-see="Java Flight Recorder" data-type="indexterm" id="idm45775558848600"/><a data-primary="JIT compiler" data-see="just-in-time compiler" data-type="indexterm" id="idm45775558847656"/><a data-primary="JVM" data-see="Java Virtual Machine" data-type="indexterm" id="idm45775558846712"/><a data-primary="memory" data-secondary="heap" data-see="heap memory" data-type="indexterm" id="idm45775558845768"/><a data-primary="memory" data-secondary="nonheap" data-see="native memory" data-type="indexterm" id="idm45775558857992"/><a data-primary="NMT" data-see="Native Memory Tracking" data-type="indexterm" id="idm45775558787368"/><a data-primary="nonheap memory" data-see="native memory" data-type="indexterm" id="idm45775558786424"/><a data-primary="operating system memory" data-see="native memory" data-type="indexterm" id="idm45775558785480"/><a data-primary="operating system tools/analysis" data-see="OS tools/analysis" data-type="indexterm" id="idm45775558784536"/><a data-primary="parallel garbage collector" data-see="throughput garbage collector" data-type="indexterm" id="idm45775558783576"/><a data-primary="removing unused" data-see="garbage collection" data-type="indexterm" id="idm45775558782600"/><a data-primary="searching for unused objects" data-see="garbage collection" data-type="indexterm" id="idm45775558781656"/><a data-primary="software containers" data-see="containers" data-type="indexterm" id="idm45775558780696"/><a data-primary="synchronization" data-see="thread synchronization" data-type="indexterm" id="idm45775558779752"/><a data-primary="threads" data-secondary="synchronization" data-see="thread synchronization" data-type="indexterm" id="idm45775558778808"/><a data-primary="tools" data-see="performance tools" data-type="indexterm" id="idm45775558777592"/><a data-primary="tuning flags" data-see="flags" data-type="indexterm" id="idm45775558776648"/></p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<div data-type="footnotes"><p data-type="footnote" id="idm45775551886680"><sup><a href="ch01.html#idm45775551886680-marker">1</a></sup> Rarely, differences between the two exist; for example, the AdoptOpenJDK versions of Java contain new garbage collectors in JDK 11. I’ll point out those differences when they occur.</p><p data-type="footnote" id="idm45775551341432"><sup><a href="ch01.html#idm45775551341432-marker">2</a></sup> You can specify fractional values for CPU limits in Docker. Java rounds up all fractional values to the next highest integer.</p><p data-type="footnote" id="idm45775551378952"><sup><a href="ch01.html#idm45775551378952-marker">3</a></sup> There is some dispute over who said this originally, Donald Knuth or Topy Hoare, but it appears in an article by Knuth entitled “Structured Programming with <code>goto</code> Statements.” And in context, it is an argument <em>for</em> optimizing code, even if it requires inelegant solutions like a <code>goto</code> statement.</p></div></div></section></body></html>