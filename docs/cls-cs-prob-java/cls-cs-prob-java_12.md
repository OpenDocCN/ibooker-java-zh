# 附录 A 术语表

本附录定义了本书中的一些关键术语。

激活函数 一种将 *人工神经网络* 中 *神经元* 的输出进行转换的函数，通常是为了使其能够处理非线性转换，或者确保其输出值在某个范围内（第七章）。

无环的 没有环的 *图*（第四章）。

可接受启发式 A* 搜索算法的 *启发式*，它从不高估达到目标成本（第二章）。

人工神经网络 使用计算工具模拟生物 *神经网络* 以解决难以用传统算法方法简化的问题的模拟。请注意，*人工神经网络* 的操作通常与其生物对应物有显著差异（第七章）。

自动记忆化 在语言级别实现的 *记忆化* 版本，其中存储了没有副作用的功能调用的结果，以便在进一步的相同调用中进行查找（第一章）。

反向传播 一种用于根据一组具有已知正确输出的输入来训练 *神经网络* 权重的技术。使用偏导数来计算每个权重对实际结果和预期结果之间误差的“责任”。这些 *delta* 用于更新未来运行的权重（第七章）。

回溯法 在搜索问题中遇到障碍后，返回到较早的决策点（选择不同于上次追求的方向）（第三章）。

位串 一种数据结构，使用单个位存储一系列 1 和 0。这有时被称为 *位向量* 或 *位数组*（第一章）。

质心 在 *簇* 中的中心点。通常，该点的每个维度是该维度中其余点的平均值（第六章）。

染色体 在遗传算法中，*种群* 中的每个个体被称为 *染色体*（第五章）。

簇 见 *聚类*（第六章）。

聚类 一种 *无监督学习* 技术，将数据集划分为相关点的组，称为 *簇*（第六章）。

密码子 由三个 *核苷酸* 组成的组合，形成一种氨基酸（第二章）。

压缩 将数据（改变其形式）编码以占用更少的空间（第一章）。

连通的 一个图属性，表示从任何 *顶点* 到任何其他 *顶点* 都存在 *路径*（第四章）。

约束 为了解决约束满足问题，必须满足的要求（第三章）。

交叉 在遗传算法中，将 *种群* 中的个体结合以创建后代，这些后代是父母双方的混合体，并将成为下一 *代* 的一部分（第五章）。

CSV 一种文本交换格式，其中数据集的行值由逗号分隔，行本身通常由换行符分隔。*CSV* 代表 *comma-separated values*。CSV 是电子表格和数据库的常见导出格式（第七章）。

循环 在 *graph* 中访问相同 *vertex* 两次而不 *backtracking* 的 *path*（第四章）。

解压缩 反向过程 *compression*，将数据恢复到原始形式（第一章）。

深度学习 有点像流行语，深度学习可以指任何使用高级机器学习算法分析大数据的几种技术之一。最常见的是，深度学习指的是使用多层 *artificial neural networks* 来解决使用大数据集的问题（第七章）。

delta 代表一个 *neural network* 中权重预期值与其实际值之间差距的值。预期值是通过使用 *training* 数据和 *backpropagation* 确定的（第七章）。

digraph 看见 *directed graph*（第四章）。

有向图 也称为 *digraph*，有向图是一种 *graph*，其中 *edges* 只能单向遍历（第四章）。

范围 在约束满足问题中 *variable* 的可能值（第三章）。

动态规划 不是直接使用暴力方法一次性解决大问题，在动态规划中，问题被分解成更小的子问题，每个子问题更容易管理（第九章）。

边 在 *graph* 中两个 *vertices*（节点）之间的连接（第四章）。

独异或 看见 *XOR*（第一章）。

前馈 一种 *neural network* 类型，其中信号单向传播（第七章）。

适应度函数 评估问题潜在解决方案有效性的函数（第五章）。

生成 在遗传算法评估中的一轮；也用来指代一轮中活跃的 *population*（第五章）。

遗传编程 使用 *selection*、*crossover* 和 *mutation* 操作员修改自身以找到解决编程问题的程序，这些问题是非显而易见的（第五章）。

梯度下降 使用在 *backpropagation* 期间计算的 *deltas* 和 *learning rate* 修改 *artificial neural network* 权重的算法（第七章）。

图 一种抽象的数学结构，通过将问题划分为一组 *connected* 节点来模拟现实世界问题。节点被称为 *vertices*，连接被称为 *edges*（第四章）。

贪婪算法 一种算法，在任意决策点总是选择最佳即时选择，希望它能导致全局最优解（第四章）。

启发式 关于解决问题方式的直觉，指向正确的方向（第二章）。

隐藏层 在 *feed-forward artificial neural network* 中位于 *input layer* 和 *output layer* 之间的任何层（第七章）。

infinite loop 一个不会终止的循环（第一章）。

infinite recursion 一组递归调用，不会终止，而是继续进行额外的递归调用。类似于*无限循环*。通常是由于缺少基例（第一章）。

input layer 在前馈人工神经网络中的第一层，从某种外部实体接收其输入（第七章）。

learning rate 一个值，通常是一个常数，用于根据计算的*delta*调整在人工神经网络中修改权重的速率（第七章）。

memoization 一种技术，将计算任务的输出结果存储在内存中，以便稍后从内存中检索，从而节省重新创建相同结果所需的额外计算时间（第一章）。

minimum spanning tree 连接所有顶点的*生成树*，使用*边*的最小总权重（第四章）。

mutate 在遗传算法中，在个体被包含在下一代之前随机改变其某些属性（第五章）。

natural selection 通过适应良好的生物成功而适应不良的生物失败来实现的进化过程。在环境中有限的资源下，最适合利用这些资源的生物将生存并繁衍。在几代*之后*，这导致有助于生存的有益特征在*种群*中传播，因此被环境约束自然选择（第五章）。

neural network 由多个*神经元*组成的网络，它们协同处理信息。*神经元*通常被认为是组织在层中（第七章）。

neuron 一个单独的神经细胞，如人类大脑中的那些（第七章），或人工神经网络中最小的计算单元。

normalization 使不同类型的数据可比较的过程（第六章）。

NP-hard 属于一类问题，对于这类问题，没有已知的多项式时间算法可以解决（第九章）。

nucleotide DNA 四种碱基之一的一个实例：腺嘌呤（A）、胞嘧啶（C）、鸟嘌呤（G）和胸腺嘧啶（T）（第二章）。

output layer 在前馈人工神经网络中的最后一层，用于确定给定输入和问题的网络结果（第七章）。

path 在*图*中连接两个顶点的*边*集合（第四章）。

ply 在两人游戏中的一步（通常被认为是一次移动）（第八章）。

population 在遗传算法中，种群是代表问题潜在解决方案的个体的集合（每个个体都代表问题的一个潜在解决方案），它们竞争解决问题（第五章）。

priority queue 一种基于“优先级”排序的数据结构，根据优先级弹出项目。例如，可以使用优先队列与紧急呼叫集合一起使用，以便首先响应优先级最高的呼叫（第二章）。

队列 一种强制执行 FIFO（先进先出）顺序的抽象数据结构。队列实现至少提供 push 和 pop 操作，分别用于添加和删除元素（第二章）。

递归函数 一种调用自身的函数（第一章）。

选择 在遗传算法的 *一代* 中选择个体进行繁殖以创建下一代个体的过程（第五章）。

sigmoid 函数 在人工神经网络中常用的一组 *激活函数* 之一。同名的 sigmoid 函数总是返回介于 0 和 1 之间的值。它还有助于确保网络可以表示除了线性变换之外的结果（第七章）。

SIMD 指令 优化用于使用向量进行计算的微处理器指令，也有时称为向量指令。*SIMD* 代表 *单指令*，*多数据*（第七章）。

跨度树 连接图中每个 *顶点* 的 *树*（第四章）。

栈 一种强制执行 LIFO（后进先出）顺序的抽象数据结构。栈实现至少提供 push 和 pop 操作，分别用于添加和删除元素（第二章）。

监督学习 任何一种机器学习技术，其中算法通过使用外部资源以某种方式引导到正确的结果（第七章）。

突触 神经元之间的间隙，神经递质在此释放以允许电流传导。用通俗的话说，这些是神经元之间的连接（第七章）。

训练 一个阶段，其中 *人工神经网络* 通过使用已知正确输出的 *反向传播* 来调整其权重（第七章）。

树 任何两个顶点之间只有一条 *路径* 的 *图*。树是 *无环的*（第四章）。

无监督学习 任何一种不使用先验知识得出结论的机器学习技术——换句话说，一种不是受指导而是自行运行的技术（第六章）。

变量 在约束满足问题的上下文中，变量是作为问题解决方案的一部分必须解决的某些参数。变量的可能值是其 *域*。解决方案的要求是一或多个 *约束*（第三章）。

顶点 图中的一个单个节点（第四章）。

XOR 一种逻辑位运算，当其任一操作数为真时返回真，但两个操作数都为真或都为假时不返回真。该缩写代表 *排他性* *或*。在 Java 中，^ 运算符用于 XOR（第一章）。

z 分数 数据点与数据集平均值的标准差数（第六章）。
